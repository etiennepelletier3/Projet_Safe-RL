{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./ppo_tb/PPO_6\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -0.0361  |\n",
      "| time/              |          |\n",
      "|    fps             | 733      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chaos/miniconda3/envs/safe_rl/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=10000, episode_reward=-26.77 +/- 2.07\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | -26.8       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004337332 |\n",
      "|    clip_fraction        | 0.021       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | -9.75       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00613     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00221    |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 0.0478      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -0.14    |\n",
      "| time/              |          |\n",
      "|    fps             | 585      |\n",
      "|    iterations      | 2        |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 16384    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-27.78 +/- 0.63\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | -27.8        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 20000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043371115 |\n",
      "|    clip_fraction        | 0.00776      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | -0.574       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00466      |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00132     |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 0.0195       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -0.189   |\n",
      "| time/              |          |\n",
      "|    fps             | 555      |\n",
      "|    iterations      | 3        |\n",
      "|    time_elapsed    | 44       |\n",
      "|    total_timesteps | 24576    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-9.82 +/- 1.08\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | -9.82        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 30000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028500862 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | -0.882       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00402      |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.000855    |\n",
      "|    std                  | 0.991        |\n",
      "|    value_loss           | 0.014        |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -0.249   |\n",
      "| time/              |          |\n",
      "|    fps             | 542      |\n",
      "|    iterations      | 4        |\n",
      "|    time_elapsed    | 60       |\n",
      "|    total_timesteps | 32768    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-2.42 +/- 1.58\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | -2.42        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 40000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041593304 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | -0.359       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00304      |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 0.00947      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -0.0949  |\n",
      "| time/              |          |\n",
      "|    fps             | 534      |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 76       |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -0.0887      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 562          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 87           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045744795 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | -0.325       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.003        |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00155     |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 0.0132       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-0.33 +/- 0.40\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | -0.334       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 50000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037205967 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | -0.954       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00108     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00164     |\n",
      "|    std                  | 0.989        |\n",
      "|    value_loss           | 0.00829      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -0.15    |\n",
      "| time/              |          |\n",
      "|    fps             | 554      |\n",
      "|    iterations      | 7        |\n",
      "|    time_elapsed    | 103      |\n",
      "|    total_timesteps | 57344    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-21.16 +/- 3.16\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | -21.2        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 60000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040732194 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | -0.664       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.000625     |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00141     |\n",
      "|    std                  | 0.988        |\n",
      "|    value_loss           | 0.00753      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -0.0643  |\n",
      "| time/              |          |\n",
      "|    fps             | 547      |\n",
      "|    iterations      | 8        |\n",
      "|    time_elapsed    | 119      |\n",
      "|    total_timesteps | 65536    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-26.91 +/- 0.72\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | -26.9        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 70000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011907689 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | -0.738       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00268      |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.000681    |\n",
      "|    std                  | 0.986        |\n",
      "|    value_loss           | 0.00853      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -0.0325  |\n",
      "| time/              |          |\n",
      "|    fps             | 542      |\n",
      "|    iterations      | 9        |\n",
      "|    time_elapsed    | 135      |\n",
      "|    total_timesteps | 73728    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-28.60 +/- 0.43\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | -28.6        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025316407 |\n",
      "|    clip_fraction        | 0.0024       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.8         |\n",
      "|    explained_variance   | -0.326       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00287      |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00104     |\n",
      "|    std                  | 0.981        |\n",
      "|    value_loss           | 0.00846      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -0.0331  |\n",
      "| time/              |          |\n",
      "|    fps             | 538      |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 152      |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=-26.85 +/- 1.05\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | -26.8       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 90000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004518569 |\n",
      "|    clip_fraction        | 0.0375      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | -0.585      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0012     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    std                  | 0.98        |\n",
      "|    value_loss           | 0.00698     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 0.0682   |\n",
      "| time/              |          |\n",
      "|    fps             | 533      |\n",
      "|    iterations      | 11       |\n",
      "|    time_elapsed    | 168      |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 0.0898       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 549          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 178          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028892646 |\n",
      "|    clip_fraction        | 0.00459      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.8         |\n",
      "|    explained_variance   | -0.395       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00145      |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00143     |\n",
      "|    std                  | 0.979        |\n",
      "|    value_loss           | 0.00873      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=-28.04 +/- 0.91\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | -28          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 100000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034907856 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.8         |\n",
      "|    explained_variance   | -0.92        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -5.11e-05    |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    std                  | 0.979        |\n",
      "|    value_loss           | 0.00514      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 0.0888   |\n",
      "| time/              |          |\n",
      "|    fps             | 545      |\n",
      "|    iterations      | 13       |\n",
      "|    time_elapsed    | 195      |\n",
      "|    total_timesteps | 106496   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=-28.09 +/- 0.86\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+03      |\n",
      "|    mean_reward          | -28.1      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 110000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00402264 |\n",
      "|    clip_fraction        | 0.0452     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.79      |\n",
      "|    explained_variance   | -1.57      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00401   |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.00405   |\n",
      "|    std                  | 0.978      |\n",
      "|    value_loss           | 0.00557    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 0.147    |\n",
      "| time/              |          |\n",
      "|    fps             | 542      |\n",
      "|    iterations      | 14       |\n",
      "|    time_elapsed    | 211      |\n",
      "|    total_timesteps | 114688   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-27.48 +/- 1.42\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | -27.5        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 120000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025384077 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.79        |\n",
      "|    explained_variance   | -0.526       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.000763     |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    std                  | 0.977        |\n",
      "|    value_loss           | 0.00819      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 0.317    |\n",
      "| time/              |          |\n",
      "|    fps             | 539      |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 227      |\n",
      "|    total_timesteps | 122880   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=-27.29 +/- 1.09\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | -27.3        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 130000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024680411 |\n",
      "|    clip_fraction        | 0.0346       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.79        |\n",
      "|    explained_variance   | -0.592       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000588    |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    std                  | 0.976        |\n",
      "|    value_loss           | 0.00742      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 0.354    |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 16       |\n",
      "|    time_elapsed    | 244      |\n",
      "|    total_timesteps | 131072   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 0.409        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 546          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 254          |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032887843 |\n",
      "|    clip_fraction        | 0.0258       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.79        |\n",
      "|    explained_variance   | -0.764       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00161     |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    std                  | 0.974        |\n",
      "|    value_loss           | 0.00514      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=-27.89 +/- 1.24\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | -27.9        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 140000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031968765 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.79        |\n",
      "|    explained_variance   | -0.214       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00163      |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    std                  | 0.975        |\n",
      "|    value_loss           | 0.0106       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 0.541    |\n",
      "| time/              |          |\n",
      "|    fps             | 544      |\n",
      "|    iterations      | 18       |\n",
      "|    time_elapsed    | 270      |\n",
      "|    total_timesteps | 147456   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=-20.70 +/- 10.71\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | -20.7        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 150000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073678796 |\n",
      "|    clip_fraction        | 0.0346       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.78        |\n",
      "|    explained_variance   | -0.115       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000264    |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    std                  | 0.971        |\n",
      "|    value_loss           | 0.00932      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 0.665    |\n",
      "| time/              |          |\n",
      "|    fps             | 542      |\n",
      "|    iterations      | 19       |\n",
      "|    time_elapsed    | 287      |\n",
      "|    total_timesteps | 155648   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=-10.69 +/- 13.50\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | -10.7        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 160000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055265566 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.78        |\n",
      "|    explained_variance   | -0.0454      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00393     |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    std                  | 0.968        |\n",
      "|    value_loss           | 0.00985      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 0.942    |\n",
      "| time/              |          |\n",
      "|    fps             | 540      |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 303      |\n",
      "|    total_timesteps | 163840   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=-3.17 +/- 3.94\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | -3.17        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 170000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046193236 |\n",
      "|    clip_fraction        | 0.0616       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.77        |\n",
      "|    explained_variance   | 0.0767       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00182      |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    std                  | 0.966        |\n",
      "|    value_loss           | 0.0167       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.19     |\n",
      "| time/              |          |\n",
      "|    fps             | 537      |\n",
      "|    iterations      | 21       |\n",
      "|    time_elapsed    | 320      |\n",
      "|    total_timesteps | 172032   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=-6.74 +/- 1.47\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | -6.74        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 180000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017263534 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.77        |\n",
      "|    explained_variance   | 0.0845       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00175      |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00249     |\n",
      "|    std                  | 0.966        |\n",
      "|    value_loss           | 0.0141       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.56     |\n",
      "| time/              |          |\n",
      "|    fps             | 535      |\n",
      "|    iterations      | 22       |\n",
      "|    time_elapsed    | 336      |\n",
      "|    total_timesteps | 180224   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.92         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 543          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 346          |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028781565 |\n",
      "|    clip_fraction        | 0.0224       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.77        |\n",
      "|    explained_variance   | 0.0936       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00673      |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    std                  | 0.963        |\n",
      "|    value_loss           | 0.0209       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=190000, episode_reward=-10.23 +/- 9.10\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | -10.2       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 190000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005481588 |\n",
      "|    clip_fraction        | 0.0238      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.007       |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00271    |\n",
      "|    std                  | 0.962       |\n",
      "|    value_loss           | 0.0239      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.31     |\n",
      "| time/              |          |\n",
      "|    fps             | 541      |\n",
      "|    iterations      | 24       |\n",
      "|    time_elapsed    | 362      |\n",
      "|    total_timesteps | 196608   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=-6.98 +/- 10.39\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | -6.98       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 200000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005087306 |\n",
      "|    clip_fraction        | 0.0205      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00752     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    std                  | 0.962       |\n",
      "|    value_loss           | 0.0264      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.86     |\n",
      "| time/              |          |\n",
      "|    fps             | 540      |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 379      |\n",
      "|    total_timesteps | 204800   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=-6.72 +/- 13.90\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | -6.72        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 210000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043519777 |\n",
      "|    clip_fraction        | 0.028        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.76        |\n",
      "|    explained_variance   | 0.367        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00806      |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    std                  | 0.959        |\n",
      "|    value_loss           | 0.0284       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 3.43     |\n",
      "| time/              |          |\n",
      "|    fps             | 538      |\n",
      "|    iterations      | 26       |\n",
      "|    time_elapsed    | 395      |\n",
      "|    total_timesteps | 212992   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=-1.09 +/- 8.82\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | -1.09       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 220000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006159896 |\n",
      "|    clip_fraction        | 0.0328      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0111      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00318    |\n",
      "|    std                  | 0.956       |\n",
      "|    value_loss           | 0.0332      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 3.96     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 27       |\n",
      "|    time_elapsed    | 412      |\n",
      "|    total_timesteps | 221184   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 4.51         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 543          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 422          |\n",
      "|    total_timesteps      | 229376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038593856 |\n",
      "|    clip_fraction        | 0.0239       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.74        |\n",
      "|    explained_variance   | 0.313        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00776      |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    std                  | 0.952        |\n",
      "|    value_loss           | 0.0296       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=7.18 +/- 3.93\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 7.18         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 230000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032406556 |\n",
      "|    clip_fraction        | 0.0457       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.73        |\n",
      "|    explained_variance   | 0.418        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0095       |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    std                  | 0.946        |\n",
      "|    value_loss           | 0.0297       |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 5.35     |\n",
      "| time/              |          |\n",
      "|    fps             | 541      |\n",
      "|    iterations      | 29       |\n",
      "|    time_elapsed    | 438      |\n",
      "|    total_timesteps | 237568   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=11.54 +/- 4.51\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 11.5        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 240000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005461791 |\n",
      "|    clip_fraction        | 0.0401      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.72       |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00856     |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00387    |\n",
      "|    std                  | 0.94        |\n",
      "|    value_loss           | 0.0369      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 5.9      |\n",
      "| time/              |          |\n",
      "|    fps             | 540      |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 454      |\n",
      "|    total_timesteps | 245760   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=12.11 +/- 3.37\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 12.1         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 250000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041748947 |\n",
      "|    clip_fraction        | 0.0423       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.71        |\n",
      "|    explained_variance   | 0.555        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0106       |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    std                  | 0.937        |\n",
      "|    value_loss           | 0.0338       |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 6.75     |\n",
      "| time/              |          |\n",
      "|    fps             | 538      |\n",
      "|    iterations      | 31       |\n",
      "|    time_elapsed    | 471      |\n",
      "|    total_timesteps | 253952   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=11.24 +/- 7.13\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 11.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 260000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046538003 |\n",
      "|    clip_fraction        | 0.0363       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.71        |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0098       |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    std                  | 0.936        |\n",
      "|    value_loss           | 0.0385       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 7.44     |\n",
      "| time/              |          |\n",
      "|    fps             | 537      |\n",
      "|    iterations      | 32       |\n",
      "|    time_elapsed    | 488      |\n",
      "|    total_timesteps | 262144   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=270000, episode_reward=19.15 +/- 2.65\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 19.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 270000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005658893 |\n",
      "|    clip_fraction        | 0.0218      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.7        |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.013       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0037     |\n",
      "|    std                  | 0.933       |\n",
      "|    value_loss           | 0.0413      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 8.16     |\n",
      "| time/              |          |\n",
      "|    fps             | 535      |\n",
      "|    iterations      | 33       |\n",
      "|    time_elapsed    | 504      |\n",
      "|    total_timesteps | 270336   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 8.84         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 541          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 514          |\n",
      "|    total_timesteps      | 278528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046489895 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.7         |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0143       |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    std                  | 0.933        |\n",
      "|    value_loss           | 0.0408       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=19.13 +/- 1.79\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 19.1         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 280000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052951425 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.7         |\n",
      "|    explained_variance   | 0.453        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0172       |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    std                  | 0.929        |\n",
      "|    value_loss           | 0.0481       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 9.43     |\n",
      "| time/              |          |\n",
      "|    fps             | 540      |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 530      |\n",
      "|    total_timesteps | 286720   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=290000, episode_reward=18.16 +/- 2.18\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 18.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 290000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052020326 |\n",
      "|    clip_fraction        | 0.0336       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.69        |\n",
      "|    explained_variance   | 0.371        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0128       |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    std                  | 0.924        |\n",
      "|    value_loss           | 0.0435       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 10.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 539      |\n",
      "|    iterations      | 36       |\n",
      "|    time_elapsed    | 547      |\n",
      "|    total_timesteps | 294912   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=17.25 +/- 5.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 17.3         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 300000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027947444 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.68        |\n",
      "|    explained_variance   | 0.485        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0139       |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    std                  | 0.921        |\n",
      "|    value_loss           | 0.0426       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 10.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 537      |\n",
      "|    iterations      | 37       |\n",
      "|    time_elapsed    | 563      |\n",
      "|    total_timesteps | 303104   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=310000, episode_reward=19.83 +/- 1.56\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+03      |\n",
      "|    mean_reward          | 19.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 310000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00523631 |\n",
      "|    clip_fraction        | 0.0336     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.67      |\n",
      "|    explained_variance   | 0.48       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0153     |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.00356   |\n",
      "|    std                  | 0.916      |\n",
      "|    value_loss           | 0.0459     |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 11.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 38       |\n",
      "|    time_elapsed    | 580      |\n",
      "|    total_timesteps | 311296   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 12.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 541          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 590          |\n",
      "|    total_timesteps      | 319488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034481147 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.66        |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0151       |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    std                  | 0.912        |\n",
      "|    value_loss           | 0.0455       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=18.43 +/- 1.43\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 18.4         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 320000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034331859 |\n",
      "|    clip_fraction        | 0.0265       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.65        |\n",
      "|    explained_variance   | 0.487        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.014        |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    std                  | 0.91         |\n",
      "|    value_loss           | 0.0436       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 12.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 540      |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 606      |\n",
      "|    total_timesteps | 327680   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=330000, episode_reward=19.93 +/- 0.40\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 19.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 330000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032885666 |\n",
      "|    clip_fraction        | 0.0296       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.64        |\n",
      "|    explained_variance   | 0.56         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0122       |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    std                  | 0.906        |\n",
      "|    value_loss           | 0.0378       |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 13.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 539      |\n",
      "|    iterations      | 41       |\n",
      "|    time_elapsed    | 622      |\n",
      "|    total_timesteps | 335872   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=340000, episode_reward=18.42 +/- 0.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 18.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 340000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003939902 |\n",
      "|    clip_fraction        | 0.0322      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.64       |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.014       |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00391    |\n",
      "|    std                  | 0.902       |\n",
      "|    value_loss           | 0.0399      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 14.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 537      |\n",
      "|    iterations      | 42       |\n",
      "|    time_elapsed    | 639      |\n",
      "|    total_timesteps | 344064   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=19.21 +/- 2.62\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 19.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 350000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026288605 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.63        |\n",
      "|    explained_variance   | 0.593        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00807      |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    std                  | 0.898        |\n",
      "|    value_loss           | 0.0363       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 14.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 43       |\n",
      "|    time_elapsed    | 656      |\n",
      "|    total_timesteps | 352256   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=19.91 +/- 1.77\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 19.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 360000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037796989 |\n",
      "|    clip_fraction        | 0.0413       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.62        |\n",
      "|    explained_variance   | 0.597        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00801      |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    std                  | 0.895        |\n",
      "|    value_loss           | 0.0354       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 15       |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 672      |\n",
      "|    total_timesteps | 360448   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 15.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 540          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 682          |\n",
      "|    total_timesteps      | 368640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031365848 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.61        |\n",
      "|    explained_variance   | 0.67         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00782      |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    std                  | 0.891        |\n",
      "|    value_loss           | 0.0319       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=370000, episode_reward=20.32 +/- 0.93\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 20.3        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 370000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005344484 |\n",
      "|    clip_fraction        | 0.0278      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.6        |\n",
      "|    explained_variance   | 0.67        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0106      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00373    |\n",
      "|    std                  | 0.888       |\n",
      "|    value_loss           | 0.0343      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 15.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 539      |\n",
      "|    iterations      | 46       |\n",
      "|    time_elapsed    | 698      |\n",
      "|    total_timesteps | 376832   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=380000, episode_reward=20.30 +/- 1.13\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 20.3         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 380000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036111851 |\n",
      "|    clip_fraction        | 0.034        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.59        |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0121       |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    std                  | 0.882        |\n",
      "|    value_loss           | 0.0413       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 16.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 537      |\n",
      "|    iterations      | 47       |\n",
      "|    time_elapsed    | 715      |\n",
      "|    total_timesteps | 385024   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=390000, episode_reward=21.15 +/- 0.93\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 21.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 390000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041250014 |\n",
      "|    clip_fraction        | 0.0396       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.58        |\n",
      "|    explained_variance   | 0.52         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0104       |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    std                  | 0.881        |\n",
      "|    value_loss           | 0.0408       |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 16.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 537      |\n",
      "|    iterations      | 48       |\n",
      "|    time_elapsed    | 732      |\n",
      "|    total_timesteps | 393216   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=21.75 +/- 1.09\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 21.7         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 400000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038856748 |\n",
      "|    clip_fraction        | 0.0364       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.58        |\n",
      "|    explained_variance   | 0.658        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00696      |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    std                  | 0.877        |\n",
      "|    value_loss           | 0.0343       |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 16.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 748      |\n",
      "|    total_timesteps | 401408   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 17.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 539          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 758          |\n",
      "|    total_timesteps      | 409600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049563395 |\n",
      "|    clip_fraction        | 0.0335       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.57        |\n",
      "|    explained_variance   | 0.698        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.008        |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.00434     |\n",
      "|    std                  | 0.872        |\n",
      "|    value_loss           | 0.0317       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=410000, episode_reward=21.33 +/- 1.43\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 21.3         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 410000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035207402 |\n",
      "|    clip_fraction        | 0.0241       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.56        |\n",
      "|    explained_variance   | 0.733        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00635      |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.00433     |\n",
      "|    std                  | 0.869        |\n",
      "|    value_loss           | 0.0306       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 17.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 539      |\n",
      "|    iterations      | 51       |\n",
      "|    time_elapsed    | 774      |\n",
      "|    total_timesteps | 417792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=420000, episode_reward=19.99 +/- 1.46\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 20           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 420000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045366837 |\n",
      "|    clip_fraction        | 0.0422       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.55        |\n",
      "|    explained_variance   | 0.742        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0053       |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.00491     |\n",
      "|    std                  | 0.864        |\n",
      "|    value_loss           | 0.0308       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 17.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 538      |\n",
      "|    iterations      | 52       |\n",
      "|    time_elapsed    | 791      |\n",
      "|    total_timesteps | 425984   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=430000, episode_reward=21.79 +/- 1.23\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 21.8         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 430000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055347085 |\n",
      "|    clip_fraction        | 0.033        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.54        |\n",
      "|    explained_variance   | 0.716        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00708      |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    std                  | 0.86         |\n",
      "|    value_loss           | 0.0323       |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 17.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 537      |\n",
      "|    iterations      | 53       |\n",
      "|    time_elapsed    | 808      |\n",
      "|    total_timesteps | 434176   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=20.83 +/- 0.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 20.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 440000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005316832 |\n",
      "|    clip_fraction        | 0.0331      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.53       |\n",
      "|    explained_variance   | 0.776       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00431     |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0043     |\n",
      "|    std                  | 0.856       |\n",
      "|    value_loss           | 0.0252      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 18       |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 54       |\n",
      "|    time_elapsed    | 824      |\n",
      "|    total_timesteps | 442368   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=22.63 +/- 0.69\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 22.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 450000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039211623 |\n",
      "|    clip_fraction        | 0.026        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.52        |\n",
      "|    explained_variance   | 0.802        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00472      |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    std                  | 0.853        |\n",
      "|    value_loss           | 0.0244       |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 18.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 535      |\n",
      "|    iterations      | 55       |\n",
      "|    time_elapsed    | 840      |\n",
      "|    total_timesteps | 450560   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 18.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 539         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 850         |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004065814 |\n",
      "|    clip_fraction        | 0.0337      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.52       |\n",
      "|    explained_variance   | 0.805       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00431     |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    std                  | 0.85        |\n",
      "|    value_loss           | 0.0258      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=460000, episode_reward=21.34 +/- 1.13\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 21.3         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 460000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054824743 |\n",
      "|    clip_fraction        | 0.0347       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.51        |\n",
      "|    explained_variance   | 0.764        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00907      |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    std                  | 0.844        |\n",
      "|    value_loss           | 0.0319       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 19.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 538      |\n",
      "|    iterations      | 57       |\n",
      "|    time_elapsed    | 867      |\n",
      "|    total_timesteps | 466944   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=470000, episode_reward=22.13 +/- 1.10\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 22.1         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 470000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043423744 |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.49        |\n",
      "|    explained_variance   | 0.787        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00716      |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    std                  | 0.84         |\n",
      "|    value_loss           | 0.0301       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 19.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 537      |\n",
      "|    iterations      | 58       |\n",
      "|    time_elapsed    | 883      |\n",
      "|    total_timesteps | 475136   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=24.40 +/- 0.65\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 24.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 480000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005425877 |\n",
      "|    clip_fraction        | 0.0336      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.48       |\n",
      "|    explained_variance   | 0.78        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00607     |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.00435    |\n",
      "|    std                  | 0.838       |\n",
      "|    value_loss           | 0.0291      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 19.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 59       |\n",
      "|    time_elapsed    | 900      |\n",
      "|    total_timesteps | 483328   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=490000, episode_reward=21.88 +/- 2.77\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 21.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 490000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053198976 |\n",
      "|    clip_fraction        | 0.0381       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.48        |\n",
      "|    explained_variance   | 0.77         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00523      |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.0047      |\n",
      "|    std                  | 0.837        |\n",
      "|    value_loss           | 0.0295       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 19.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 60       |\n",
      "|    time_elapsed    | 916      |\n",
      "|    total_timesteps | 491520   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 20           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 539          |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 926          |\n",
      "|    total_timesteps      | 499712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059726164 |\n",
      "|    clip_fraction        | 0.0361       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.48        |\n",
      "|    explained_variance   | 0.784        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00765      |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    std                  | 0.833        |\n",
      "|    value_loss           | 0.029        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=500000, episode_reward=23.57 +/- 1.45\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 23.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 500000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054242536 |\n",
      "|    clip_fraction        | 0.0313       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.47        |\n",
      "|    explained_variance   | 0.822        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00247      |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.00492     |\n",
      "|    std                  | 0.832        |\n",
      "|    value_loss           | 0.0252       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 20.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 538      |\n",
      "|    iterations      | 62       |\n",
      "|    time_elapsed    | 942      |\n",
      "|    total_timesteps | 507904   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=510000, episode_reward=24.16 +/- 0.38\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 24.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 510000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004573595 |\n",
      "|    clip_fraction        | 0.026       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.46       |\n",
      "|    explained_variance   | 0.809       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00333     |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    std                  | 0.828       |\n",
      "|    value_loss           | 0.0261      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 20.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 537      |\n",
      "|    iterations      | 63       |\n",
      "|    time_elapsed    | 959      |\n",
      "|    total_timesteps | 516096   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=520000, episode_reward=24.14 +/- 1.02\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 24.1         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 520000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061073857 |\n",
      "|    clip_fraction        | 0.0412       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.46        |\n",
      "|    explained_variance   | 0.823        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00828      |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    std                  | 0.826        |\n",
      "|    value_loss           | 0.0268       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 20.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 537      |\n",
      "|    iterations      | 64       |\n",
      "|    time_elapsed    | 976      |\n",
      "|    total_timesteps | 524288   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=530000, episode_reward=25.68 +/- 1.08\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 25.7         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 530000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054951767 |\n",
      "|    clip_fraction        | 0.0308       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.45        |\n",
      "|    explained_variance   | 0.813        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00625      |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.00444     |\n",
      "|    std                  | 0.823        |\n",
      "|    value_loss           | 0.0296       |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 21.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 65       |\n",
      "|    time_elapsed    | 992      |\n",
      "|    total_timesteps | 532480   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=540000, episode_reward=23.15 +/- 1.96\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 23.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 540000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004785003 |\n",
      "|    clip_fraction        | 0.0389      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.44       |\n",
      "|    explained_variance   | 0.829       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00166     |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.00395    |\n",
      "|    std                  | 0.82        |\n",
      "|    value_loss           | 0.0221      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 21.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 535      |\n",
      "|    iterations      | 66       |\n",
      "|    time_elapsed    | 1008     |\n",
      "|    total_timesteps | 540672   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 21.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 538         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 1019        |\n",
      "|    total_timesteps      | 548864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003794818 |\n",
      "|    clip_fraction        | 0.017       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.44       |\n",
      "|    explained_variance   | 0.845       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00475     |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    std                  | 0.817       |\n",
      "|    value_loss           | 0.0223      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=550000, episode_reward=24.76 +/- 1.40\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 24.8         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 550000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046437364 |\n",
      "|    clip_fraction        | 0.0404       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.43        |\n",
      "|    explained_variance   | 0.828        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00231      |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.0044      |\n",
      "|    std                  | 0.814        |\n",
      "|    value_loss           | 0.0247       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 22.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 537      |\n",
      "|    iterations      | 68       |\n",
      "|    time_elapsed    | 1035     |\n",
      "|    total_timesteps | 557056   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=560000, episode_reward=23.47 +/- 1.83\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 23.5        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 560000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005329944 |\n",
      "|    clip_fraction        | 0.0382      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.42       |\n",
      "|    explained_variance   | 0.84        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00261     |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.00427    |\n",
      "|    std                  | 0.812       |\n",
      "|    value_loss           | 0.023       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 22.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 537      |\n",
      "|    iterations      | 69       |\n",
      "|    time_elapsed    | 1052     |\n",
      "|    total_timesteps | 565248   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=570000, episode_reward=25.06 +/- 1.19\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 25.1         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 570000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045173634 |\n",
      "|    clip_fraction        | 0.0395       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.42        |\n",
      "|    explained_variance   | 0.834        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00693      |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    std                  | 0.811        |\n",
      "|    value_loss           | 0.0245       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 22.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 70       |\n",
      "|    time_elapsed    | 1068     |\n",
      "|    total_timesteps | 573440   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=580000, episode_reward=25.23 +/- 0.78\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 25.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 580000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004087383 |\n",
      "|    clip_fraction        | 0.0511      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.41       |\n",
      "|    explained_variance   | 0.852       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0019      |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.00502    |\n",
      "|    std                  | 0.808       |\n",
      "|    value_loss           | 0.0218      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 22.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 71       |\n",
      "|    time_elapsed    | 1084     |\n",
      "|    total_timesteps | 581632   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 23           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 538          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 1095         |\n",
      "|    total_timesteps      | 589824       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048876884 |\n",
      "|    clip_fraction        | 0.0321       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.41        |\n",
      "|    explained_variance   | 0.854        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00492      |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    std                  | 0.805        |\n",
      "|    value_loss           | 0.0214       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=590000, episode_reward=25.16 +/- 1.67\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 25.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 590000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048008235 |\n",
      "|    clip_fraction        | 0.0398       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.4         |\n",
      "|    explained_variance   | 0.835        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00548      |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    std                  | 0.802        |\n",
      "|    value_loss           | 0.0261       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 23.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 537      |\n",
      "|    iterations      | 73       |\n",
      "|    time_elapsed    | 1111     |\n",
      "|    total_timesteps | 598016   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=25.13 +/- 1.24\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 25.1         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 600000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039106123 |\n",
      "|    clip_fraction        | 0.0541       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.39        |\n",
      "|    explained_variance   | 0.858        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000916    |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.00483     |\n",
      "|    std                  | 0.798        |\n",
      "|    value_loss           | 0.0183       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 23.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 537      |\n",
      "|    iterations      | 74       |\n",
      "|    time_elapsed    | 1128     |\n",
      "|    total_timesteps | 606208   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=610000, episode_reward=25.18 +/- 0.70\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 25.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 610000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004775597 |\n",
      "|    clip_fraction        | 0.0465      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.38       |\n",
      "|    explained_variance   | 0.843       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000309    |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.00542    |\n",
      "|    std                  | 0.796       |\n",
      "|    value_loss           | 0.0228      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 23.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 75       |\n",
      "|    time_elapsed    | 1144     |\n",
      "|    total_timesteps | 614400   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=620000, episode_reward=25.68 +/- 0.56\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 25.7         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 620000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035623768 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.38        |\n",
      "|    explained_variance   | 0.793        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00738      |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    std                  | 0.795        |\n",
      "|    value_loss           | 0.0273       |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 23.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 76       |\n",
      "|    time_elapsed    | 1160     |\n",
      "|    total_timesteps | 622592   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=630000, episode_reward=23.77 +/- 1.41\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1e+03     |\n",
      "|    mean_reward          | 23.8      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 630000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0036021 |\n",
      "|    clip_fraction        | 0.0305    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.38     |\n",
      "|    explained_variance   | 0.817     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00281   |\n",
      "|    n_updates            | 760       |\n",
      "|    policy_gradient_loss | -0.00442  |\n",
      "|    std                  | 0.793     |\n",
      "|    value_loss           | 0.0231    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 24       |\n",
      "| time/              |          |\n",
      "|    fps             | 535      |\n",
      "|    iterations      | 77       |\n",
      "|    time_elapsed    | 1177     |\n",
      "|    total_timesteps | 630784   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 24.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 538          |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 1187         |\n",
      "|    total_timesteps      | 638976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042354255 |\n",
      "|    clip_fraction        | 0.0331       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.37        |\n",
      "|    explained_variance   | 0.848        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00351      |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    std                  | 0.79         |\n",
      "|    value_loss           | 0.0216       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=26.76 +/- 1.03\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 26.8         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 640000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038342346 |\n",
      "|    clip_fraction        | 0.0252       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.36        |\n",
      "|    explained_variance   | 0.858        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00158      |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    std                  | 0.789        |\n",
      "|    value_loss           | 0.0202       |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 24.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 537      |\n",
      "|    iterations      | 79       |\n",
      "|    time_elapsed    | 1204     |\n",
      "|    total_timesteps | 647168   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=650000, episode_reward=25.93 +/- 1.06\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 25.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 650000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035985834 |\n",
      "|    clip_fraction        | 0.0231       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.36        |\n",
      "|    explained_variance   | 0.858        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00172      |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    std                  | 0.786        |\n",
      "|    value_loss           | 0.019        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 24.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 80       |\n",
      "|    time_elapsed    | 1220     |\n",
      "|    total_timesteps | 655360   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=660000, episode_reward=26.49 +/- 1.71\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 26.5        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 660000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005978329 |\n",
      "|    clip_fraction        | 0.0451      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.35       |\n",
      "|    explained_variance   | 0.859       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00216     |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    std                  | 0.784       |\n",
      "|    value_loss           | 0.0195      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 24.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 81       |\n",
      "|    time_elapsed    | 1237     |\n",
      "|    total_timesteps | 663552   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=670000, episode_reward=25.98 +/- 1.67\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 26          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 670000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004576396 |\n",
      "|    clip_fraction        | 0.0405      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.35       |\n",
      "|    explained_variance   | 0.849       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00163     |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.00316    |\n",
      "|    std                  | 0.783       |\n",
      "|    value_loss           | 0.0178      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 24.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 535      |\n",
      "|    iterations      | 82       |\n",
      "|    time_elapsed    | 1253     |\n",
      "|    total_timesteps | 671744   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 24.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 538          |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 1263         |\n",
      "|    total_timesteps      | 679936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031756815 |\n",
      "|    clip_fraction        | 0.0252       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.35        |\n",
      "|    explained_variance   | 0.853        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00374      |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    std                  | 0.782        |\n",
      "|    value_loss           | 0.0203       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=680000, episode_reward=26.15 +/- 1.26\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 26.1         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 680000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055164206 |\n",
      "|    clip_fraction        | 0.0368       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.34        |\n",
      "|    explained_variance   | 0.814        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00618      |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    std                  | 0.779        |\n",
      "|    value_loss           | 0.024        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 24.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 537      |\n",
      "|    iterations      | 84       |\n",
      "|    time_elapsed    | 1280     |\n",
      "|    total_timesteps | 688128   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=690000, episode_reward=25.28 +/- 1.70\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 25.3         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 690000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034340234 |\n",
      "|    clip_fraction        | 0.0385       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.33        |\n",
      "|    explained_variance   | 0.866        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00203      |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.00424     |\n",
      "|    std                  | 0.775        |\n",
      "|    value_loss           | 0.0169       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 24.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 85       |\n",
      "|    time_elapsed    | 1296     |\n",
      "|    total_timesteps | 696320   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=24.84 +/- 1.99\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 24.8         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 700000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042033223 |\n",
      "|    clip_fraction        | 0.0387       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.33        |\n",
      "|    explained_variance   | 0.853        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.000744     |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.00435     |\n",
      "|    std                  | 0.773        |\n",
      "|    value_loss           | 0.0172       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 24.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 86       |\n",
      "|    time_elapsed    | 1312     |\n",
      "|    total_timesteps | 704512   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=710000, episode_reward=25.42 +/- 1.59\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 25.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 710000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005200683 |\n",
      "|    clip_fraction        | 0.0469      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.32       |\n",
      "|    explained_variance   | 0.853       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00158     |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00403    |\n",
      "|    std                  | 0.772       |\n",
      "|    value_loss           | 0.0181      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 24.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 87       |\n",
      "|    time_elapsed    | 1329     |\n",
      "|    total_timesteps | 712704   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=720000, episode_reward=26.38 +/- 0.84\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 26.4         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 720000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051384615 |\n",
      "|    clip_fraction        | 0.0345       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.32        |\n",
      "|    explained_variance   | 0.865        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00131      |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    std                  | 0.772        |\n",
      "|    value_loss           | 0.0148       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 25       |\n",
      "| time/              |          |\n",
      "|    fps             | 535      |\n",
      "|    iterations      | 88       |\n",
      "|    time_elapsed    | 1345     |\n",
      "|    total_timesteps | 720896   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 25.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 537         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 1356        |\n",
      "|    total_timesteps      | 729088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005448199 |\n",
      "|    clip_fraction        | 0.0495      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.32       |\n",
      "|    explained_variance   | 0.846       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00329     |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.00465    |\n",
      "|    std                  | 0.769       |\n",
      "|    value_loss           | 0.0207      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=730000, episode_reward=25.72 +/- 1.43\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 25.7         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 730000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059956843 |\n",
      "|    clip_fraction        | 0.0472       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.31        |\n",
      "|    explained_variance   | 0.86         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00132      |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    std                  | 0.766        |\n",
      "|    value_loss           | 0.0168       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 25.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 537      |\n",
      "|    iterations      | 90       |\n",
      "|    time_elapsed    | 1372     |\n",
      "|    total_timesteps | 737280   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=740000, episode_reward=25.74 +/- 0.83\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 25.7         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 740000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042310935 |\n",
      "|    clip_fraction        | 0.0308       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.3         |\n",
      "|    explained_variance   | 0.877        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.000588     |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    std                  | 0.764        |\n",
      "|    value_loss           | 0.0168       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 25.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 91       |\n",
      "|    time_elapsed    | 1389     |\n",
      "|    total_timesteps | 745472   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=750000, episode_reward=26.16 +/- 1.25\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 26.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 750000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004421553 |\n",
      "|    clip_fraction        | 0.0399      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.3        |\n",
      "|    explained_variance   | 0.865       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -5.21e-05   |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.00468    |\n",
      "|    std                  | 0.764       |\n",
      "|    value_loss           | 0.0165      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 25.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 92       |\n",
      "|    time_elapsed    | 1405     |\n",
      "|    total_timesteps | 753664   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=760000, episode_reward=24.91 +/- 0.66\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 24.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 760000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043159556 |\n",
      "|    clip_fraction        | 0.0394       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.3         |\n",
      "|    explained_variance   | 0.846        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00223      |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    std                  | 0.762        |\n",
      "|    value_loss           | 0.019        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 25.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 535      |\n",
      "|    iterations      | 93       |\n",
      "|    time_elapsed    | 1421     |\n",
      "|    total_timesteps | 761856   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=770000, episode_reward=24.36 +/- 1.42\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 24.4         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 770000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050797034 |\n",
      "|    clip_fraction        | 0.0307       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.29        |\n",
      "|    explained_variance   | 0.875        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00172     |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    std                  | 0.76         |\n",
      "|    value_loss           | 0.0137       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 25.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 535      |\n",
      "|    iterations      | 94       |\n",
      "|    time_elapsed    | 1438     |\n",
      "|    total_timesteps | 770048   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 25.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 537          |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 1449         |\n",
      "|    total_timesteps      | 778240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053263395 |\n",
      "|    clip_fraction        | 0.0382       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.28        |\n",
      "|    explained_variance   | 0.857        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.000589     |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    std                  | 0.757        |\n",
      "|    value_loss           | 0.0176       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=780000, episode_reward=27.32 +/- 0.78\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 27.3         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 780000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048988927 |\n",
      "|    clip_fraction        | 0.0423       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.28        |\n",
      "|    explained_variance   | 0.875        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00191      |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    std                  | 0.755        |\n",
      "|    value_loss           | 0.0145       |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 25.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 96       |\n",
      "|    time_elapsed    | 1465     |\n",
      "|    total_timesteps | 786432   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=790000, episode_reward=26.13 +/- 1.26\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 26.1        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 790000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003861004 |\n",
      "|    clip_fraction        | 0.0292      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.27       |\n",
      "|    explained_variance   | 0.883       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000796   |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.00341    |\n",
      "|    std                  | 0.753       |\n",
      "|    value_loss           | 0.013       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 25.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 97       |\n",
      "|    time_elapsed    | 1481     |\n",
      "|    total_timesteps | 794624   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=26.00 +/- 1.02\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 26           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 800000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055137007 |\n",
      "|    clip_fraction        | 0.036        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.27        |\n",
      "|    explained_variance   | 0.853        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00082      |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.00442     |\n",
      "|    std                  | 0.749        |\n",
      "|    value_loss           | 0.0166       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 25.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 535      |\n",
      "|    iterations      | 98       |\n",
      "|    time_elapsed    | 1498     |\n",
      "|    total_timesteps | 802816   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=810000, episode_reward=26.64 +/- 1.18\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 26.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 810000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005093402 |\n",
      "|    clip_fraction        | 0.0277      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 0.871       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000542    |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.00287    |\n",
      "|    std                  | 0.745       |\n",
      "|    value_loss           | 0.0159      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 25.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 535      |\n",
      "|    iterations      | 99       |\n",
      "|    time_elapsed    | 1515     |\n",
      "|    total_timesteps | 811008   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 25.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 537         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 1525        |\n",
      "|    total_timesteps      | 819200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003966308 |\n",
      "|    clip_fraction        | 0.0351      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.24       |\n",
      "|    explained_variance   | 0.858       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00105    |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.00424    |\n",
      "|    std                  | 0.742       |\n",
      "|    value_loss           | 0.018       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=820000, episode_reward=25.36 +/- 0.85\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 25.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 820000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005946453 |\n",
      "|    clip_fraction        | 0.0347      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.24       |\n",
      "|    explained_variance   | 0.863       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00212     |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.00316    |\n",
      "|    std                  | 0.741       |\n",
      "|    value_loss           | 0.0157      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 25.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 101      |\n",
      "|    time_elapsed    | 1541     |\n",
      "|    total_timesteps | 827392   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=830000, episode_reward=26.00 +/- 1.03\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 26          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 830000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003920978 |\n",
      "|    clip_fraction        | 0.0263      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.24       |\n",
      "|    explained_variance   | 0.865       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000113    |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    std                  | 0.74        |\n",
      "|    value_loss           | 0.0152      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 25.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 102      |\n",
      "|    time_elapsed    | 1558     |\n",
      "|    total_timesteps | 835584   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=840000, episode_reward=26.37 +/- 1.31\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 26.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 840000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004341674 |\n",
      "|    clip_fraction        | 0.0334      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.23       |\n",
      "|    explained_variance   | 0.868       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00261    |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.00403    |\n",
      "|    std                  | 0.739       |\n",
      "|    value_loss           | 0.0138      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 25.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 535      |\n",
      "|    iterations      | 103      |\n",
      "|    time_elapsed    | 1574     |\n",
      "|    total_timesteps | 843776   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=850000, episode_reward=26.15 +/- 0.57\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 26.1         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 850000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048107365 |\n",
      "|    clip_fraction        | 0.0458       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.23        |\n",
      "|    explained_variance   | 0.856        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00038      |\n",
      "|    n_updates            | 1030         |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    std                  | 0.738        |\n",
      "|    value_loss           | 0.0172       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 25.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 535      |\n",
      "|    iterations      | 104      |\n",
      "|    time_elapsed    | 1590     |\n",
      "|    total_timesteps | 851968   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=860000, episode_reward=25.90 +/- 1.05\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 25.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 860000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004548189 |\n",
      "|    clip_fraction        | 0.0338      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.23       |\n",
      "|    explained_variance   | 0.859       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000903    |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    std                  | 0.736       |\n",
      "|    value_loss           | 0.0161      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 25.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 535      |\n",
      "|    iterations      | 105      |\n",
      "|    time_elapsed    | 1607     |\n",
      "|    total_timesteps | 860160   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 25.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 536         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 1617        |\n",
      "|    total_timesteps      | 868352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004008079 |\n",
      "|    clip_fraction        | 0.03        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.22       |\n",
      "|    explained_variance   | 0.875       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000905    |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.00339    |\n",
      "|    std                  | 0.735       |\n",
      "|    value_loss           | 0.0139      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=870000, episode_reward=25.67 +/- 1.10\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 25.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 870000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005776823 |\n",
      "|    clip_fraction        | 0.0574      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.22       |\n",
      "|    explained_variance   | 0.855       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00139    |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.0047     |\n",
      "|    std                  | 0.733       |\n",
      "|    value_loss           | 0.0155      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 25.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 107      |\n",
      "|    time_elapsed    | 1634     |\n",
      "|    total_timesteps | 876544   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=880000, episode_reward=25.95 +/- 1.12\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 26           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 880000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053797495 |\n",
      "|    clip_fraction        | 0.0365       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.21        |\n",
      "|    explained_variance   | 0.881        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00233     |\n",
      "|    n_updates            | 1070         |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    std                  | 0.731        |\n",
      "|    value_loss           | 0.014        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 25.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 108      |\n",
      "|    time_elapsed    | 1650     |\n",
      "|    total_timesteps | 884736   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=890000, episode_reward=26.21 +/- 1.11\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 26.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 890000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052971486 |\n",
      "|    clip_fraction        | 0.0513       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.21        |\n",
      "|    explained_variance   | 0.87         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00116     |\n",
      "|    n_updates            | 1080         |\n",
      "|    policy_gradient_loss | -0.00435     |\n",
      "|    std                  | 0.73         |\n",
      "|    value_loss           | 0.0148       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 25.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 535      |\n",
      "|    iterations      | 109      |\n",
      "|    time_elapsed    | 1666     |\n",
      "|    total_timesteps | 892928   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=900000, episode_reward=27.16 +/- 1.16\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 27.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 900000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003663806 |\n",
      "|    clip_fraction        | 0.0249      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.2        |\n",
      "|    explained_variance   | 0.869       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00123     |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.00352    |\n",
      "|    std                  | 0.727       |\n",
      "|    value_loss           | 0.0178      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 25.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 535      |\n",
      "|    iterations      | 110      |\n",
      "|    time_elapsed    | 1683     |\n",
      "|    total_timesteps | 901120   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 25.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 536         |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 1694        |\n",
      "|    total_timesteps      | 909312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004449929 |\n",
      "|    clip_fraction        | 0.0319      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.2        |\n",
      "|    explained_variance   | 0.869       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000193    |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.00378    |\n",
      "|    std                  | 0.724       |\n",
      "|    value_loss           | 0.0156      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=910000, episode_reward=26.66 +/- 1.29\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 26.7         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 910000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048824227 |\n",
      "|    clip_fraction        | 0.0355       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.19        |\n",
      "|    explained_variance   | 0.875        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00219     |\n",
      "|    n_updates            | 1110         |\n",
      "|    policy_gradient_loss | -0.00443     |\n",
      "|    std                  | 0.723        |\n",
      "|    value_loss           | 0.0146       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 25.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 112      |\n",
      "|    time_elapsed    | 1710     |\n",
      "|    total_timesteps | 917504   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=920000, episode_reward=25.92 +/- 1.51\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 25.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 920000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005107634 |\n",
      "|    clip_fraction        | 0.0536      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.19       |\n",
      "|    explained_variance   | 0.89        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00142    |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.00397    |\n",
      "|    std                  | 0.722       |\n",
      "|    value_loss           | 0.0123      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 25.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 113      |\n",
      "|    time_elapsed    | 1726     |\n",
      "|    total_timesteps | 925696   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=930000, episode_reward=26.30 +/- 1.28\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 26.3         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 930000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053683138 |\n",
      "|    clip_fraction        | 0.0344       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.18        |\n",
      "|    explained_variance   | 0.89         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00415     |\n",
      "|    n_updates            | 1130         |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    std                  | 0.72         |\n",
      "|    value_loss           | 0.0117       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 25.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 535      |\n",
      "|    iterations      | 114      |\n",
      "|    time_elapsed    | 1743     |\n",
      "|    total_timesteps | 933888   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=940000, episode_reward=25.57 +/- 0.74\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 25.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 940000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043261927 |\n",
      "|    clip_fraction        | 0.0557       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.18        |\n",
      "|    explained_variance   | 0.878        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000395    |\n",
      "|    n_updates            | 1140         |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    std                  | 0.718        |\n",
      "|    value_loss           | 0.0134       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 26       |\n",
      "| time/              |          |\n",
      "|    fps             | 535      |\n",
      "|    iterations      | 115      |\n",
      "|    time_elapsed    | 1760     |\n",
      "|    total_timesteps | 942080   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=950000, episode_reward=25.79 +/- 0.43\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 25.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 950000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004618396 |\n",
      "|    clip_fraction        | 0.0402      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.17       |\n",
      "|    explained_variance   | 0.899       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00331    |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    std                  | 0.716       |\n",
      "|    value_loss           | 0.00993     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 26.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 534      |\n",
      "|    iterations      | 116      |\n",
      "|    time_elapsed    | 1776     |\n",
      "|    total_timesteps | 950272   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 26.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 536         |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 1786        |\n",
      "|    total_timesteps      | 958464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005501439 |\n",
      "|    clip_fraction        | 0.0507      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.17       |\n",
      "|    explained_variance   | 0.86        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00138     |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    std                  | 0.713       |\n",
      "|    value_loss           | 0.0165      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=960000, episode_reward=26.72 +/- 1.47\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 26.7         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 960000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064331563 |\n",
      "|    clip_fraction        | 0.0432       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.16        |\n",
      "|    explained_variance   | 0.877        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.23e-05     |\n",
      "|    n_updates            | 1170         |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    std                  | 0.713        |\n",
      "|    value_loss           | 0.0132       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 26.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 118      |\n",
      "|    time_elapsed    | 1803     |\n",
      "|    total_timesteps | 966656   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=970000, episode_reward=26.36 +/- 0.93\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 26.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 970000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005278039 |\n",
      "|    clip_fraction        | 0.0485      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.16       |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00372    |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.00432    |\n",
      "|    std                  | 0.713       |\n",
      "|    value_loss           | 0.0118      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 26.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 535      |\n",
      "|    iterations      | 119      |\n",
      "|    time_elapsed    | 1819     |\n",
      "|    total_timesteps | 974848   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=980000, episode_reward=26.44 +/- 1.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 26.4         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 980000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055858116 |\n",
      "|    clip_fraction        | 0.0364       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.16        |\n",
      "|    explained_variance   | 0.868        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00124      |\n",
      "|    n_updates            | 1190         |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    std                  | 0.711        |\n",
      "|    value_loss           | 0.0147       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 26.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 535      |\n",
      "|    iterations      | 120      |\n",
      "|    time_elapsed    | 1836     |\n",
      "|    total_timesteps | 983040   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=990000, episode_reward=26.78 +/- 0.68\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 26.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 990000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004696855 |\n",
      "|    clip_fraction        | 0.0464      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.15       |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000789   |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.00412    |\n",
      "|    std                  | 0.708       |\n",
      "|    value_loss           | 0.0102      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 26.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 535      |\n",
      "|    iterations      | 121      |\n",
      "|    time_elapsed    | 1852     |\n",
      "|    total_timesteps | 991232   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 26.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 536        |\n",
      "|    iterations           | 122        |\n",
      "|    time_elapsed         | 1862       |\n",
      "|    total_timesteps      | 999424     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00628654 |\n",
      "|    clip_fraction        | 0.0577     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.15      |\n",
      "|    explained_variance   | 0.892      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00362   |\n",
      "|    n_updates            | 1210       |\n",
      "|    policy_gradient_loss | -0.00411   |\n",
      "|    std                  | 0.707      |\n",
      "|    value_loss           | 0.0112     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1000000, episode_reward=26.18 +/- 1.49\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 26.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051847813 |\n",
      "|    clip_fraction        | 0.0419       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.14        |\n",
      "|    explained_variance   | 0.859        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.000553     |\n",
      "|    n_updates            | 1220         |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    std                  | 0.704        |\n",
      "|    value_loss           | 0.016        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 26.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 123      |\n",
      "|    time_elapsed    | 1879     |\n",
      "|    total_timesteps | 1007616  |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import safety_gymnasium\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "\n",
    "ENV_ID = \"SafetyPointGoal1-v0\"     # tâche simple, contrainte de collision\n",
    "\n",
    "import gymnasium as gym\n",
    "import safety_gymnasium\n",
    "from safety_gymnasium.wrappers import SafetyGymnasium2Gymnasium\n",
    "\n",
    "def make_env():\n",
    "    safe_env = safety_gymnasium.make(\"SafetyPointGoal1-v0\", render_mode=None)\n",
    "    env = SafetyGymnasium2Gymnasium(safe_env)   # ⇨ API Gymnasium\n",
    "    return env\n",
    "if __name__ == \"__main__\":\n",
    "    train_env = make_env()\n",
    "    eval_env  = make_env()\n",
    "\n",
    "    model = PPO(\n",
    "        policy=\"MlpPolicy\",\n",
    "        env=train_env,\n",
    "        verbose=1,\n",
    "        tensorboard_log=\"./ppo/ppo_tb\",\n",
    "        batch_size=4096,\n",
    "        n_steps=8192,\n",
    "    )\n",
    "\n",
    "    eval_cb = EvalCallback(\n",
    "        eval_env,\n",
    "        eval_freq=10_000,\n",
    "        best_model_save_path=\"./ppo/ppo_best\",\n",
    "        log_path=\"./ppo/ppo_eval\",\n",
    "        deterministic=True,\n",
    "    )\n",
    "\n",
    "    model.learn(total_timesteps=1_000_000, callback=eval_cb)\n",
    "    model.save(\"ppo_safety_point_goal1\")\n",
    "\n",
    "    train_env.close(); eval_env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chaos/miniconda3/envs/safe_rl/lib/python3.10/site-packages/gymnasium/wrappers/record_video.py:87: UserWarning: \u001b[33mWARN: Overwriting existing videos at /home/chaos/Desktop/Projet_Safe-RL folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  saved → /home/chaos/Desktop/Projet_Safe-RL/ppo_rollout_3rd-episode-0.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"MUJOCO_GL\"] = \"egl\"           # or osmesa\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\"\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "import safety_gymnasium\n",
    "from safety_gymnasium.wrappers import SafetyGymnasium2Gymnasium\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "# --- 1. 3rd‑person env ----------------------------------------------------\n",
    "base_env = safety_gymnasium.make(\n",
    "    \"SafetyPointGoal1-v0\",\n",
    "    render_mode=\"rgb_array\",\n",
    "    camera_name=\"track\",          # <‑‑ HERE: 3rd‑person chase camera\n",
    ")\n",
    "env = SafetyGymnasium2Gymnasium(base_env)\n",
    "\n",
    "# --- 2. Record exactly one episode ---------------------------------------\n",
    "env = RecordVideo(\n",
    "    env,\n",
    "    video_folder=\"/home/chaos/Desktop/Projet_Safe-RL\",\n",
    "    episode_trigger=lambda ep: ep == 0,\n",
    "    name_prefix=\"ppo_rollout_3rd\",\n",
    "    disable_logger=True,\n",
    ")\n",
    "\n",
    "# --- 3. Load policy & roll ~30 s (900 steps) ------------------------------\n",
    "model = PPO.load(\"ppo/ppo_best/best_model\")   # best checkpoint\n",
    "\n",
    "obs, _ = env.reset(seed=0)\n",
    "for _ in range(900):                      # 30 s @ 30 FPS\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, _, done, truncated, _ = env.step(action)\n",
    "    if done or truncated:\n",
    "        break\n",
    "\n",
    "env.close()\n",
    "print(\"✅  saved → /home/chaos/Desktop/Projet_Safe-RL/ppo_rollout_3rd-episode-0.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "data = np.load(\"ppo_eval/evaluations.npz\")\n",
    "timesteps      = data[\"timesteps\"]          # shape (k,)\n",
    "results        = data[\"results\"]            # shape (k, n_eval_episodes)\n",
    "mean_rewards   = results.mean(axis=1)\n",
    "std_rewards    = results.std(axis=1)\n",
    "\n",
    "plt.plot(timesteps, mean_rewards, label=\"mean reward\")\n",
    "plt.fill_between(\n",
    "    timesteps,\n",
    "    mean_rewards - std_rewards,\n",
    "    mean_rewards + std_rewards,\n",
    "    alpha=0.3,\n",
    "    label=\"±1 σ\",\n",
    ")\n",
    "plt.xlabel(\"environment steps\")\n",
    "plt.ylabel(\"episode reward\")\n",
    "plt.title(\"PPO – SafetyPointGoal1\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## omnisafe train --algo CPO --env-id SafetyPointGoal1-v0 --total-steps 1000000 --vector-env-nums 1 --device cuda:0 --log-dir cpo_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/chaos/Desktop/Projet_Safe-RL\n",
      "Contents of './cpo_logs/train/CPO-{SafetyPointGoal1-v0}/seed-000-2025-04-13-22-53-59/torch_save': ['epoch-0.pt', 'epoch-50.pt']\n",
      "Observation dimension: 60, Action dimension: 2\n",
      "Policy state dict keys: ['log_std', 'mean.0.weight', 'mean.0.bias', 'mean.2.weight', 'mean.2.bias', 'mean.4.weight', 'mean.4.bias']\n",
      "Missing keys after loading: ['net.0.weight', 'net.0.bias', 'net.2.weight', 'net.2.bias', 'net.4.weight', 'net.4.bias']\n",
      "Unexpected keys after loading: ['log_std', 'mean.0.weight', 'mean.0.bias', 'mean.2.weight', 'mean.2.bias', 'mean.4.weight', 'mean.4.bias']\n",
      "✅ Successfully loaded the CPO model.\n",
      "✅ Video saved → ./cpo_logs/video/cpo_rollout_3rd-episode-0.mp4\n",
      "Evaluation log file not found at ./cpo_logs/evaluations.npz. Skipping evaluation plot.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gymnasium as gym\n",
    "import safety_gymnasium\n",
    "from safety_gymnasium.wrappers import SafetyGymnasium2Gymnasium\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Environment variables for headless rendering (if applicable)\n",
    "os.environ[\"MUJOCO_GL\"] = \"egl\"           # or \"osmesa\"\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Define the policy network architecture that matches OmniSafe's checkpoint.\n",
    "class CPOPolicyNetwork(nn.Module):\n",
    "    def __init__(self, obs_dim: int, action_dim: int, hidden_sizes=(64, 64)):\n",
    "        super(CPOPolicyNetwork, self).__init__()\n",
    "        layers = []\n",
    "        last_dim = obs_dim\n",
    "        # Build the network and assign it to self.mean so that the keys match.\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(last_dim, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            last_dim = hidden_size\n",
    "        layers.append(nn.Linear(last_dim, action_dim))\n",
    "        self.mean = nn.Sequential(*layers)\n",
    "        # Create a learnable log_std parameter (one per action dimension)\n",
    "        self.log_std = nn.Parameter(torch.zeros(action_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Return the mean of the policy.\n",
    "        return self.mean(x)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Wrapper to provide a predict() method similar to Stable Baselines3.\n",
    "class CPOModuleWrapper:\n",
    "    def __init__(self, model: nn.Module):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "\n",
    "    def predict(self, obs, deterministic=True):\n",
    "        # Convert observation (NumPy array) to a torch tensor with a batch dimension.\n",
    "        obs_tensor = torch.tensor(obs, dtype=torch.float32).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            # Use the model's forward method to get the mean action.\n",
    "            action_tensor = self.model(obs_tensor)\n",
    "        # Remove the batch dimension and convert the result to NumPy.\n",
    "        action = action_tensor.squeeze(0).cpu().numpy()\n",
    "        return action, None\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Function to load the OmniSafe CPO model checkpoint.\n",
    "def load_cpo_model(checkpoint_path: str, obs_dim: int, action_dim: int) -> CPOModuleWrapper:\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"Checkpoint file was not found at: {checkpoint_path}. \"\n",
    "            \"Please verify the file path and name, or check if the model was saved correctly.\"\n",
    "        )\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "    \n",
    "    # If the checkpoint is a dictionary with key \"pi\", extract the policy state dict.\n",
    "    if isinstance(checkpoint, dict) and \"pi\" in checkpoint:\n",
    "        policy_state_dict = checkpoint[\"pi\"]\n",
    "    else:\n",
    "        policy_state_dict = checkpoint\n",
    "\n",
    "    # Print out the keys of the loaded state dictionary for inspection.\n",
    "    print(\"Policy state dict keys:\", list(policy_state_dict.keys()))\n",
    "    \n",
    "    # Instantiate the model with the new architecture.\n",
    "    model = CPOPolicyNetwork(obs_dim, action_dim, hidden_sizes=(64, 64))\n",
    "    \n",
    "    # Load the state dictionary with strict=True now that the keys should match.\n",
    "    load_info = model.load_state_dict(policy_state_dict, strict=False)\n",
    "    print(\"Missing keys after loading:\", load_info.missing_keys)\n",
    "    print(\"Unexpected keys after loading:\", load_info.unexpected_keys)\n",
    "    \n",
    "    return CPOModuleWrapper(model)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Function to set up the environment with video recording.\n",
    "def setup_video_env(video_folder: str):\n",
    "    base_env = safety_gymnasium.make(\n",
    "        \"SafetyPointGoal1-v0\",\n",
    "        render_mode=\"rgb_array\",\n",
    "        camera_name=\"track\",  # Third-person chase camera view\n",
    "    )\n",
    "    env = SafetyGymnasium2Gymnasium(base_env)\n",
    "    env = RecordVideo(\n",
    "        env,\n",
    "        video_folder=video_folder,\n",
    "        episode_trigger=lambda episode_id: episode_id == 0,  # Record only the first episode.\n",
    "        name_prefix=\"cpo_rollout_3rd\",\n",
    "        disable_logger=True,\n",
    "    )\n",
    "    return env\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Main script: load model, run rollout, and plot evaluation results.\n",
    "if __name__ == \"__main__\":\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Define the checkpoint path based on your directory structure.\n",
    "    checkpoint_path = (\n",
    "        \"./cpo_logs/train/CPO-{SafetyPointGoal1-v0}/seed-000-2025-04-13-22-53-59/\"\n",
    "        \"torch_save/epoch-50.pt\"\n",
    "    )\n",
    "    \n",
    "    # Print debug info: current working directory and checkpoint folder contents.\n",
    "    print(\"Current working directory:\", os.getcwd())\n",
    "    ckpt_folder = os.path.dirname(checkpoint_path)\n",
    "    if os.path.exists(ckpt_folder):\n",
    "        print(f\"Contents of '{ckpt_folder}':\", os.listdir(ckpt_folder))\n",
    "    else:\n",
    "        print(f\"Folder '{ckpt_folder}' does not exist.\")\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Create a temporary environment to determine observation and action dimensions.\n",
    "    temp_env = safety_gymnasium.make(\"SafetyPointGoal1-v0\", render_mode=None)\n",
    "    obs_space = temp_env.observation_space\n",
    "    if hasattr(obs_space, 'shape'):\n",
    "        obs_dim = obs_space.shape[0]\n",
    "    else:\n",
    "        # If the observation space is a dict, adjust accordingly (e.g., use obs_space['obs'])\n",
    "        raise ValueError(\"Unexpected observation space format. Adjust the code accordingly.\")\n",
    "    action_dim = temp_env.action_space.shape[0]\n",
    "    temp_env.close()\n",
    "    print(f\"Observation dimension: {obs_dim}, Action dimension: {action_dim}\")\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Load the trained CPO model.\n",
    "    model_wrapper = load_cpo_model(checkpoint_path, obs_dim, action_dim)\n",
    "    print(\"✅ Successfully loaded the CPO model.\")\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Set up the video environment.\n",
    "    video_folder = \"./cpo_logs/video\"\n",
    "    env = setup_video_env(video_folder)\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Run a rollout of approximately 30 seconds (900 steps at 30 FPS).\n",
    "    obs, info = env.reset(seed=0)\n",
    "    for step in range(900):\n",
    "        action, _ = model_wrapper.predict(obs, deterministic=True)\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        if done or truncated:\n",
    "            print(f\"Episode terminated at step {step + 1}.\")\n",
    "            break\n",
    "\n",
    "    env.close()\n",
    "    video_path = os.path.join(video_folder, \"cpo_rollout_3rd-episode-0.mp4\")\n",
    "    print(f\"✅ Video saved → {video_path}\")\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Load evaluation data and plot the performance graph.\n",
    "    eval_log_path = \"./cpo_logs/evaluations.npz\"\n",
    "    if not os.path.exists(eval_log_path):\n",
    "        print(f\"Evaluation log file not found at {eval_log_path}. Skipping evaluation plot.\")\n",
    "    else:\n",
    "        try:\n",
    "            data = np.load(eval_log_path)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error loading evaluation logs: {e}\")\n",
    "\n",
    "        timesteps    = data[\"timesteps\"]    # 1D array of timesteps.\n",
    "        results      = data[\"results\"]      # 2D array (evaluations x episodes)\n",
    "        mean_rewards = results.mean(axis=1)\n",
    "        std_rewards  = results.std(axis=1)\n",
    "\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(timesteps, mean_rewards, label=\"Mean Reward\")\n",
    "        plt.fill_between(\n",
    "            timesteps,\n",
    "            mean_rewards - std_rewards,\n",
    "            mean_rewards + std_rewards,\n",
    "            alpha=0.3,\n",
    "            label=\"±1 σ\"\n",
    "        )\n",
    "        plt.xlabel(\"Environment Steps\")\n",
    "        plt.ylabel(\"Episode Reward\")\n",
    "        plt.title(\"CPO – SafetyPointGoal1 Evaluation\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test PPO et CPO par Omnisafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PPO.yaml from /home/napoleon/safe_RL/.venv/lib/python3.10/site-packages/omnisafe/utils/../configs/on-policy/PPO.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Logging data to .</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">/results/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">PPO-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">{SafetyPointGoal1-v0}</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">/seed-000-2025-04-15-17-53-47/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">progress.csv</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mLogging data to .\u001b[0m\u001b[1;35m/results/\u001b[0m\u001b[1;95mPPO-\u001b[0m\u001b[1;36m{\u001b[0m\u001b[1;36mSafetyPointGoal1-v0\u001b[0m\u001b[1;36m}\u001b[0m\u001b[1;35m/seed-000-2025-04-15-17-53-47/\u001b[0m\u001b[1;95mprogress.csv\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Save with config in config.json</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mSave with config in config.json\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">INFO: Start training</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mINFO: Start training\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ -0.5171959400177002    │\n",
       "│ Metrics/EpCost                │ 160.0                  │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 0.0                    │\n",
       "│ Train/Entropy                 │ 1.4186091423034668     │\n",
       "│ Train/KL                      │ 0.01209575030952692    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9934464693069458     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9934464693069458     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9934464693069458     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016366688534617424   │\n",
       "│ Train/LR                      │ 0.00029940000968053937 │\n",
       "│ Train/PolicyStd               │ 0.9996857643127441     │\n",
       "│ TotalEnvSteps                 │ 2048.0                 │\n",
       "│ Loss/Loss_pi                  │ -0.01703210547566414   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.01703210547566414   │\n",
       "│ Value/Adv                     │ 0.03242161497473717    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02977116033434868    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.02977116033434868    │\n",
       "│ Value/reward                  │ -0.06652169674634933   │\n",
       "│ Time/Total                    │ 13.945426940917969     │\n",
       "│ Time/Rollout                  │ 12.141347885131836     │\n",
       "│ Time/Update                   │ 1.8028321266174316     │\n",
       "│ Time/Epoch                    │ 13.944226264953613     │\n",
       "│ Time/FPS                      │ 146.87083435058594     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ -0.5171959400177002    │\n",
       "│ Metrics/EpCost                │ 160.0                  │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 0.0                    │\n",
       "│ Train/Entropy                 │ 1.4186091423034668     │\n",
       "│ Train/KL                      │ 0.01209575030952692    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9934464693069458     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9934464693069458     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9934464693069458     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016366688534617424   │\n",
       "│ Train/LR                      │ 0.00029940000968053937 │\n",
       "│ Train/PolicyStd               │ 0.9996857643127441     │\n",
       "│ TotalEnvSteps                 │ 2048.0                 │\n",
       "│ Loss/Loss_pi                  │ -0.01703210547566414   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.01703210547566414   │\n",
       "│ Value/Adv                     │ 0.03242161497473717    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02977116033434868    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.02977116033434868    │\n",
       "│ Value/reward                  │ -0.06652169674634933   │\n",
       "│ Time/Total                    │ 13.945426940917969     │\n",
       "│ Time/Rollout                  │ 12.141347885131836     │\n",
       "│ Time/Update                   │ 1.8028321266174316     │\n",
       "│ Time/Epoch                    │ 13.944226264953613     │\n",
       "│ Time/FPS                      │ 146.87083435058594     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ -0.6963911056518555    │\n",
       "│ Metrics/EpCost                │ 92.0                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 1.0                    │\n",
       "│ Train/Entropy                 │ 1.413905143737793      │\n",
       "│ Train/KL                      │ 0.012971781194210052   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0032873153686523     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0032873153686523     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0032873153686523     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01744179241359234    │\n",
       "│ Train/LR                      │ 0.00029880000511184335 │\n",
       "│ Train/PolicyStd               │ 0.9950898885726929     │\n",
       "│ TotalEnvSteps                 │ 4096.0                 │\n",
       "│ Loss/Loss_pi                  │ -0.0139822568744421    │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0030498486012220383  │\n",
       "│ Value/Adv                     │ -0.18496325612068176   │\n",
       "│ Loss/Loss_reward_critic       │ 0.010805997997522354   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.018965162336826324  │\n",
       "│ Value/reward                  │ -0.03788800910115242   │\n",
       "│ Time/Total                    │ 27.469860076904297     │\n",
       "│ Time/Rollout                  │ 11.659074783325195     │\n",
       "│ Time/Update                   │ 1.8522529602050781     │\n",
       "│ Time/Epoch                    │ 13.511387825012207     │\n",
       "│ Time/FPS                      │ 151.57586669921875     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ -0.6963911056518555    │\n",
       "│ Metrics/EpCost                │ 92.0                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 1.0                    │\n",
       "│ Train/Entropy                 │ 1.413905143737793      │\n",
       "│ Train/KL                      │ 0.012971781194210052   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0032873153686523     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0032873153686523     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0032873153686523     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01744179241359234    │\n",
       "│ Train/LR                      │ 0.00029880000511184335 │\n",
       "│ Train/PolicyStd               │ 0.9950898885726929     │\n",
       "│ TotalEnvSteps                 │ 4096.0                 │\n",
       "│ Loss/Loss_pi                  │ -0.0139822568744421    │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0030498486012220383  │\n",
       "│ Value/Adv                     │ -0.18496325612068176   │\n",
       "│ Loss/Loss_reward_critic       │ 0.010805997997522354   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.018965162336826324  │\n",
       "│ Value/reward                  │ -0.03788800910115242   │\n",
       "│ Time/Total                    │ 27.469860076904297     │\n",
       "│ Time/Rollout                  │ 11.659074783325195     │\n",
       "│ Time/Update                   │ 1.8522529602050781     │\n",
       "│ Time/Epoch                    │ 13.511387825012207     │\n",
       "│ Time/FPS                      │ 151.57586669921875     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ -0.05475000664591789  │\n",
       "│ Metrics/EpCost                │ 76.5                  │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 2.0                   │\n",
       "│ Train/Entropy                 │ 1.412365198135376     │\n",
       "│ Train/KL                      │ 0.014129296876490116  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9996505975723267    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9996505975723267    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9996505975723267    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01804918423295021   │\n",
       "│ Train/LR                      │ 0.0002982000005431473 │\n",
       "│ Train/PolicyStd               │ 0.9936186671257019    │\n",
       "│ TotalEnvSteps                 │ 6144.0                │\n",
       "│ Loss/Loss_pi                  │ -0.012836487963795662 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0011457689106464386 │\n",
       "│ Value/Adv                     │ 0.13867875933647156   │\n",
       "│ Loss/Loss_reward_critic       │ 0.00532873161137104   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005477266386151314 │\n",
       "│ Value/reward                  │ -0.017279157415032387 │\n",
       "│ Time/Total                    │ 40.84660339355469     │\n",
       "│ Time/Rollout                  │ 11.567846298217773    │\n",
       "│ Time/Update                   │ 1.7967455387115479    │\n",
       "│ Time/Epoch                    │ 13.364631652832031    │\n",
       "│ Time/FPS                      │ 153.24029541015625    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ -0.05475000664591789  │\n",
       "│ Metrics/EpCost                │ 76.5                  │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 2.0                   │\n",
       "│ Train/Entropy                 │ 1.412365198135376     │\n",
       "│ Train/KL                      │ 0.014129296876490116  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9996505975723267    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9996505975723267    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9996505975723267    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01804918423295021   │\n",
       "│ Train/LR                      │ 0.0002982000005431473 │\n",
       "│ Train/PolicyStd               │ 0.9936186671257019    │\n",
       "│ TotalEnvSteps                 │ 6144.0                │\n",
       "│ Loss/Loss_pi                  │ -0.012836487963795662 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0011457689106464386 │\n",
       "│ Value/Adv                     │ 0.13867875933647156   │\n",
       "│ Loss/Loss_reward_critic       │ 0.00532873161137104   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005477266386151314 │\n",
       "│ Value/reward                  │ -0.017279157415032387 │\n",
       "│ Time/Total                    │ 40.84660339355469     │\n",
       "│ Time/Rollout                  │ 11.567846298217773    │\n",
       "│ Time/Update                   │ 1.7967455387115479    │\n",
       "│ Time/Epoch                    │ 13.364631652832031    │\n",
       "│ Time/FPS                      │ 153.24029541015625    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 0.09124717116355896    │\n",
       "│ Metrics/EpCost                │ 74.375                 │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 3.0                    │\n",
       "│ Train/Entropy                 │ 1.415527582168579      │\n",
       "│ Train/KL                      │ 0.01189988013356924    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9990431070327759     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9990431070327759     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9990431070327759     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01719563640654087    │\n",
       "│ Train/LR                      │ 0.0002975999959744513  │\n",
       "│ Train/PolicyStd               │ 0.9968209266662598     │\n",
       "│ TotalEnvSteps                 │ 8192.0                 │\n",
       "│ Loss/Loss_pi                  │ -0.00920955277979374   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0036269351840019226  │\n",
       "│ Value/Adv                     │ -0.11947731673717499   │\n",
       "│ Loss/Loss_reward_critic       │ 0.0036274201702326536  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0017013114411383867 │\n",
       "│ Value/reward                  │ 0.05267662927508354    │\n",
       "│ Time/Total                    │ 54.34081268310547      │\n",
       "│ Time/Rollout                  │ 11.615191459655762     │\n",
       "│ Time/Update                   │ 1.866776704788208      │\n",
       "│ Time/Epoch                    │ 13.48200798034668      │\n",
       "│ Time/FPS                      │ 151.90615844726562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 0.09124717116355896    │\n",
       "│ Metrics/EpCost                │ 74.375                 │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 3.0                    │\n",
       "│ Train/Entropy                 │ 1.415527582168579      │\n",
       "│ Train/KL                      │ 0.01189988013356924    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9990431070327759     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9990431070327759     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9990431070327759     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01719563640654087    │\n",
       "│ Train/LR                      │ 0.0002975999959744513  │\n",
       "│ Train/PolicyStd               │ 0.9968209266662598     │\n",
       "│ TotalEnvSteps                 │ 8192.0                 │\n",
       "│ Loss/Loss_pi                  │ -0.00920955277979374   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0036269351840019226  │\n",
       "│ Value/Adv                     │ -0.11947731673717499   │\n",
       "│ Loss/Loss_reward_critic       │ 0.0036274201702326536  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0017013114411383867 │\n",
       "│ Value/reward                  │ 0.05267662927508354    │\n",
       "│ Time/Total                    │ 54.34081268310547      │\n",
       "│ Time/Rollout                  │ 11.615191459655762     │\n",
       "│ Time/Update                   │ 1.866776704788208      │\n",
       "│ Time/Epoch                    │ 13.48200798034668      │\n",
       "│ Time/FPS                      │ 151.90615844726562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 0.48921042680740356   │\n",
       "│ Metrics/EpCost                │ 69.19999694824219     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 4.0                   │\n",
       "│ Train/Entropy                 │ 1.4115691184997559    │\n",
       "│ Train/KL                      │ 0.014714842662215233  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9981666803359985    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9981666803359985    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9981666803359985    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01597432605922222   │\n",
       "│ Train/LR                      │ 0.0002969999914057553 │\n",
       "│ Train/PolicyStd               │ 0.9929086565971375    │\n",
       "│ TotalEnvSteps                 │ 10240.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014692617580294609 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00548306480050087  │\n",
       "│ Value/Adv                     │ -0.0628545880317688   │\n",
       "│ Loss/Loss_reward_critic       │ 0.004672312643378973  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0010448924731463194 │\n",
       "│ Value/reward                  │ 0.03953893482685089   │\n",
       "│ Time/Total                    │ 67.88640594482422     │\n",
       "│ Time/Rollout                  │ 11.686569213867188    │\n",
       "│ Time/Update                   │ 1.8462793827056885    │\n",
       "│ Time/Epoch                    │ 13.532892227172852    │\n",
       "│ Time/FPS                      │ 151.33499145507812    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 0.48921042680740356   │\n",
       "│ Metrics/EpCost                │ 69.19999694824219     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 4.0                   │\n",
       "│ Train/Entropy                 │ 1.4115691184997559    │\n",
       "│ Train/KL                      │ 0.014714842662215233  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9981666803359985    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9981666803359985    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9981666803359985    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01597432605922222   │\n",
       "│ Train/LR                      │ 0.0002969999914057553 │\n",
       "│ Train/PolicyStd               │ 0.9929086565971375    │\n",
       "│ TotalEnvSteps                 │ 10240.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014692617580294609 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00548306480050087  │\n",
       "│ Value/Adv                     │ -0.0628545880317688   │\n",
       "│ Loss/Loss_reward_critic       │ 0.004672312643378973  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0010448924731463194 │\n",
       "│ Value/reward                  │ 0.03953893482685089   │\n",
       "│ Time/Total                    │ 67.88640594482422     │\n",
       "│ Time/Rollout                  │ 11.686569213867188    │\n",
       "│ Time/Update                   │ 1.8462793827056885    │\n",
       "│ Time/Epoch                    │ 13.532892227172852    │\n",
       "│ Time/FPS                      │ 151.33499145507812    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 0.5047287344932556     │\n",
       "│ Metrics/EpCost                │ 69.41666412353516      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 5.0                    │\n",
       "│ Train/Entropy                 │ 1.4093431234359741     │\n",
       "│ Train/KL                      │ 0.014810450375080109   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9991062879562378     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9991062879562378     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9991062879562378     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01995469257235527    │\n",
       "│ Train/LR                      │ 0.00029639998683705926 │\n",
       "│ Train/PolicyStd               │ 0.9906789660453796     │\n",
       "│ TotalEnvSteps                 │ 12288.0                │\n",
       "│ Loss/Loss_pi                  │ -0.018977884203195572  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004285266622900963  │\n",
       "│ Value/Adv                     │ -0.023086896166205406  │\n",
       "│ Loss/Loss_reward_critic       │ 0.0032594159711152315  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0014128966722637415 │\n",
       "│ Value/reward                  │ 0.12286173552274704    │\n",
       "│ Time/Total                    │ 81.57026672363281      │\n",
       "│ Time/Rollout                  │ 11.792122840881348     │\n",
       "│ Time/Update                   │ 1.8793890476226807     │\n",
       "│ Time/Epoch                    │ 13.67155647277832      │\n",
       "│ Time/FPS                      │ 149.80006408691406     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 0.5047287344932556     │\n",
       "│ Metrics/EpCost                │ 69.41666412353516      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 5.0                    │\n",
       "│ Train/Entropy                 │ 1.4093431234359741     │\n",
       "│ Train/KL                      │ 0.014810450375080109   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9991062879562378     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9991062879562378     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9991062879562378     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01995469257235527    │\n",
       "│ Train/LR                      │ 0.00029639998683705926 │\n",
       "│ Train/PolicyStd               │ 0.9906789660453796     │\n",
       "│ TotalEnvSteps                 │ 12288.0                │\n",
       "│ Loss/Loss_pi                  │ -0.018977884203195572  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004285266622900963  │\n",
       "│ Value/Adv                     │ -0.023086896166205406  │\n",
       "│ Loss/Loss_reward_critic       │ 0.0032594159711152315  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0014128966722637415 │\n",
       "│ Value/reward                  │ 0.12286173552274704    │\n",
       "│ Time/Total                    │ 81.57026672363281      │\n",
       "│ Time/Rollout                  │ 11.792122840881348     │\n",
       "│ Time/Update                   │ 1.8793890476226807     │\n",
       "│ Time/Epoch                    │ 13.67155647277832      │\n",
       "│ Time/FPS                      │ 149.80006408691406     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 0.7044267654418945     │\n",
       "│ Metrics/EpCost                │ 95.64286041259766      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 6.0                    │\n",
       "│ Train/Entropy                 │ 1.4085636138916016     │\n",
       "│ Train/KL                      │ 0.010557910427451134   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0000907182693481     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0000907182693481     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0000907182693481     │\n",
       "│ Train/PolicyRatio/Std         │ 0.0175543911755085     │\n",
       "│ Train/LR                      │ 0.0002958000113721937  │\n",
       "│ Train/PolicyStd               │ 0.9900562167167664     │\n",
       "│ TotalEnvSteps                 │ 14336.0                │\n",
       "│ Loss/Loss_pi                  │ -0.014173673465847969  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004804210737347603   │\n",
       "│ Value/Adv                     │ 0.29192686080932617    │\n",
       "│ Loss/Loss_reward_critic       │ 0.0029880914371460676  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0002713245339691639 │\n",
       "│ Value/reward                  │ -0.005129016935825348  │\n",
       "│ Time/Total                    │ 95.15318298339844      │\n",
       "│ Time/Rollout                  │ 11.738980293273926     │\n",
       "│ Time/Update                   │ 1.8297855854034424     │\n",
       "│ Time/Epoch                    │ 13.568815231323242     │\n",
       "│ Time/FPS                      │ 150.93434143066406     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 0.7044267654418945     │\n",
       "│ Metrics/EpCost                │ 95.64286041259766      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 6.0                    │\n",
       "│ Train/Entropy                 │ 1.4085636138916016     │\n",
       "│ Train/KL                      │ 0.010557910427451134   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0000907182693481     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0000907182693481     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0000907182693481     │\n",
       "│ Train/PolicyRatio/Std         │ 0.0175543911755085     │\n",
       "│ Train/LR                      │ 0.0002958000113721937  │\n",
       "│ Train/PolicyStd               │ 0.9900562167167664     │\n",
       "│ TotalEnvSteps                 │ 14336.0                │\n",
       "│ Loss/Loss_pi                  │ -0.014173673465847969  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004804210737347603   │\n",
       "│ Value/Adv                     │ 0.29192686080932617    │\n",
       "│ Loss/Loss_reward_critic       │ 0.0029880914371460676  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0002713245339691639 │\n",
       "│ Value/reward                  │ -0.005129016935825348  │\n",
       "│ Time/Total                    │ 95.15318298339844      │\n",
       "│ Time/Rollout                  │ 11.738980293273926     │\n",
       "│ Time/Update                   │ 1.8297855854034424     │\n",
       "│ Time/Epoch                    │ 13.568815231323242     │\n",
       "│ Time/FPS                      │ 150.93434143066406     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 0.729386031627655      │\n",
       "│ Metrics/EpCost                │ 86.25                  │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 7.0                    │\n",
       "│ Train/Entropy                 │ 1.400043249130249      │\n",
       "│ Train/KL                      │ 0.014926786534488201   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9989246129989624     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9989246129989624     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9989246129989624     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020921384915709496   │\n",
       "│ Train/LR                      │ 0.00029520000680349767 │\n",
       "│ Train/PolicyStd               │ 0.9819475412368774     │\n",
       "│ TotalEnvSteps                 │ 16384.0                │\n",
       "│ Loss/Loss_pi                  │ -0.012963773682713509  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0012098997831344604  │\n",
       "│ Value/Adv                     │ -0.129231795668602     │\n",
       "│ Loss/Loss_reward_critic       │ 0.004587588366121054   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.001599496928974986   │\n",
       "│ Value/reward                  │ 0.058384135365486145   │\n",
       "│ Time/Total                    │ 108.6556625366211      │\n",
       "│ Time/Rollout                  │ 11.762680053710938     │\n",
       "│ Time/Update                   │ 1.7262983322143555     │\n",
       "│ Time/Epoch                    │ 13.489020347595215     │\n",
       "│ Time/FPS                      │ 151.8271942138672      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 0.729386031627655      │\n",
       "│ Metrics/EpCost                │ 86.25                  │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 7.0                    │\n",
       "│ Train/Entropy                 │ 1.400043249130249      │\n",
       "│ Train/KL                      │ 0.014926786534488201   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9989246129989624     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9989246129989624     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9989246129989624     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020921384915709496   │\n",
       "│ Train/LR                      │ 0.00029520000680349767 │\n",
       "│ Train/PolicyStd               │ 0.9819475412368774     │\n",
       "│ TotalEnvSteps                 │ 16384.0                │\n",
       "│ Loss/Loss_pi                  │ -0.012963773682713509  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0012098997831344604  │\n",
       "│ Value/Adv                     │ -0.129231795668602     │\n",
       "│ Loss/Loss_reward_critic       │ 0.004587588366121054   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.001599496928974986   │\n",
       "│ Value/reward                  │ 0.058384135365486145   │\n",
       "│ Time/Total                    │ 108.6556625366211      │\n",
       "│ Time/Rollout                  │ 11.762680053710938     │\n",
       "│ Time/Update                   │ 1.7262983322143555     │\n",
       "│ Time/Epoch                    │ 13.489020347595215     │\n",
       "│ Time/FPS                      │ 151.8271942138672      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 1.0196658372879028     │\n",
       "│ Metrics/EpCost                │ 80.38888549804688      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 8.0                    │\n",
       "│ Train/Entropy                 │ 1.385493516921997      │\n",
       "│ Train/KL                      │ 0.01158205047249794    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9985524415969849     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9985524415969849     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9985524415969849     │\n",
       "│ Train/PolicyRatio/Std         │ 0.015402240678668022   │\n",
       "│ Train/LR                      │ 0.00029460000223480165 │\n",
       "│ Train/PolicyStd               │ 0.9678937792778015     │\n",
       "│ TotalEnvSteps                 │ 18432.0                │\n",
       "│ Loss/Loss_pi                  │ -0.012439721263945103  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0005240524187684059  │\n",
       "│ Value/Adv                     │ 0.20165421068668365    │\n",
       "│ Loss/Loss_reward_critic       │ 0.004883102606981993   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.000295514240860939   │\n",
       "│ Value/reward                  │ 0.10465170443058014    │\n",
       "│ Time/Total                    │ 122.39946746826172     │\n",
       "│ Time/Rollout                  │ 11.892988204956055     │\n",
       "│ Time/Update                   │ 1.83864426612854       │\n",
       "│ Time/Epoch                    │ 13.731674194335938     │\n",
       "│ Time/FPS                      │ 149.1442413330078      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 1.0196658372879028     │\n",
       "│ Metrics/EpCost                │ 80.38888549804688      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 8.0                    │\n",
       "│ Train/Entropy                 │ 1.385493516921997      │\n",
       "│ Train/KL                      │ 0.01158205047249794    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9985524415969849     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9985524415969849     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9985524415969849     │\n",
       "│ Train/PolicyRatio/Std         │ 0.015402240678668022   │\n",
       "│ Train/LR                      │ 0.00029460000223480165 │\n",
       "│ Train/PolicyStd               │ 0.9678937792778015     │\n",
       "│ TotalEnvSteps                 │ 18432.0                │\n",
       "│ Loss/Loss_pi                  │ -0.012439721263945103  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0005240524187684059  │\n",
       "│ Value/Adv                     │ 0.20165421068668365    │\n",
       "│ Loss/Loss_reward_critic       │ 0.004883102606981993   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.000295514240860939   │\n",
       "│ Value/reward                  │ 0.10465170443058014    │\n",
       "│ Time/Total                    │ 122.39946746826172     │\n",
       "│ Time/Rollout                  │ 11.892988204956055     │\n",
       "│ Time/Update                   │ 1.83864426612854       │\n",
       "│ Time/Epoch                    │ 13.731674194335938     │\n",
       "│ Time/FPS                      │ 149.1442413330078      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 1.3415597677230835     │\n",
       "│ Metrics/EpCost                │ 94.0                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 9.0                    │\n",
       "│ Train/Entropy                 │ 1.3787281513214111     │\n",
       "│ Train/KL                      │ 0.01174912415444851    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9976779818534851     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9976779818534851     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9976779818534851     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01921680010855198    │\n",
       "│ Train/LR                      │ 0.00029399999766610563 │\n",
       "│ Train/PolicyStd               │ 0.9614613652229309     │\n",
       "│ TotalEnvSteps                 │ 20480.0                │\n",
       "│ Loss/Loss_pi                  │ -0.015449238009750843  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0030095167458057404 │\n",
       "│ Value/Adv                     │ -0.17510564625263214   │\n",
       "│ Loss/Loss_reward_critic       │ 0.004905871581286192   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 2.276897430419922e-05  │\n",
       "│ Value/reward                  │ 0.1753077507019043     │\n",
       "│ Time/Total                    │ 135.8899383544922      │\n",
       "│ Time/Rollout                  │ 11.793667793273926     │\n",
       "│ Time/Update                   │ 1.6837434768676758     │\n",
       "│ Time/Epoch                    │ 13.477455139160156     │\n",
       "│ Time/FPS                      │ 151.9574737548828      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 1.3415597677230835     │\n",
       "│ Metrics/EpCost                │ 94.0                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 9.0                    │\n",
       "│ Train/Entropy                 │ 1.3787281513214111     │\n",
       "│ Train/KL                      │ 0.01174912415444851    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9976779818534851     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9976779818534851     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9976779818534851     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01921680010855198    │\n",
       "│ Train/LR                      │ 0.00029399999766610563 │\n",
       "│ Train/PolicyStd               │ 0.9614613652229309     │\n",
       "│ TotalEnvSteps                 │ 20480.0                │\n",
       "│ Loss/Loss_pi                  │ -0.015449238009750843  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0030095167458057404 │\n",
       "│ Value/Adv                     │ -0.17510564625263214   │\n",
       "│ Loss/Loss_reward_critic       │ 0.004905871581286192   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 2.276897430419922e-05  │\n",
       "│ Value/reward                  │ 0.1753077507019043     │\n",
       "│ Time/Total                    │ 135.8899383544922      │\n",
       "│ Time/Rollout                  │ 11.793667793273926     │\n",
       "│ Time/Update                   │ 1.6837434768676758     │\n",
       "│ Time/Epoch                    │ 13.477455139160156     │\n",
       "│ Time/FPS                      │ 151.9574737548828      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 1.3176074028015137     │\n",
       "│ Metrics/EpCost                │ 87.18181610107422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 10.0                   │\n",
       "│ Train/Entropy                 │ 1.377897024154663      │\n",
       "│ Train/KL                      │ 0.018271518871188164   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9980016946792603     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9980016946792603     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9980016946792603     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017799319699406624   │\n",
       "│ Train/LR                      │ 0.0002933999930974096  │\n",
       "│ Train/PolicyStd               │ 0.9607664346694946     │\n",
       "│ TotalEnvSteps                 │ 22528.0                │\n",
       "│ Loss/Loss_pi                  │ -0.014539000578224659  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0009102374315261841  │\n",
       "│ Value/Adv                     │ 0.09824410825967789    │\n",
       "│ Loss/Loss_reward_critic       │ 0.0022674628999084234  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0026384086813777685 │\n",
       "│ Value/reward                  │ 0.004919549450278282   │\n",
       "│ Time/Total                    │ 148.91213989257812     │\n",
       "│ Time/Rollout                  │ 11.247808456420898     │\n",
       "│ Time/Update                   │ 1.7612764835357666     │\n",
       "│ Time/Epoch                    │ 13.00912857055664      │\n",
       "│ Time/FPS                      │ 157.4279327392578      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 1.3176074028015137     │\n",
       "│ Metrics/EpCost                │ 87.18181610107422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 10.0                   │\n",
       "│ Train/Entropy                 │ 1.377897024154663      │\n",
       "│ Train/KL                      │ 0.018271518871188164   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9980016946792603     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9980016946792603     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9980016946792603     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017799319699406624   │\n",
       "│ Train/LR                      │ 0.0002933999930974096  │\n",
       "│ Train/PolicyStd               │ 0.9607664346694946     │\n",
       "│ TotalEnvSteps                 │ 22528.0                │\n",
       "│ Loss/Loss_pi                  │ -0.014539000578224659  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0009102374315261841  │\n",
       "│ Value/Adv                     │ 0.09824410825967789    │\n",
       "│ Loss/Loss_reward_critic       │ 0.0022674628999084234  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0026384086813777685 │\n",
       "│ Value/reward                  │ 0.004919549450278282   │\n",
       "│ Time/Total                    │ 148.91213989257812     │\n",
       "│ Time/Rollout                  │ 11.247808456420898     │\n",
       "│ Time/Update                   │ 1.7612764835357666     │\n",
       "│ Time/Epoch                    │ 13.00912857055664      │\n",
       "│ Time/FPS                      │ 157.4279327392578      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 1.5186511278152466    │\n",
       "│ Metrics/EpCost                │ 86.875                │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 11.0                  │\n",
       "│ Train/Entropy                 │ 1.3731036186218262    │\n",
       "│ Train/KL                      │ 0.013781437650322914  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9993082284927368    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9993082284927368    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9993082284927368    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01776096224784851   │\n",
       "│ Train/LR                      │ 0.0002927999885287136 │\n",
       "│ Train/PolicyStd               │ 0.9563396573066711    │\n",
       "│ TotalEnvSteps                 │ 24576.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013973912224173546 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0005650883540511131 │\n",
       "│ Value/Adv                     │ 0.3161247968673706    │\n",
       "│ Loss/Loss_reward_critic       │ 0.005021495744585991  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0027540328446775675 │\n",
       "│ Value/reward                  │ 0.12742848694324493   │\n",
       "│ Time/Total                    │ 162.36880493164062    │\n",
       "│ Time/Rollout                  │ 11.703651428222656    │\n",
       "│ Time/Update                   │ 1.7413122653961182    │\n",
       "│ Time/Epoch                    │ 13.445013046264648    │\n",
       "│ Time/FPS                      │ 152.3241424560547     │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 1.5186511278152466    │\n",
       "│ Metrics/EpCost                │ 86.875                │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 11.0                  │\n",
       "│ Train/Entropy                 │ 1.3731036186218262    │\n",
       "│ Train/KL                      │ 0.013781437650322914  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9993082284927368    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9993082284927368    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9993082284927368    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01776096224784851   │\n",
       "│ Train/LR                      │ 0.0002927999885287136 │\n",
       "│ Train/PolicyStd               │ 0.9563396573066711    │\n",
       "│ TotalEnvSteps                 │ 24576.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013973912224173546 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0005650883540511131 │\n",
       "│ Value/Adv                     │ 0.3161247968673706    │\n",
       "│ Loss/Loss_reward_critic       │ 0.005021495744585991  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0027540328446775675 │\n",
       "│ Value/reward                  │ 0.12742848694324493   │\n",
       "│ Time/Total                    │ 162.36880493164062    │\n",
       "│ Time/Rollout                  │ 11.703651428222656    │\n",
       "│ Time/Update                   │ 1.7413122653961182    │\n",
       "│ Time/Epoch                    │ 13.445013046264648    │\n",
       "│ Time/FPS                      │ 152.3241424560547     │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 1.7877436876296997     │\n",
       "│ Metrics/EpCost                │ 81.88461303710938      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 12.0                   │\n",
       "│ Train/Entropy                 │ 1.3554935455322266     │\n",
       "│ Train/KL                      │ 0.01249705720692873    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0031416416168213     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0031416416168213     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0031416416168213     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016242321580648422   │\n",
       "│ Train/LR                      │ 0.000292200013063848   │\n",
       "│ Train/PolicyStd               │ 0.9398989677429199     │\n",
       "│ TotalEnvSteps                 │ 26624.0                │\n",
       "│ Loss/Loss_pi                  │ -0.015062833204865456  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0010889209806919098 │\n",
       "│ Value/Adv                     │ -0.06089358404278755   │\n",
       "│ Loss/Loss_reward_critic       │ 0.006445142440497875   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0014236466959118843  │\n",
       "│ Value/reward                  │ 0.3817744851112366     │\n",
       "│ Time/Total                    │ 175.77059936523438     │\n",
       "│ Time/Rollout                  │ 11.603917121887207     │\n",
       "│ Time/Update                   │ 1.7855315208435059     │\n",
       "│ Time/Epoch                    │ 13.38949203491211      │\n",
       "│ Time/FPS                      │ 152.9557647705078      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 1.7877436876296997     │\n",
       "│ Metrics/EpCost                │ 81.88461303710938      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 12.0                   │\n",
       "│ Train/Entropy                 │ 1.3554935455322266     │\n",
       "│ Train/KL                      │ 0.01249705720692873    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0031416416168213     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0031416416168213     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0031416416168213     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016242321580648422   │\n",
       "│ Train/LR                      │ 0.000292200013063848   │\n",
       "│ Train/PolicyStd               │ 0.9398989677429199     │\n",
       "│ TotalEnvSteps                 │ 26624.0                │\n",
       "│ Loss/Loss_pi                  │ -0.015062833204865456  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0010889209806919098 │\n",
       "│ Value/Adv                     │ -0.06089358404278755   │\n",
       "│ Loss/Loss_reward_critic       │ 0.006445142440497875   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0014236466959118843  │\n",
       "│ Value/reward                  │ 0.3817744851112366     │\n",
       "│ Time/Total                    │ 175.77059936523438     │\n",
       "│ Time/Rollout                  │ 11.603917121887207     │\n",
       "│ Time/Update                   │ 1.7855315208435059     │\n",
       "│ Time/Epoch                    │ 13.38949203491211      │\n",
       "│ Time/FPS                      │ 152.9557647705078      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 1.7913495302200317     │\n",
       "│ Metrics/EpCost                │ 78.57142639160156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 13.0                   │\n",
       "│ Train/Entropy                 │ 1.342596411705017      │\n",
       "│ Train/KL                      │ 0.010349536314606667   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.003564715385437      │\n",
       "│ Train/PolicyRatio/Min         │ 1.003564715385437      │\n",
       "│ Train/PolicyRatio/Max         │ 1.003564715385437      │\n",
       "│ Train/PolicyRatio/Std         │ 0.018700791522860527   │\n",
       "│ Train/LR                      │ 0.000291600008495152   │\n",
       "│ Train/PolicyStd               │ 0.9282391667366028     │\n",
       "│ TotalEnvSteps                 │ 28672.0                │\n",
       "│ Loss/Loss_pi                  │ -0.011334501206874847  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.003728331997990608   │\n",
       "│ Value/Adv                     │ 0.01741015911102295    │\n",
       "│ Loss/Loss_reward_critic       │ 0.0035249176435172558  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0029202247969806194 │\n",
       "│ Value/reward                  │ 0.4037509858608246     │\n",
       "│ Time/Total                    │ 188.41116333007812     │\n",
       "│ Time/Rollout                  │ 10.997016906738281     │\n",
       "│ Time/Update                   │ 1.6296911239624023     │\n",
       "│ Time/Epoch                    │ 12.62675952911377      │\n",
       "│ Time/FPS                      │ 162.19522094726562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 1.7913495302200317     │\n",
       "│ Metrics/EpCost                │ 78.57142639160156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 13.0                   │\n",
       "│ Train/Entropy                 │ 1.342596411705017      │\n",
       "│ Train/KL                      │ 0.010349536314606667   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.003564715385437      │\n",
       "│ Train/PolicyRatio/Min         │ 1.003564715385437      │\n",
       "│ Train/PolicyRatio/Max         │ 1.003564715385437      │\n",
       "│ Train/PolicyRatio/Std         │ 0.018700791522860527   │\n",
       "│ Train/LR                      │ 0.000291600008495152   │\n",
       "│ Train/PolicyStd               │ 0.9282391667366028     │\n",
       "│ TotalEnvSteps                 │ 28672.0                │\n",
       "│ Loss/Loss_pi                  │ -0.011334501206874847  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.003728331997990608   │\n",
       "│ Value/Adv                     │ 0.01741015911102295    │\n",
       "│ Loss/Loss_reward_critic       │ 0.0035249176435172558  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0029202247969806194 │\n",
       "│ Value/reward                  │ 0.4037509858608246     │\n",
       "│ Time/Total                    │ 188.41116333007812     │\n",
       "│ Time/Rollout                  │ 10.997016906738281     │\n",
       "│ Time/Update                   │ 1.6296911239624023     │\n",
       "│ Time/Epoch                    │ 12.62675952911377      │\n",
       "│ Time/FPS                      │ 162.19522094726562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 2.007957935333252     │\n",
       "│ Metrics/EpCost                │ 73.5999984741211      │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 14.0                  │\n",
       "│ Train/Entropy                 │ 1.3326187133789062    │\n",
       "│ Train/KL                      │ 0.011252653785049915  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9974700808525085    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9974700808525085    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9974700808525085    │\n",
       "│ Train/PolicyRatio/Std         │ 0.017346715554594994  │\n",
       "│ Train/LR                      │ 0.000291000003926456  │\n",
       "│ Train/PolicyStd               │ 0.9196935892105103    │\n",
       "│ TotalEnvSteps                 │ 30720.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016332462430000305 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004997961223125458 │\n",
       "│ Value/Adv                     │ 0.09197748452425003   │\n",
       "│ Loss/Loss_reward_critic       │ 0.006386472377926111  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0028615547344088554 │\n",
       "│ Value/reward                  │ 0.41047316789627075   │\n",
       "│ Time/Total                    │ 200.88058471679688    │\n",
       "│ Time/Rollout                  │ 10.829486846923828    │\n",
       "│ Time/Update                   │ 1.6282680034637451    │\n",
       "│ Time/Epoch                    │ 12.457796096801758    │\n",
       "│ Time/FPS                      │ 164.3950653076172     │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 2.007957935333252     │\n",
       "│ Metrics/EpCost                │ 73.5999984741211      │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 14.0                  │\n",
       "│ Train/Entropy                 │ 1.3326187133789062    │\n",
       "│ Train/KL                      │ 0.011252653785049915  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9974700808525085    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9974700808525085    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9974700808525085    │\n",
       "│ Train/PolicyRatio/Std         │ 0.017346715554594994  │\n",
       "│ Train/LR                      │ 0.000291000003926456  │\n",
       "│ Train/PolicyStd               │ 0.9196935892105103    │\n",
       "│ TotalEnvSteps                 │ 30720.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016332462430000305 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004997961223125458 │\n",
       "│ Value/Adv                     │ 0.09197748452425003   │\n",
       "│ Loss/Loss_reward_critic       │ 0.006386472377926111  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0028615547344088554 │\n",
       "│ Value/reward                  │ 0.41047316789627075   │\n",
       "│ Time/Total                    │ 200.88058471679688    │\n",
       "│ Time/Rollout                  │ 10.829486846923828    │\n",
       "│ Time/Update                   │ 1.6282680034637451    │\n",
       "│ Time/Epoch                    │ 12.457796096801758    │\n",
       "│ Time/FPS                      │ 164.3950653076172     │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 2.1461384296417236     │\n",
       "│ Metrics/EpCost                │ 100.90625              │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 15.0                   │\n",
       "│ Train/Entropy                 │ 1.3238402605056763     │\n",
       "│ Train/KL                      │ 0.007756068371236324   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9999433755874634     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9999433755874634     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9999433755874634     │\n",
       "│ Train/PolicyRatio/Std         │ 0.015446130186319351   │\n",
       "│ Train/LR                      │ 0.00029039999935775995 │\n",
       "│ Train/PolicyStd               │ 0.911481499671936      │\n",
       "│ TotalEnvSteps                 │ 32768.0                │\n",
       "│ Loss/Loss_pi                  │ -0.01001476775854826   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0063176946714520454  │\n",
       "│ Value/Adv                     │ -0.0015218481421470642 │\n",
       "│ Loss/Loss_reward_critic       │ 0.00891166739165783    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002525195013731718   │\n",
       "│ Value/reward                  │ 0.5972390174865723     │\n",
       "│ Time/Total                    │ 213.41851806640625     │\n",
       "│ Time/Rollout                  │ 10.83740234375         │\n",
       "│ Time/Update                   │ 1.6887166500091553     │\n",
       "│ Time/Epoch                    │ 12.526166915893555     │\n",
       "│ Time/FPS                      │ 163.4977569580078      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 2.1461384296417236     │\n",
       "│ Metrics/EpCost                │ 100.90625              │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 15.0                   │\n",
       "│ Train/Entropy                 │ 1.3238402605056763     │\n",
       "│ Train/KL                      │ 0.007756068371236324   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9999433755874634     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9999433755874634     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9999433755874634     │\n",
       "│ Train/PolicyRatio/Std         │ 0.015446130186319351   │\n",
       "│ Train/LR                      │ 0.00029039999935775995 │\n",
       "│ Train/PolicyStd               │ 0.911481499671936      │\n",
       "│ TotalEnvSteps                 │ 32768.0                │\n",
       "│ Loss/Loss_pi                  │ -0.01001476775854826   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0063176946714520454  │\n",
       "│ Value/Adv                     │ -0.0015218481421470642 │\n",
       "│ Loss/Loss_reward_critic       │ 0.00891166739165783    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002525195013731718   │\n",
       "│ Value/reward                  │ 0.5972390174865723     │\n",
       "│ Time/Total                    │ 213.41851806640625     │\n",
       "│ Time/Rollout                  │ 10.83740234375         │\n",
       "│ Time/Update                   │ 1.6887166500091553     │\n",
       "│ Time/Epoch                    │ 12.526166915893555     │\n",
       "│ Time/FPS                      │ 163.4977569580078      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 2.0474352836608887     │\n",
       "│ Metrics/EpCost                │ 113.11764526367188     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 16.0                   │\n",
       "│ Train/Entropy                 │ 1.3175256252288818     │\n",
       "│ Train/KL                      │ 0.011838234029710293   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0003684759140015     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0003684759140015     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0003684759140015     │\n",
       "│ Train/PolicyRatio/Std         │ 0.015788333490490913   │\n",
       "│ Train/LR                      │ 0.00028979999478906393 │\n",
       "│ Train/PolicyStd               │ 0.9058883786201477     │\n",
       "│ TotalEnvSteps                 │ 34816.0                │\n",
       "│ Loss/Loss_pi                  │ -0.010906119830906391  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0008913520723581314 │\n",
       "│ Value/Adv                     │ -0.10765761137008667   │\n",
       "│ Loss/Loss_reward_critic       │ 0.0029322425834834576  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005979424808174372  │\n",
       "│ Value/reward                  │ 0.11421626806259155    │\n",
       "│ Time/Total                    │ 225.93768310546875     │\n",
       "│ Time/Rollout                  │ 10.856833457946777     │\n",
       "│ Time/Update                   │ 1.6493782997131348     │\n",
       "│ Time/Epoch                    │ 12.506254196166992     │\n",
       "│ Time/FPS                      │ 163.75807189941406     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 2.0474352836608887     │\n",
       "│ Metrics/EpCost                │ 113.11764526367188     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 16.0                   │\n",
       "│ Train/Entropy                 │ 1.3175256252288818     │\n",
       "│ Train/KL                      │ 0.011838234029710293   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0003684759140015     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0003684759140015     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0003684759140015     │\n",
       "│ Train/PolicyRatio/Std         │ 0.015788333490490913   │\n",
       "│ Train/LR                      │ 0.00028979999478906393 │\n",
       "│ Train/PolicyStd               │ 0.9058883786201477     │\n",
       "│ TotalEnvSteps                 │ 34816.0                │\n",
       "│ Loss/Loss_pi                  │ -0.010906119830906391  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0008913520723581314 │\n",
       "│ Value/Adv                     │ -0.10765761137008667   │\n",
       "│ Loss/Loss_reward_critic       │ 0.0029322425834834576  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005979424808174372  │\n",
       "│ Value/reward                  │ 0.11421626806259155    │\n",
       "│ Time/Total                    │ 225.93768310546875     │\n",
       "│ Time/Rollout                  │ 10.856833457946777     │\n",
       "│ Time/Update                   │ 1.6493782997131348     │\n",
       "│ Time/Epoch                    │ 12.506254196166992     │\n",
       "│ Time/FPS                      │ 163.75807189941406     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 2.1372933387756348     │\n",
       "│ Metrics/EpCost                │ 114.97222137451172     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 17.0                   │\n",
       "│ Train/Entropy                 │ 1.3147146701812744     │\n",
       "│ Train/KL                      │ 0.014716845005750656   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9959033131599426     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9959033131599426     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9959033131599426     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018605543300509453   │\n",
       "│ Train/LR                      │ 0.0002891999902203679  │\n",
       "│ Train/PolicyStd               │ 0.9038289785385132     │\n",
       "│ TotalEnvSteps                 │ 36864.0                │\n",
       "│ Loss/Loss_pi                  │ -0.012370146811008453  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0014640269801020622 │\n",
       "│ Value/Adv                     │ -0.14517056941986084   │\n",
       "│ Loss/Loss_reward_critic       │ 0.005480041261762381   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002547798678278923   │\n",
       "│ Value/reward                  │ 0.23973581194877625    │\n",
       "│ Time/Total                    │ 238.44737243652344     │\n",
       "│ Time/Rollout                  │ 10.822912216186523     │\n",
       "│ Time/Update                   │ 1.6751010417938232     │\n",
       "│ Time/Epoch                    │ 12.49807071685791      │\n",
       "│ Time/FPS                      │ 163.8653106689453      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 2.1372933387756348     │\n",
       "│ Metrics/EpCost                │ 114.97222137451172     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 17.0                   │\n",
       "│ Train/Entropy                 │ 1.3147146701812744     │\n",
       "│ Train/KL                      │ 0.014716845005750656   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9959033131599426     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9959033131599426     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9959033131599426     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018605543300509453   │\n",
       "│ Train/LR                      │ 0.0002891999902203679  │\n",
       "│ Train/PolicyStd               │ 0.9038289785385132     │\n",
       "│ TotalEnvSteps                 │ 36864.0                │\n",
       "│ Loss/Loss_pi                  │ -0.012370146811008453  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0014640269801020622 │\n",
       "│ Value/Adv                     │ -0.14517056941986084   │\n",
       "│ Loss/Loss_reward_critic       │ 0.005480041261762381   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002547798678278923   │\n",
       "│ Value/reward                  │ 0.23973581194877625    │\n",
       "│ Time/Total                    │ 238.44737243652344     │\n",
       "│ Time/Rollout                  │ 10.822912216186523     │\n",
       "│ Time/Update                   │ 1.6751010417938232     │\n",
       "│ Time/Epoch                    │ 12.49807071685791      │\n",
       "│ Time/FPS                      │ 163.8653106689453      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 2.513962507247925     │\n",
       "│ Metrics/EpCost                │ 110.89473724365234    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 18.0                  │\n",
       "│ Train/Entropy                 │ 1.306275725364685     │\n",
       "│ Train/KL                      │ 0.009532337076961994  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0030806064605713    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0030806064605713    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0030806064605713    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01541789248585701   │\n",
       "│ Train/LR                      │ 0.0002885999856516719 │\n",
       "│ Train/PolicyStd               │ 0.8965600728988647    │\n",
       "│ TotalEnvSteps                 │ 38912.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011811918579041958 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0005582282319664955 │\n",
       "│ Value/Adv                     │ 0.10761149227619171   │\n",
       "│ Loss/Loss_reward_critic       │ 0.0076765986159443855 │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002196557354182005  │\n",
       "│ Value/reward                  │ 0.571629524230957     │\n",
       "│ Time/Total                    │ 250.8970184326172     │\n",
       "│ Time/Rollout                  │ 10.791508674621582    │\n",
       "│ Time/Update                   │ 1.6457633972167969    │\n",
       "│ Time/Epoch                    │ 12.437313079833984    │\n",
       "│ Time/FPS                      │ 164.66580200195312    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 2.513962507247925     │\n",
       "│ Metrics/EpCost                │ 110.89473724365234    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 18.0                  │\n",
       "│ Train/Entropy                 │ 1.306275725364685     │\n",
       "│ Train/KL                      │ 0.009532337076961994  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0030806064605713    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0030806064605713    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0030806064605713    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01541789248585701   │\n",
       "│ Train/LR                      │ 0.0002885999856516719 │\n",
       "│ Train/PolicyStd               │ 0.8965600728988647    │\n",
       "│ TotalEnvSteps                 │ 38912.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011811918579041958 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0005582282319664955 │\n",
       "│ Value/Adv                     │ 0.10761149227619171   │\n",
       "│ Loss/Loss_reward_critic       │ 0.0076765986159443855 │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002196557354182005  │\n",
       "│ Value/reward                  │ 0.571629524230957     │\n",
       "│ Time/Total                    │ 250.8970184326172     │\n",
       "│ Time/Rollout                  │ 10.791508674621582    │\n",
       "│ Time/Update                   │ 1.6457633972167969    │\n",
       "│ Time/Epoch                    │ 12.437313079833984    │\n",
       "│ Time/FPS                      │ 164.66580200195312    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m6\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 2.5353500843048096     │\n",
       "│ Metrics/EpCost                │ 109.32499694824219     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 19.0                   │\n",
       "│ Train/Entropy                 │ 1.2952100038528442     │\n",
       "│ Train/KL                      │ 0.02378733828663826    │\n",
       "│ Train/StopIter                │ 6.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9978005290031433     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9978005290031433     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9978005290031433     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018239522352814674   │\n",
       "│ Train/LR                      │ 0.0002880000101868063  │\n",
       "│ Train/PolicyStd               │ 0.886580228805542      │\n",
       "│ TotalEnvSteps                 │ 40960.0                │\n",
       "│ Loss/Loss_pi                  │ -0.013015392236411572  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0012034736573696136 │\n",
       "│ Value/Adv                     │ 0.1151050552725792     │\n",
       "│ Loss/Loss_reward_critic       │ 0.00413854094222188    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0035380576737225056 │\n",
       "│ Value/reward                  │ 0.5099475383758545     │\n",
       "│ Time/Total                    │ 262.69781494140625     │\n",
       "│ Time/Rollout                  │ 10.793395042419434     │\n",
       "│ Time/Update                   │ 0.9921548366546631     │\n",
       "│ Time/Epoch                    │ 11.785593032836914     │\n",
       "│ Time/FPS                      │ 173.771484375          │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 2.5353500843048096     │\n",
       "│ Metrics/EpCost                │ 109.32499694824219     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 19.0                   │\n",
       "│ Train/Entropy                 │ 1.2952100038528442     │\n",
       "│ Train/KL                      │ 0.02378733828663826    │\n",
       "│ Train/StopIter                │ 6.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9978005290031433     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9978005290031433     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9978005290031433     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018239522352814674   │\n",
       "│ Train/LR                      │ 0.0002880000101868063  │\n",
       "│ Train/PolicyStd               │ 0.886580228805542      │\n",
       "│ TotalEnvSteps                 │ 40960.0                │\n",
       "│ Loss/Loss_pi                  │ -0.013015392236411572  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0012034736573696136 │\n",
       "│ Value/Adv                     │ 0.1151050552725792     │\n",
       "│ Loss/Loss_reward_critic       │ 0.00413854094222188    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0035380576737225056 │\n",
       "│ Value/reward                  │ 0.5099475383758545     │\n",
       "│ Time/Total                    │ 262.69781494140625     │\n",
       "│ Time/Rollout                  │ 10.793395042419434     │\n",
       "│ Time/Update                   │ 0.9921548366546631     │\n",
       "│ Time/Epoch                    │ 11.785593032836914     │\n",
       "│ Time/FPS                      │ 173.771484375          │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 2.6775612831115723     │\n",
       "│ Metrics/EpCost                │ 107.80952453613281     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 20.0                   │\n",
       "│ Train/Entropy                 │ 1.285111427307129      │\n",
       "│ Train/KL                      │ 0.0118419723585248     │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9961341619491577     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9961341619491577     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9961341619491577     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017856156453490257   │\n",
       "│ Train/LR                      │ 0.0002874000056181103  │\n",
       "│ Train/PolicyStd               │ 0.8770718574523926     │\n",
       "│ TotalEnvSteps                 │ 43008.0                │\n",
       "│ Loss/Loss_pi                  │ -0.015218352898955345  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0022029606625437737 │\n",
       "│ Value/Adv                     │ -0.03953581303358078   │\n",
       "│ Loss/Loss_reward_critic       │ 0.006874066777527332   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0027355258353054523  │\n",
       "│ Value/reward                  │ 0.5713939666748047     │\n",
       "│ Time/Total                    │ 275.2617492675781      │\n",
       "│ Time/Rollout                  │ 10.85103988647461      │\n",
       "│ Time/Update                   │ 1.6950793266296387     │\n",
       "│ Time/Epoch                    │ 12.54616928100586      │\n",
       "│ Time/FPS                      │ 163.23709106445312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 2.6775612831115723     │\n",
       "│ Metrics/EpCost                │ 107.80952453613281     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 20.0                   │\n",
       "│ Train/Entropy                 │ 1.285111427307129      │\n",
       "│ Train/KL                      │ 0.0118419723585248     │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9961341619491577     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9961341619491577     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9961341619491577     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017856156453490257   │\n",
       "│ Train/LR                      │ 0.0002874000056181103  │\n",
       "│ Train/PolicyStd               │ 0.8770718574523926     │\n",
       "│ TotalEnvSteps                 │ 43008.0                │\n",
       "│ Loss/Loss_pi                  │ -0.015218352898955345  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0022029606625437737 │\n",
       "│ Value/Adv                     │ -0.03953581303358078   │\n",
       "│ Loss/Loss_reward_critic       │ 0.006874066777527332   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0027355258353054523  │\n",
       "│ Value/reward                  │ 0.5713939666748047     │\n",
       "│ Time/Total                    │ 275.2617492675781      │\n",
       "│ Time/Rollout                  │ 10.85103988647461      │\n",
       "│ Time/Update                   │ 1.6950793266296387     │\n",
       "│ Time/Epoch                    │ 12.54616928100586      │\n",
       "│ Time/FPS                      │ 163.23709106445312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 2.9890401363372803    │\n",
       "│ Metrics/EpCost                │ 104.81818389892578    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 21.0                  │\n",
       "│ Train/Entropy                 │ 1.2794538736343384    │\n",
       "│ Train/KL                      │ 0.01524317730218172   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9969674348831177    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9969674348831177    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9969674348831177    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01806304045021534   │\n",
       "│ Train/LR                      │ 0.0002868000010494143 │\n",
       "│ Train/PolicyStd               │ 0.8719485402107239    │\n",
       "│ TotalEnvSteps                 │ 45056.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013968393206596375 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0012499596923589706 │\n",
       "│ Value/Adv                     │ -0.06340079009532928  │\n",
       "│ Loss/Loss_reward_critic       │ 0.012971781194210052  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00609771441668272   │\n",
       "│ Value/reward                  │ 0.7313148379325867    │\n",
       "│ Time/Total                    │ 287.7486572265625     │\n",
       "│ Time/Rollout                  │ 10.834623336791992    │\n",
       "│ Time/Update                   │ 1.6395761966705322    │\n",
       "│ Time/Epoch                    │ 12.474252700805664    │\n",
       "│ Time/FPS                      │ 164.1781768798828     │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 2.9890401363372803    │\n",
       "│ Metrics/EpCost                │ 104.81818389892578    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 21.0                  │\n",
       "│ Train/Entropy                 │ 1.2794538736343384    │\n",
       "│ Train/KL                      │ 0.01524317730218172   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9969674348831177    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9969674348831177    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9969674348831177    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01806304045021534   │\n",
       "│ Train/LR                      │ 0.0002868000010494143 │\n",
       "│ Train/PolicyStd               │ 0.8719485402107239    │\n",
       "│ TotalEnvSteps                 │ 45056.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013968393206596375 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0012499596923589706 │\n",
       "│ Value/Adv                     │ -0.06340079009532928  │\n",
       "│ Loss/Loss_reward_critic       │ 0.012971781194210052  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00609771441668272   │\n",
       "│ Value/reward                  │ 0.7313148379325867    │\n",
       "│ Time/Total                    │ 287.7486572265625     │\n",
       "│ Time/Rollout                  │ 10.834623336791992    │\n",
       "│ Time/Update                   │ 1.6395761966705322    │\n",
       "│ Time/Epoch                    │ 12.474252700805664    │\n",
       "│ Time/FPS                      │ 164.1781768798828     │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 3.2256314754486084     │\n",
       "│ Metrics/EpCost                │ 102.26087188720703     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 22.0                   │\n",
       "│ Train/Entropy                 │ 1.2717134952545166     │\n",
       "│ Train/KL                      │ 0.012571902014315128   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9984204173088074     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9984204173088074     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9984204173088074     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016271725296974182   │\n",
       "│ Train/LR                      │ 0.00028619999648071826 │\n",
       "│ Train/PolicyStd               │ 0.865044891834259      │\n",
       "│ TotalEnvSteps                 │ 47104.0                │\n",
       "│ Loss/Loss_pi                  │ -0.011981924995779991  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0019864682108163834  │\n",
       "│ Value/Adv                     │ 0.020689908415079117   │\n",
       "│ Loss/Loss_reward_critic       │ 0.010418503545224667   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.002553277648985386  │\n",
       "│ Value/reward                  │ 0.628012478351593      │\n",
       "│ Time/Total                    │ 300.2572021484375      │\n",
       "│ Time/Rollout                  │ 10.863105773925781     │\n",
       "│ Time/Update                   │ 1.6339025497436523     │\n",
       "│ Time/Epoch                    │ 12.497058868408203     │\n",
       "│ Time/FPS                      │ 163.8785858154297      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 3.2256314754486084     │\n",
       "│ Metrics/EpCost                │ 102.26087188720703     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 22.0                   │\n",
       "│ Train/Entropy                 │ 1.2717134952545166     │\n",
       "│ Train/KL                      │ 0.012571902014315128   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9984204173088074     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9984204173088074     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9984204173088074     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016271725296974182   │\n",
       "│ Train/LR                      │ 0.00028619999648071826 │\n",
       "│ Train/PolicyStd               │ 0.865044891834259      │\n",
       "│ TotalEnvSteps                 │ 47104.0                │\n",
       "│ Loss/Loss_pi                  │ -0.011981924995779991  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0019864682108163834  │\n",
       "│ Value/Adv                     │ 0.020689908415079117   │\n",
       "│ Loss/Loss_reward_critic       │ 0.010418503545224667   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.002553277648985386  │\n",
       "│ Value/reward                  │ 0.628012478351593      │\n",
       "│ Time/Total                    │ 300.2572021484375      │\n",
       "│ Time/Rollout                  │ 10.863105773925781     │\n",
       "│ Time/Update                   │ 1.6339025497436523     │\n",
       "│ Time/Epoch                    │ 12.497058868408203     │\n",
       "│ Time/FPS                      │ 163.8785858154297      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 3.5272438526153564     │\n",
       "│ Metrics/EpCost                │ 101.625                │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 23.0                   │\n",
       "│ Train/Entropy                 │ 1.2609983682632446     │\n",
       "│ Train/KL                      │ 0.012731032446026802   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9922804832458496     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9922804832458496     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9922804832458496     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01958245038986206    │\n",
       "│ Train/LR                      │ 0.00028559999191202223 │\n",
       "│ Train/PolicyStd               │ 0.855660617351532      │\n",
       "│ TotalEnvSteps                 │ 49152.0                │\n",
       "│ Loss/Loss_pi                  │ -0.012400567531585693  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0004186425358057022 │\n",
       "│ Value/Adv                     │ -0.26398786902427673   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02103988267481327    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.010621379129588604   │\n",
       "│ Value/reward                  │ 0.7080803513526917     │\n",
       "│ Time/Total                    │ 312.762939453125       │\n",
       "│ Time/Rollout                  │ 10.854605674743652     │\n",
       "│ Time/Update                   │ 1.6396760940551758     │\n",
       "│ Time/Epoch                    │ 12.494321823120117     │\n",
       "│ Time/FPS                      │ 163.91445922851562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 3.5272438526153564     │\n",
       "│ Metrics/EpCost                │ 101.625                │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 23.0                   │\n",
       "│ Train/Entropy                 │ 1.2609983682632446     │\n",
       "│ Train/KL                      │ 0.012731032446026802   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9922804832458496     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9922804832458496     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9922804832458496     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01958245038986206    │\n",
       "│ Train/LR                      │ 0.00028559999191202223 │\n",
       "│ Train/PolicyStd               │ 0.855660617351532      │\n",
       "│ TotalEnvSteps                 │ 49152.0                │\n",
       "│ Loss/Loss_pi                  │ -0.012400567531585693  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0004186425358057022 │\n",
       "│ Value/Adv                     │ -0.26398786902427673   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02103988267481327    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.010621379129588604   │\n",
       "│ Value/reward                  │ 0.7080803513526917     │\n",
       "│ Time/Total                    │ 312.762939453125       │\n",
       "│ Time/Rollout                  │ 10.854605674743652     │\n",
       "│ Time/Update                   │ 1.6396760940551758     │\n",
       "│ Time/Epoch                    │ 12.494321823120117     │\n",
       "│ Time/FPS                      │ 163.91445922851562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 3.6008167266845703    │\n",
       "│ Metrics/EpCost                │ 102.81999969482422    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 24.0                  │\n",
       "│ Train/Entropy                 │ 1.2500824928283691    │\n",
       "│ Train/KL                      │ 0.011539298109710217  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9978740811347961    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9978740811347961    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9978740811347961    │\n",
       "│ Train/PolicyRatio/Std         │ 0.017308901995420456  │\n",
       "│ Train/LR                      │ 0.0002849999873433262 │\n",
       "│ Train/PolicyStd               │ 0.8461747169494629    │\n",
       "│ TotalEnvSteps                 │ 51200.0               │\n",
       "│ Loss/Loss_pi                  │ -0.009022600017488003 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0033779675140976906 │\n",
       "│ Value/Adv                     │ 0.17631319165229797   │\n",
       "│ Loss/Loss_reward_critic       │ 0.005668063648045063  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.015371819026768208 │\n",
       "│ Value/reward                  │ 0.7030925750732422    │\n",
       "│ Time/Total                    │ 325.27557373046875    │\n",
       "│ Time/Rollout                  │ 10.870344161987305    │\n",
       "│ Time/Update                   │ 1.630389928817749     │\n",
       "│ Time/Epoch                    │ 12.500788688659668    │\n",
       "│ Time/FPS                      │ 163.82968139648438    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 3.6008167266845703    │\n",
       "│ Metrics/EpCost                │ 102.81999969482422    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 24.0                  │\n",
       "│ Train/Entropy                 │ 1.2500824928283691    │\n",
       "│ Train/KL                      │ 0.011539298109710217  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9978740811347961    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9978740811347961    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9978740811347961    │\n",
       "│ Train/PolicyRatio/Std         │ 0.017308901995420456  │\n",
       "│ Train/LR                      │ 0.0002849999873433262 │\n",
       "│ Train/PolicyStd               │ 0.8461747169494629    │\n",
       "│ TotalEnvSteps                 │ 51200.0               │\n",
       "│ Loss/Loss_pi                  │ -0.009022600017488003 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0033779675140976906 │\n",
       "│ Value/Adv                     │ 0.17631319165229797   │\n",
       "│ Loss/Loss_reward_critic       │ 0.005668063648045063  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.015371819026768208 │\n",
       "│ Value/reward                  │ 0.7030925750732422    │\n",
       "│ Time/Total                    │ 325.27557373046875    │\n",
       "│ Time/Rollout                  │ 10.870344161987305    │\n",
       "│ Time/Update                   │ 1.630389928817749     │\n",
       "│ Time/Epoch                    │ 12.500788688659668    │\n",
       "│ Time/FPS                      │ 163.82968139648438    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 4.021853446960449      │\n",
       "│ Metrics/EpCost                │ 99.9800033569336       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 25.0                   │\n",
       "│ Train/Entropy                 │ 1.2396085262298584     │\n",
       "│ Train/KL                      │ 0.012300319969654083   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9967433214187622     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9967433214187622     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9967433214187622     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017164230346679688   │\n",
       "│ Train/LR                      │ 0.00028440001187846065 │\n",
       "│ Train/PolicyStd               │ 0.8370752334594727     │\n",
       "│ TotalEnvSteps                 │ 53248.0                │\n",
       "│ Loss/Loss_pi                  │ -0.010986581444740295  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0019639814272522926 │\n",
       "│ Value/Adv                     │ -0.19223250448703766   │\n",
       "│ Loss/Loss_reward_critic       │ 0.013032296672463417   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.007364233024418354   │\n",
       "│ Value/reward                  │ 0.9199461340904236     │\n",
       "│ Time/Total                    │ 337.73919677734375     │\n",
       "│ Time/Rollout                  │ 10.812210083007812     │\n",
       "│ Time/Update                   │ 1.6395344734191895     │\n",
       "│ Time/Epoch                    │ 12.451787948608398     │\n",
       "│ Time/FPS                      │ 164.47438049316406     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 4.021853446960449      │\n",
       "│ Metrics/EpCost                │ 99.9800033569336       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 25.0                   │\n",
       "│ Train/Entropy                 │ 1.2396085262298584     │\n",
       "│ Train/KL                      │ 0.012300319969654083   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9967433214187622     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9967433214187622     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9967433214187622     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017164230346679688   │\n",
       "│ Train/LR                      │ 0.00028440001187846065 │\n",
       "│ Train/PolicyStd               │ 0.8370752334594727     │\n",
       "│ TotalEnvSteps                 │ 53248.0                │\n",
       "│ Loss/Loss_pi                  │ -0.010986581444740295  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0019639814272522926 │\n",
       "│ Value/Adv                     │ -0.19223250448703766   │\n",
       "│ Loss/Loss_reward_critic       │ 0.013032296672463417   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.007364233024418354   │\n",
       "│ Value/reward                  │ 0.9199461340904236     │\n",
       "│ Time/Total                    │ 337.73919677734375     │\n",
       "│ Time/Rollout                  │ 10.812210083007812     │\n",
       "│ Time/Update                   │ 1.6395344734191895     │\n",
       "│ Time/Epoch                    │ 12.451787948608398     │\n",
       "│ Time/FPS                      │ 164.47438049316406     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 4.37286376953125      │\n",
       "│ Metrics/EpCost                │ 100.72000122070312    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 26.0                  │\n",
       "│ Train/Entropy                 │ 1.2291760444641113    │\n",
       "│ Train/KL                      │ 0.015130409970879555  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0014886856079102    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0014886856079102    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0014886856079102    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01836075820028782   │\n",
       "│ Train/LR                      │ 0.0002838000073097646 │\n",
       "│ Train/PolicyStd               │ 0.8283531069755554    │\n",
       "│ TotalEnvSteps                 │ 55296.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017799407243728638 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.006812825798988342 │\n",
       "│ Value/Adv                     │ 0.06338783353567123   │\n",
       "│ Loss/Loss_reward_critic       │ 0.010493045672774315  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.002539250999689102 │\n",
       "│ Value/reward                  │ 0.602063775062561     │\n",
       "│ Time/Total                    │ 350.2785949707031     │\n",
       "│ Time/Rollout                  │ 10.878436088562012    │\n",
       "│ Time/Update                   │ 1.6492199897766113    │\n",
       "│ Time/Epoch                    │ 12.52769660949707     │\n",
       "│ Time/FPS                      │ 163.477783203125      │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 4.37286376953125      │\n",
       "│ Metrics/EpCost                │ 100.72000122070312    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 26.0                  │\n",
       "│ Train/Entropy                 │ 1.2291760444641113    │\n",
       "│ Train/KL                      │ 0.015130409970879555  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0014886856079102    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0014886856079102    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0014886856079102    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01836075820028782   │\n",
       "│ Train/LR                      │ 0.0002838000073097646 │\n",
       "│ Train/PolicyStd               │ 0.8283531069755554    │\n",
       "│ TotalEnvSteps                 │ 55296.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017799407243728638 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.006812825798988342 │\n",
       "│ Value/Adv                     │ 0.06338783353567123   │\n",
       "│ Loss/Loss_reward_critic       │ 0.010493045672774315  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.002539250999689102 │\n",
       "│ Value/reward                  │ 0.602063775062561     │\n",
       "│ Time/Total                    │ 350.2785949707031     │\n",
       "│ Time/Rollout                  │ 10.878436088562012    │\n",
       "│ Time/Update                   │ 1.6492199897766113    │\n",
       "│ Time/Epoch                    │ 12.52769660949707     │\n",
       "│ Time/FPS                      │ 163.477783203125      │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 4.780488967895508     │\n",
       "│ Metrics/EpCost                │ 100.5                 │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 27.0                  │\n",
       "│ Train/Entropy                 │ 1.2251722812652588    │\n",
       "│ Train/KL                      │ 0.014993689954280853  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9963825345039368    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9963825345039368    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9963825345039368    │\n",
       "│ Train/PolicyRatio/Std         │ 0.017235008999705315  │\n",
       "│ Train/LR                      │ 0.0002832000027410686 │\n",
       "│ Train/PolicyStd               │ 0.8252444267272949    │\n",
       "│ TotalEnvSteps                 │ 57344.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015663612633943558 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00213579460978508   │\n",
       "│ Value/Adv                     │ 0.08570751547813416   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014171351678669453  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.003678306005895138  │\n",
       "│ Value/reward                  │ 0.7380086183547974    │\n",
       "│ Time/Total                    │ 362.79931640625       │\n",
       "│ Time/Rollout                  │ 10.844100952148438    │\n",
       "│ Time/Update                   │ 1.6641483306884766    │\n",
       "│ Time/Epoch                    │ 12.508299827575684    │\n",
       "│ Time/FPS                      │ 163.73129272460938    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 4.780488967895508     │\n",
       "│ Metrics/EpCost                │ 100.5                 │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 27.0                  │\n",
       "│ Train/Entropy                 │ 1.2251722812652588    │\n",
       "│ Train/KL                      │ 0.014993689954280853  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9963825345039368    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9963825345039368    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9963825345039368    │\n",
       "│ Train/PolicyRatio/Std         │ 0.017235008999705315  │\n",
       "│ Train/LR                      │ 0.0002832000027410686 │\n",
       "│ Train/PolicyStd               │ 0.8252444267272949    │\n",
       "│ TotalEnvSteps                 │ 57344.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015663612633943558 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00213579460978508   │\n",
       "│ Value/Adv                     │ 0.08570751547813416   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014171351678669453  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.003678306005895138  │\n",
       "│ Value/reward                  │ 0.7380086183547974    │\n",
       "│ Time/Total                    │ 362.79931640625       │\n",
       "│ Time/Rollout                  │ 10.844100952148438    │\n",
       "│ Time/Update                   │ 1.6641483306884766    │\n",
       "│ Time/Epoch                    │ 12.508299827575684    │\n",
       "│ Time/FPS                      │ 163.73129272460938    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 5.309787750244141      │\n",
       "│ Metrics/EpCost                │ 99.68000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 28.0                   │\n",
       "│ Train/Entropy                 │ 1.2273558378219604     │\n",
       "│ Train/KL                      │ 0.014778688549995422   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9971588850021362     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9971588850021362     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9971588850021362     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016442129388451576   │\n",
       "│ Train/LR                      │ 0.0002825999981723726  │\n",
       "│ Train/PolicyStd               │ 0.8271816968917847     │\n",
       "│ TotalEnvSteps                 │ 59392.0                │\n",
       "│ Loss/Loss_pi                  │ -0.016080375760793686  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0004167631268501282 │\n",
       "│ Value/Adv                     │ 0.06395785510540009    │\n",
       "│ Loss/Loss_reward_critic       │ 0.00882886815816164    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0053424835205078125 │\n",
       "│ Value/reward                  │ 0.939166784286499      │\n",
       "│ Time/Total                    │ 376.5455627441406      │\n",
       "│ Time/Rollout                  │ 11.417545318603516     │\n",
       "│ Time/Update                   │ 2.3169777393341064     │\n",
       "│ Time/Epoch                    │ 13.734567642211914     │\n",
       "│ Time/FPS                      │ 149.11282348632812     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 5.309787750244141      │\n",
       "│ Metrics/EpCost                │ 99.68000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 28.0                   │\n",
       "│ Train/Entropy                 │ 1.2273558378219604     │\n",
       "│ Train/KL                      │ 0.014778688549995422   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9971588850021362     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9971588850021362     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9971588850021362     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016442129388451576   │\n",
       "│ Train/LR                      │ 0.0002825999981723726  │\n",
       "│ Train/PolicyStd               │ 0.8271816968917847     │\n",
       "│ TotalEnvSteps                 │ 59392.0                │\n",
       "│ Loss/Loss_pi                  │ -0.016080375760793686  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0004167631268501282 │\n",
       "│ Value/Adv                     │ 0.06395785510540009    │\n",
       "│ Loss/Loss_reward_critic       │ 0.00882886815816164    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0053424835205078125 │\n",
       "│ Value/reward                  │ 0.939166784286499      │\n",
       "│ Time/Total                    │ 376.5455627441406      │\n",
       "│ Time/Rollout                  │ 11.417545318603516     │\n",
       "│ Time/Update                   │ 2.3169777393341064     │\n",
       "│ Time/Epoch                    │ 13.734567642211914     │\n",
       "│ Time/FPS                      │ 149.11282348632812     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 5.7572550773620605     │\n",
       "│ Metrics/EpCost                │ 100.4000015258789      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 29.0                   │\n",
       "│ Train/Entropy                 │ 1.2186681032180786     │\n",
       "│ Train/KL                      │ 0.016731498762965202   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9950565099716187     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9950565099716187     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9950565099716187     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019142385572195053   │\n",
       "│ Train/LR                      │ 0.00028199999360367656 │\n",
       "│ Train/PolicyStd               │ 0.8196345567703247     │\n",
       "│ TotalEnvSteps                 │ 61440.0                │\n",
       "│ Loss/Loss_pi                  │ -0.01667034439742565   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0005899686366319656 │\n",
       "│ Value/Adv                     │ -0.04969638213515282   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018560990691184998   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.009732122533023357   │\n",
       "│ Value/reward                  │ 1.0326039791107178     │\n",
       "│ Time/Total                    │ 391.35491943359375     │\n",
       "│ Time/Rollout                  │ 12.741903305053711     │\n",
       "│ Time/Update                   │ 2.055511236190796      │\n",
       "│ Time/Epoch                    │ 14.797460556030273     │\n",
       "│ Time/FPS                      │ 138.40213012695312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 5.7572550773620605     │\n",
       "│ Metrics/EpCost                │ 100.4000015258789      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 29.0                   │\n",
       "│ Train/Entropy                 │ 1.2186681032180786     │\n",
       "│ Train/KL                      │ 0.016731498762965202   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9950565099716187     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9950565099716187     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9950565099716187     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019142385572195053   │\n",
       "│ Train/LR                      │ 0.00028199999360367656 │\n",
       "│ Train/PolicyStd               │ 0.8196345567703247     │\n",
       "│ TotalEnvSteps                 │ 61440.0                │\n",
       "│ Loss/Loss_pi                  │ -0.01667034439742565   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0005899686366319656 │\n",
       "│ Value/Adv                     │ -0.04969638213515282   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018560990691184998   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.009732122533023357   │\n",
       "│ Value/reward                  │ 1.0326039791107178     │\n",
       "│ Time/Total                    │ 391.35491943359375     │\n",
       "│ Time/Rollout                  │ 12.741903305053711     │\n",
       "│ Time/Update                   │ 2.055511236190796      │\n",
       "│ Time/Epoch                    │ 14.797460556030273     │\n",
       "│ Time/FPS                      │ 138.40213012695312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 6.132941722869873      │\n",
       "│ Metrics/EpCost                │ 99.16000366210938      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 30.0                   │\n",
       "│ Train/Entropy                 │ 1.1984813213348389     │\n",
       "│ Train/KL                      │ 0.0105051314458251     │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0053808689117432     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0053808689117432     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0053808689117432     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01577853038907051    │\n",
       "│ Train/LR                      │ 0.00028139998903498054 │\n",
       "│ Train/PolicyStd               │ 0.8027752041816711     │\n",
       "│ TotalEnvSteps                 │ 63488.0                │\n",
       "│ Loss/Loss_pi                  │ -0.012179319746792316  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004491024650633335   │\n",
       "│ Value/Adv                     │ 0.08440300822257996    │\n",
       "│ Loss/Loss_reward_critic       │ 0.011558321304619312   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.007002669386565685  │\n",
       "│ Value/reward                  │ 0.9794994592666626     │\n",
       "│ Time/Total                    │ 404.73486328125        │\n",
       "│ Time/Rollout                  │ 11.68137264251709      │\n",
       "│ Time/Update                   │ 1.6842079162597656     │\n",
       "│ Time/Epoch                    │ 13.365620613098145     │\n",
       "│ Time/FPS                      │ 153.2289581298828      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 6.132941722869873      │\n",
       "│ Metrics/EpCost                │ 99.16000366210938      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 30.0                   │\n",
       "│ Train/Entropy                 │ 1.1984813213348389     │\n",
       "│ Train/KL                      │ 0.0105051314458251     │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0053808689117432     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0053808689117432     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0053808689117432     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01577853038907051    │\n",
       "│ Train/LR                      │ 0.00028139998903498054 │\n",
       "│ Train/PolicyStd               │ 0.8027752041816711     │\n",
       "│ TotalEnvSteps                 │ 63488.0                │\n",
       "│ Loss/Loss_pi                  │ -0.012179319746792316  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004491024650633335   │\n",
       "│ Value/Adv                     │ 0.08440300822257996    │\n",
       "│ Loss/Loss_reward_critic       │ 0.011558321304619312   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.007002669386565685  │\n",
       "│ Value/reward                  │ 0.9794994592666626     │\n",
       "│ Time/Total                    │ 404.73486328125        │\n",
       "│ Time/Rollout                  │ 11.68137264251709      │\n",
       "│ Time/Update                   │ 1.6842079162597656     │\n",
       "│ Time/Epoch                    │ 13.365620613098145     │\n",
       "│ Time/FPS                      │ 153.2289581298828      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 6.558402061462402      │\n",
       "│ Metrics/EpCost                │ 91.66000366210938      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 31.0                   │\n",
       "│ Train/Entropy                 │ 1.1817774772644043     │\n",
       "│ Train/KL                      │ 0.013262389227747917   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0005052089691162     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0005052089691162     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0005052089691162     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01868259906768799    │\n",
       "│ Train/LR                      │ 0.00028080001357011497 │\n",
       "│ Train/PolicyStd               │ 0.7893442511558533     │\n",
       "│ TotalEnvSteps                 │ 65536.0                │\n",
       "│ Loss/Loss_pi                  │ -0.01589914783835411   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0037198280915617943 │\n",
       "│ Value/Adv                     │ 0.12132398039102554    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017515890300273895   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.005957568995654583   │\n",
       "│ Value/reward                  │ 1.0039819478988647     │\n",
       "│ Time/Total                    │ 417.2439880371094      │\n",
       "│ Time/Rollout                  │ 10.856437683105469     │\n",
       "│ Time/Update                   │ 1.6411726474761963     │\n",
       "│ Time/Epoch                    │ 12.497661590576172     │\n",
       "│ Time/FPS                      │ 163.8706817626953      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 6.558402061462402      │\n",
       "│ Metrics/EpCost                │ 91.66000366210938      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 31.0                   │\n",
       "│ Train/Entropy                 │ 1.1817774772644043     │\n",
       "│ Train/KL                      │ 0.013262389227747917   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0005052089691162     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0005052089691162     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0005052089691162     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01868259906768799    │\n",
       "│ Train/LR                      │ 0.00028080001357011497 │\n",
       "│ Train/PolicyStd               │ 0.7893442511558533     │\n",
       "│ TotalEnvSteps                 │ 65536.0                │\n",
       "│ Loss/Loss_pi                  │ -0.01589914783835411   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0037198280915617943 │\n",
       "│ Value/Adv                     │ 0.12132398039102554    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017515890300273895   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.005957568995654583   │\n",
       "│ Value/reward                  │ 1.0039819478988647     │\n",
       "│ Time/Total                    │ 417.2439880371094      │\n",
       "│ Time/Rollout                  │ 10.856437683105469     │\n",
       "│ Time/Update                   │ 1.6411726474761963     │\n",
       "│ Time/Epoch                    │ 12.497661590576172     │\n",
       "│ Time/FPS                      │ 163.8706817626953      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 7.004364490509033      │\n",
       "│ Metrics/EpCost                │ 92.37999725341797      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 32.0                   │\n",
       "│ Train/Entropy                 │ 1.168886661529541      │\n",
       "│ Train/KL                      │ 0.010483227670192719   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.000675082206726      │\n",
       "│ Train/PolicyRatio/Min         │ 1.000675082206726      │\n",
       "│ Train/PolicyRatio/Max         │ 1.000675082206726      │\n",
       "│ Train/PolicyRatio/Std         │ 0.018290234729647636   │\n",
       "│ Train/LR                      │ 0.00028020000900141895 │\n",
       "│ Train/PolicyStd               │ 0.7792171835899353     │\n",
       "│ TotalEnvSteps                 │ 67584.0                │\n",
       "│ Loss/Loss_pi                  │ -0.014326108619570732  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0015730392187833786  │\n",
       "│ Value/Adv                     │ 0.158444344997406      │\n",
       "│ Loss/Loss_reward_critic       │ 0.018380988389253616   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0008650980889797211  │\n",
       "│ Value/reward                  │ 1.0467336177825928     │\n",
       "│ Time/Total                    │ 429.822021484375       │\n",
       "│ Time/Rollout                  │ 10.905802726745605     │\n",
       "│ Time/Update                   │ 1.6598122119903564     │\n",
       "│ Time/Epoch                    │ 12.565667152404785     │\n",
       "│ Time/FPS                      │ 162.98379516601562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 7.004364490509033      │\n",
       "│ Metrics/EpCost                │ 92.37999725341797      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 32.0                   │\n",
       "│ Train/Entropy                 │ 1.168886661529541      │\n",
       "│ Train/KL                      │ 0.010483227670192719   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.000675082206726      │\n",
       "│ Train/PolicyRatio/Min         │ 1.000675082206726      │\n",
       "│ Train/PolicyRatio/Max         │ 1.000675082206726      │\n",
       "│ Train/PolicyRatio/Std         │ 0.018290234729647636   │\n",
       "│ Train/LR                      │ 0.00028020000900141895 │\n",
       "│ Train/PolicyStd               │ 0.7792171835899353     │\n",
       "│ TotalEnvSteps                 │ 67584.0                │\n",
       "│ Loss/Loss_pi                  │ -0.014326108619570732  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0015730392187833786  │\n",
       "│ Value/Adv                     │ 0.158444344997406      │\n",
       "│ Loss/Loss_reward_critic       │ 0.018380988389253616   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0008650980889797211  │\n",
       "│ Value/reward                  │ 1.0467336177825928     │\n",
       "│ Time/Total                    │ 429.822021484375       │\n",
       "│ Time/Rollout                  │ 10.905802726745605     │\n",
       "│ Time/Update                   │ 1.6598122119903564     │\n",
       "│ Time/Epoch                    │ 12.565667152404785     │\n",
       "│ Time/FPS                      │ 162.98379516601562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 7.460451602935791     │\n",
       "│ Metrics/EpCost                │ 91.94000244140625     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 33.0                  │\n",
       "│ Train/Entropy                 │ 1.16200852394104      │\n",
       "│ Train/KL                      │ 0.012332320213317871  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0002392530441284    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0002392530441284    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0002392530441284    │\n",
       "│ Train/PolicyRatio/Std         │ 0.016118744388222694  │\n",
       "│ Train/LR                      │ 0.0002796000044327229 │\n",
       "│ Train/PolicyStd               │ 0.7738130688667297    │\n",
       "│ TotalEnvSteps                 │ 69632.0               │\n",
       "│ Loss/Loss_pi                  │ -0.007909417152404785 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.006416691467165947  │\n",
       "│ Value/Adv                     │ 0.11063764989376068   │\n",
       "│ Loss/Loss_reward_critic       │ 0.020124852657318115  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.001743864268064499  │\n",
       "│ Value/reward                  │ 1.2008213996887207    │\n",
       "│ Time/Total                    │ 442.3132629394531     │\n",
       "│ Time/Rollout                  │ 10.811177253723145    │\n",
       "│ Time/Update                   │ 1.6676898002624512    │\n",
       "│ Time/Epoch                    │ 12.478910446166992    │\n",
       "│ Time/FPS                      │ 164.11691284179688    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 7.460451602935791     │\n",
       "│ Metrics/EpCost                │ 91.94000244140625     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 33.0                  │\n",
       "│ Train/Entropy                 │ 1.16200852394104      │\n",
       "│ Train/KL                      │ 0.012332320213317871  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0002392530441284    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0002392530441284    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0002392530441284    │\n",
       "│ Train/PolicyRatio/Std         │ 0.016118744388222694  │\n",
       "│ Train/LR                      │ 0.0002796000044327229 │\n",
       "│ Train/PolicyStd               │ 0.7738130688667297    │\n",
       "│ TotalEnvSteps                 │ 69632.0               │\n",
       "│ Loss/Loss_pi                  │ -0.007909417152404785 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.006416691467165947  │\n",
       "│ Value/Adv                     │ 0.11063764989376068   │\n",
       "│ Loss/Loss_reward_critic       │ 0.020124852657318115  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.001743864268064499  │\n",
       "│ Value/reward                  │ 1.2008213996887207    │\n",
       "│ Time/Total                    │ 442.3132629394531     │\n",
       "│ Time/Rollout                  │ 10.811177253723145    │\n",
       "│ Time/Update                   │ 1.6676898002624512    │\n",
       "│ Time/Epoch                    │ 12.478910446166992    │\n",
       "│ Time/FPS                      │ 164.11691284179688    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 7.906324863433838      │\n",
       "│ Metrics/EpCost                │ 85.58000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 34.0                   │\n",
       "│ Train/Entropy                 │ 1.15890634059906       │\n",
       "│ Train/KL                      │ 0.01299281232059002    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9970641136169434     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9970641136169434     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9970641136169434     │\n",
       "│ Train/PolicyRatio/Std         │ 0.0170939639210701     │\n",
       "│ Train/LR                      │ 0.0002789999998640269  │\n",
       "│ Train/PolicyStd               │ 0.771396279335022      │\n",
       "│ TotalEnvSteps                 │ 71680.0                │\n",
       "│ Loss/Loss_pi                  │ -0.012886963784694672  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0049775466322898865 │\n",
       "│ Value/Adv                     │ 0.07060789316892624    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01557566225528717    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.004549190402030945  │\n",
       "│ Value/reward                  │ 1.3455082178115845     │\n",
       "│ Time/Total                    │ 455.55450439453125     │\n",
       "│ Time/Rollout                  │ 11.257814407348633     │\n",
       "│ Time/Update                   │ 1.9717967510223389     │\n",
       "│ Time/Epoch                    │ 13.229656219482422     │\n",
       "│ Time/FPS                      │ 154.80372619628906     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 7.906324863433838      │\n",
       "│ Metrics/EpCost                │ 85.58000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 34.0                   │\n",
       "│ Train/Entropy                 │ 1.15890634059906       │\n",
       "│ Train/KL                      │ 0.01299281232059002    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9970641136169434     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9970641136169434     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9970641136169434     │\n",
       "│ Train/PolicyRatio/Std         │ 0.0170939639210701     │\n",
       "│ Train/LR                      │ 0.0002789999998640269  │\n",
       "│ Train/PolicyStd               │ 0.771396279335022      │\n",
       "│ TotalEnvSteps                 │ 71680.0                │\n",
       "│ Loss/Loss_pi                  │ -0.012886963784694672  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0049775466322898865 │\n",
       "│ Value/Adv                     │ 0.07060789316892624    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01557566225528717    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.004549190402030945  │\n",
       "│ Value/reward                  │ 1.3455082178115845     │\n",
       "│ Time/Total                    │ 455.55450439453125     │\n",
       "│ Time/Rollout                  │ 11.257814407348633     │\n",
       "│ Time/Update                   │ 1.9717967510223389     │\n",
       "│ Time/Epoch                    │ 13.229656219482422     │\n",
       "│ Time/FPS                      │ 154.80372619628906     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 8.375836372375488      │\n",
       "│ Metrics/EpCost                │ 90.0199966430664       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 35.0                   │\n",
       "│ Train/Entropy                 │ 1.1432294845581055     │\n",
       "│ Train/KL                      │ 0.013505633920431137   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9977685809135437     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9977685809135437     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9977685809135437     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016789959743618965   │\n",
       "│ Train/LR                      │ 0.0002783999952953309  │\n",
       "│ Train/PolicyStd               │ 0.7594189047813416     │\n",
       "│ TotalEnvSteps                 │ 73728.0                │\n",
       "│ Loss/Loss_pi                  │ -0.014190047979354858  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0013030841946601868 │\n",
       "│ Value/Adv                     │ 0.08958993852138519    │\n",
       "│ Loss/Loss_reward_critic       │ 0.014349980279803276   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0012256819754838943 │\n",
       "│ Value/reward                  │ 1.1438820362091064     │\n",
       "│ Time/Total                    │ 469.2055969238281      │\n",
       "│ Time/Rollout                  │ 11.743515014648438     │\n",
       "│ Time/Update                   │ 1.8936638832092285     │\n",
       "│ Time/Epoch                    │ 13.63724136352539      │\n",
       "│ Time/FPS                      │ 150.177001953125       │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 8.375836372375488      │\n",
       "│ Metrics/EpCost                │ 90.0199966430664       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 35.0                   │\n",
       "│ Train/Entropy                 │ 1.1432294845581055     │\n",
       "│ Train/KL                      │ 0.013505633920431137   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9977685809135437     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9977685809135437     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9977685809135437     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016789959743618965   │\n",
       "│ Train/LR                      │ 0.0002783999952953309  │\n",
       "│ Train/PolicyStd               │ 0.7594189047813416     │\n",
       "│ TotalEnvSteps                 │ 73728.0                │\n",
       "│ Loss/Loss_pi                  │ -0.014190047979354858  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0013030841946601868 │\n",
       "│ Value/Adv                     │ 0.08958993852138519    │\n",
       "│ Loss/Loss_reward_critic       │ 0.014349980279803276   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0012256819754838943 │\n",
       "│ Value/reward                  │ 1.1438820362091064     │\n",
       "│ Time/Total                    │ 469.2055969238281      │\n",
       "│ Time/Rollout                  │ 11.743515014648438     │\n",
       "│ Time/Update                   │ 1.8936638832092285     │\n",
       "│ Time/Epoch                    │ 13.63724136352539      │\n",
       "│ Time/FPS                      │ 150.177001953125       │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 8.948758125305176      │\n",
       "│ Metrics/EpCost                │ 90.76000213623047      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 36.0                   │\n",
       "│ Train/Entropy                 │ 1.1323885917663574     │\n",
       "│ Train/KL                      │ 0.013498956337571144   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9993711709976196     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9993711709976196     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9993711709976196     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017824852839112282   │\n",
       "│ Train/LR                      │ 0.00027779999072663486 │\n",
       "│ Train/PolicyStd               │ 0.7511469125747681     │\n",
       "│ TotalEnvSteps                 │ 75776.0                │\n",
       "│ Loss/Loss_pi                  │ -0.016291851177811623  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0021018031984567642 │\n",
       "│ Value/Adv                     │ -0.0006805360317230225 │\n",
       "│ Loss/Loss_reward_critic       │ 0.017941657453775406   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00359167717397213    │\n",
       "│ Value/reward                  │ 1.3259936571121216     │\n",
       "│ Time/Total                    │ 482.1116027832031      │\n",
       "│ Time/Rollout                  │ 11.19875717163086      │\n",
       "│ Time/Update                   │ 1.6936850547790527     │\n",
       "│ Time/Epoch                    │ 12.892487525939941     │\n",
       "│ Time/FPS                      │ 158.85220336914062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 8.948758125305176      │\n",
       "│ Metrics/EpCost                │ 90.76000213623047      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 36.0                   │\n",
       "│ Train/Entropy                 │ 1.1323885917663574     │\n",
       "│ Train/KL                      │ 0.013498956337571144   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9993711709976196     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9993711709976196     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9993711709976196     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017824852839112282   │\n",
       "│ Train/LR                      │ 0.00027779999072663486 │\n",
       "│ Train/PolicyStd               │ 0.7511469125747681     │\n",
       "│ TotalEnvSteps                 │ 75776.0                │\n",
       "│ Loss/Loss_pi                  │ -0.016291851177811623  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0021018031984567642 │\n",
       "│ Value/Adv                     │ -0.0006805360317230225 │\n",
       "│ Loss/Loss_reward_critic       │ 0.017941657453775406   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00359167717397213    │\n",
       "│ Value/reward                  │ 1.3259936571121216     │\n",
       "│ Time/Total                    │ 482.1116027832031      │\n",
       "│ Time/Rollout                  │ 11.19875717163086      │\n",
       "│ Time/Update                   │ 1.6936850547790527     │\n",
       "│ Time/Epoch                    │ 12.892487525939941     │\n",
       "│ Time/FPS                      │ 158.85220336914062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 9.23681926727295       │\n",
       "│ Metrics/EpCost                │ 92.76000213623047      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 37.0                   │\n",
       "│ Train/Entropy                 │ 1.1255080699920654     │\n",
       "│ Train/KL                      │ 0.013289416208863258   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0066964626312256     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0066964626312256     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0066964626312256     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016671543940901756   │\n",
       "│ Train/LR                      │ 0.00027719998615793884 │\n",
       "│ Train/PolicyStd               │ 0.7459095120429993     │\n",
       "│ TotalEnvSteps                 │ 77824.0                │\n",
       "│ Loss/Loss_pi                  │ -0.010747266001999378  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005544585175812244   │\n",
       "│ Value/Adv                     │ -0.08960802853107452   │\n",
       "│ Loss/Loss_reward_critic       │ 0.020648520439863205   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002706862986087799   │\n",
       "│ Value/reward                  │ 1.3779312372207642     │\n",
       "│ Time/Total                    │ 494.6525573730469      │\n",
       "│ Time/Rollout                  │ 10.848127365112305     │\n",
       "│ Time/Update                   │ 1.6814548969268799     │\n",
       "│ Time/Epoch                    │ 12.529623985290527     │\n",
       "│ Time/FPS                      │ 163.45263671875        │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 9.23681926727295       │\n",
       "│ Metrics/EpCost                │ 92.76000213623047      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 37.0                   │\n",
       "│ Train/Entropy                 │ 1.1255080699920654     │\n",
       "│ Train/KL                      │ 0.013289416208863258   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0066964626312256     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0066964626312256     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0066964626312256     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016671543940901756   │\n",
       "│ Train/LR                      │ 0.00027719998615793884 │\n",
       "│ Train/PolicyStd               │ 0.7459095120429993     │\n",
       "│ TotalEnvSteps                 │ 77824.0                │\n",
       "│ Loss/Loss_pi                  │ -0.010747266001999378  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005544585175812244   │\n",
       "│ Value/Adv                     │ -0.08960802853107452   │\n",
       "│ Loss/Loss_reward_critic       │ 0.020648520439863205   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002706862986087799   │\n",
       "│ Value/reward                  │ 1.3779312372207642     │\n",
       "│ Time/Total                    │ 494.6525573730469      │\n",
       "│ Time/Rollout                  │ 10.848127365112305     │\n",
       "│ Time/Update                   │ 1.6814548969268799     │\n",
       "│ Time/Epoch                    │ 12.529623985290527     │\n",
       "│ Time/FPS                      │ 163.45263671875        │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 9.577013969421387      │\n",
       "│ Metrics/EpCost                │ 93.73999786376953      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 38.0                   │\n",
       "│ Train/Entropy                 │ 1.1137317419052124     │\n",
       "│ Train/KL                      │ 0.011997600086033344   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9979777336120605     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9979777336120605     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9979777336120605     │\n",
       "│ Train/PolicyRatio/Std         │ 0.015639426186680794   │\n",
       "│ Train/LR                      │ 0.00027660001069307327 │\n",
       "│ Train/PolicyStd               │ 0.7371955513954163     │\n",
       "│ TotalEnvSteps                 │ 79872.0                │\n",
       "│ Loss/Loss_pi                  │ -0.011365659534931183  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0006183935329318047 │\n",
       "│ Value/Adv                     │ 0.012583564966917038   │\n",
       "│ Loss/Loss_reward_critic       │ 0.010807998478412628   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.009840521961450577  │\n",
       "│ Value/reward                  │ 1.0419210195541382     │\n",
       "│ Time/Total                    │ 507.2038269042969      │\n",
       "│ Time/Rollout                  │ 10.8665771484375       │\n",
       "│ Time/Update                   │ 1.6725714206695557     │\n",
       "│ Time/Epoch                    │ 12.539190292358398     │\n",
       "│ Time/FPS                      │ 163.32794189453125     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 9.577013969421387      │\n",
       "│ Metrics/EpCost                │ 93.73999786376953      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 38.0                   │\n",
       "│ Train/Entropy                 │ 1.1137317419052124     │\n",
       "│ Train/KL                      │ 0.011997600086033344   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9979777336120605     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9979777336120605     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9979777336120605     │\n",
       "│ Train/PolicyRatio/Std         │ 0.015639426186680794   │\n",
       "│ Train/LR                      │ 0.00027660001069307327 │\n",
       "│ Train/PolicyStd               │ 0.7371955513954163     │\n",
       "│ TotalEnvSteps                 │ 79872.0                │\n",
       "│ Loss/Loss_pi                  │ -0.011365659534931183  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0006183935329318047 │\n",
       "│ Value/Adv                     │ 0.012583564966917038   │\n",
       "│ Loss/Loss_reward_critic       │ 0.010807998478412628   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.009840521961450577  │\n",
       "│ Value/reward                  │ 1.0419210195541382     │\n",
       "│ Time/Total                    │ 507.2038269042969      │\n",
       "│ Time/Rollout                  │ 10.8665771484375       │\n",
       "│ Time/Update                   │ 1.6725714206695557     │\n",
       "│ Time/Epoch                    │ 12.539190292358398     │\n",
       "│ Time/FPS                      │ 163.32794189453125     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 10.065084457397461     │\n",
       "│ Metrics/EpCost                │ 96.9000015258789       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 39.0                   │\n",
       "│ Train/Entropy                 │ 1.1081969738006592     │\n",
       "│ Train/KL                      │ 0.011175721883773804   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9993974566459656     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9993974566459656     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9993974566459656     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01616147719323635    │\n",
       "│ Train/LR                      │ 0.00027600000612437725 │\n",
       "│ Train/PolicyStd               │ 0.7331734895706177     │\n",
       "│ TotalEnvSteps                 │ 81920.0                │\n",
       "│ Loss/Loss_pi                  │ -0.012259961105883121  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0008943015709519386 │\n",
       "│ Value/Adv                     │ -0.028257101774215698  │\n",
       "│ Loss/Loss_reward_critic       │ 0.017812173813581467   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0070041753351688385  │\n",
       "│ Value/reward                  │ 1.4508737325668335     │\n",
       "│ Time/Total                    │ 519.9083862304688      │\n",
       "│ Time/Rollout                  │ 10.974514961242676     │\n",
       "│ Time/Update                   │ 1.718247652053833      │\n",
       "│ Time/Epoch                    │ 12.692813873291016     │\n",
       "│ Time/FPS                      │ 161.3511505126953      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 10.065084457397461     │\n",
       "│ Metrics/EpCost                │ 96.9000015258789       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 39.0                   │\n",
       "│ Train/Entropy                 │ 1.1081969738006592     │\n",
       "│ Train/KL                      │ 0.011175721883773804   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9993974566459656     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9993974566459656     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9993974566459656     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01616147719323635    │\n",
       "│ Train/LR                      │ 0.00027600000612437725 │\n",
       "│ Train/PolicyStd               │ 0.7331734895706177     │\n",
       "│ TotalEnvSteps                 │ 81920.0                │\n",
       "│ Loss/Loss_pi                  │ -0.012259961105883121  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0008943015709519386 │\n",
       "│ Value/Adv                     │ -0.028257101774215698  │\n",
       "│ Loss/Loss_reward_critic       │ 0.017812173813581467   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0070041753351688385  │\n",
       "│ Value/reward                  │ 1.4508737325668335     │\n",
       "│ Time/Total                    │ 519.9083862304688      │\n",
       "│ Time/Rollout                  │ 10.974514961242676     │\n",
       "│ Time/Update                   │ 1.718247652053833      │\n",
       "│ Time/Epoch                    │ 12.692813873291016     │\n",
       "│ Time/FPS                      │ 161.3511505126953      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 10.568114280700684     │\n",
       "│ Metrics/EpCost                │ 78.31999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 40.0                   │\n",
       "│ Train/Entropy                 │ 1.093042016029358      │\n",
       "│ Train/KL                      │ 0.012516036629676819   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.003492832183838      │\n",
       "│ Train/PolicyRatio/Min         │ 1.003492832183838      │\n",
       "│ Train/PolicyRatio/Max         │ 1.003492832183838      │\n",
       "│ Train/PolicyRatio/Std         │ 0.016680225729942322   │\n",
       "│ Train/LR                      │ 0.00027540000155568123 │\n",
       "│ Train/PolicyStd               │ 0.7221487760543823     │\n",
       "│ TotalEnvSteps                 │ 83968.0                │\n",
       "│ Loss/Loss_pi                  │ -0.013169564306735992  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0009096032008528709 │\n",
       "│ Value/Adv                     │ -0.030091889202594757  │\n",
       "│ Loss/Loss_reward_critic       │ 0.019808650016784668   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0019964762032032013  │\n",
       "│ Value/reward                  │ 1.4879902601242065     │\n",
       "│ Time/Total                    │ 532.5955810546875      │\n",
       "│ Time/Rollout                  │ 10.961446762084961     │\n",
       "│ Time/Update                   │ 1.7052412033081055     │\n",
       "│ Time/Epoch                    │ 12.666728973388672     │\n",
       "│ Time/FPS                      │ 161.6834259033203      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 10.568114280700684     │\n",
       "│ Metrics/EpCost                │ 78.31999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 40.0                   │\n",
       "│ Train/Entropy                 │ 1.093042016029358      │\n",
       "│ Train/KL                      │ 0.012516036629676819   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.003492832183838      │\n",
       "│ Train/PolicyRatio/Min         │ 1.003492832183838      │\n",
       "│ Train/PolicyRatio/Max         │ 1.003492832183838      │\n",
       "│ Train/PolicyRatio/Std         │ 0.016680225729942322   │\n",
       "│ Train/LR                      │ 0.00027540000155568123 │\n",
       "│ Train/PolicyStd               │ 0.7221487760543823     │\n",
       "│ TotalEnvSteps                 │ 83968.0                │\n",
       "│ Loss/Loss_pi                  │ -0.013169564306735992  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0009096032008528709 │\n",
       "│ Value/Adv                     │ -0.030091889202594757  │\n",
       "│ Loss/Loss_reward_critic       │ 0.019808650016784668   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0019964762032032013  │\n",
       "│ Value/reward                  │ 1.4879902601242065     │\n",
       "│ Time/Total                    │ 532.5955810546875      │\n",
       "│ Time/Rollout                  │ 10.961446762084961     │\n",
       "│ Time/Update                   │ 1.7052412033081055     │\n",
       "│ Time/Epoch                    │ 12.666728973388672     │\n",
       "│ Time/FPS                      │ 161.6834259033203      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 11.086913108825684     │\n",
       "│ Metrics/EpCost                │ 68.81999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 41.0                   │\n",
       "│ Train/Entropy                 │ 1.080776572227478      │\n",
       "│ Train/KL                      │ 0.01364632323384285    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9969035983085632     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9969035983085632     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9969035983085632     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017586680129170418   │\n",
       "│ Train/LR                      │ 0.0002747999969869852  │\n",
       "│ Train/PolicyStd               │ 0.7134860157966614     │\n",
       "│ TotalEnvSteps                 │ 86016.0                │\n",
       "│ Loss/Loss_pi                  │ -0.015743672847747803  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0025741085410118103 │\n",
       "│ Value/Adv                     │ 0.014530189335346222   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01893770508468151    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.000870944932103157  │\n",
       "│ Value/reward                  │ 1.3581645488739014     │\n",
       "│ Time/Total                    │ 545.5452270507812      │\n",
       "│ Time/Rollout                  │ 11.252584457397461     │\n",
       "│ Time/Update                   │ 1.68532395362854       │\n",
       "│ Time/Epoch                    │ 12.937949180603027     │\n",
       "│ Time/FPS                      │ 158.29403686523438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 11.086913108825684     │\n",
       "│ Metrics/EpCost                │ 68.81999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 41.0                   │\n",
       "│ Train/Entropy                 │ 1.080776572227478      │\n",
       "│ Train/KL                      │ 0.01364632323384285    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9969035983085632     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9969035983085632     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9969035983085632     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017586680129170418   │\n",
       "│ Train/LR                      │ 0.0002747999969869852  │\n",
       "│ Train/PolicyStd               │ 0.7134860157966614     │\n",
       "│ TotalEnvSteps                 │ 86016.0                │\n",
       "│ Loss/Loss_pi                  │ -0.015743672847747803  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0025741085410118103 │\n",
       "│ Value/Adv                     │ 0.014530189335346222   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01893770508468151    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.000870944932103157  │\n",
       "│ Value/reward                  │ 1.3581645488739014     │\n",
       "│ Time/Total                    │ 545.5452270507812      │\n",
       "│ Time/Rollout                  │ 11.252584457397461     │\n",
       "│ Time/Update                   │ 1.68532395362854       │\n",
       "│ Time/Epoch                    │ 12.937949180603027     │\n",
       "│ Time/FPS                      │ 158.29403686523438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 11.630180358886719     │\n",
       "│ Metrics/EpCost                │ 65.55999755859375      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 42.0                   │\n",
       "│ Train/Entropy                 │ 1.07451593875885       │\n",
       "│ Train/KL                      │ 0.013651956804096699   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9989582896232605     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9989582896232605     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9989582896232605     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019283851608633995   │\n",
       "│ Train/LR                      │ 0.0002741999924182892  │\n",
       "│ Train/PolicyStd               │ 0.7090820670127869     │\n",
       "│ TotalEnvSteps                 │ 88064.0                │\n",
       "│ Loss/Loss_pi                  │ -0.017502453178167343  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0017587803304195404 │\n",
       "│ Value/Adv                     │ 0.03288343921303749    │\n",
       "│ Loss/Loss_reward_critic       │ 0.018056955188512802   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0008807498961687088 │\n",
       "│ Value/reward                  │ 1.5158544778823853     │\n",
       "│ Time/Total                    │ 558.8282470703125      │\n",
       "│ Time/Rollout                  │ 11.402141571044922     │\n",
       "│ Time/Update                   │ 1.869295358657837      │\n",
       "│ Time/Epoch                    │ 13.271492004394531     │\n",
       "│ Time/FPS                      │ 154.31573486328125     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 11.630180358886719     │\n",
       "│ Metrics/EpCost                │ 65.55999755859375      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 42.0                   │\n",
       "│ Train/Entropy                 │ 1.07451593875885       │\n",
       "│ Train/KL                      │ 0.013651956804096699   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9989582896232605     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9989582896232605     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9989582896232605     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019283851608633995   │\n",
       "│ Train/LR                      │ 0.0002741999924182892  │\n",
       "│ Train/PolicyStd               │ 0.7090820670127869     │\n",
       "│ TotalEnvSteps                 │ 88064.0                │\n",
       "│ Loss/Loss_pi                  │ -0.017502453178167343  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0017587803304195404 │\n",
       "│ Value/Adv                     │ 0.03288343921303749    │\n",
       "│ Loss/Loss_reward_critic       │ 0.018056955188512802   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0008807498961687088 │\n",
       "│ Value/reward                  │ 1.5158544778823853     │\n",
       "│ Time/Total                    │ 558.8282470703125      │\n",
       "│ Time/Rollout                  │ 11.402141571044922     │\n",
       "│ Time/Update                   │ 1.869295358657837      │\n",
       "│ Time/Epoch                    │ 13.271492004394531     │\n",
       "│ Time/FPS                      │ 154.31573486328125     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 11.936395645141602     │\n",
       "│ Metrics/EpCost                │ 66.05999755859375      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 43.0                   │\n",
       "│ Train/Entropy                 │ 1.0682512521743774     │\n",
       "│ Train/KL                      │ 0.012758453376591206   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0020294189453125     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0020294189453125     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0020294189453125     │\n",
       "│ Train/PolicyRatio/Std         │ 0.014985339716076851   │\n",
       "│ Train/LR                      │ 0.00027359998784959316 │\n",
       "│ Train/PolicyStd               │ 0.7045738697052002     │\n",
       "│ TotalEnvSteps                 │ 90112.0                │\n",
       "│ Loss/Loss_pi                  │ -0.012656206265091896  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004846246913075447   │\n",
       "│ Value/Adv                     │ -0.24156132340431213   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018557820469141006   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0005008652806282043  │\n",
       "│ Value/reward                  │ 1.5809597969055176     │\n",
       "│ Time/Total                    │ 573.0437622070312      │\n",
       "│ Time/Rollout                  │ 12.10049819946289      │\n",
       "│ Time/Update                   │ 2.1018149852752686     │\n",
       "│ Time/Epoch                    │ 14.202366828918457     │\n",
       "│ Time/FPS                      │ 144.20132446289062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 11.936395645141602     │\n",
       "│ Metrics/EpCost                │ 66.05999755859375      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 43.0                   │\n",
       "│ Train/Entropy                 │ 1.0682512521743774     │\n",
       "│ Train/KL                      │ 0.012758453376591206   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0020294189453125     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0020294189453125     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0020294189453125     │\n",
       "│ Train/PolicyRatio/Std         │ 0.014985339716076851   │\n",
       "│ Train/LR                      │ 0.00027359998784959316 │\n",
       "│ Train/PolicyStd               │ 0.7045738697052002     │\n",
       "│ TotalEnvSteps                 │ 90112.0                │\n",
       "│ Loss/Loss_pi                  │ -0.012656206265091896  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004846246913075447   │\n",
       "│ Value/Adv                     │ -0.24156132340431213   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018557820469141006   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0005008652806282043  │\n",
       "│ Value/reward                  │ 1.5809597969055176     │\n",
       "│ Time/Total                    │ 573.0437622070312      │\n",
       "│ Time/Rollout                  │ 12.10049819946289      │\n",
       "│ Time/Update                   │ 2.1018149852752686     │\n",
       "│ Time/Epoch                    │ 14.202366828918457     │\n",
       "│ Time/FPS                      │ 144.20132446289062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 12.36825942993164     │\n",
       "│ Metrics/EpCost                │ 66.33999633789062     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 44.0                  │\n",
       "│ Train/Entropy                 │ 1.0642130374908447    │\n",
       "│ Train/KL                      │ 0.014875439926981926  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0012599229812622    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0012599229812622    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0012599229812622    │\n",
       "│ Train/PolicyRatio/Std         │ 0.019737014546990395  │\n",
       "│ Train/LR                      │ 0.0002730000123847276 │\n",
       "│ Train/PolicyStd               │ 0.7018019556999207    │\n",
       "│ TotalEnvSteps                 │ 92160.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013933887705206871 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.001277681440114975 │\n",
       "│ Value/Adv                     │ 0.1604548990726471    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01465524174273014   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.003902578726410866 │\n",
       "│ Value/reward                  │ 1.4406349658966064    │\n",
       "│ Time/Total                    │ 587.2498168945312     │\n",
       "│ Time/Rollout                  │ 12.224802017211914    │\n",
       "│ Time/Update                   │ 1.9633862972259521    │\n",
       "│ Time/Epoch                    │ 14.188230514526367    │\n",
       "│ Time/FPS                      │ 144.34500122070312    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 12.36825942993164     │\n",
       "│ Metrics/EpCost                │ 66.33999633789062     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 44.0                  │\n",
       "│ Train/Entropy                 │ 1.0642130374908447    │\n",
       "│ Train/KL                      │ 0.014875439926981926  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0012599229812622    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0012599229812622    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0012599229812622    │\n",
       "│ Train/PolicyRatio/Std         │ 0.019737014546990395  │\n",
       "│ Train/LR                      │ 0.0002730000123847276 │\n",
       "│ Train/PolicyStd               │ 0.7018019556999207    │\n",
       "│ TotalEnvSteps                 │ 92160.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013933887705206871 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.001277681440114975 │\n",
       "│ Value/Adv                     │ 0.1604548990726471    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01465524174273014   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.003902578726410866 │\n",
       "│ Value/reward                  │ 1.4406349658966064    │\n",
       "│ Time/Total                    │ 587.2498168945312     │\n",
       "│ Time/Rollout                  │ 12.224802017211914    │\n",
       "│ Time/Update                   │ 1.9633862972259521    │\n",
       "│ Time/Epoch                    │ 14.188230514526367    │\n",
       "│ Time/FPS                      │ 144.34500122070312    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 12.759961128234863     │\n",
       "│ Metrics/EpCost                │ 65.5                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 45.0                   │\n",
       "│ Train/Entropy                 │ 1.0527112483978271     │\n",
       "│ Train/KL                      │ 0.015405259095132351   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9983459711074829     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9983459711074829     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9983459711074829     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018104849383234978   │\n",
       "│ Train/LR                      │ 0.0002724000078160316  │\n",
       "│ Train/PolicyStd               │ 0.693715512752533      │\n",
       "│ TotalEnvSteps                 │ 94208.0                │\n",
       "│ Loss/Loss_pi                  │ -0.014590376988053322  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0006564892828464508 │\n",
       "│ Value/Adv                     │ 0.0181790292263031     │\n",
       "│ Loss/Loss_reward_critic       │ 0.01189742423593998    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.002757817506790161  │\n",
       "│ Value/reward                  │ 1.504820704460144      │\n",
       "│ Time/Total                    │ 601.1436767578125      │\n",
       "│ Time/Rollout                  │ 12.116755485534668     │\n",
       "│ Time/Update                   │ 1.7642481327056885     │\n",
       "│ Time/Epoch                    │ 13.881063461303711     │\n",
       "│ Time/FPS                      │ 147.5391387939453      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 12.759961128234863     │\n",
       "│ Metrics/EpCost                │ 65.5                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 45.0                   │\n",
       "│ Train/Entropy                 │ 1.0527112483978271     │\n",
       "│ Train/KL                      │ 0.015405259095132351   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9983459711074829     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9983459711074829     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9983459711074829     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018104849383234978   │\n",
       "│ Train/LR                      │ 0.0002724000078160316  │\n",
       "│ Train/PolicyStd               │ 0.693715512752533      │\n",
       "│ TotalEnvSteps                 │ 94208.0                │\n",
       "│ Loss/Loss_pi                  │ -0.014590376988053322  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0006564892828464508 │\n",
       "│ Value/Adv                     │ 0.0181790292263031     │\n",
       "│ Loss/Loss_reward_critic       │ 0.01189742423593998    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.002757817506790161  │\n",
       "│ Value/reward                  │ 1.504820704460144      │\n",
       "│ Time/Total                    │ 601.1436767578125      │\n",
       "│ Time/Rollout                  │ 12.116755485534668     │\n",
       "│ Time/Update                   │ 1.7642481327056885     │\n",
       "│ Time/Epoch                    │ 13.881063461303711     │\n",
       "│ Time/FPS                      │ 147.5391387939453      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 12.9779052734375        │\n",
       "│ Metrics/EpCost                │ 66.87999725341797       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 46.0                    │\n",
       "│ Train/Entropy                 │ 1.040057897567749       │\n",
       "│ Train/KL                      │ 0.014468350447714329    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9964259266853333      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9964259266853333      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9964259266853333      │\n",
       "│ Train/PolicyRatio/Std         │ 0.017725111916661263    │\n",
       "│ Train/LR                      │ 0.00027180000324733555  │\n",
       "│ Train/PolicyStd               │ 0.6849635243415833      │\n",
       "│ TotalEnvSteps                 │ 96256.0                 │\n",
       "│ Loss/Loss_pi                  │ -0.015015947632491589   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00042557064443826675 │\n",
       "│ Value/Adv                     │ -0.06775099784135818    │\n",
       "│ Loss/Loss_reward_critic       │ 0.015832412987947464    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0039349887520074844   │\n",
       "│ Value/reward                  │ 1.522848129272461       │\n",
       "│ Time/Total                    │ 614.9683837890625       │\n",
       "│ Time/Rollout                  │ 11.743977546691895      │\n",
       "│ Time/Update                   │ 2.0682358741760254      │\n",
       "│ Time/Epoch                    │ 13.812277793884277      │\n",
       "│ Time/FPS                      │ 148.27389526367188      │\n",
       "└───────────────────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 12.9779052734375        │\n",
       "│ Metrics/EpCost                │ 66.87999725341797       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 46.0                    │\n",
       "│ Train/Entropy                 │ 1.040057897567749       │\n",
       "│ Train/KL                      │ 0.014468350447714329    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9964259266853333      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9964259266853333      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9964259266853333      │\n",
       "│ Train/PolicyRatio/Std         │ 0.017725111916661263    │\n",
       "│ Train/LR                      │ 0.00027180000324733555  │\n",
       "│ Train/PolicyStd               │ 0.6849635243415833      │\n",
       "│ TotalEnvSteps                 │ 96256.0                 │\n",
       "│ Loss/Loss_pi                  │ -0.015015947632491589   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00042557064443826675 │\n",
       "│ Value/Adv                     │ -0.06775099784135818    │\n",
       "│ Loss/Loss_reward_critic       │ 0.015832412987947464    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0039349887520074844   │\n",
       "│ Value/reward                  │ 1.522848129272461       │\n",
       "│ Time/Total                    │ 614.9683837890625       │\n",
       "│ Time/Rollout                  │ 11.743977546691895      │\n",
       "│ Time/Update                   │ 2.0682358741760254      │\n",
       "│ Time/Epoch                    │ 13.812277793884277      │\n",
       "│ Time/FPS                      │ 148.27389526367188      │\n",
       "└───────────────────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 13.131991386413574     │\n",
       "│ Metrics/EpCost                │ 76.73999786376953      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 47.0                   │\n",
       "│ Train/Entropy                 │ 1.0367017984390259     │\n",
       "│ Train/KL                      │ 0.01657191477715969    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9989644885063171     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9989644885063171     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9989644885063171     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01817929744720459    │\n",
       "│ Train/LR                      │ 0.00027119999867863953 │\n",
       "│ Train/PolicyStd               │ 0.6827009320259094     │\n",
       "│ TotalEnvSteps                 │ 98304.0                │\n",
       "│ Loss/Loss_pi                  │ -0.014218844473361969  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0007971031591296196  │\n",
       "│ Value/Adv                     │ -0.4159165024757385    │\n",
       "│ Loss/Loss_reward_critic       │ 0.029867181554436684   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.01403476856648922    │\n",
       "│ Value/reward                  │ 1.40346360206604       │\n",
       "│ Time/Total                    │ 629.82763671875        │\n",
       "│ Time/Rollout                  │ 12.852299690246582     │\n",
       "│ Time/Update                   │ 1.9877889156341553     │\n",
       "│ Time/Epoch                    │ 14.840131759643555     │\n",
       "│ Time/FPS                      │ 138.00418090820312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 13.131991386413574     │\n",
       "│ Metrics/EpCost                │ 76.73999786376953      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 47.0                   │\n",
       "│ Train/Entropy                 │ 1.0367017984390259     │\n",
       "│ Train/KL                      │ 0.01657191477715969    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9989644885063171     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9989644885063171     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9989644885063171     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01817929744720459    │\n",
       "│ Train/LR                      │ 0.00027119999867863953 │\n",
       "│ Train/PolicyStd               │ 0.6827009320259094     │\n",
       "│ TotalEnvSteps                 │ 98304.0                │\n",
       "│ Loss/Loss_pi                  │ -0.014218844473361969  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0007971031591296196  │\n",
       "│ Value/Adv                     │ -0.4159165024757385    │\n",
       "│ Loss/Loss_reward_critic       │ 0.029867181554436684   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.01403476856648922    │\n",
       "│ Value/reward                  │ 1.40346360206604       │\n",
       "│ Time/Total                    │ 629.82763671875        │\n",
       "│ Time/Rollout                  │ 12.852299690246582     │\n",
       "│ Time/Update                   │ 1.9877889156341553     │\n",
       "│ Time/Epoch                    │ 14.840131759643555     │\n",
       "│ Time/FPS                      │ 138.00418090820312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 13.196819305419922    │\n",
       "│ Metrics/EpCost                │ 89.16000366210938     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 48.0                  │\n",
       "│ Train/Entropy                 │ 1.0346962213516235    │\n",
       "│ Train/KL                      │ 0.012078030966222286  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0016435384750366    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0016435384750366    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0016435384750366    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01854526624083519   │\n",
       "│ Train/LR                      │ 0.0002705999941099435 │\n",
       "│ Train/PolicyStd               │ 0.6814566850662231    │\n",
       "│ TotalEnvSteps                 │ 100352.0              │\n",
       "│ Loss/Loss_pi                  │ -0.012715284712612629 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00150355976074934   │\n",
       "│ Value/Adv                     │ 0.028969094157218933  │\n",
       "│ Loss/Loss_reward_critic       │ 0.018179094418883324  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.01168808713555336  │\n",
       "│ Value/reward                  │ 1.299191951751709     │\n",
       "│ Time/Total                    │ 642.963623046875      │\n",
       "│ Time/Rollout                  │ 11.34113883972168     │\n",
       "│ Time/Update                   │ 1.7833960056304932    │\n",
       "│ Time/Epoch                    │ 13.124576568603516    │\n",
       "│ Time/FPS                      │ 156.0431365966797     │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 13.196819305419922    │\n",
       "│ Metrics/EpCost                │ 89.16000366210938     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 48.0                  │\n",
       "│ Train/Entropy                 │ 1.0346962213516235    │\n",
       "│ Train/KL                      │ 0.012078030966222286  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0016435384750366    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0016435384750366    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0016435384750366    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01854526624083519   │\n",
       "│ Train/LR                      │ 0.0002705999941099435 │\n",
       "│ Train/PolicyStd               │ 0.6814566850662231    │\n",
       "│ TotalEnvSteps                 │ 100352.0              │\n",
       "│ Loss/Loss_pi                  │ -0.012715284712612629 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00150355976074934   │\n",
       "│ Value/Adv                     │ 0.028969094157218933  │\n",
       "│ Loss/Loss_reward_critic       │ 0.018179094418883324  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.01168808713555336  │\n",
       "│ Value/reward                  │ 1.299191951751709     │\n",
       "│ Time/Total                    │ 642.963623046875      │\n",
       "│ Time/Rollout                  │ 11.34113883972168     │\n",
       "│ Time/Update                   │ 1.7833960056304932    │\n",
       "│ Time/Epoch                    │ 13.124576568603516    │\n",
       "│ Time/FPS                      │ 156.0431365966797     │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 13.685890197753906     │\n",
       "│ Metrics/EpCost                │ 84.95999908447266      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 49.0                   │\n",
       "│ Train/Entropy                 │ 1.038081169128418      │\n",
       "│ Train/KL                      │ 0.011187107302248478   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9985081553459167     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9985081553459167     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9985081553459167     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017095398157835007   │\n",
       "│ Train/LR                      │ 0.0002699999895412475  │\n",
       "│ Train/PolicyStd               │ 0.6836327314376831     │\n",
       "│ TotalEnvSteps                 │ 102400.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014417360536754131  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0017020758241415024 │\n",
       "│ Value/Adv                     │ 0.1716417670249939     │\n",
       "│ Loss/Loss_reward_critic       │ 0.022906210273504257   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0047271158546209335  │\n",
       "│ Value/reward                  │ 1.5979337692260742     │\n",
       "│ Time/Total                    │ 656.2119140625         │\n",
       "│ Time/Rollout                  │ 11.411953926086426     │\n",
       "│ Time/Update                   │ 1.8244361877441406     │\n",
       "│ Time/Epoch                    │ 13.236449241638184     │\n",
       "│ Time/FPS                      │ 154.7242889404297      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 13.685890197753906     │\n",
       "│ Metrics/EpCost                │ 84.95999908447266      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 49.0                   │\n",
       "│ Train/Entropy                 │ 1.038081169128418      │\n",
       "│ Train/KL                      │ 0.011187107302248478   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9985081553459167     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9985081553459167     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9985081553459167     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017095398157835007   │\n",
       "│ Train/LR                      │ 0.0002699999895412475  │\n",
       "│ Train/PolicyStd               │ 0.6836327314376831     │\n",
       "│ TotalEnvSteps                 │ 102400.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014417360536754131  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0017020758241415024 │\n",
       "│ Value/Adv                     │ 0.1716417670249939     │\n",
       "│ Loss/Loss_reward_critic       │ 0.022906210273504257   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0047271158546209335  │\n",
       "│ Value/reward                  │ 1.5979337692260742     │\n",
       "│ Time/Total                    │ 656.2119140625         │\n",
       "│ Time/Rollout                  │ 11.411953926086426     │\n",
       "│ Time/Update                   │ 1.8244361877441406     │\n",
       "│ Time/Epoch                    │ 13.236449241638184     │\n",
       "│ Time/FPS                      │ 154.7242889404297      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 13.804361343383789     │\n",
       "│ Metrics/EpCost                │ 86.04000091552734      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 50.0                   │\n",
       "│ Train/Entropy                 │ 1.0323489904403687     │\n",
       "│ Train/KL                      │ 0.01851150579750538    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.001315712928772      │\n",
       "│ Train/PolicyRatio/Min         │ 1.001315712928772      │\n",
       "│ Train/PolicyRatio/Max         │ 1.001315712928772      │\n",
       "│ Train/PolicyRatio/Std         │ 0.01966935582458973    │\n",
       "│ Train/LR                      │ 0.0002694000140763819  │\n",
       "│ Train/PolicyStd               │ 0.6797264814376831     │\n",
       "│ TotalEnvSteps                 │ 104448.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018469447270035744  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004052086733281612  │\n",
       "│ Value/Adv                     │ -0.06881409138441086   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02112090215086937    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0017853081226348877 │\n",
       "│ Value/reward                  │ 1.439411997795105      │\n",
       "│ Time/Total                    │ 668.9830932617188      │\n",
       "│ Time/Rollout                  │ 11.060619354248047     │\n",
       "│ Time/Update                   │ 1.6974005699157715     │\n",
       "│ Time/Epoch                    │ 12.758062362670898     │\n",
       "│ Time/FPS                      │ 160.5259552001953      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 13.804361343383789     │\n",
       "│ Metrics/EpCost                │ 86.04000091552734      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 50.0                   │\n",
       "│ Train/Entropy                 │ 1.0323489904403687     │\n",
       "│ Train/KL                      │ 0.01851150579750538    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.001315712928772      │\n",
       "│ Train/PolicyRatio/Min         │ 1.001315712928772      │\n",
       "│ Train/PolicyRatio/Max         │ 1.001315712928772      │\n",
       "│ Train/PolicyRatio/Std         │ 0.01966935582458973    │\n",
       "│ Train/LR                      │ 0.0002694000140763819  │\n",
       "│ Train/PolicyStd               │ 0.6797264814376831     │\n",
       "│ TotalEnvSteps                 │ 104448.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018469447270035744  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004052086733281612  │\n",
       "│ Value/Adv                     │ -0.06881409138441086   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02112090215086937    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0017853081226348877 │\n",
       "│ Value/reward                  │ 1.439411997795105      │\n",
       "│ Time/Total                    │ 668.9830932617188      │\n",
       "│ Time/Rollout                  │ 11.060619354248047     │\n",
       "│ Time/Update                   │ 1.6974005699157715     │\n",
       "│ Time/Epoch                    │ 12.758062362670898     │\n",
       "│ Time/FPS                      │ 160.5259552001953      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 14.115431785583496    │\n",
       "│ Metrics/EpCost                │ 86.63999938964844     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 51.0                  │\n",
       "│ Train/Entropy                 │ 1.0152828693389893    │\n",
       "│ Train/KL                      │ 0.017756281420588493  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9959007501602173    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9959007501602173    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9959007501602173    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01806734874844551   │\n",
       "│ Train/LR                      │ 0.0002688000095076859 │\n",
       "│ Train/PolicyStd               │ 0.6682130694389343    │\n",
       "│ TotalEnvSteps                 │ 106496.0              │\n",
       "│ Loss/Loss_pi                  │ -0.015637720003724098 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0028317272663116455 │\n",
       "│ Value/Adv                     │ -0.07196064293384552  │\n",
       "│ Loss/Loss_reward_critic       │ 0.019659848883748055  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.001461053267121315 │\n",
       "│ Value/reward                  │ 1.569015622138977     │\n",
       "│ Time/Total                    │ 682.5105590820312     │\n",
       "│ Time/Rollout                  │ 11.655033111572266    │\n",
       "│ Time/Update                   │ 1.8605492115020752    │\n",
       "│ Time/Epoch                    │ 13.515628814697266    │\n",
       "│ Time/FPS                      │ 151.52828979492188    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 14.115431785583496    │\n",
       "│ Metrics/EpCost                │ 86.63999938964844     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 51.0                  │\n",
       "│ Train/Entropy                 │ 1.0152828693389893    │\n",
       "│ Train/KL                      │ 0.017756281420588493  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9959007501602173    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9959007501602173    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9959007501602173    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01806734874844551   │\n",
       "│ Train/LR                      │ 0.0002688000095076859 │\n",
       "│ Train/PolicyStd               │ 0.6682130694389343    │\n",
       "│ TotalEnvSteps                 │ 106496.0              │\n",
       "│ Loss/Loss_pi                  │ -0.015637720003724098 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0028317272663116455 │\n",
       "│ Value/Adv                     │ -0.07196064293384552  │\n",
       "│ Loss/Loss_reward_critic       │ 0.019659848883748055  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.001461053267121315 │\n",
       "│ Value/reward                  │ 1.569015622138977     │\n",
       "│ Time/Total                    │ 682.5105590820312     │\n",
       "│ Time/Rollout                  │ 11.655033111572266    │\n",
       "│ Time/Update                   │ 1.8605492115020752    │\n",
       "│ Time/Epoch                    │ 13.515628814697266    │\n",
       "│ Time/FPS                      │ 151.52828979492188    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 14.374032974243164    │\n",
       "│ Metrics/EpCost                │ 87.63999938964844     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 52.0                  │\n",
       "│ Train/Entropy                 │ 1.0081391334533691    │\n",
       "│ Train/KL                      │ 0.014909300953149796  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9972494840621948    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9972494840621948    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9972494840621948    │\n",
       "│ Train/PolicyRatio/Std         │ 0.018022676929831505  │\n",
       "│ Train/LR                      │ 0.0002682000049389899 │\n",
       "│ Train/PolicyStd               │ 0.6633588075637817    │\n",
       "│ TotalEnvSteps                 │ 108544.0              │\n",
       "│ Loss/Loss_pi                  │ -0.013608229346573353 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0020294906571507454 │\n",
       "│ Value/Adv                     │ 0.27918124198913574   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02076527662575245   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0011054277420043945 │\n",
       "│ Value/reward                  │ 1.6166372299194336    │\n",
       "│ Time/Total                    │ 696.7015991210938     │\n",
       "│ Time/Rollout                  │ 12.141953468322754    │\n",
       "│ Time/Update                   │ 2.0367953777313232    │\n",
       "│ Time/Epoch                    │ 14.178800582885742    │\n",
       "│ Time/FPS                      │ 144.44100952148438    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 14.374032974243164    │\n",
       "│ Metrics/EpCost                │ 87.63999938964844     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 52.0                  │\n",
       "│ Train/Entropy                 │ 1.0081391334533691    │\n",
       "│ Train/KL                      │ 0.014909300953149796  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9972494840621948    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9972494840621948    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9972494840621948    │\n",
       "│ Train/PolicyRatio/Std         │ 0.018022676929831505  │\n",
       "│ Train/LR                      │ 0.0002682000049389899 │\n",
       "│ Train/PolicyStd               │ 0.6633588075637817    │\n",
       "│ TotalEnvSteps                 │ 108544.0              │\n",
       "│ Loss/Loss_pi                  │ -0.013608229346573353 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0020294906571507454 │\n",
       "│ Value/Adv                     │ 0.27918124198913574   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02076527662575245   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0011054277420043945 │\n",
       "│ Value/reward                  │ 1.6166372299194336    │\n",
       "│ Time/Total                    │ 696.7015991210938     │\n",
       "│ Time/Rollout                  │ 12.141953468322754    │\n",
       "│ Time/Update                   │ 2.0367953777313232    │\n",
       "│ Time/Epoch                    │ 14.178800582885742    │\n",
       "│ Time/FPS                      │ 144.44100952148438    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m8\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 14.493683815002441     │\n",
       "│ Metrics/EpCost                │ 88.4000015258789       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 53.0                   │\n",
       "│ Train/Entropy                 │ 0.9989782571792603     │\n",
       "│ Train/KL                      │ 0.023098314180970192   │\n",
       "│ Train/StopIter                │ 8.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9969805479049683     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9969805479049683     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9969805479049683     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01862008310854435    │\n",
       "│ Train/LR                      │ 0.00026760000037029386 │\n",
       "│ Train/PolicyStd               │ 0.6574414968490601     │\n",
       "│ TotalEnvSteps                 │ 110592.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014832821674644947  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0012245923280715942 │\n",
       "│ Value/Adv                     │ -0.033434540033340454  │\n",
       "│ Loss/Loss_reward_critic       │ 0.018642235547304153   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0021230410784482956 │\n",
       "│ Value/reward                  │ 1.7074637413024902     │\n",
       "│ Time/Total                    │ 710.309326171875       │\n",
       "│ Time/Rollout                  │ 11.55910873413086      │\n",
       "│ Time/Update                   │ 2.0346648693084717     │\n",
       "│ Time/Epoch                    │ 13.593836784362793     │\n",
       "│ Time/FPS                      │ 150.65652465820312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 14.493683815002441     │\n",
       "│ Metrics/EpCost                │ 88.4000015258789       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 53.0                   │\n",
       "│ Train/Entropy                 │ 0.9989782571792603     │\n",
       "│ Train/KL                      │ 0.023098314180970192   │\n",
       "│ Train/StopIter                │ 8.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9969805479049683     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9969805479049683     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9969805479049683     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01862008310854435    │\n",
       "│ Train/LR                      │ 0.00026760000037029386 │\n",
       "│ Train/PolicyStd               │ 0.6574414968490601     │\n",
       "│ TotalEnvSteps                 │ 110592.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014832821674644947  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0012245923280715942 │\n",
       "│ Value/Adv                     │ -0.033434540033340454  │\n",
       "│ Loss/Loss_reward_critic       │ 0.018642235547304153   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0021230410784482956 │\n",
       "│ Value/reward                  │ 1.7074637413024902     │\n",
       "│ Time/Total                    │ 710.309326171875       │\n",
       "│ Time/Rollout                  │ 11.55910873413086      │\n",
       "│ Time/Update                   │ 2.0346648693084717     │\n",
       "│ Time/Epoch                    │ 13.593836784362793     │\n",
       "│ Time/FPS                      │ 150.65652465820312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 14.620821952819824     │\n",
       "│ Metrics/EpCost                │ 88.22000122070312      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 54.0                   │\n",
       "│ Train/Entropy                 │ 0.9982650876045227     │\n",
       "│ Train/KL                      │ 0.014934386126697063   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0017989873886108     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0017989873886108     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0017989873886108     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01844685710966587    │\n",
       "│ Train/LR                      │ 0.00026699999580159783 │\n",
       "│ Train/PolicyStd               │ 0.6570184230804443     │\n",
       "│ TotalEnvSteps                 │ 112640.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013860614970326424  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0009722067043185234  │\n",
       "│ Value/Adv                     │ -0.05830931290984154   │\n",
       "│ Loss/Loss_reward_critic       │ 0.022836316376924515   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004194080829620361   │\n",
       "│ Value/reward                  │ 1.5451139211654663     │\n",
       "│ Time/Total                    │ 723.847900390625       │\n",
       "│ Time/Rollout                  │ 11.742788314819336     │\n",
       "│ Time/Update                   │ 1.7834784984588623     │\n",
       "│ Time/Epoch                    │ 13.526310920715332     │\n",
       "│ Time/FPS                      │ 151.4086151123047      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 14.620821952819824     │\n",
       "│ Metrics/EpCost                │ 88.22000122070312      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 54.0                   │\n",
       "│ Train/Entropy                 │ 0.9982650876045227     │\n",
       "│ Train/KL                      │ 0.014934386126697063   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0017989873886108     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0017989873886108     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0017989873886108     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01844685710966587    │\n",
       "│ Train/LR                      │ 0.00026699999580159783 │\n",
       "│ Train/PolicyStd               │ 0.6570184230804443     │\n",
       "│ TotalEnvSteps                 │ 112640.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013860614970326424  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0009722067043185234  │\n",
       "│ Value/Adv                     │ -0.05830931290984154   │\n",
       "│ Loss/Loss_reward_critic       │ 0.022836316376924515   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004194080829620361   │\n",
       "│ Value/reward                  │ 1.5451139211654663     │\n",
       "│ Time/Total                    │ 723.847900390625       │\n",
       "│ Time/Rollout                  │ 11.742788314819336     │\n",
       "│ Time/Update                   │ 1.7834784984588623     │\n",
       "│ Time/Epoch                    │ 13.526310920715332     │\n",
       "│ Time/FPS                      │ 151.4086151123047      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 14.949728965759277     │\n",
       "│ Metrics/EpCost                │ 90.69999694824219      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 55.0                   │\n",
       "│ Train/Entropy                 │ 0.9962522387504578     │\n",
       "│ Train/KL                      │ 0.012145187705755234   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0047917366027832     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0047917366027832     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0047917366027832     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01902313157916069    │\n",
       "│ Train/LR                      │ 0.0002663999912329018  │\n",
       "│ Train/PolicyStd               │ 0.6557746529579163     │\n",
       "│ TotalEnvSteps                 │ 114688.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013536730781197548  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00032388418912887573 │\n",
       "│ Value/Adv                     │ 0.02277359738945961    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02068759873509407    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0021487176418304443 │\n",
       "│ Value/reward                  │ 1.5993318557739258     │\n",
       "│ Time/Total                    │ 738.1427001953125      │\n",
       "│ Time/Rollout                  │ 12.442704200744629     │\n",
       "│ Time/Update                   │ 1.840146780014038      │\n",
       "│ Time/Epoch                    │ 14.282898902893066     │\n",
       "│ Time/FPS                      │ 143.38827514648438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 14.949728965759277     │\n",
       "│ Metrics/EpCost                │ 90.69999694824219      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 55.0                   │\n",
       "│ Train/Entropy                 │ 0.9962522387504578     │\n",
       "│ Train/KL                      │ 0.012145187705755234   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0047917366027832     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0047917366027832     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0047917366027832     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01902313157916069    │\n",
       "│ Train/LR                      │ 0.0002663999912329018  │\n",
       "│ Train/PolicyStd               │ 0.6557746529579163     │\n",
       "│ TotalEnvSteps                 │ 114688.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013536730781197548  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00032388418912887573 │\n",
       "│ Value/Adv                     │ 0.02277359738945961    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02068759873509407    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0021487176418304443 │\n",
       "│ Value/reward                  │ 1.5993318557739258     │\n",
       "│ Time/Total                    │ 738.1427001953125      │\n",
       "│ Time/Rollout                  │ 12.442704200744629     │\n",
       "│ Time/Update                   │ 1.840146780014038      │\n",
       "│ Time/Epoch                    │ 14.282898902893066     │\n",
       "│ Time/FPS                      │ 143.38827514648438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 15.099296569824219    │\n",
       "│ Metrics/EpCost                │ 90.86000061035156     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 56.0                  │\n",
       "│ Train/Entropy                 │ 0.9973660707473755    │\n",
       "│ Train/KL                      │ 0.0157554280012846    │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9930758476257324    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9930758476257324    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9930758476257324    │\n",
       "│ Train/PolicyRatio/Std         │ 0.019974306225776672  │\n",
       "│ Train/LR                      │ 0.0002657999866642058 │\n",
       "│ Train/PolicyStd               │ 0.6567871570587158    │\n",
       "│ TotalEnvSteps                 │ 116736.0              │\n",
       "│ Loss/Loss_pi                  │ -0.018693974241614342 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.005157243460416794 │\n",
       "│ Value/Adv                     │ -0.010569235309958458 │\n",
       "│ Loss/Loss_reward_critic       │ 0.012530380859971046  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.008157217875123024 │\n",
       "│ Value/reward                  │ 1.60565185546875      │\n",
       "│ Time/Total                    │ 752.896240234375      │\n",
       "│ Time/Rollout                  │ 12.062554359436035    │\n",
       "│ Time/Update                   │ 2.678816318511963     │\n",
       "│ Time/Epoch                    │ 14.741415977478027    │\n",
       "│ Time/FPS                      │ 138.92831420898438    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 15.099296569824219    │\n",
       "│ Metrics/EpCost                │ 90.86000061035156     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 56.0                  │\n",
       "│ Train/Entropy                 │ 0.9973660707473755    │\n",
       "│ Train/KL                      │ 0.0157554280012846    │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9930758476257324    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9930758476257324    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9930758476257324    │\n",
       "│ Train/PolicyRatio/Std         │ 0.019974306225776672  │\n",
       "│ Train/LR                      │ 0.0002657999866642058 │\n",
       "│ Train/PolicyStd               │ 0.6567871570587158    │\n",
       "│ TotalEnvSteps                 │ 116736.0              │\n",
       "│ Loss/Loss_pi                  │ -0.018693974241614342 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.005157243460416794 │\n",
       "│ Value/Adv                     │ -0.010569235309958458 │\n",
       "│ Loss/Loss_reward_critic       │ 0.012530380859971046  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.008157217875123024 │\n",
       "│ Value/reward                  │ 1.60565185546875      │\n",
       "│ Time/Total                    │ 752.896240234375      │\n",
       "│ Time/Rollout                  │ 12.062554359436035    │\n",
       "│ Time/Update                   │ 2.678816318511963     │\n",
       "│ Time/Epoch                    │ 14.741415977478027    │\n",
       "│ Time/FPS                      │ 138.92831420898438    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 15.285223007202148    │\n",
       "│ Metrics/EpCost                │ 90.37999725341797     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 57.0                  │\n",
       "│ Train/Entropy                 │ 0.9919480085372925    │\n",
       "│ Train/KL                      │ 0.013080701231956482  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.994803249835968     │\n",
       "│ Train/PolicyRatio/Min         │ 0.994803249835968     │\n",
       "│ Train/PolicyRatio/Max         │ 0.994803249835968     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017559172585606575  │\n",
       "│ Train/LR                      │ 0.0002652000111993402 │\n",
       "│ Train/PolicyStd               │ 0.6532487273216248    │\n",
       "│ TotalEnvSteps                 │ 118784.0              │\n",
       "│ Loss/Loss_pi                  │ -0.011762267909944057 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.006931706331670284  │\n",
       "│ Value/Adv                     │ 0.348391592502594     │\n",
       "│ Loss/Loss_reward_critic       │ 0.01980275847017765   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.007272377610206604  │\n",
       "│ Value/reward                  │ 1.6636829376220703    │\n",
       "│ Time/Total                    │ 767.4583740234375     │\n",
       "│ Time/Rollout                  │ 12.431631088256836    │\n",
       "│ Time/Update                   │ 2.116640329360962     │\n",
       "│ Time/Epoch                    │ 14.548315048217773    │\n",
       "│ Time/FPS                      │ 140.77232360839844    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 15.285223007202148    │\n",
       "│ Metrics/EpCost                │ 90.37999725341797     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 57.0                  │\n",
       "│ Train/Entropy                 │ 0.9919480085372925    │\n",
       "│ Train/KL                      │ 0.013080701231956482  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.994803249835968     │\n",
       "│ Train/PolicyRatio/Min         │ 0.994803249835968     │\n",
       "│ Train/PolicyRatio/Max         │ 0.994803249835968     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017559172585606575  │\n",
       "│ Train/LR                      │ 0.0002652000111993402 │\n",
       "│ Train/PolicyStd               │ 0.6532487273216248    │\n",
       "│ TotalEnvSteps                 │ 118784.0              │\n",
       "│ Loss/Loss_pi                  │ -0.011762267909944057 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.006931706331670284  │\n",
       "│ Value/Adv                     │ 0.348391592502594     │\n",
       "│ Loss/Loss_reward_critic       │ 0.01980275847017765   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.007272377610206604  │\n",
       "│ Value/reward                  │ 1.6636829376220703    │\n",
       "│ Time/Total                    │ 767.4583740234375     │\n",
       "│ Time/Rollout                  │ 12.431631088256836    │\n",
       "│ Time/Update                   │ 2.116640329360962     │\n",
       "│ Time/Epoch                    │ 14.548315048217773    │\n",
       "│ Time/FPS                      │ 140.77232360839844    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 15.515790939331055     │\n",
       "│ Metrics/EpCost                │ 91.27999877929688      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 58.0                   │\n",
       "│ Train/Entropy                 │ 0.9876160621643066     │\n",
       "│ Train/KL                      │ 0.014538551680743694   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9919880628585815     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9919880628585815     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9919880628585815     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019537849351763725   │\n",
       "│ Train/LR                      │ 0.0002646000066306442  │\n",
       "│ Train/PolicyStd               │ 0.6504493951797485     │\n",
       "│ TotalEnvSteps                 │ 120832.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01317303441464901   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0014107665047049522 │\n",
       "│ Value/Adv                     │ 0.04217180982232094    │\n",
       "│ Loss/Loss_reward_critic       │ 0.024758847430348396   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004956088960170746   │\n",
       "│ Value/reward                  │ 1.6416308879852295     │\n",
       "│ Time/Total                    │ 782.92626953125        │\n",
       "│ Time/Rollout                  │ 13.464704513549805     │\n",
       "│ Time/Update                   │ 1.9906737804412842     │\n",
       "│ Time/Epoch                    │ 15.455421447753906     │\n",
       "│ Time/FPS                      │ 132.51014709472656     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 15.515790939331055     │\n",
       "│ Metrics/EpCost                │ 91.27999877929688      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 58.0                   │\n",
       "│ Train/Entropy                 │ 0.9876160621643066     │\n",
       "│ Train/KL                      │ 0.014538551680743694   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9919880628585815     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9919880628585815     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9919880628585815     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019537849351763725   │\n",
       "│ Train/LR                      │ 0.0002646000066306442  │\n",
       "│ Train/PolicyStd               │ 0.6504493951797485     │\n",
       "│ TotalEnvSteps                 │ 120832.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01317303441464901   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0014107665047049522 │\n",
       "│ Value/Adv                     │ 0.04217180982232094    │\n",
       "│ Loss/Loss_reward_critic       │ 0.024758847430348396   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004956088960170746   │\n",
       "│ Value/reward                  │ 1.6416308879852295     │\n",
       "│ Time/Total                    │ 782.92626953125        │\n",
       "│ Time/Rollout                  │ 13.464704513549805     │\n",
       "│ Time/Update                   │ 1.9906737804412842     │\n",
       "│ Time/Epoch                    │ 15.455421447753906     │\n",
       "│ Time/FPS                      │ 132.51014709472656     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 15.636560440063477     │\n",
       "│ Metrics/EpCost                │ 91.0                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 59.0                   │\n",
       "│ Train/Entropy                 │ 0.985113799571991      │\n",
       "│ Train/KL                      │ 0.0179480891674757     │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.997974693775177      │\n",
       "│ Train/PolicyRatio/Min         │ 0.997974693775177      │\n",
       "│ Train/PolicyRatio/Max         │ 0.997974693775177      │\n",
       "│ Train/PolicyRatio/Std         │ 0.019347617402672768   │\n",
       "│ Train/LR                      │ 0.0002640000020619482  │\n",
       "│ Train/PolicyStd               │ 0.6488769054412842     │\n",
       "│ TotalEnvSteps                 │ 122880.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015091490931808949  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0019184565171599388 │\n",
       "│ Value/Adv                     │ 0.012299053370952606   │\n",
       "│ Loss/Loss_reward_critic       │ 0.019420508295297623   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005338339135050774  │\n",
       "│ Value/reward                  │ 1.7183481454849243     │\n",
       "│ Time/Total                    │ 796.898193359375       │\n",
       "│ Time/Rollout                  │ 12.059842109680176     │\n",
       "│ Time/Update                   │ 1.8979783058166504     │\n",
       "│ Time/Epoch                    │ 13.95787239074707      │\n",
       "│ Time/FPS                      │ 146.7272491455078      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 15.636560440063477     │\n",
       "│ Metrics/EpCost                │ 91.0                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 59.0                   │\n",
       "│ Train/Entropy                 │ 0.985113799571991      │\n",
       "│ Train/KL                      │ 0.0179480891674757     │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.997974693775177      │\n",
       "│ Train/PolicyRatio/Min         │ 0.997974693775177      │\n",
       "│ Train/PolicyRatio/Max         │ 0.997974693775177      │\n",
       "│ Train/PolicyRatio/Std         │ 0.019347617402672768   │\n",
       "│ Train/LR                      │ 0.0002640000020619482  │\n",
       "│ Train/PolicyStd               │ 0.6488769054412842     │\n",
       "│ TotalEnvSteps                 │ 122880.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015091490931808949  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0019184565171599388 │\n",
       "│ Value/Adv                     │ 0.012299053370952606   │\n",
       "│ Loss/Loss_reward_critic       │ 0.019420508295297623   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005338339135050774  │\n",
       "│ Value/reward                  │ 1.7183481454849243     │\n",
       "│ Time/Total                    │ 796.898193359375       │\n",
       "│ Time/Rollout                  │ 12.059842109680176     │\n",
       "│ Time/Update                   │ 1.8979783058166504     │\n",
       "│ Time/Epoch                    │ 13.95787239074707      │\n",
       "│ Time/FPS                      │ 146.7272491455078      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 15.8530912399292       │\n",
       "│ Metrics/EpCost                │ 88.08000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 60.0                   │\n",
       "│ Train/Entropy                 │ 0.9740020036697388     │\n",
       "│ Train/KL                      │ 0.018628941848874092   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.999679446220398      │\n",
       "│ Train/PolicyRatio/Min         │ 0.999679446220398      │\n",
       "│ Train/PolicyRatio/Max         │ 0.999679446220398      │\n",
       "│ Train/PolicyRatio/Std         │ 0.017926353961229324   │\n",
       "│ Train/LR                      │ 0.00026339999749325216 │\n",
       "│ Train/PolicyStd               │ 0.6417204141616821     │\n",
       "│ TotalEnvSteps                 │ 124928.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01767943985760212   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002587948925793171  │\n",
       "│ Value/Adv                     │ 0.09710410237312317    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01838359236717224    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0010369159281253815 │\n",
       "│ Value/reward                  │ 1.7826663255691528     │\n",
       "│ Time/Total                    │ 811.803466796875       │\n",
       "│ Time/Rollout                  │ 12.854068756103516     │\n",
       "│ Time/Update                   │ 2.0364785194396973     │\n",
       "│ Time/Epoch                    │ 14.890588760375977     │\n",
       "│ Time/FPS                      │ 137.5365447998047      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 15.8530912399292       │\n",
       "│ Metrics/EpCost                │ 88.08000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 60.0                   │\n",
       "│ Train/Entropy                 │ 0.9740020036697388     │\n",
       "│ Train/KL                      │ 0.018628941848874092   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.999679446220398      │\n",
       "│ Train/PolicyRatio/Min         │ 0.999679446220398      │\n",
       "│ Train/PolicyRatio/Max         │ 0.999679446220398      │\n",
       "│ Train/PolicyRatio/Std         │ 0.017926353961229324   │\n",
       "│ Train/LR                      │ 0.00026339999749325216 │\n",
       "│ Train/PolicyStd               │ 0.6417204141616821     │\n",
       "│ TotalEnvSteps                 │ 124928.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01767943985760212   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002587948925793171  │\n",
       "│ Value/Adv                     │ 0.09710410237312317    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01838359236717224    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0010369159281253815 │\n",
       "│ Value/reward                  │ 1.7826663255691528     │\n",
       "│ Time/Total                    │ 811.803466796875       │\n",
       "│ Time/Rollout                  │ 12.854068756103516     │\n",
       "│ Time/Update                   │ 2.0364785194396973     │\n",
       "│ Time/Epoch                    │ 14.890588760375977     │\n",
       "│ Time/FPS                      │ 137.5365447998047      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 15.742361068725586     │\n",
       "│ Metrics/EpCost                │ 84.58000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 61.0                   │\n",
       "│ Train/Entropy                 │ 0.9628693461418152     │\n",
       "│ Train/KL                      │ 0.013276815414428711   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9991504549980164     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9991504549980164     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9991504549980164     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01770627312362194    │\n",
       "│ Train/LR                      │ 0.00026279999292455614 │\n",
       "│ Train/PolicyStd               │ 0.6346302628517151     │\n",
       "│ TotalEnvSteps                 │ 126976.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01256243884563446   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005117001011967659   │\n",
       "│ Value/Adv                     │ 0.023190509527921677   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014070737175643444   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.004312855191528797  │\n",
       "│ Value/reward                  │ 1.5992799997329712     │\n",
       "│ Time/Total                    │ 826.6670532226562      │\n",
       "│ Time/Rollout                  │ 12.986903190612793     │\n",
       "│ Time/Update                   │ 1.863548994064331      │\n",
       "│ Time/Epoch                    │ 14.850493431091309     │\n",
       "│ Time/FPS                      │ 137.9078826904297      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 15.742361068725586     │\n",
       "│ Metrics/EpCost                │ 84.58000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 61.0                   │\n",
       "│ Train/Entropy                 │ 0.9628693461418152     │\n",
       "│ Train/KL                      │ 0.013276815414428711   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9991504549980164     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9991504549980164     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9991504549980164     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01770627312362194    │\n",
       "│ Train/LR                      │ 0.00026279999292455614 │\n",
       "│ Train/PolicyStd               │ 0.6346302628517151     │\n",
       "│ TotalEnvSteps                 │ 126976.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01256243884563446   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005117001011967659   │\n",
       "│ Value/Adv                     │ 0.023190509527921677   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014070737175643444   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.004312855191528797  │\n",
       "│ Value/reward                  │ 1.5992799997329712     │\n",
       "│ Time/Total                    │ 826.6670532226562      │\n",
       "│ Time/Rollout                  │ 12.986903190612793     │\n",
       "│ Time/Update                   │ 1.863548994064331      │\n",
       "│ Time/Epoch                    │ 14.850493431091309     │\n",
       "│ Time/FPS                      │ 137.9078826904297      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 15.920323371887207     │\n",
       "│ Metrics/EpCost                │ 85.5                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 62.0                   │\n",
       "│ Train/Entropy                 │ 0.950259804725647      │\n",
       "│ Train/KL                      │ 0.012904947623610497   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9978723526000977     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9978723526000977     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9978723526000977     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01666153594851494    │\n",
       "│ Train/LR                      │ 0.0002621999883558601  │\n",
       "│ Train/PolicyStd               │ 0.6266214847564697     │\n",
       "│ TotalEnvSteps                 │ 129024.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014043515548110008  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0014810767024755478 │\n",
       "│ Value/Adv                     │ -0.039011768996715546  │\n",
       "│ Loss/Loss_reward_critic       │ 0.02009524218738079    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006024505011737347   │\n",
       "│ Value/reward                  │ 1.767702341079712      │\n",
       "│ Time/Total                    │ 840.1076049804688      │\n",
       "│ Time/Rollout                  │ 11.734479904174805     │\n",
       "│ Time/Update                   │ 1.6944565773010254     │\n",
       "│ Time/Epoch                    │ 13.428985595703125     │\n",
       "│ Time/FPS                      │ 152.5059356689453      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 15.920323371887207     │\n",
       "│ Metrics/EpCost                │ 85.5                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 62.0                   │\n",
       "│ Train/Entropy                 │ 0.950259804725647      │\n",
       "│ Train/KL                      │ 0.012904947623610497   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9978723526000977     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9978723526000977     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9978723526000977     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01666153594851494    │\n",
       "│ Train/LR                      │ 0.0002621999883558601  │\n",
       "│ Train/PolicyStd               │ 0.6266214847564697     │\n",
       "│ TotalEnvSteps                 │ 129024.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014043515548110008  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0014810767024755478 │\n",
       "│ Value/Adv                     │ -0.039011768996715546  │\n",
       "│ Loss/Loss_reward_critic       │ 0.02009524218738079    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006024505011737347   │\n",
       "│ Value/reward                  │ 1.767702341079712      │\n",
       "│ Time/Total                    │ 840.1076049804688      │\n",
       "│ Time/Rollout                  │ 11.734479904174805     │\n",
       "│ Time/Update                   │ 1.6944565773010254     │\n",
       "│ Time/Epoch                    │ 13.428985595703125     │\n",
       "│ Time/FPS                      │ 152.5059356689453      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 16.271085739135742     │\n",
       "│ Metrics/EpCost                │ 84.55999755859375      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 63.0                   │\n",
       "│ Train/Entropy                 │ 0.9434267282485962     │\n",
       "│ Train/KL                      │ 0.015369814820587635   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9958239793777466     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9958239793777466     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9958239793777466     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020469626411795616   │\n",
       "│ Train/LR                      │ 0.00026160001289099455 │\n",
       "│ Train/PolicyStd               │ 0.6222109794616699     │\n",
       "│ TotalEnvSteps                 │ 131072.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016176695004105568  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0021331794559955597 │\n",
       "│ Value/Adv                     │ -0.07762309163808823   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01583273336291313    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.004262508824467659  │\n",
       "│ Value/reward                  │ 1.7425988912582397     │\n",
       "│ Time/Total                    │ 852.5528564453125      │\n",
       "│ Time/Rollout                  │ 10.76010513305664      │\n",
       "│ Time/Update                   │ 1.6725175380706787     │\n",
       "│ Time/Epoch                    │ 12.432662963867188     │\n",
       "│ Time/FPS                      │ 164.72738647460938     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 16.271085739135742     │\n",
       "│ Metrics/EpCost                │ 84.55999755859375      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 63.0                   │\n",
       "│ Train/Entropy                 │ 0.9434267282485962     │\n",
       "│ Train/KL                      │ 0.015369814820587635   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9958239793777466     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9958239793777466     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9958239793777466     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020469626411795616   │\n",
       "│ Train/LR                      │ 0.00026160001289099455 │\n",
       "│ Train/PolicyStd               │ 0.6222109794616699     │\n",
       "│ TotalEnvSteps                 │ 131072.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016176695004105568  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0021331794559955597 │\n",
       "│ Value/Adv                     │ -0.07762309163808823   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01583273336291313    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.004262508824467659  │\n",
       "│ Value/reward                  │ 1.7425988912582397     │\n",
       "│ Time/Total                    │ 852.5528564453125      │\n",
       "│ Time/Rollout                  │ 10.76010513305664      │\n",
       "│ Time/Update                   │ 1.6725175380706787     │\n",
       "│ Time/Epoch                    │ 12.432662963867188     │\n",
       "│ Time/FPS                      │ 164.72738647460938     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 16.059053421020508    │\n",
       "│ Metrics/EpCost                │ 87.30000305175781     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 64.0                  │\n",
       "│ Train/Entropy                 │ 0.9448186755180359    │\n",
       "│ Train/KL                      │ 0.014194730669260025  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.000929355621338     │\n",
       "│ Train/PolicyRatio/Min         │ 1.000929355621338     │\n",
       "│ Train/PolicyRatio/Max         │ 1.000929355621338     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018798988312482834  │\n",
       "│ Train/LR                      │ 0.0002610000083222985 │\n",
       "│ Train/PolicyStd               │ 0.6230119466781616    │\n",
       "│ TotalEnvSteps                 │ 133120.0              │\n",
       "│ Loss/Loss_pi                  │ -0.014846136793494225 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0013305582106113434 │\n",
       "│ Value/Adv                     │ 0.005530616268515587  │\n",
       "│ Loss/Loss_reward_critic       │ 0.017984328791499138  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002151595428586006  │\n",
       "│ Value/reward                  │ 1.4243427515029907    │\n",
       "│ Time/Total                    │ 864.9937744140625     │\n",
       "│ Time/Rollout                  │ 10.761810302734375    │\n",
       "│ Time/Update                   │ 1.6663143634796143    │\n",
       "│ Time/Epoch                    │ 12.428168296813965    │\n",
       "│ Time/FPS                      │ 164.78695678710938    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 16.059053421020508    │\n",
       "│ Metrics/EpCost                │ 87.30000305175781     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 64.0                  │\n",
       "│ Train/Entropy                 │ 0.9448186755180359    │\n",
       "│ Train/KL                      │ 0.014194730669260025  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.000929355621338     │\n",
       "│ Train/PolicyRatio/Min         │ 1.000929355621338     │\n",
       "│ Train/PolicyRatio/Max         │ 1.000929355621338     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018798988312482834  │\n",
       "│ Train/LR                      │ 0.0002610000083222985 │\n",
       "│ Train/PolicyStd               │ 0.6230119466781616    │\n",
       "│ TotalEnvSteps                 │ 133120.0              │\n",
       "│ Loss/Loss_pi                  │ -0.014846136793494225 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0013305582106113434 │\n",
       "│ Value/Adv                     │ 0.005530616268515587  │\n",
       "│ Loss/Loss_reward_critic       │ 0.017984328791499138  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002151595428586006  │\n",
       "│ Value/reward                  │ 1.4243427515029907    │\n",
       "│ Time/Total                    │ 864.9937744140625     │\n",
       "│ Time/Rollout                  │ 10.761810302734375    │\n",
       "│ Time/Update                   │ 1.6663143634796143    │\n",
       "│ Time/Epoch                    │ 12.428168296813965    │\n",
       "│ Time/FPS                      │ 164.78695678710938    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 15.855874061584473     │\n",
       "│ Metrics/EpCost                │ 86.45999908447266      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 65.0                   │\n",
       "│ Train/Entropy                 │ 0.9495195150375366     │\n",
       "│ Train/KL                      │ 0.012963785789906979   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9949833154678345     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9949833154678345     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9949833154678345     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017511781305074692   │\n",
       "│ Train/LR                      │ 0.0002604000037536025  │\n",
       "│ Train/PolicyStd               │ 0.6260048747062683     │\n",
       "│ TotalEnvSteps                 │ 135168.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012119678780436516  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0027264580130577087  │\n",
       "│ Value/Adv                     │ -0.017028138041496277  │\n",
       "│ Loss/Loss_reward_critic       │ 0.017749328166246414   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0002350006252527237 │\n",
       "│ Value/reward                  │ 1.4357742071151733     │\n",
       "│ Time/Total                    │ 877.4857788085938      │\n",
       "│ Time/Rollout                  │ 10.798261642456055     │\n",
       "│ Time/Update                   │ 1.682138442993164      │\n",
       "│ Time/Epoch                    │ 12.480443954467773     │\n",
       "│ Time/FPS                      │ 164.09674072265625     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 15.855874061584473     │\n",
       "│ Metrics/EpCost                │ 86.45999908447266      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 65.0                   │\n",
       "│ Train/Entropy                 │ 0.9495195150375366     │\n",
       "│ Train/KL                      │ 0.012963785789906979   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9949833154678345     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9949833154678345     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9949833154678345     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017511781305074692   │\n",
       "│ Train/LR                      │ 0.0002604000037536025  │\n",
       "│ Train/PolicyStd               │ 0.6260048747062683     │\n",
       "│ TotalEnvSteps                 │ 135168.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012119678780436516  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0027264580130577087  │\n",
       "│ Value/Adv                     │ -0.017028138041496277  │\n",
       "│ Loss/Loss_reward_critic       │ 0.017749328166246414   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0002350006252527237 │\n",
       "│ Value/reward                  │ 1.4357742071151733     │\n",
       "│ Time/Total                    │ 877.4857788085938      │\n",
       "│ Time/Rollout                  │ 10.798261642456055     │\n",
       "│ Time/Update                   │ 1.682138442993164      │\n",
       "│ Time/Epoch                    │ 12.480443954467773     │\n",
       "│ Time/FPS                      │ 164.09674072265625     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 16.01962661743164      │\n",
       "│ Metrics/EpCost                │ 85.18000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 66.0                   │\n",
       "│ Train/Entropy                 │ 0.9403082132339478     │\n",
       "│ Train/KL                      │ 0.016752896830439568   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9994057416915894     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9994057416915894     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9994057416915894     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02004297636449337    │\n",
       "│ Train/LR                      │ 0.0002597999991849065  │\n",
       "│ Train/PolicyStd               │ 0.6202121376991272     │\n",
       "│ TotalEnvSteps                 │ 137216.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016237687319517136  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00411800853908062   │\n",
       "│ Value/Adv                     │ -0.08651819080114365   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015918206423521042   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0018311217427253723 │\n",
       "│ Value/reward                  │ 1.7455554008483887     │\n",
       "│ Time/Total                    │ 890.0028076171875      │\n",
       "│ Time/Rollout                  │ 10.858051300048828     │\n",
       "│ Time/Update                   │ 1.646233081817627      │\n",
       "│ Time/Epoch                    │ 12.504327774047852     │\n",
       "│ Time/FPS                      │ 163.78329467773438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 16.01962661743164      │\n",
       "│ Metrics/EpCost                │ 85.18000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 66.0                   │\n",
       "│ Train/Entropy                 │ 0.9403082132339478     │\n",
       "│ Train/KL                      │ 0.016752896830439568   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9994057416915894     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9994057416915894     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9994057416915894     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02004297636449337    │\n",
       "│ Train/LR                      │ 0.0002597999991849065  │\n",
       "│ Train/PolicyStd               │ 0.6202121376991272     │\n",
       "│ TotalEnvSteps                 │ 137216.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016237687319517136  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00411800853908062   │\n",
       "│ Value/Adv                     │ -0.08651819080114365   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015918206423521042   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0018311217427253723 │\n",
       "│ Value/reward                  │ 1.7455554008483887     │\n",
       "│ Time/Total                    │ 890.0028076171875      │\n",
       "│ Time/Rollout                  │ 10.858051300048828     │\n",
       "│ Time/Update                   │ 1.646233081817627      │\n",
       "│ Time/Epoch                    │ 12.504327774047852     │\n",
       "│ Time/FPS                      │ 163.78329467773438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 16.068151473999023      │\n",
       "│ Metrics/EpCost                │ 83.69999694824219       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 67.0                    │\n",
       "│ Train/Entropy                 │ 0.9286020994186401      │\n",
       "│ Train/KL                      │ 0.014057692140340805    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9989300966262817      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9989300966262817      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9989300966262817      │\n",
       "│ Train/PolicyRatio/Std         │ 0.01824689842760563     │\n",
       "│ Train/LR                      │ 0.00025919999461621046  │\n",
       "│ Train/PolicyStd               │ 0.6129485368728638      │\n",
       "│ TotalEnvSteps                 │ 139264.0                │\n",
       "│ Loss/Loss_pi                  │ -0.014931226149201393   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0013064611703157425   │\n",
       "│ Value/Adv                     │ -0.15931737422943115    │\n",
       "│ Loss/Loss_reward_critic       │ 0.015693040564656258    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00022516585886478424 │\n",
       "│ Value/reward                  │ 1.7811014652252197      │\n",
       "│ Time/Total                    │ 902.4949340820312       │\n",
       "│ Time/Rollout                  │ 10.813292503356934      │\n",
       "│ Time/Update                   │ 1.6672656536102295      │\n",
       "│ Time/Epoch                    │ 12.480600357055664      │\n",
       "│ Time/FPS                      │ 164.0946807861328       │\n",
       "└───────────────────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 16.068151473999023      │\n",
       "│ Metrics/EpCost                │ 83.69999694824219       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 67.0                    │\n",
       "│ Train/Entropy                 │ 0.9286020994186401      │\n",
       "│ Train/KL                      │ 0.014057692140340805    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9989300966262817      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9989300966262817      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9989300966262817      │\n",
       "│ Train/PolicyRatio/Std         │ 0.01824689842760563     │\n",
       "│ Train/LR                      │ 0.00025919999461621046  │\n",
       "│ Train/PolicyStd               │ 0.6129485368728638      │\n",
       "│ TotalEnvSteps                 │ 139264.0                │\n",
       "│ Loss/Loss_pi                  │ -0.014931226149201393   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0013064611703157425   │\n",
       "│ Value/Adv                     │ -0.15931737422943115    │\n",
       "│ Loss/Loss_reward_critic       │ 0.015693040564656258    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00022516585886478424 │\n",
       "│ Value/reward                  │ 1.7811014652252197      │\n",
       "│ Time/Total                    │ 902.4949340820312       │\n",
       "│ Time/Rollout                  │ 10.813292503356934      │\n",
       "│ Time/Update                   │ 1.6672656536102295      │\n",
       "│ Time/Epoch                    │ 12.480600357055664      │\n",
       "│ Time/FPS                      │ 164.0946807861328       │\n",
       "└───────────────────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 15.938509941101074     │\n",
       "│ Metrics/EpCost                │ 83.45999908447266      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 68.0                   │\n",
       "│ Train/Entropy                 │ 0.927585780620575      │\n",
       "│ Train/KL                      │ 0.014339634217321873   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0024083852767944     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0024083852767944     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0024083852767944     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018855098634958267   │\n",
       "│ Train/LR                      │ 0.00025859999004751444 │\n",
       "│ Train/PolicyStd               │ 0.6124087572097778     │\n",
       "│ TotalEnvSteps                 │ 141312.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01403299905359745   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0008982270956039429  │\n",
       "│ Value/Adv                     │ -0.05440344661474228   │\n",
       "│ Loss/Loss_reward_critic       │ 0.022272810339927673   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006579769775271416   │\n",
       "│ Value/reward                  │ 1.4772104024887085     │\n",
       "│ Time/Total                    │ 914.9871826171875      │\n",
       "│ Time/Rollout                  │ 10.810362815856934     │\n",
       "│ Time/Update                   │ 1.6706929206848145     │\n",
       "│ Time/Epoch                    │ 12.48110580444336      │\n",
       "│ Time/FPS                      │ 164.08804321289062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 15.938509941101074     │\n",
       "│ Metrics/EpCost                │ 83.45999908447266      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 68.0                   │\n",
       "│ Train/Entropy                 │ 0.927585780620575      │\n",
       "│ Train/KL                      │ 0.014339634217321873   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0024083852767944     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0024083852767944     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0024083852767944     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018855098634958267   │\n",
       "│ Train/LR                      │ 0.00025859999004751444 │\n",
       "│ Train/PolicyStd               │ 0.6124087572097778     │\n",
       "│ TotalEnvSteps                 │ 141312.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01403299905359745   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0008982270956039429  │\n",
       "│ Value/Adv                     │ -0.05440344661474228   │\n",
       "│ Loss/Loss_reward_critic       │ 0.022272810339927673   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006579769775271416   │\n",
       "│ Value/reward                  │ 1.4772104024887085     │\n",
       "│ Time/Total                    │ 914.9871826171875      │\n",
       "│ Time/Rollout                  │ 10.810362815856934     │\n",
       "│ Time/Update                   │ 1.6706929206848145     │\n",
       "│ Time/Epoch                    │ 12.48110580444336      │\n",
       "│ Time/FPS                      │ 164.08804321289062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 16.131427764892578     │\n",
       "│ Metrics/EpCost                │ 85.22000122070312      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 69.0                   │\n",
       "│ Train/Entropy                 │ 0.9251443147659302     │\n",
       "│ Train/KL                      │ 0.015395496040582657   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9945186376571655     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9945186376571655     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9945186376571655     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019894151017069817   │\n",
       "│ Train/LR                      │ 0.0002579999854788184  │\n",
       "│ Train/PolicyStd               │ 0.6107996106147766     │\n",
       "│ TotalEnvSteps                 │ 143360.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01192762702703476   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0021053720265626907  │\n",
       "│ Value/Adv                     │ -0.07951352745294571   │\n",
       "│ Loss/Loss_reward_critic       │ 0.022311747074127197   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 3.8936734199523926e-05 │\n",
       "│ Value/reward                  │ 1.711593508720398      │\n",
       "│ Time/Total                    │ 927.6868896484375      │\n",
       "│ Time/Rollout                  │ 10.837553024291992     │\n",
       "│ Time/Update                   │ 1.8503332138061523     │\n",
       "│ Time/Epoch                    │ 12.687929153442383     │\n",
       "│ Time/FPS                      │ 161.41326904296875     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 16.131427764892578     │\n",
       "│ Metrics/EpCost                │ 85.22000122070312      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 69.0                   │\n",
       "│ Train/Entropy                 │ 0.9251443147659302     │\n",
       "│ Train/KL                      │ 0.015395496040582657   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9945186376571655     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9945186376571655     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9945186376571655     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019894151017069817   │\n",
       "│ Train/LR                      │ 0.0002579999854788184  │\n",
       "│ Train/PolicyStd               │ 0.6107996106147766     │\n",
       "│ TotalEnvSteps                 │ 143360.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01192762702703476   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0021053720265626907  │\n",
       "│ Value/Adv                     │ -0.07951352745294571   │\n",
       "│ Loss/Loss_reward_critic       │ 0.022311747074127197   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 3.8936734199523926e-05 │\n",
       "│ Value/reward                  │ 1.711593508720398      │\n",
       "│ Time/Total                    │ 927.6868896484375      │\n",
       "│ Time/Rollout                  │ 10.837553024291992     │\n",
       "│ Time/Update                   │ 1.8503332138061523     │\n",
       "│ Time/Epoch                    │ 12.687929153442383     │\n",
       "│ Time/FPS                      │ 161.41326904296875     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 16.25537872314453      │\n",
       "│ Metrics/EpCost                │ 88.13999938964844      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 70.0                   │\n",
       "│ Train/Entropy                 │ 0.9096148610115051     │\n",
       "│ Train/KL                      │ 0.015820631757378578   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9962002038955688     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9962002038955688     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9962002038955688     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01904575154185295    │\n",
       "│ Train/LR                      │ 0.00025740001001395285 │\n",
       "│ Train/PolicyStd               │ 0.6012347340583801     │\n",
       "│ TotalEnvSteps                 │ 145408.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014892654493451118  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002965027466416359  │\n",
       "│ Value/Adv                     │ 0.12209313362836838    │\n",
       "│ Loss/Loss_reward_critic       │ 0.021699903532862663   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.000611843541264534  │\n",
       "│ Value/reward                  │ 1.7020848989486694     │\n",
       "│ Time/Total                    │ 941.5755615234375      │\n",
       "│ Time/Rollout                  │ 11.933064460754395     │\n",
       "│ Time/Update                   │ 1.937283992767334      │\n",
       "│ Time/Epoch                    │ 13.870392799377441     │\n",
       "│ Time/FPS                      │ 147.65264892578125     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 16.25537872314453      │\n",
       "│ Metrics/EpCost                │ 88.13999938964844      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 70.0                   │\n",
       "│ Train/Entropy                 │ 0.9096148610115051     │\n",
       "│ Train/KL                      │ 0.015820631757378578   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9962002038955688     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9962002038955688     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9962002038955688     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01904575154185295    │\n",
       "│ Train/LR                      │ 0.00025740001001395285 │\n",
       "│ Train/PolicyStd               │ 0.6012347340583801     │\n",
       "│ TotalEnvSteps                 │ 145408.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014892654493451118  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002965027466416359  │\n",
       "│ Value/Adv                     │ 0.12209313362836838    │\n",
       "│ Loss/Loss_reward_critic       │ 0.021699903532862663   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.000611843541264534  │\n",
       "│ Value/reward                  │ 1.7020848989486694     │\n",
       "│ Time/Total                    │ 941.5755615234375      │\n",
       "│ Time/Rollout                  │ 11.933064460754395     │\n",
       "│ Time/Update                   │ 1.937283992767334      │\n",
       "│ Time/Epoch                    │ 13.870392799377441     │\n",
       "│ Time/FPS                      │ 147.65264892578125     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 16.30995750427246      │\n",
       "│ Metrics/EpCost                │ 89.91999816894531      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 71.0                   │\n",
       "│ Train/Entropy                 │ 0.9024173021316528     │\n",
       "│ Train/KL                      │ 0.013815094716846943   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9982234239578247     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9982234239578247     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9982234239578247     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01818549819290638    │\n",
       "│ Train/LR                      │ 0.00025680000544525683 │\n",
       "│ Train/PolicyStd               │ 0.5968813896179199     │\n",
       "│ TotalEnvSteps                 │ 147456.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012594548054039478  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00229810643941164    │\n",
       "│ Value/Adv                     │ -0.1050243228673935    │\n",
       "│ Loss/Loss_reward_critic       │ 0.023668568581342697   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.001968665048480034   │\n",
       "│ Value/reward                  │ 1.6072335243225098     │\n",
       "│ Time/Total                    │ 955.2323608398438      │\n",
       "│ Time/Rollout                  │ 11.714543342590332     │\n",
       "│ Time/Update                   │ 1.9263203144073486     │\n",
       "│ Time/Epoch                    │ 13.640908241271973     │\n",
       "│ Time/FPS                      │ 150.1366424560547      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 16.30995750427246      │\n",
       "│ Metrics/EpCost                │ 89.91999816894531      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 71.0                   │\n",
       "│ Train/Entropy                 │ 0.9024173021316528     │\n",
       "│ Train/KL                      │ 0.013815094716846943   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9982234239578247     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9982234239578247     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9982234239578247     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01818549819290638    │\n",
       "│ Train/LR                      │ 0.00025680000544525683 │\n",
       "│ Train/PolicyStd               │ 0.5968813896179199     │\n",
       "│ TotalEnvSteps                 │ 147456.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012594548054039478  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00229810643941164    │\n",
       "│ Value/Adv                     │ -0.1050243228673935    │\n",
       "│ Loss/Loss_reward_critic       │ 0.023668568581342697   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.001968665048480034   │\n",
       "│ Value/reward                  │ 1.6072335243225098     │\n",
       "│ Time/Total                    │ 955.2323608398438      │\n",
       "│ Time/Rollout                  │ 11.714543342590332     │\n",
       "│ Time/Update                   │ 1.9263203144073486     │\n",
       "│ Time/Epoch                    │ 13.640908241271973     │\n",
       "│ Time/FPS                      │ 150.1366424560547      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 16.438032150268555    │\n",
       "│ Metrics/EpCost                │ 81.27999877929688     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 72.0                  │\n",
       "│ Train/Entropy                 │ 0.907873272895813     │\n",
       "│ Train/KL                      │ 0.014685911126434803  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9998676180839539    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9998676180839539    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9998676180839539    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01846371404826641   │\n",
       "│ Train/LR                      │ 0.0002562000008765608 │\n",
       "│ Train/PolicyStd               │ 0.6002025604248047    │\n",
       "│ TotalEnvSteps                 │ 149504.0              │\n",
       "│ Loss/Loss_pi                  │ -0.00867602787911892  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.003918520174920559  │\n",
       "│ Value/Adv                     │ 0.029492877423763275  │\n",
       "│ Loss/Loss_reward_critic       │ 0.025392305105924606  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0017237365245819092 │\n",
       "│ Value/reward                  │ 1.7605197429656982    │\n",
       "│ Time/Total                    │ 968.8073120117188     │\n",
       "│ Time/Rollout                  │ 11.649007797241211    │\n",
       "│ Time/Update                   │ 1.9128189086914062    │\n",
       "│ Time/Epoch                    │ 13.561885833740234    │\n",
       "│ Time/FPS                      │ 151.01145935058594    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 16.438032150268555    │\n",
       "│ Metrics/EpCost                │ 81.27999877929688     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 72.0                  │\n",
       "│ Train/Entropy                 │ 0.907873272895813     │\n",
       "│ Train/KL                      │ 0.014685911126434803  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9998676180839539    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9998676180839539    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9998676180839539    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01846371404826641   │\n",
       "│ Train/LR                      │ 0.0002562000008765608 │\n",
       "│ Train/PolicyStd               │ 0.6002025604248047    │\n",
       "│ TotalEnvSteps                 │ 149504.0              │\n",
       "│ Loss/Loss_pi                  │ -0.00867602787911892  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.003918520174920559  │\n",
       "│ Value/Adv                     │ 0.029492877423763275  │\n",
       "│ Loss/Loss_reward_critic       │ 0.025392305105924606  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0017237365245819092 │\n",
       "│ Value/reward                  │ 1.7605197429656982    │\n",
       "│ Time/Total                    │ 968.8073120117188     │\n",
       "│ Time/Rollout                  │ 11.649007797241211    │\n",
       "│ Time/Update                   │ 1.9128189086914062    │\n",
       "│ Time/Epoch                    │ 13.561885833740234    │\n",
       "│ Time/FPS                      │ 151.01145935058594    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 16.754724502563477     │\n",
       "│ Metrics/EpCost                │ 66.36000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 73.0                   │\n",
       "│ Train/Entropy                 │ 0.9077247381210327     │\n",
       "│ Train/KL                      │ 0.013695375062525272   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9970608949661255     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9970608949661255     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9970608949661255     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018864266574382782   │\n",
       "│ Train/LR                      │ 0.0002555999963078648  │\n",
       "│ Train/PolicyStd               │ 0.6001017689704895     │\n",
       "│ TotalEnvSteps                 │ 151552.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012072376906871796  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0033963490277528763 │\n",
       "│ Value/Adv                     │ 0.05802043154835701    │\n",
       "│ Loss/Loss_reward_critic       │ 0.026412809267640114   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0010205041617155075  │\n",
       "│ Value/reward                  │ 1.732674241065979      │\n",
       "│ Time/Total                    │ 982.4086303710938      │\n",
       "│ Time/Rollout                  │ 11.63929557800293      │\n",
       "│ Time/Update                   │ 1.948193073272705      │\n",
       "│ Time/Epoch                    │ 13.587542533874512     │\n",
       "│ Time/FPS                      │ 150.72630310058594     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 16.754724502563477     │\n",
       "│ Metrics/EpCost                │ 66.36000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 73.0                   │\n",
       "│ Train/Entropy                 │ 0.9077247381210327     │\n",
       "│ Train/KL                      │ 0.013695375062525272   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9970608949661255     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9970608949661255     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9970608949661255     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018864266574382782   │\n",
       "│ Train/LR                      │ 0.0002555999963078648  │\n",
       "│ Train/PolicyStd               │ 0.6001017689704895     │\n",
       "│ TotalEnvSteps                 │ 151552.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012072376906871796  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0033963490277528763 │\n",
       "│ Value/Adv                     │ 0.05802043154835701    │\n",
       "│ Loss/Loss_reward_critic       │ 0.026412809267640114   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0010205041617155075  │\n",
       "│ Value/reward                  │ 1.732674241065979      │\n",
       "│ Time/Total                    │ 982.4086303710938      │\n",
       "│ Time/Rollout                  │ 11.63929557800293      │\n",
       "│ Time/Update                   │ 1.948193073272705      │\n",
       "│ Time/Epoch                    │ 13.587542533874512     │\n",
       "│ Time/FPS                      │ 150.72630310058594     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 16.84410858154297      │\n",
       "│ Metrics/EpCost                │ 67.72000122070312      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 74.0                   │\n",
       "│ Train/Entropy                 │ 0.8996365666389465     │\n",
       "│ Train/KL                      │ 0.017283199355006218   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0001447200775146     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0001447200775146     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0001447200775146     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020493799820542336   │\n",
       "│ Train/LR                      │ 0.00025499999173916876 │\n",
       "│ Train/PolicyStd               │ 0.5952633023262024     │\n",
       "│ TotalEnvSteps                 │ 153600.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018022160977125168  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.005949784070253372  │\n",
       "│ Value/Adv                     │ -0.036398597061634064  │\n",
       "│ Loss/Loss_reward_critic       │ 0.017513690516352654   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00889911875128746   │\n",
       "│ Value/reward                  │ 1.7677686214447021     │\n",
       "│ Time/Total                    │ 996.0494384765625      │\n",
       "│ Time/Rollout                  │ 11.640284538269043     │\n",
       "│ Time/Update                   │ 1.986450433731079      │\n",
       "│ Time/Epoch                    │ 13.626777648925781     │\n",
       "│ Time/FPS                      │ 150.29232788085938     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 16.84410858154297      │\n",
       "│ Metrics/EpCost                │ 67.72000122070312      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 74.0                   │\n",
       "│ Train/Entropy                 │ 0.8996365666389465     │\n",
       "│ Train/KL                      │ 0.017283199355006218   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0001447200775146     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0001447200775146     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0001447200775146     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020493799820542336   │\n",
       "│ Train/LR                      │ 0.00025499999173916876 │\n",
       "│ Train/PolicyStd               │ 0.5952633023262024     │\n",
       "│ TotalEnvSteps                 │ 153600.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018022160977125168  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.005949784070253372  │\n",
       "│ Value/Adv                     │ -0.036398597061634064  │\n",
       "│ Loss/Loss_reward_critic       │ 0.017513690516352654   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00889911875128746   │\n",
       "│ Value/reward                  │ 1.7677686214447021     │\n",
       "│ Time/Total                    │ 996.0494384765625      │\n",
       "│ Time/Rollout                  │ 11.640284538269043     │\n",
       "│ Time/Update                   │ 1.986450433731079      │\n",
       "│ Time/Epoch                    │ 13.626777648925781     │\n",
       "│ Time/FPS                      │ 150.29232788085938     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.138641357421875     │\n",
       "│ Metrics/EpCost                │ 65.69999694824219      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 75.0                   │\n",
       "│ Train/Entropy                 │ 0.8923923373222351     │\n",
       "│ Train/KL                      │ 0.01666031777858734    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0001561641693115     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0001561641693115     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0001561641693115     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019449429586529732   │\n",
       "│ Train/LR                      │ 0.00025439998717047274 │\n",
       "│ Train/PolicyStd               │ 0.5909516215324402     │\n",
       "│ TotalEnvSteps                 │ 155648.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014970177784562111  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.003051983192563057   │\n",
       "│ Value/Adv                     │ -0.10776729881763458   │\n",
       "│ Loss/Loss_reward_critic       │ 0.022470882162451744   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004957191646099091   │\n",
       "│ Value/reward                  │ 1.7577511072158813     │\n",
       "│ Time/Total                    │ 1009.933349609375      │\n",
       "│ Time/Rollout                  │ 11.839343070983887     │\n",
       "│ Time/Update                   │ 2.0323638916015625     │\n",
       "│ Time/Epoch                    │ 13.871767044067383     │\n",
       "│ Time/FPS                      │ 147.6380157470703      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.138641357421875     │\n",
       "│ Metrics/EpCost                │ 65.69999694824219      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 75.0                   │\n",
       "│ Train/Entropy                 │ 0.8923923373222351     │\n",
       "│ Train/KL                      │ 0.01666031777858734    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0001561641693115     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0001561641693115     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0001561641693115     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019449429586529732   │\n",
       "│ Train/LR                      │ 0.00025439998717047274 │\n",
       "│ Train/PolicyStd               │ 0.5909516215324402     │\n",
       "│ TotalEnvSteps                 │ 155648.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014970177784562111  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.003051983192563057   │\n",
       "│ Value/Adv                     │ -0.10776729881763458   │\n",
       "│ Loss/Loss_reward_critic       │ 0.022470882162451744   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004957191646099091   │\n",
       "│ Value/reward                  │ 1.7577511072158813     │\n",
       "│ Time/Total                    │ 1009.933349609375      │\n",
       "│ Time/Rollout                  │ 11.839343070983887     │\n",
       "│ Time/Update                   │ 2.0323638916015625     │\n",
       "│ Time/Epoch                    │ 13.871767044067383     │\n",
       "│ Time/FPS                      │ 147.6380157470703      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m9\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.252765655517578     │\n",
       "│ Metrics/EpCost                │ 66.16000366210938      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 76.0                   │\n",
       "│ Train/Entropy                 │ 0.8876852989196777     │\n",
       "│ Train/KL                      │ 0.023505760356783867   │\n",
       "│ Train/StopIter                │ 9.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.99897700548172       │\n",
       "│ Train/PolicyRatio/Min         │ 0.99897700548172       │\n",
       "│ Train/PolicyRatio/Max         │ 0.99897700548172       │\n",
       "│ Train/PolicyRatio/Std         │ 0.017981914803385735   │\n",
       "│ Train/LR                      │ 0.0002538000117056072  │\n",
       "│ Train/PolicyStd               │ 0.5881659388542175     │\n",
       "│ TotalEnvSteps                 │ 157696.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012937006540596485  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0020331712439656258  │\n",
       "│ Value/Adv                     │ 0.024811826646327972   │\n",
       "│ Loss/Loss_reward_critic       │ 0.019472196698188782   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0029986854642629623 │\n",
       "│ Value/reward                  │ 1.805392861366272      │\n",
       "│ Time/Total                    │ 1023.688232421875      │\n",
       "│ Time/Rollout                  │ 11.874425888061523     │\n",
       "│ Time/Update                   │ 1.8671388626098633     │\n",
       "│ Time/Epoch                    │ 13.741616249084473     │\n",
       "│ Time/FPS                      │ 149.0363311767578      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.252765655517578     │\n",
       "│ Metrics/EpCost                │ 66.16000366210938      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 76.0                   │\n",
       "│ Train/Entropy                 │ 0.8876852989196777     │\n",
       "│ Train/KL                      │ 0.023505760356783867   │\n",
       "│ Train/StopIter                │ 9.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.99897700548172       │\n",
       "│ Train/PolicyRatio/Min         │ 0.99897700548172       │\n",
       "│ Train/PolicyRatio/Max         │ 0.99897700548172       │\n",
       "│ Train/PolicyRatio/Std         │ 0.017981914803385735   │\n",
       "│ Train/LR                      │ 0.0002538000117056072  │\n",
       "│ Train/PolicyStd               │ 0.5881659388542175     │\n",
       "│ TotalEnvSteps                 │ 157696.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012937006540596485  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0020331712439656258  │\n",
       "│ Value/Adv                     │ 0.024811826646327972   │\n",
       "│ Loss/Loss_reward_critic       │ 0.019472196698188782   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0029986854642629623 │\n",
       "│ Value/reward                  │ 1.805392861366272      │\n",
       "│ Time/Total                    │ 1023.688232421875      │\n",
       "│ Time/Rollout                  │ 11.874425888061523     │\n",
       "│ Time/Update                   │ 1.8671388626098633     │\n",
       "│ Time/Epoch                    │ 13.741616249084473     │\n",
       "│ Time/FPS                      │ 149.0363311767578      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.288349151611328     │\n",
       "│ Metrics/EpCost                │ 65.9000015258789       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 77.0                   │\n",
       "│ Train/Entropy                 │ 0.8821762204170227     │\n",
       "│ Train/KL                      │ 0.0168501827865839     │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9947148561477661     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9947148561477661     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9947148561477661     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017898615449666977   │\n",
       "│ Train/LR                      │ 0.00025320000713691115 │\n",
       "│ Train/PolicyStd               │ 0.5850629806518555     │\n",
       "│ TotalEnvSteps                 │ 159744.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011290987022221088  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0016460195183753967  │\n",
       "│ Value/Adv                     │ -0.08430234342813492   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02630377933382988    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006831582635641098   │\n",
       "│ Value/reward                  │ 1.7312283515930176     │\n",
       "│ Time/Total                    │ 1037.3929443359375     │\n",
       "│ Time/Rollout                  │ 11.743803024291992     │\n",
       "│ Time/Update                   │ 1.947310447692871      │\n",
       "│ Time/Epoch                    │ 13.69115161895752      │\n",
       "│ Time/FPS                      │ 149.58566284179688     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.288349151611328     │\n",
       "│ Metrics/EpCost                │ 65.9000015258789       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 77.0                   │\n",
       "│ Train/Entropy                 │ 0.8821762204170227     │\n",
       "│ Train/KL                      │ 0.0168501827865839     │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9947148561477661     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9947148561477661     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9947148561477661     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017898615449666977   │\n",
       "│ Train/LR                      │ 0.00025320000713691115 │\n",
       "│ Train/PolicyStd               │ 0.5850629806518555     │\n",
       "│ TotalEnvSteps                 │ 159744.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011290987022221088  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0016460195183753967  │\n",
       "│ Value/Adv                     │ -0.08430234342813492   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02630377933382988    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006831582635641098   │\n",
       "│ Value/reward                  │ 1.7312283515930176     │\n",
       "│ Time/Total                    │ 1037.3929443359375     │\n",
       "│ Time/Rollout                  │ 11.743803024291992     │\n",
       "│ Time/Update                   │ 1.947310447692871      │\n",
       "│ Time/Epoch                    │ 13.69115161895752      │\n",
       "│ Time/FPS                      │ 149.58566284179688     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.379758834838867     │\n",
       "│ Metrics/EpCost                │ 66.76000213623047      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 78.0                   │\n",
       "│ Train/Entropy                 │ 0.8762257695198059     │\n",
       "│ Train/KL                      │ 0.01329985074698925    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0010292530059814     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0010292530059814     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0010292530059814     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01799745112657547    │\n",
       "│ Train/LR                      │ 0.00025260000256821513 │\n",
       "│ Train/PolicyStd               │ 0.5816408395767212     │\n",
       "│ TotalEnvSteps                 │ 161792.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017212379723787308  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.005921392701566219  │\n",
       "│ Value/Adv                     │ -0.16649241745471954   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02030462585389614    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005999153479933739  │\n",
       "│ Value/reward                  │ 1.8171703815460205     │\n",
       "│ Time/Total                    │ 1051.21044921875       │\n",
       "│ Time/Rollout                  │ 11.839359283447266     │\n",
       "│ Time/Update                   │ 1.966196060180664      │\n",
       "│ Time/Epoch                    │ 13.805609703063965     │\n",
       "│ Time/FPS                      │ 148.3455047607422      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.379758834838867     │\n",
       "│ Metrics/EpCost                │ 66.76000213623047      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 78.0                   │\n",
       "│ Train/Entropy                 │ 0.8762257695198059     │\n",
       "│ Train/KL                      │ 0.01329985074698925    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0010292530059814     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0010292530059814     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0010292530059814     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01799745112657547    │\n",
       "│ Train/LR                      │ 0.00025260000256821513 │\n",
       "│ Train/PolicyStd               │ 0.5816408395767212     │\n",
       "│ TotalEnvSteps                 │ 161792.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017212379723787308  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.005921392701566219  │\n",
       "│ Value/Adv                     │ -0.16649241745471954   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02030462585389614    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005999153479933739  │\n",
       "│ Value/reward                  │ 1.8171703815460205     │\n",
       "│ Time/Total                    │ 1051.21044921875       │\n",
       "│ Time/Rollout                  │ 11.839359283447266     │\n",
       "│ Time/Update                   │ 1.966196060180664      │\n",
       "│ Time/Epoch                    │ 13.805609703063965     │\n",
       "│ Time/FPS                      │ 148.3455047607422      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.418540954589844     │\n",
       "│ Metrics/EpCost                │ 67.23999786376953      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 79.0                   │\n",
       "│ Train/Entropy                 │ 0.8709584474563599     │\n",
       "│ Train/KL                      │ 0.01193082146346569    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9956115484237671     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9956115484237671     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9956115484237671     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017801081761717796   │\n",
       "│ Train/LR                      │ 0.0002519999979995191  │\n",
       "│ Train/PolicyStd               │ 0.5785784125328064     │\n",
       "│ TotalEnvSteps                 │ 163840.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011156288906931877  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.006056090816855431   │\n",
       "│ Value/Adv                     │ 0.20762419700622559    │\n",
       "│ Loss/Loss_reward_critic       │ 0.019554805010557175   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0007498208433389664 │\n",
       "│ Value/reward                  │ 1.7475810050964355     │\n",
       "│ Time/Total                    │ 1065.037109375         │\n",
       "│ Time/Rollout                  │ 11.879753112792969     │\n",
       "│ Time/Update                   │ 1.9325695037841797     │\n",
       "│ Time/Epoch                    │ 13.812363624572754     │\n",
       "│ Time/FPS                      │ 148.27296447753906     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.418540954589844     │\n",
       "│ Metrics/EpCost                │ 67.23999786376953      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 79.0                   │\n",
       "│ Train/Entropy                 │ 0.8709584474563599     │\n",
       "│ Train/KL                      │ 0.01193082146346569    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9956115484237671     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9956115484237671     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9956115484237671     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017801081761717796   │\n",
       "│ Train/LR                      │ 0.0002519999979995191  │\n",
       "│ Train/PolicyStd               │ 0.5785784125328064     │\n",
       "│ TotalEnvSteps                 │ 163840.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011156288906931877  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.006056090816855431   │\n",
       "│ Value/Adv                     │ 0.20762419700622559    │\n",
       "│ Loss/Loss_reward_critic       │ 0.019554805010557175   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0007498208433389664 │\n",
       "│ Value/reward                  │ 1.7475810050964355     │\n",
       "│ Time/Total                    │ 1065.037109375         │\n",
       "│ Time/Rollout                  │ 11.879753112792969     │\n",
       "│ Time/Update                   │ 1.9325695037841797     │\n",
       "│ Time/Epoch                    │ 13.812363624572754     │\n",
       "│ Time/FPS                      │ 148.27296447753906     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.39502716064453      │\n",
       "│ Metrics/EpCost                │ 65.26000213623047      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 80.0                   │\n",
       "│ Train/Entropy                 │ 0.8585892915725708     │\n",
       "│ Train/KL                      │ 0.013541056774556637   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0002422332763672     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0002422332763672     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0002422332763672     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01789243333041668    │\n",
       "│ Train/LR                      │ 0.0002513999934308231  │\n",
       "│ Train/PolicyStd               │ 0.5714655518531799     │\n",
       "│ TotalEnvSteps                 │ 165888.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012439553625881672  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0012832647189497948 │\n",
       "│ Value/Adv                     │ -0.09593985229730606   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015595917589962482   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.003958887420594692  │\n",
       "│ Value/reward                  │ 1.6294013261795044     │\n",
       "│ Time/Total                    │ 1078.863525390625      │\n",
       "│ Time/Rollout                  │ 11.890117645263672     │\n",
       "│ Time/Update                   │ 1.9194579124450684     │\n",
       "│ Time/Epoch                    │ 13.809624671936035     │\n",
       "│ Time/FPS                      │ 148.30238342285156     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.39502716064453      │\n",
       "│ Metrics/EpCost                │ 65.26000213623047      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 80.0                   │\n",
       "│ Train/Entropy                 │ 0.8585892915725708     │\n",
       "│ Train/KL                      │ 0.013541056774556637   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0002422332763672     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0002422332763672     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0002422332763672     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01789243333041668    │\n",
       "│ Train/LR                      │ 0.0002513999934308231  │\n",
       "│ Train/PolicyStd               │ 0.5714655518531799     │\n",
       "│ TotalEnvSteps                 │ 165888.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012439553625881672  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0012832647189497948 │\n",
       "│ Value/Adv                     │ -0.09593985229730606   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015595917589962482   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.003958887420594692  │\n",
       "│ Value/reward                  │ 1.6294013261795044     │\n",
       "│ Time/Total                    │ 1078.863525390625      │\n",
       "│ Time/Rollout                  │ 11.890117645263672     │\n",
       "│ Time/Update                   │ 1.9194579124450684     │\n",
       "│ Time/Epoch                    │ 13.809624671936035     │\n",
       "│ Time/FPS                      │ 148.30238342285156     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.462125778198242     │\n",
       "│ Metrics/EpCost                │ 65.87999725341797      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 81.0                   │\n",
       "│ Train/Entropy                 │ 0.8543075323104858     │\n",
       "│ Train/KL                      │ 0.015876658260822296   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9977947473526001     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9977947473526001     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9977947473526001     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019206052646040916   │\n",
       "│ Train/LR                      │ 0.00025079998886212707 │\n",
       "│ Train/PolicyStd               │ 0.5689066648483276     │\n",
       "│ TotalEnvSteps                 │ 167936.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011074315756559372  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0013652378693223     │\n",
       "│ Value/Adv                     │ -0.00855809822678566   │\n",
       "│ Loss/Loss_reward_critic       │ 0.022629404440522194   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0070334868505597115  │\n",
       "│ Value/reward                  │ 1.6344181299209595     │\n",
       "│ Time/Total                    │ 1092.5653076171875     │\n",
       "│ Time/Rollout                  │ 11.738299369812012     │\n",
       "│ Time/Update                   │ 1.9515464305877686     │\n",
       "│ Time/Epoch                    │ 13.689897537231445     │\n",
       "│ Time/FPS                      │ 149.59938049316406     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.462125778198242     │\n",
       "│ Metrics/EpCost                │ 65.87999725341797      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 81.0                   │\n",
       "│ Train/Entropy                 │ 0.8543075323104858     │\n",
       "│ Train/KL                      │ 0.015876658260822296   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9977947473526001     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9977947473526001     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9977947473526001     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019206052646040916   │\n",
       "│ Train/LR                      │ 0.00025079998886212707 │\n",
       "│ Train/PolicyStd               │ 0.5689066648483276     │\n",
       "│ TotalEnvSteps                 │ 167936.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011074315756559372  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0013652378693223     │\n",
       "│ Value/Adv                     │ -0.00855809822678566   │\n",
       "│ Loss/Loss_reward_critic       │ 0.022629404440522194   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0070334868505597115  │\n",
       "│ Value/reward                  │ 1.6344181299209595     │\n",
       "│ Time/Total                    │ 1092.5653076171875     │\n",
       "│ Time/Rollout                  │ 11.738299369812012     │\n",
       "│ Time/Update                   │ 1.9515464305877686     │\n",
       "│ Time/Epoch                    │ 13.689897537231445     │\n",
       "│ Time/FPS                      │ 149.59938049316406     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.422752380371094     │\n",
       "│ Metrics/EpCost                │ 67.27999877929688      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 82.0                   │\n",
       "│ Train/Entropy                 │ 0.8505913019180298     │\n",
       "│ Train/KL                      │ 0.011737596243619919   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0002726316452026     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0002726316452026     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0002726316452026     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01739358715713024    │\n",
       "│ Train/LR                      │ 0.0002502000133972615  │\n",
       "│ Train/PolicyStd               │ 0.5667952299118042     │\n",
       "│ TotalEnvSteps                 │ 169984.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012101306580007076  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0010269908234477043 │\n",
       "│ Value/Adv                     │ -0.2197362184524536    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017454011365771294   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0051753930747509    │\n",
       "│ Value/reward                  │ 1.7153534889221191     │\n",
       "│ Time/Total                    │ 1106.4222412109375     │\n",
       "│ Time/Rollout                  │ 11.870107650756836     │\n",
       "│ Time/Update                   │ 1.9724392890930176     │\n",
       "│ Time/Epoch                    │ 13.8425874710083       │\n",
       "│ Time/FPS                      │ 147.94923400878906     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.422752380371094     │\n",
       "│ Metrics/EpCost                │ 67.27999877929688      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 82.0                   │\n",
       "│ Train/Entropy                 │ 0.8505913019180298     │\n",
       "│ Train/KL                      │ 0.011737596243619919   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0002726316452026     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0002726316452026     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0002726316452026     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01739358715713024    │\n",
       "│ Train/LR                      │ 0.0002502000133972615  │\n",
       "│ Train/PolicyStd               │ 0.5667952299118042     │\n",
       "│ TotalEnvSteps                 │ 169984.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012101306580007076  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0010269908234477043 │\n",
       "│ Value/Adv                     │ -0.2197362184524536    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017454011365771294   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0051753930747509    │\n",
       "│ Value/reward                  │ 1.7153534889221191     │\n",
       "│ Time/Total                    │ 1106.4222412109375     │\n",
       "│ Time/Rollout                  │ 11.870107650756836     │\n",
       "│ Time/Update                   │ 1.9724392890930176     │\n",
       "│ Time/Epoch                    │ 13.8425874710083       │\n",
       "│ Time/FPS                      │ 147.94923400878906     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m8\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.43960189819336     │\n",
       "│ Metrics/EpCost                │ 69.44000244140625     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 83.0                  │\n",
       "│ Train/Entropy                 │ 0.8434100151062012    │\n",
       "│ Train/KL                      │ 0.020464148372411728  │\n",
       "│ Train/StopIter                │ 8.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9997352361679077    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9997352361679077    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9997352361679077    │\n",
       "│ Train/PolicyRatio/Std         │ 0.02117196097970009   │\n",
       "│ Train/LR                      │ 0.0002496000088285655 │\n",
       "│ Train/PolicyStd               │ 0.562727153301239     │\n",
       "│ TotalEnvSteps                 │ 172032.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01348151732236147  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.001380210742354393 │\n",
       "│ Value/Adv                     │ -0.08556703478097916  │\n",
       "│ Loss/Loss_reward_critic       │ 0.021660353988409042  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004206342622637749  │\n",
       "│ Value/reward                  │ 1.8295842409133911    │\n",
       "│ Time/Total                    │ 1119.828125           │\n",
       "│ Time/Rollout                  │ 11.800275802612305    │\n",
       "│ Time/Update                   │ 1.5928151607513428    │\n",
       "│ Time/Epoch                    │ 13.393139839172363    │\n",
       "│ Time/FPS                      │ 152.9141082763672     │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.43960189819336     │\n",
       "│ Metrics/EpCost                │ 69.44000244140625     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 83.0                  │\n",
       "│ Train/Entropy                 │ 0.8434100151062012    │\n",
       "│ Train/KL                      │ 0.020464148372411728  │\n",
       "│ Train/StopIter                │ 8.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9997352361679077    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9997352361679077    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9997352361679077    │\n",
       "│ Train/PolicyRatio/Std         │ 0.02117196097970009   │\n",
       "│ Train/LR                      │ 0.0002496000088285655 │\n",
       "│ Train/PolicyStd               │ 0.562727153301239     │\n",
       "│ TotalEnvSteps                 │ 172032.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01348151732236147  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.001380210742354393 │\n",
       "│ Value/Adv                     │ -0.08556703478097916  │\n",
       "│ Loss/Loss_reward_critic       │ 0.021660353988409042  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004206342622637749  │\n",
       "│ Value/reward                  │ 1.8295842409133911    │\n",
       "│ Time/Total                    │ 1119.828125           │\n",
       "│ Time/Rollout                  │ 11.800275802612305    │\n",
       "│ Time/Update                   │ 1.5928151607513428    │\n",
       "│ Time/Epoch                    │ 13.393139839172363    │\n",
       "│ Time/FPS                      │ 152.9141082763672     │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.160507202148438      │\n",
       "│ Metrics/EpCost                │ 69.91999816894531       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 84.0                    │\n",
       "│ Train/Entropy                 │ 0.8408852815628052      │\n",
       "│ Train/KL                      │ 0.015625998377799988    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9989660978317261      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9989660978317261      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9989660978317261      │\n",
       "│ Train/PolicyRatio/Std         │ 0.017375078052282333    │\n",
       "│ Train/LR                      │ 0.00024900000425986946  │\n",
       "│ Train/PolicyStd               │ 0.5612961649894714      │\n",
       "│ TotalEnvSteps                 │ 174080.0                │\n",
       "│ Loss/Loss_pi                  │ -0.013584142550826073   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00010262522846460342 │\n",
       "│ Value/Adv                     │ 0.17343579232692719     │\n",
       "│ Loss/Loss_reward_critic       │ 0.012839806266129017    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.008820547722280025   │\n",
       "│ Value/reward                  │ 1.5837534666061401      │\n",
       "│ Time/Total                    │ 1133.5386962890625      │\n",
       "│ Time/Rollout                  │ 11.733736991882324      │\n",
       "│ Time/Update                   │ 1.9622938632965088      │\n",
       "│ Time/Epoch                    │ 13.696087837219238      │\n",
       "│ Time/FPS                      │ 149.53175354003906      │\n",
       "└───────────────────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.160507202148438      │\n",
       "│ Metrics/EpCost                │ 69.91999816894531       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 84.0                    │\n",
       "│ Train/Entropy                 │ 0.8408852815628052      │\n",
       "│ Train/KL                      │ 0.015625998377799988    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9989660978317261      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9989660978317261      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9989660978317261      │\n",
       "│ Train/PolicyRatio/Std         │ 0.017375078052282333    │\n",
       "│ Train/LR                      │ 0.00024900000425986946  │\n",
       "│ Train/PolicyStd               │ 0.5612961649894714      │\n",
       "│ TotalEnvSteps                 │ 174080.0                │\n",
       "│ Loss/Loss_pi                  │ -0.013584142550826073   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00010262522846460342 │\n",
       "│ Value/Adv                     │ 0.17343579232692719     │\n",
       "│ Loss/Loss_reward_critic       │ 0.012839806266129017    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.008820547722280025   │\n",
       "│ Value/reward                  │ 1.5837534666061401      │\n",
       "│ Time/Total                    │ 1133.5386962890625      │\n",
       "│ Time/Rollout                  │ 11.733736991882324      │\n",
       "│ Time/Update                   │ 1.9622938632965088      │\n",
       "│ Time/Epoch                    │ 13.696087837219238      │\n",
       "│ Time/FPS                      │ 149.53175354003906      │\n",
       "└───────────────────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 16.91824722290039      │\n",
       "│ Metrics/EpCost                │ 70.05999755859375      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 85.0                   │\n",
       "│ Train/Entropy                 │ 0.830104649066925      │\n",
       "│ Train/KL                      │ 0.014415784738957882   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9995112419128418     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9995112419128418     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9995112419128418     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018154285848140717   │\n",
       "│ Train/LR                      │ 0.00024839999969117343 │\n",
       "│ Train/PolicyStd               │ 0.5552718043327332     │\n",
       "│ TotalEnvSteps                 │ 176128.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015228064730763435  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0016439221799373627 │\n",
       "│ Value/Adv                     │ -0.04587790369987488   │\n",
       "│ Loss/Loss_reward_critic       │ 0.0161574799567461     │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0033176736906170845  │\n",
       "│ Value/reward                  │ 1.4355998039245605     │\n",
       "│ Time/Total                    │ 1147.3426513671875     │\n",
       "│ Time/Rollout                  │ 11.795886039733887     │\n",
       "│ Time/Update                   │ 1.995776653289795      │\n",
       "│ Time/Epoch                    │ 13.791704177856445     │\n",
       "│ Time/FPS                      │ 148.4950714111328      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 16.91824722290039      │\n",
       "│ Metrics/EpCost                │ 70.05999755859375      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 85.0                   │\n",
       "│ Train/Entropy                 │ 0.830104649066925      │\n",
       "│ Train/KL                      │ 0.014415784738957882   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9995112419128418     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9995112419128418     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9995112419128418     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018154285848140717   │\n",
       "│ Train/LR                      │ 0.00024839999969117343 │\n",
       "│ Train/PolicyStd               │ 0.5552718043327332     │\n",
       "│ TotalEnvSteps                 │ 176128.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015228064730763435  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0016439221799373627 │\n",
       "│ Value/Adv                     │ -0.04587790369987488   │\n",
       "│ Loss/Loss_reward_critic       │ 0.0161574799567461     │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0033176736906170845  │\n",
       "│ Value/reward                  │ 1.4355998039245605     │\n",
       "│ Time/Total                    │ 1147.3426513671875     │\n",
       "│ Time/Rollout                  │ 11.795886039733887     │\n",
       "│ Time/Update                   │ 1.995776653289795      │\n",
       "│ Time/Epoch                    │ 13.791704177856445     │\n",
       "│ Time/FPS                      │ 148.4950714111328      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m9\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.073348999023438     │\n",
       "│ Metrics/EpCost                │ 71.5                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 86.0                   │\n",
       "│ Train/Entropy                 │ 0.8134179711341858     │\n",
       "│ Train/KL                      │ 0.022588655352592468   │\n",
       "│ Train/StopIter                │ 9.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9994841814041138     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9994841814041138     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9994841814041138     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01999610848724842    │\n",
       "│ Train/LR                      │ 0.0002477999951224774  │\n",
       "│ Train/PolicyStd               │ 0.5462018847465515     │\n",
       "│ TotalEnvSteps                 │ 178176.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01720019243657589   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0019721277058124542 │\n",
       "│ Value/Adv                     │ -0.05442396551370621   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02056988887488842    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004412408918142319   │\n",
       "│ Value/reward                  │ 1.7174197435379028     │\n",
       "│ Time/Total                    │ 1160.801513671875      │\n",
       "│ Time/Rollout                  │ 11.69246768951416      │\n",
       "│ Time/Update                   │ 1.7542223930358887     │\n",
       "│ Time/Epoch                    │ 13.446751594543457     │\n",
       "│ Time/FPS                      │ 152.30445861816406     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.073348999023438     │\n",
       "│ Metrics/EpCost                │ 71.5                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 86.0                   │\n",
       "│ Train/Entropy                 │ 0.8134179711341858     │\n",
       "│ Train/KL                      │ 0.022588655352592468   │\n",
       "│ Train/StopIter                │ 9.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9994841814041138     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9994841814041138     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9994841814041138     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01999610848724842    │\n",
       "│ Train/LR                      │ 0.0002477999951224774  │\n",
       "│ Train/PolicyStd               │ 0.5462018847465515     │\n",
       "│ TotalEnvSteps                 │ 178176.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01720019243657589   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0019721277058124542 │\n",
       "│ Value/Adv                     │ -0.05442396551370621   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02056988887488842    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004412408918142319   │\n",
       "│ Value/reward                  │ 1.7174197435379028     │\n",
       "│ Time/Total                    │ 1160.801513671875      │\n",
       "│ Time/Rollout                  │ 11.69246768951416      │\n",
       "│ Time/Update                   │ 1.7542223930358887     │\n",
       "│ Time/Epoch                    │ 13.446751594543457     │\n",
       "│ Time/FPS                      │ 152.30445861816406     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.24656105041504      │\n",
       "│ Metrics/EpCost                │ 69.94000244140625      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 87.0                   │\n",
       "│ Train/Entropy                 │ 0.8070275187492371     │\n",
       "│ Train/KL                      │ 0.019635837525129318   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0001417398452759     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0001417398452759     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0001417398452759     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020693765953183174   │\n",
       "│ Train/LR                      │ 0.0002471999905537814  │\n",
       "│ Train/PolicyStd               │ 0.5428225994110107     │\n",
       "│ TotalEnvSteps                 │ 180224.0               │\n",
       "│ Loss/Loss_pi                  │ -0.02014831453561783   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0029481220990419388 │\n",
       "│ Value/Adv                     │ 0.024902556091547012   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01945810206234455    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.001111786812543869  │\n",
       "│ Value/reward                  │ 1.847535490989685      │\n",
       "│ Time/Total                    │ 1174.5595703125        │\n",
       "│ Time/Rollout                  │ 11.810443878173828     │\n",
       "│ Time/Update                   │ 1.9347412586212158     │\n",
       "│ Time/Epoch                    │ 13.74522876739502      │\n",
       "│ Time/FPS                      │ 148.99716186523438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.24656105041504      │\n",
       "│ Metrics/EpCost                │ 69.94000244140625      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 87.0                   │\n",
       "│ Train/Entropy                 │ 0.8070275187492371     │\n",
       "│ Train/KL                      │ 0.019635837525129318   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0001417398452759     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0001417398452759     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0001417398452759     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020693765953183174   │\n",
       "│ Train/LR                      │ 0.0002471999905537814  │\n",
       "│ Train/PolicyStd               │ 0.5428225994110107     │\n",
       "│ TotalEnvSteps                 │ 180224.0               │\n",
       "│ Loss/Loss_pi                  │ -0.02014831453561783   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0029481220990419388 │\n",
       "│ Value/Adv                     │ 0.024902556091547012   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01945810206234455    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.001111786812543869  │\n",
       "│ Value/reward                  │ 1.847535490989685      │\n",
       "│ Time/Total                    │ 1174.5595703125        │\n",
       "│ Time/Rollout                  │ 11.810443878173828     │\n",
       "│ Time/Update                   │ 1.9347412586212158     │\n",
       "│ Time/Epoch                    │ 13.74522876739502      │\n",
       "│ Time/FPS                      │ 148.99716186523438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.328449249267578     │\n",
       "│ Metrics/EpCost                │ 72.36000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 88.0                   │\n",
       "│ Train/Entropy                 │ 0.8015047907829285     │\n",
       "│ Train/KL                      │ 0.015971491113305092   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9952491521835327     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9952491521835327     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9952491521835327     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019411658868193626   │\n",
       "│ Train/LR                      │ 0.00024659998598508537 │\n",
       "│ Train/PolicyStd               │ 0.5398327708244324     │\n",
       "│ TotalEnvSteps                 │ 182272.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01439146138727665   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005756853148341179   │\n",
       "│ Value/Adv                     │ 0.09378009289503098    │\n",
       "│ Loss/Loss_reward_critic       │ 0.016120191663503647   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0033379103988409042 │\n",
       "│ Value/reward                  │ 1.8803074359893799     │\n",
       "│ Time/Total                    │ 1188.7261962890625     │\n",
       "│ Time/Rollout                  │ 12.053279876708984     │\n",
       "│ Time/Update                   │ 2.1005170345306396     │\n",
       "│ Time/Epoch                    │ 14.153844833374023     │\n",
       "│ Time/FPS                      │ 144.6956787109375      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.328449249267578     │\n",
       "│ Metrics/EpCost                │ 72.36000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 88.0                   │\n",
       "│ Train/Entropy                 │ 0.8015047907829285     │\n",
       "│ Train/KL                      │ 0.015971491113305092   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9952491521835327     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9952491521835327     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9952491521835327     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019411658868193626   │\n",
       "│ Train/LR                      │ 0.00024659998598508537 │\n",
       "│ Train/PolicyStd               │ 0.5398327708244324     │\n",
       "│ TotalEnvSteps                 │ 182272.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01439146138727665   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005756853148341179   │\n",
       "│ Value/Adv                     │ 0.09378009289503098    │\n",
       "│ Loss/Loss_reward_critic       │ 0.016120191663503647   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0033379103988409042 │\n",
       "│ Value/reward                  │ 1.8803074359893799     │\n",
       "│ Time/Total                    │ 1188.7261962890625     │\n",
       "│ Time/Rollout                  │ 12.053279876708984     │\n",
       "│ Time/Update                   │ 2.1005170345306396     │\n",
       "│ Time/Epoch                    │ 14.153844833374023     │\n",
       "│ Time/FPS                      │ 144.6956787109375      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.4134464263916       │\n",
       "│ Metrics/EpCost                │ 67.5199966430664       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 89.0                   │\n",
       "│ Train/Entropy                 │ 0.7996311187744141     │\n",
       "│ Train/KL                      │ 0.01530982181429863    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0070265531539917     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0070265531539917     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0070265531539917     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02112075872719288    │\n",
       "│ Train/LR                      │ 0.0002460000105202198  │\n",
       "│ Train/PolicyStd               │ 0.5388572812080383     │\n",
       "│ TotalEnvSteps                 │ 184320.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014939242973923683  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0005477815866470337 │\n",
       "│ Value/Adv                     │ -0.3642367124557495    │\n",
       "│ Loss/Loss_reward_critic       │ 0.023209944367408752   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.007089752703905106   │\n",
       "│ Value/reward                  │ 1.7451019287109375     │\n",
       "│ Time/Total                    │ 1202.5623779296875     │\n",
       "│ Time/Rollout                  │ 11.89341926574707      │\n",
       "│ Time/Update                   │ 1.9293317794799805     │\n",
       "│ Time/Epoch                    │ 13.822832107543945     │\n",
       "│ Time/FPS                      │ 148.1606903076172      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.4134464263916       │\n",
       "│ Metrics/EpCost                │ 67.5199966430664       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 89.0                   │\n",
       "│ Train/Entropy                 │ 0.7996311187744141     │\n",
       "│ Train/KL                      │ 0.01530982181429863    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0070265531539917     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0070265531539917     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0070265531539917     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02112075872719288    │\n",
       "│ Train/LR                      │ 0.0002460000105202198  │\n",
       "│ Train/PolicyStd               │ 0.5388572812080383     │\n",
       "│ TotalEnvSteps                 │ 184320.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014939242973923683  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0005477815866470337 │\n",
       "│ Value/Adv                     │ -0.3642367124557495    │\n",
       "│ Loss/Loss_reward_critic       │ 0.023209944367408752   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.007089752703905106   │\n",
       "│ Value/reward                  │ 1.7451019287109375     │\n",
       "│ Time/Total                    │ 1202.5623779296875     │\n",
       "│ Time/Rollout                  │ 11.89341926574707      │\n",
       "│ Time/Update                   │ 1.9293317794799805     │\n",
       "│ Time/Epoch                    │ 13.822832107543945     │\n",
       "│ Time/FPS                      │ 148.1606903076172      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.711650848388672    │\n",
       "│ Metrics/EpCost                │ 69.44000244140625     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 90.0                  │\n",
       "│ Train/Entropy                 │ 0.8014852404594421    │\n",
       "│ Train/KL                      │ 0.013111591339111328  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0033689737319946    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0033689737319946    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0033689737319946    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01841992326080799   │\n",
       "│ Train/LR                      │ 0.0002454000059515238 │\n",
       "│ Train/PolicyStd               │ 0.5399802327156067    │\n",
       "│ TotalEnvSteps                 │ 186368.0              │\n",
       "│ Loss/Loss_pi                  │ -0.009812982752919197 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005126260221004486  │\n",
       "│ Value/Adv                     │ -0.01001318171620369  │\n",
       "│ Loss/Loss_reward_critic       │ 0.02096041850745678   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.002249525859951973 │\n",
       "│ Value/reward                  │ 1.9073069095611572    │\n",
       "│ Time/Total                    │ 1216.3262939453125    │\n",
       "│ Time/Rollout                  │ 11.783048629760742    │\n",
       "│ Time/Update                   │ 1.9649765491485596    │\n",
       "│ Time/Epoch                    │ 13.748077392578125    │\n",
       "│ Time/FPS                      │ 148.96630859375       │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.711650848388672    │\n",
       "│ Metrics/EpCost                │ 69.44000244140625     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 90.0                  │\n",
       "│ Train/Entropy                 │ 0.8014852404594421    │\n",
       "│ Train/KL                      │ 0.013111591339111328  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0033689737319946    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0033689737319946    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0033689737319946    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01841992326080799   │\n",
       "│ Train/LR                      │ 0.0002454000059515238 │\n",
       "│ Train/PolicyStd               │ 0.5399802327156067    │\n",
       "│ TotalEnvSteps                 │ 186368.0              │\n",
       "│ Loss/Loss_pi                  │ -0.009812982752919197 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005126260221004486  │\n",
       "│ Value/Adv                     │ -0.01001318171620369  │\n",
       "│ Loss/Loss_reward_critic       │ 0.02096041850745678   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.002249525859951973 │\n",
       "│ Value/reward                  │ 1.9073069095611572    │\n",
       "│ Time/Total                    │ 1216.3262939453125    │\n",
       "│ Time/Rollout                  │ 11.783048629760742    │\n",
       "│ Time/Update                   │ 1.9649765491485596    │\n",
       "│ Time/Epoch                    │ 13.748077392578125    │\n",
       "│ Time/FPS                      │ 148.96630859375       │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.72015380859375       │\n",
       "│ Metrics/EpCost                │ 71.55999755859375       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 91.0                    │\n",
       "│ Train/Entropy                 │ 0.8087409734725952      │\n",
       "│ Train/KL                      │ 0.013974816538393497    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9918176531791687      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9918176531791687      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9918176531791687      │\n",
       "│ Train/PolicyRatio/Std         │ 0.01794528029859066     │\n",
       "│ Train/LR                      │ 0.00024480000138282776  │\n",
       "│ Train/PolicyStd               │ 0.5438401103019714      │\n",
       "│ TotalEnvSteps                 │ 188416.0                │\n",
       "│ Loss/Loss_pi                  │ -0.01402824092656374    │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004215258173644543   │\n",
       "│ Value/Adv                     │ -0.016301795840263367   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02090887352824211     │\n",
       "│ Loss/Loss_reward_critic/Delta │ -5.1544979214668274e-05 │\n",
       "│ Value/reward                  │ 1.876617670059204       │\n",
       "│ Time/Total                    │ 1230.17822265625        │\n",
       "│ Time/Rollout                  │ 11.880732536315918      │\n",
       "│ Time/Update                   │ 1.9582300186157227      │\n",
       "│ Time/Epoch                    │ 13.839014053344727      │\n",
       "│ Time/FPS                      │ 147.9874267578125       │\n",
       "└───────────────────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.72015380859375       │\n",
       "│ Metrics/EpCost                │ 71.55999755859375       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 91.0                    │\n",
       "│ Train/Entropy                 │ 0.8087409734725952      │\n",
       "│ Train/KL                      │ 0.013974816538393497    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9918176531791687      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9918176531791687      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9918176531791687      │\n",
       "│ Train/PolicyRatio/Std         │ 0.01794528029859066     │\n",
       "│ Train/LR                      │ 0.00024480000138282776  │\n",
       "│ Train/PolicyStd               │ 0.5438401103019714      │\n",
       "│ TotalEnvSteps                 │ 188416.0                │\n",
       "│ Loss/Loss_pi                  │ -0.01402824092656374    │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004215258173644543   │\n",
       "│ Value/Adv                     │ -0.016301795840263367   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02090887352824211     │\n",
       "│ Loss/Loss_reward_critic/Delta │ -5.1544979214668274e-05 │\n",
       "│ Value/reward                  │ 1.876617670059204       │\n",
       "│ Time/Total                    │ 1230.17822265625        │\n",
       "│ Time/Rollout                  │ 11.880732536315918      │\n",
       "│ Time/Update                   │ 1.9582300186157227      │\n",
       "│ Time/Epoch                    │ 13.839014053344727      │\n",
       "│ Time/FPS                      │ 147.9874267578125       │\n",
       "└───────────────────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.709644317626953     │\n",
       "│ Metrics/EpCost                │ 72.31999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 92.0                   │\n",
       "│ Train/Entropy                 │ 0.8163688778877258     │\n",
       "│ Train/KL                      │ 0.013668913394212723   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.00303053855896       │\n",
       "│ Train/PolicyRatio/Min         │ 1.00303053855896       │\n",
       "│ Train/PolicyRatio/Max         │ 1.00303053855896       │\n",
       "│ Train/PolicyRatio/Std         │ 0.01756235584616661    │\n",
       "│ Train/LR                      │ 0.00024419999681413174 │\n",
       "│ Train/PolicyStd               │ 0.5478532314300537     │\n",
       "│ TotalEnvSteps                 │ 190464.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013140050694346428  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0008881902322173119  │\n",
       "│ Value/Adv                     │ 0.09603887796401978    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01606714352965355    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.004841729998588562  │\n",
       "│ Value/reward                  │ 1.8205057382583618     │\n",
       "│ Time/Total                    │ 1244.2437744140625     │\n",
       "│ Time/Rollout                  │ 12.044509887695312     │\n",
       "│ Time/Update                   │ 2.0078816413879395     │\n",
       "│ Time/Epoch                    │ 14.052453994750977     │\n",
       "│ Time/FPS                      │ 145.73968505859375     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.709644317626953     │\n",
       "│ Metrics/EpCost                │ 72.31999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 92.0                   │\n",
       "│ Train/Entropy                 │ 0.8163688778877258     │\n",
       "│ Train/KL                      │ 0.013668913394212723   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.00303053855896       │\n",
       "│ Train/PolicyRatio/Min         │ 1.00303053855896       │\n",
       "│ Train/PolicyRatio/Max         │ 1.00303053855896       │\n",
       "│ Train/PolicyRatio/Std         │ 0.01756235584616661    │\n",
       "│ Train/LR                      │ 0.00024419999681413174 │\n",
       "│ Train/PolicyStd               │ 0.5478532314300537     │\n",
       "│ TotalEnvSteps                 │ 190464.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013140050694346428  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0008881902322173119  │\n",
       "│ Value/Adv                     │ 0.09603887796401978    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01606714352965355    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.004841729998588562  │\n",
       "│ Value/reward                  │ 1.8205057382583618     │\n",
       "│ Time/Total                    │ 1244.2437744140625     │\n",
       "│ Time/Rollout                  │ 12.044509887695312     │\n",
       "│ Time/Update                   │ 2.0078816413879395     │\n",
       "│ Time/Epoch                    │ 14.052453994750977     │\n",
       "│ Time/FPS                      │ 145.73968505859375     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.862018585205078     │\n",
       "│ Metrics/EpCost                │ 72.91999816894531      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 93.0                   │\n",
       "│ Train/Entropy                 │ 0.8136598467826843     │\n",
       "│ Train/KL                      │ 0.01707383431494236    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9975738525390625     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9975738525390625     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9975738525390625     │\n",
       "│ Train/PolicyRatio/Std         │ 0.021184006705880165   │\n",
       "│ Train/LR                      │ 0.00024360000679735094 │\n",
       "│ Train/PolicyStd               │ 0.5464242696762085     │\n",
       "│ TotalEnvSteps                 │ 192512.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017280761152505875  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004140710458159447  │\n",
       "│ Value/Adv                     │ -0.013513896614313126  │\n",
       "│ Loss/Loss_reward_critic       │ 0.024193570017814636   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.008126426488161087   │\n",
       "│ Value/reward                  │ 1.9404594898223877     │\n",
       "│ Time/Total                    │ 1258.2435302734375     │\n",
       "│ Time/Rollout                  │ 11.995329856872559     │\n",
       "│ Time/Update                   │ 1.9905586242675781     │\n",
       "│ Time/Epoch                    │ 13.985933303833008     │\n",
       "│ Time/FPS                      │ 146.43284606933594     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.862018585205078     │\n",
       "│ Metrics/EpCost                │ 72.91999816894531      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 93.0                   │\n",
       "│ Train/Entropy                 │ 0.8136598467826843     │\n",
       "│ Train/KL                      │ 0.01707383431494236    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9975738525390625     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9975738525390625     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9975738525390625     │\n",
       "│ Train/PolicyRatio/Std         │ 0.021184006705880165   │\n",
       "│ Train/LR                      │ 0.00024360000679735094 │\n",
       "│ Train/PolicyStd               │ 0.5464242696762085     │\n",
       "│ TotalEnvSteps                 │ 192512.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017280761152505875  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004140710458159447  │\n",
       "│ Value/Adv                     │ -0.013513896614313126  │\n",
       "│ Loss/Loss_reward_critic       │ 0.024193570017814636   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.008126426488161087   │\n",
       "│ Value/reward                  │ 1.9404594898223877     │\n",
       "│ Time/Total                    │ 1258.2435302734375     │\n",
       "│ Time/Rollout                  │ 11.995329856872559     │\n",
       "│ Time/Update                   │ 1.9905586242675781     │\n",
       "│ Time/Epoch                    │ 13.985933303833008     │\n",
       "│ Time/FPS                      │ 146.43284606933594     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.92530059814453      │\n",
       "│ Metrics/EpCost                │ 68.68000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 94.0                   │\n",
       "│ Train/Entropy                 │ 0.8166645765304565     │\n",
       "│ Train/KL                      │ 0.01953181065618992    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9943777322769165     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9943777322769165     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9943777322769165     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02026933990418911    │\n",
       "│ Train/LR                      │ 0.00024300000222865492 │\n",
       "│ Train/PolicyStd               │ 0.5479821562767029     │\n",
       "│ TotalEnvSteps                 │ 194560.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017072688788175583  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00020807236433029175 │\n",
       "│ Value/Adv                     │ 0.08592667430639267    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017670495435595512   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.006523074582219124  │\n",
       "│ Value/reward                  │ 1.884033203125         │\n",
       "│ Time/Total                    │ 1272.22119140625       │\n",
       "│ Time/Rollout                  │ 11.873546600341797     │\n",
       "│ Time/Update                   │ 2.0922117233276367     │\n",
       "│ Time/Epoch                    │ 13.96580982208252      │\n",
       "│ Time/FPS                      │ 146.64385986328125     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.92530059814453      │\n",
       "│ Metrics/EpCost                │ 68.68000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 94.0                   │\n",
       "│ Train/Entropy                 │ 0.8166645765304565     │\n",
       "│ Train/KL                      │ 0.01953181065618992    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9943777322769165     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9943777322769165     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9943777322769165     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02026933990418911    │\n",
       "│ Train/LR                      │ 0.00024300000222865492 │\n",
       "│ Train/PolicyStd               │ 0.5479821562767029     │\n",
       "│ TotalEnvSteps                 │ 194560.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017072688788175583  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00020807236433029175 │\n",
       "│ Value/Adv                     │ 0.08592667430639267    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017670495435595512   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.006523074582219124  │\n",
       "│ Value/reward                  │ 1.884033203125         │\n",
       "│ Time/Total                    │ 1272.22119140625       │\n",
       "│ Time/Rollout                  │ 11.873546600341797     │\n",
       "│ Time/Update                   │ 2.0922117233276367     │\n",
       "│ Time/Epoch                    │ 13.96580982208252      │\n",
       "│ Time/FPS                      │ 146.64385986328125     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.940336227416992    │\n",
       "│ Metrics/EpCost                │ 65.31999969482422     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 95.0                  │\n",
       "│ Train/Entropy                 │ 0.8167423009872437    │\n",
       "│ Train/KL                      │ 0.012697872705757618  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0001330375671387    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0001330375671387    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0001330375671387    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01720532774925232   │\n",
       "│ Train/LR                      │ 0.0002423999976599589 │\n",
       "│ Train/PolicyStd               │ 0.547961413860321     │\n",
       "│ TotalEnvSteps                 │ 196608.0              │\n",
       "│ Loss/Loss_pi                  │ -0.0149935781955719   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0020791105926036835 │\n",
       "│ Value/Adv                     │ 0.07981887459754944   │\n",
       "│ Loss/Loss_reward_critic       │ 0.020963409915566444  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.003292914479970932  │\n",
       "│ Value/reward                  │ 1.7938448190689087    │\n",
       "│ Time/Total                    │ 1286.1173095703125    │\n",
       "│ Time/Rollout                  │ 11.893877983093262    │\n",
       "│ Time/Update                   │ 1.9897596836090088    │\n",
       "│ Time/Epoch                    │ 13.883687973022461    │\n",
       "│ Time/FPS                      │ 147.51124572753906    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.940336227416992    │\n",
       "│ Metrics/EpCost                │ 65.31999969482422     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 95.0                  │\n",
       "│ Train/Entropy                 │ 0.8167423009872437    │\n",
       "│ Train/KL                      │ 0.012697872705757618  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0001330375671387    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0001330375671387    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0001330375671387    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01720532774925232   │\n",
       "│ Train/LR                      │ 0.0002423999976599589 │\n",
       "│ Train/PolicyStd               │ 0.547961413860321     │\n",
       "│ TotalEnvSteps                 │ 196608.0              │\n",
       "│ Loss/Loss_pi                  │ -0.0149935781955719   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0020791105926036835 │\n",
       "│ Value/Adv                     │ 0.07981887459754944   │\n",
       "│ Loss/Loss_reward_critic       │ 0.020963409915566444  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.003292914479970932  │\n",
       "│ Value/reward                  │ 1.7938448190689087    │\n",
       "│ Time/Total                    │ 1286.1173095703125    │\n",
       "│ Time/Rollout                  │ 11.893877983093262    │\n",
       "│ Time/Update                   │ 1.9897596836090088    │\n",
       "│ Time/Epoch                    │ 13.883687973022461    │\n",
       "│ Time/FPS                      │ 147.51124572753906    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.934057235717773     │\n",
       "│ Metrics/EpCost                │ 63.02000045776367      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 96.0                   │\n",
       "│ Train/Entropy                 │ 0.8064786195755005     │\n",
       "│ Train/KL                      │ 0.012999966740608215   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9984827041625977     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9984827041625977     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9984827041625977     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019355161115527153   │\n",
       "│ Train/LR                      │ 0.00024179999309126288 │\n",
       "│ Train/PolicyStd               │ 0.5424669981002808     │\n",
       "│ TotalEnvSteps                 │ 198656.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012875896878540516  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0021176813170313835  │\n",
       "│ Value/Adv                     │ -0.16031818091869354   │\n",
       "│ Loss/Loss_reward_critic       │ 0.016286160796880722   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.004677249118685722  │\n",
       "│ Value/reward                  │ 1.7611324787139893     │\n",
       "│ Time/Total                    │ 1299.99609375          │\n",
       "│ Time/Rollout                  │ 11.873342514038086     │\n",
       "│ Time/Update                   │ 1.9933502674102783     │\n",
       "│ Time/Epoch                    │ 13.866737365722656     │\n",
       "│ Time/FPS                      │ 147.69155883789062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.934057235717773     │\n",
       "│ Metrics/EpCost                │ 63.02000045776367      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 96.0                   │\n",
       "│ Train/Entropy                 │ 0.8064786195755005     │\n",
       "│ Train/KL                      │ 0.012999966740608215   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9984827041625977     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9984827041625977     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9984827041625977     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019355161115527153   │\n",
       "│ Train/LR                      │ 0.00024179999309126288 │\n",
       "│ Train/PolicyStd               │ 0.5424669981002808     │\n",
       "│ TotalEnvSteps                 │ 198656.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012875896878540516  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0021176813170313835  │\n",
       "│ Value/Adv                     │ -0.16031818091869354   │\n",
       "│ Loss/Loss_reward_critic       │ 0.016286160796880722   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.004677249118685722  │\n",
       "│ Value/reward                  │ 1.7611324787139893     │\n",
       "│ Time/Total                    │ 1299.99609375          │\n",
       "│ Time/Rollout                  │ 11.873342514038086     │\n",
       "│ Time/Update                   │ 1.9933502674102783     │\n",
       "│ Time/Epoch                    │ 13.866737365722656     │\n",
       "│ Time/FPS                      │ 147.69155883789062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.02783966064453      │\n",
       "│ Metrics/EpCost                │ 61.36000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 97.0                   │\n",
       "│ Train/Entropy                 │ 0.8029506802558899     │\n",
       "│ Train/KL                      │ 0.015039773657917976   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9998389482498169     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9998389482498169     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9998389482498169     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01892031356692314    │\n",
       "│ Train/LR                      │ 0.00024120000307448208 │\n",
       "│ Train/PolicyStd               │ 0.5405932664871216     │\n",
       "│ TotalEnvSteps                 │ 200704.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012345886789262295  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0005300100892782211  │\n",
       "│ Value/Adv                     │ -0.19985303282737732   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02013160102069378    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.003845440223813057   │\n",
       "│ Value/reward                  │ 1.7788053750991821     │\n",
       "│ Time/Total                    │ 1313.914306640625      │\n",
       "│ Time/Rollout                  │ 11.892117500305176     │\n",
       "│ Time/Update                   │ 2.0124101638793945     │\n",
       "│ Time/Epoch                    │ 13.904580116271973     │\n",
       "│ Time/FPS                      │ 147.28961181640625     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.02783966064453      │\n",
       "│ Metrics/EpCost                │ 61.36000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 97.0                   │\n",
       "│ Train/Entropy                 │ 0.8029506802558899     │\n",
       "│ Train/KL                      │ 0.015039773657917976   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9998389482498169     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9998389482498169     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9998389482498169     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01892031356692314    │\n",
       "│ Train/LR                      │ 0.00024120000307448208 │\n",
       "│ Train/PolicyStd               │ 0.5405932664871216     │\n",
       "│ TotalEnvSteps                 │ 200704.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012345886789262295  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0005300100892782211  │\n",
       "│ Value/Adv                     │ -0.19985303282737732   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02013160102069378    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.003845440223813057   │\n",
       "│ Value/reward                  │ 1.7788053750991821     │\n",
       "│ Time/Total                    │ 1313.914306640625      │\n",
       "│ Time/Rollout                  │ 11.892117500305176     │\n",
       "│ Time/Update                   │ 2.0124101638793945     │\n",
       "│ Time/Epoch                    │ 13.904580116271973     │\n",
       "│ Time/FPS                      │ 147.28961181640625     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.9819393157959       │\n",
       "│ Metrics/EpCost                │ 62.099998474121094     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 98.0                   │\n",
       "│ Train/Entropy                 │ 0.8004316091537476     │\n",
       "│ Train/KL                      │ 0.018433719873428345   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9942039251327515     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9942039251327515     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9942039251327515     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018349353224039078   │\n",
       "│ Train/LR                      │ 0.00024059999850578606 │\n",
       "│ Train/PolicyStd               │ 0.5391644239425659     │\n",
       "│ TotalEnvSteps                 │ 202752.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014834791421890259  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002488904632627964  │\n",
       "│ Value/Adv                     │ -0.08836537599563599   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018325937911868095   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0018056631088256836 │\n",
       "│ Value/reward                  │ 1.8142133951187134     │\n",
       "│ Time/Total                    │ 1327.851806640625      │\n",
       "│ Time/Rollout                  │ 11.849214553833008     │\n",
       "│ Time/Update                   │ 2.0748023986816406     │\n",
       "│ Time/Epoch                    │ 13.924072265625        │\n",
       "│ Time/FPS                      │ 147.0834197998047      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.9819393157959       │\n",
       "│ Metrics/EpCost                │ 62.099998474121094     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 98.0                   │\n",
       "│ Train/Entropy                 │ 0.8004316091537476     │\n",
       "│ Train/KL                      │ 0.018433719873428345   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9942039251327515     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9942039251327515     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9942039251327515     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018349353224039078   │\n",
       "│ Train/LR                      │ 0.00024059999850578606 │\n",
       "│ Train/PolicyStd               │ 0.5391644239425659     │\n",
       "│ TotalEnvSteps                 │ 202752.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014834791421890259  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002488904632627964  │\n",
       "│ Value/Adv                     │ -0.08836537599563599   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018325937911868095   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0018056631088256836 │\n",
       "│ Value/reward                  │ 1.8142133951187134     │\n",
       "│ Time/Total                    │ 1327.851806640625      │\n",
       "│ Time/Rollout                  │ 11.849214553833008     │\n",
       "│ Time/Update                   │ 2.0748023986816406     │\n",
       "│ Time/Epoch                    │ 13.924072265625        │\n",
       "│ Time/FPS                      │ 147.0834197998047      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.935400009155273      │\n",
       "│ Metrics/EpCost                │ 61.29999923706055       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 99.0                    │\n",
       "│ Train/Entropy                 │ 0.7961795330047607      │\n",
       "│ Train/KL                      │ 0.016387853771448135    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9973539113998413      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9973539113998413      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9973539113998413      │\n",
       "│ Train/PolicyRatio/Std         │ 0.019538316875696182    │\n",
       "│ Train/LR                      │ 0.00023999999393709004  │\n",
       "│ Train/PolicyStd               │ 0.5368081331253052      │\n",
       "│ TotalEnvSteps                 │ 204800.0                │\n",
       "│ Loss/Loss_pi                  │ -0.018709028139710426   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0038742367178201675  │\n",
       "│ Value/Adv                     │ -0.15076559782028198    │\n",
       "│ Loss/Loss_reward_critic       │ 0.018214616924524307    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00011132098734378815 │\n",
       "│ Value/reward                  │ 1.8138480186462402      │\n",
       "│ Time/Total                    │ 1341.762939453125       │\n",
       "│ Time/Rollout                  │ 11.952917098999023      │\n",
       "│ Time/Update                   │ 1.9462015628814697      │\n",
       "│ Time/Epoch                    │ 13.89918327331543       │\n",
       "│ Time/FPS                      │ 147.3468017578125       │\n",
       "└───────────────────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.935400009155273      │\n",
       "│ Metrics/EpCost                │ 61.29999923706055       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 99.0                    │\n",
       "│ Train/Entropy                 │ 0.7961795330047607      │\n",
       "│ Train/KL                      │ 0.016387853771448135    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9973539113998413      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9973539113998413      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9973539113998413      │\n",
       "│ Train/PolicyRatio/Std         │ 0.019538316875696182    │\n",
       "│ Train/LR                      │ 0.00023999999393709004  │\n",
       "│ Train/PolicyStd               │ 0.5368081331253052      │\n",
       "│ TotalEnvSteps                 │ 204800.0                │\n",
       "│ Loss/Loss_pi                  │ -0.018709028139710426   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0038742367178201675  │\n",
       "│ Value/Adv                     │ -0.15076559782028198    │\n",
       "│ Loss/Loss_reward_critic       │ 0.018214616924524307    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00011132098734378815 │\n",
       "│ Value/reward                  │ 1.8138480186462402      │\n",
       "│ Time/Total                    │ 1341.762939453125       │\n",
       "│ Time/Rollout                  │ 11.952917098999023      │\n",
       "│ Time/Update                   │ 1.9462015628814697      │\n",
       "│ Time/Epoch                    │ 13.89918327331543       │\n",
       "│ Time/FPS                      │ 147.3468017578125       │\n",
       "└───────────────────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.97832679748535       │\n",
       "│ Metrics/EpCost                │ 62.20000076293945       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 100.0                   │\n",
       "│ Train/Entropy                 │ 0.789296567440033       │\n",
       "│ Train/KL                      │ 0.016389993950724602    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9939757585525513      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9939757585525513      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9939757585525513      │\n",
       "│ Train/PolicyRatio/Std         │ 0.019390497356653214    │\n",
       "│ Train/LR                      │ 0.00023940000392030925  │\n",
       "│ Train/PolicyStd               │ 0.533048152923584       │\n",
       "│ TotalEnvSteps                 │ 206848.0                │\n",
       "│ Loss/Loss_pi                  │ -0.019121211022138596   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00041218288242816925 │\n",
       "│ Value/Adv                     │ 0.2923023998737335      │\n",
       "│ Loss/Loss_reward_critic       │ 0.02088838256895542     │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002673765644431114    │\n",
       "│ Value/reward                  │ 1.8285577297210693      │\n",
       "│ Time/Total                    │ 1355.6112060546875      │\n",
       "│ Time/Rollout                  │ 11.790379524230957      │\n",
       "│ Time/Update                   │ 2.042149543762207       │\n",
       "│ Time/Epoch                    │ 13.832578659057617      │\n",
       "│ Time/FPS                      │ 148.0562744140625       │\n",
       "└───────────────────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.97832679748535       │\n",
       "│ Metrics/EpCost                │ 62.20000076293945       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 100.0                   │\n",
       "│ Train/Entropy                 │ 0.789296567440033       │\n",
       "│ Train/KL                      │ 0.016389993950724602    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9939757585525513      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9939757585525513      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9939757585525513      │\n",
       "│ Train/PolicyRatio/Std         │ 0.019390497356653214    │\n",
       "│ Train/LR                      │ 0.00023940000392030925  │\n",
       "│ Train/PolicyStd               │ 0.533048152923584       │\n",
       "│ TotalEnvSteps                 │ 206848.0                │\n",
       "│ Loss/Loss_pi                  │ -0.019121211022138596   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00041218288242816925 │\n",
       "│ Value/Adv                     │ 0.2923023998737335      │\n",
       "│ Loss/Loss_reward_critic       │ 0.02088838256895542     │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002673765644431114    │\n",
       "│ Value/reward                  │ 1.8285577297210693      │\n",
       "│ Time/Total                    │ 1355.6112060546875      │\n",
       "│ Time/Rollout                  │ 11.790379524230957      │\n",
       "│ Time/Update                   │ 2.042149543762207       │\n",
       "│ Time/Epoch                    │ 13.832578659057617      │\n",
       "│ Time/FPS                      │ 148.0562744140625       │\n",
       "└───────────────────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.064834594726562     │\n",
       "│ Metrics/EpCost                │ 62.15999984741211      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 101.0                  │\n",
       "│ Train/Entropy                 │ 0.7826721668243408     │\n",
       "│ Train/KL                      │ 0.017135363072156906   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9946228265762329     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9946228265762329     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9946228265762329     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018816575407981873   │\n",
       "│ Train/LR                      │ 0.00023879999935161322 │\n",
       "│ Train/PolicyStd               │ 0.529510498046875      │\n",
       "│ TotalEnvSteps                 │ 208896.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018329184502363205  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0007920265197753906  │\n",
       "│ Value/Adv                     │ -0.12946230173110962   │\n",
       "│ Loss/Loss_reward_critic       │ 0.022179078310728073   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0012906957417726517  │\n",
       "│ Value/reward                  │ 1.920216679573059      │\n",
       "│ Time/Total                    │ 1369.7291259765625     │\n",
       "│ Time/Rollout                  │ 12.02120590209961      │\n",
       "│ Time/Update                   │ 2.0821354389190674     │\n",
       "│ Time/Epoch                    │ 14.10340404510498      │\n",
       "│ Time/FPS                      │ 145.2131805419922      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.064834594726562     │\n",
       "│ Metrics/EpCost                │ 62.15999984741211      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 101.0                  │\n",
       "│ Train/Entropy                 │ 0.7826721668243408     │\n",
       "│ Train/KL                      │ 0.017135363072156906   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9946228265762329     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9946228265762329     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9946228265762329     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018816575407981873   │\n",
       "│ Train/LR                      │ 0.00023879999935161322 │\n",
       "│ Train/PolicyStd               │ 0.529510498046875      │\n",
       "│ TotalEnvSteps                 │ 208896.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018329184502363205  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0007920265197753906  │\n",
       "│ Value/Adv                     │ -0.12946230173110962   │\n",
       "│ Loss/Loss_reward_critic       │ 0.022179078310728073   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0012906957417726517  │\n",
       "│ Value/reward                  │ 1.920216679573059      │\n",
       "│ Time/Total                    │ 1369.7291259765625     │\n",
       "│ Time/Rollout                  │ 12.02120590209961      │\n",
       "│ Time/Update                   │ 2.0821354389190674     │\n",
       "│ Time/Epoch                    │ 14.10340404510498      │\n",
       "│ Time/FPS                      │ 145.2131805419922      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.060426712036133     │\n",
       "│ Metrics/EpCost                │ 62.15999984741211      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 102.0                  │\n",
       "│ Train/Entropy                 │ 0.7761983871459961     │\n",
       "│ Train/KL                      │ 0.017216481268405914   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0064513683319092     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0064513683319092     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0064513683319092     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02048484981060028    │\n",
       "│ Train/LR                      │ 0.0002381999947829172  │\n",
       "│ Train/PolicyStd               │ 0.52614825963974       │\n",
       "│ TotalEnvSteps                 │ 210944.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01572575978934765   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0026034247130155563  │\n",
       "│ Value/Adv                     │ -0.04260643199086189   │\n",
       "│ Loss/Loss_reward_critic       │ 0.020256707444787025   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0019223708659410477 │\n",
       "│ Value/reward                  │ 1.8898500204086304     │\n",
       "│ Time/Total                    │ 1383.6033935546875     │\n",
       "│ Time/Rollout                  │ 11.909393310546875     │\n",
       "│ Time/Update                   │ 1.9479751586914062     │\n",
       "│ Time/Epoch                    │ 13.857409477233887     │\n",
       "│ Time/FPS                      │ 147.7909698486328      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.060426712036133     │\n",
       "│ Metrics/EpCost                │ 62.15999984741211      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 102.0                  │\n",
       "│ Train/Entropy                 │ 0.7761983871459961     │\n",
       "│ Train/KL                      │ 0.017216481268405914   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0064513683319092     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0064513683319092     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0064513683319092     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02048484981060028    │\n",
       "│ Train/LR                      │ 0.0002381999947829172  │\n",
       "│ Train/PolicyStd               │ 0.52614825963974       │\n",
       "│ TotalEnvSteps                 │ 210944.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01572575978934765   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0026034247130155563  │\n",
       "│ Value/Adv                     │ -0.04260643199086189   │\n",
       "│ Loss/Loss_reward_critic       │ 0.020256707444787025   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0019223708659410477 │\n",
       "│ Value/reward                  │ 1.8898500204086304     │\n",
       "│ Time/Total                    │ 1383.6033935546875     │\n",
       "│ Time/Rollout                  │ 11.909393310546875     │\n",
       "│ Time/Update                   │ 1.9479751586914062     │\n",
       "│ Time/Epoch                    │ 13.857409477233887     │\n",
       "│ Time/FPS                      │ 147.7909698486328      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.9741268157959       │\n",
       "│ Metrics/EpCost                │ 62.63999938964844      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 103.0                  │\n",
       "│ Train/Entropy                 │ 0.7680607438087463     │\n",
       "│ Train/KL                      │ 0.015208340249955654   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0017001628875732     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0017001628875732     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0017001628875732     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019755754619836807   │\n",
       "│ Train/LR                      │ 0.0002376000047661364  │\n",
       "│ Train/PolicyStd               │ 0.5219103097915649     │\n",
       "│ TotalEnvSteps                 │ 212992.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01540183275938034   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00032392702996730804 │\n",
       "│ Value/Adv                     │ -0.015953509137034416  │\n",
       "│ Loss/Loss_reward_critic       │ 0.017834540456533432   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0024221669882535934 │\n",
       "│ Value/reward                  │ 1.842680811882019      │\n",
       "│ Time/Total                    │ 1397.5018310546875     │\n",
       "│ Time/Rollout                  │ 11.864477157592773     │\n",
       "│ Time/Update                   │ 2.0212771892547607     │\n",
       "│ Time/Epoch                    │ 13.885795593261719     │\n",
       "│ Time/FPS                      │ 147.48886108398438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.9741268157959       │\n",
       "│ Metrics/EpCost                │ 62.63999938964844      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 103.0                  │\n",
       "│ Train/Entropy                 │ 0.7680607438087463     │\n",
       "│ Train/KL                      │ 0.015208340249955654   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0017001628875732     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0017001628875732     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0017001628875732     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019755754619836807   │\n",
       "│ Train/LR                      │ 0.0002376000047661364  │\n",
       "│ Train/PolicyStd               │ 0.5219103097915649     │\n",
       "│ TotalEnvSteps                 │ 212992.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01540183275938034   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00032392702996730804 │\n",
       "│ Value/Adv                     │ -0.015953509137034416  │\n",
       "│ Loss/Loss_reward_critic       │ 0.017834540456533432   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0024221669882535934 │\n",
       "│ Value/reward                  │ 1.842680811882019      │\n",
       "│ Time/Total                    │ 1397.5018310546875     │\n",
       "│ Time/Rollout                  │ 11.864477157592773     │\n",
       "│ Time/Update                   │ 2.0212771892547607     │\n",
       "│ Time/Epoch                    │ 13.885795593261719     │\n",
       "│ Time/FPS                      │ 147.48886108398438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.075054168701172     │\n",
       "│ Metrics/EpCost                │ 61.41999816894531      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 104.0                  │\n",
       "│ Train/Entropy                 │ 0.7573044300079346     │\n",
       "│ Train/KL                      │ 0.014589672908186913   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0028293132781982     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0028293132781982     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0028293132781982     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01853768341243267    │\n",
       "│ Train/LR                      │ 0.00023700000019744039 │\n",
       "│ Train/PolicyStd               │ 0.516219973564148      │\n",
       "│ TotalEnvSteps                 │ 215040.0               │\n",
       "│ Loss/Loss_pi                  │ -0.010793980211019516  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004607852548360825   │\n",
       "│ Value/Adv                     │ -0.032621704041957855  │\n",
       "│ Loss/Loss_reward_critic       │ 0.02801099419593811    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.010176453739404678   │\n",
       "│ Value/reward                  │ 1.8383378982543945     │\n",
       "│ Time/Total                    │ 1411.36572265625       │\n",
       "│ Time/Rollout                  │ 11.837252616882324     │\n",
       "│ Time/Update                   │ 2.014035701751709      │\n",
       "│ Time/Epoch                    │ 13.851327896118164     │\n",
       "│ Time/FPS                      │ 147.85586547851562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.075054168701172     │\n",
       "│ Metrics/EpCost                │ 61.41999816894531      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 104.0                  │\n",
       "│ Train/Entropy                 │ 0.7573044300079346     │\n",
       "│ Train/KL                      │ 0.014589672908186913   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0028293132781982     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0028293132781982     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0028293132781982     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01853768341243267    │\n",
       "│ Train/LR                      │ 0.00023700000019744039 │\n",
       "│ Train/PolicyStd               │ 0.516219973564148      │\n",
       "│ TotalEnvSteps                 │ 215040.0               │\n",
       "│ Loss/Loss_pi                  │ -0.010793980211019516  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004607852548360825   │\n",
       "│ Value/Adv                     │ -0.032621704041957855  │\n",
       "│ Loss/Loss_reward_critic       │ 0.02801099419593811    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.010176453739404678   │\n",
       "│ Value/reward                  │ 1.8383378982543945     │\n",
       "│ Time/Total                    │ 1411.36572265625       │\n",
       "│ Time/Rollout                  │ 11.837252616882324     │\n",
       "│ Time/Update                   │ 2.014035701751709      │\n",
       "│ Time/Epoch                    │ 13.851327896118164     │\n",
       "│ Time/FPS                      │ 147.85586547851562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.876934051513672     │\n",
       "│ Metrics/EpCost                │ 60.31999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 105.0                  │\n",
       "│ Train/Entropy                 │ 0.7422171235084534     │\n",
       "│ Train/KL                      │ 0.011567792855203152   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9994419813156128     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9994419813156128     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9994419813156128     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018126271665096283   │\n",
       "│ Train/LR                      │ 0.00023639999562874436 │\n",
       "│ Train/PolicyStd               │ 0.5083816051483154     │\n",
       "│ TotalEnvSteps                 │ 217088.0               │\n",
       "│ Loss/Loss_pi                  │ -0.007771342992782593  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0030226372182369232  │\n",
       "│ Value/Adv                     │ 0.0378870815038681     │\n",
       "│ Loss/Loss_reward_critic       │ 0.01758621446788311    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.010424779728055     │\n",
       "│ Value/reward                  │ 1.6826398372650146     │\n",
       "│ Time/Total                    │ 1425.2069091796875     │\n",
       "│ Time/Rollout                  │ 11.87356185913086      │\n",
       "│ Time/Update                   │ 1.9537403583526611     │\n",
       "│ Time/Epoch                    │ 13.827350616455078     │\n",
       "│ Time/FPS                      │ 148.1122589111328      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.876934051513672     │\n",
       "│ Metrics/EpCost                │ 60.31999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 105.0                  │\n",
       "│ Train/Entropy                 │ 0.7422171235084534     │\n",
       "│ Train/KL                      │ 0.011567792855203152   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9994419813156128     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9994419813156128     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9994419813156128     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018126271665096283   │\n",
       "│ Train/LR                      │ 0.00023639999562874436 │\n",
       "│ Train/PolicyStd               │ 0.5083816051483154     │\n",
       "│ TotalEnvSteps                 │ 217088.0               │\n",
       "│ Loss/Loss_pi                  │ -0.007771342992782593  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0030226372182369232  │\n",
       "│ Value/Adv                     │ 0.0378870815038681     │\n",
       "│ Loss/Loss_reward_critic       │ 0.01758621446788311    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.010424779728055     │\n",
       "│ Value/reward                  │ 1.6826398372650146     │\n",
       "│ Time/Total                    │ 1425.2069091796875     │\n",
       "│ Time/Rollout                  │ 11.87356185913086      │\n",
       "│ Time/Update                   │ 1.9537403583526611     │\n",
       "│ Time/Epoch                    │ 13.827350616455078     │\n",
       "│ Time/FPS                      │ 148.1122589111328      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.864727020263672     │\n",
       "│ Metrics/EpCost                │ 59.560001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 106.0                  │\n",
       "│ Train/Entropy                 │ 0.7356224060058594     │\n",
       "│ Train/KL                      │ 0.013349456712603569   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9996172785758972     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9996172785758972     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9996172785758972     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019231807440519333   │\n",
       "│ Train/LR                      │ 0.00023580000561196357 │\n",
       "│ Train/PolicyStd               │ 0.5050121545791626     │\n",
       "│ TotalEnvSteps                 │ 219136.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012514986097812653  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00474364310503006   │\n",
       "│ Value/Adv                     │ -0.14003051817417145   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018926482647657394   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0013402681797742844  │\n",
       "│ Value/reward                  │ 1.6884980201721191     │\n",
       "│ Time/Total                    │ 1439.098388671875      │\n",
       "│ Time/Rollout                  │ 11.884199142456055     │\n",
       "│ Time/Update                   │ 1.995603084564209      │\n",
       "│ Time/Epoch                    │ 13.879844665527344     │\n",
       "│ Time/FPS                      │ 147.5520782470703      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.864727020263672     │\n",
       "│ Metrics/EpCost                │ 59.560001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 106.0                  │\n",
       "│ Train/Entropy                 │ 0.7356224060058594     │\n",
       "│ Train/KL                      │ 0.013349456712603569   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9996172785758972     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9996172785758972     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9996172785758972     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019231807440519333   │\n",
       "│ Train/LR                      │ 0.00023580000561196357 │\n",
       "│ Train/PolicyStd               │ 0.5050121545791626     │\n",
       "│ TotalEnvSteps                 │ 219136.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012514986097812653  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00474364310503006   │\n",
       "│ Value/Adv                     │ -0.14003051817417145   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018926482647657394   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0013402681797742844  │\n",
       "│ Value/reward                  │ 1.6884980201721191     │\n",
       "│ Time/Total                    │ 1439.098388671875      │\n",
       "│ Time/Rollout                  │ 11.884199142456055     │\n",
       "│ Time/Update                   │ 1.995603084564209      │\n",
       "│ Time/Epoch                    │ 13.879844665527344     │\n",
       "│ Time/FPS                      │ 147.5520782470703      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.086917877197266     │\n",
       "│ Metrics/EpCost                │ 58.720001220703125     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 107.0                  │\n",
       "│ Train/Entropy                 │ 0.7265002727508545     │\n",
       "│ Train/KL                      │ 0.015834562480449677   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9997608065605164     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9997608065605164     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9997608065605164     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019136719405651093   │\n",
       "│ Train/LR                      │ 0.00023520000104326755 │\n",
       "│ Train/PolicyStd               │ 0.5004085898399353     │\n",
       "│ TotalEnvSteps                 │ 221184.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01561050396412611   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0030955178663134575 │\n",
       "│ Value/Adv                     │ -0.1754292994737625    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02661687135696411    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.007690388709306717   │\n",
       "│ Value/reward                  │ 1.9071601629257202     │\n",
       "│ Time/Total                    │ 1453.0401611328125     │\n",
       "│ Time/Rollout                  │ 11.886845588684082     │\n",
       "│ Time/Update                   │ 2.042208194732666      │\n",
       "│ Time/Epoch                    │ 13.929101943969727     │\n",
       "│ Time/FPS                      │ 147.0303192138672      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.086917877197266     │\n",
       "│ Metrics/EpCost                │ 58.720001220703125     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 107.0                  │\n",
       "│ Train/Entropy                 │ 0.7265002727508545     │\n",
       "│ Train/KL                      │ 0.015834562480449677   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9997608065605164     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9997608065605164     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9997608065605164     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019136719405651093   │\n",
       "│ Train/LR                      │ 0.00023520000104326755 │\n",
       "│ Train/PolicyStd               │ 0.5004085898399353     │\n",
       "│ TotalEnvSteps                 │ 221184.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01561050396412611   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0030955178663134575 │\n",
       "│ Value/Adv                     │ -0.1754292994737625    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02661687135696411    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.007690388709306717   │\n",
       "│ Value/reward                  │ 1.9071601629257202     │\n",
       "│ Time/Total                    │ 1453.0401611328125     │\n",
       "│ Time/Rollout                  │ 11.886845588684082     │\n",
       "│ Time/Update                   │ 2.042208194732666      │\n",
       "│ Time/Epoch                    │ 13.929101943969727     │\n",
       "│ Time/FPS                      │ 147.0303192138672      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.589927673339844     │\n",
       "│ Metrics/EpCost                │ 56.36000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 108.0                  │\n",
       "│ Train/Entropy                 │ 0.7147151231765747     │\n",
       "│ Train/KL                      │ 0.013479012995958328   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0058962106704712     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0058962106704712     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0058962106704712     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019175464287400246   │\n",
       "│ Train/LR                      │ 0.00023459999647457153 │\n",
       "│ Train/PolicyStd               │ 0.49455952644348145    │\n",
       "│ TotalEnvSteps                 │ 223232.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012070782482624054  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.003539721481502056   │\n",
       "│ Value/Adv                     │ -0.17526733875274658   │\n",
       "│ Loss/Loss_reward_critic       │ 0.017252497375011444   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.009364373981952667  │\n",
       "│ Value/reward                  │ 1.613182783126831      │\n",
       "│ Time/Total                    │ 1466.967529296875      │\n",
       "│ Time/Rollout                  │ 11.854301452636719     │\n",
       "│ Time/Update                   │ 2.0605716705322266     │\n",
       "│ Time/Epoch                    │ 13.914922714233398     │\n",
       "│ Time/FPS                      │ 147.1801300048828      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.589927673339844     │\n",
       "│ Metrics/EpCost                │ 56.36000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 108.0                  │\n",
       "│ Train/Entropy                 │ 0.7147151231765747     │\n",
       "│ Train/KL                      │ 0.013479012995958328   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0058962106704712     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0058962106704712     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0058962106704712     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019175464287400246   │\n",
       "│ Train/LR                      │ 0.00023459999647457153 │\n",
       "│ Train/PolicyStd               │ 0.49455952644348145    │\n",
       "│ TotalEnvSteps                 │ 223232.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012070782482624054  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.003539721481502056   │\n",
       "│ Value/Adv                     │ -0.17526733875274658   │\n",
       "│ Loss/Loss_reward_critic       │ 0.017252497375011444   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.009364373981952667  │\n",
       "│ Value/reward                  │ 1.613182783126831      │\n",
       "│ Time/Total                    │ 1466.967529296875      │\n",
       "│ Time/Rollout                  │ 11.854301452636719     │\n",
       "│ Time/Update                   │ 2.0605716705322266     │\n",
       "│ Time/Epoch                    │ 13.914922714233398     │\n",
       "│ Time/FPS                      │ 147.1801300048828      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.56922149658203      │\n",
       "│ Metrics/EpCost                │ 60.65999984741211      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 109.0                  │\n",
       "│ Train/Entropy                 │ 0.7097935676574707     │\n",
       "│ Train/KL                      │ 0.016984283924102783   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0004587173461914     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0004587173461914     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0004587173461914     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02060035802423954    │\n",
       "│ Train/LR                      │ 0.00023400000645779073 │\n",
       "│ Train/PolicyStd               │ 0.4921661913394928     │\n",
       "│ TotalEnvSteps                 │ 225280.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011901499703526497  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00016928277909755707 │\n",
       "│ Value/Adv                     │ -0.05698048323392868   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018327955156564713   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0010754577815532684  │\n",
       "│ Value/reward                  │ 1.7461193799972534     │\n",
       "│ Time/Total                    │ 1481.054931640625      │\n",
       "│ Time/Rollout                  │ 12.013480186462402     │\n",
       "│ Time/Update                   │ 2.060695171356201      │\n",
       "│ Time/Epoch                    │ 14.074214935302734     │\n",
       "│ Time/FPS                      │ 145.51434326171875     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.56922149658203      │\n",
       "│ Metrics/EpCost                │ 60.65999984741211      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 109.0                  │\n",
       "│ Train/Entropy                 │ 0.7097935676574707     │\n",
       "│ Train/KL                      │ 0.016984283924102783   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0004587173461914     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0004587173461914     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0004587173461914     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02060035802423954    │\n",
       "│ Train/LR                      │ 0.00023400000645779073 │\n",
       "│ Train/PolicyStd               │ 0.4921661913394928     │\n",
       "│ TotalEnvSteps                 │ 225280.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011901499703526497  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00016928277909755707 │\n",
       "│ Value/Adv                     │ -0.05698048323392868   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018327955156564713   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0010754577815532684  │\n",
       "│ Value/reward                  │ 1.7461193799972534     │\n",
       "│ Time/Total                    │ 1481.054931640625      │\n",
       "│ Time/Rollout                  │ 12.013480186462402     │\n",
       "│ Time/Update                   │ 2.060695171356201      │\n",
       "│ Time/Epoch                    │ 14.074214935302734     │\n",
       "│ Time/FPS                      │ 145.51434326171875     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.781009674072266      │\n",
       "│ Metrics/EpCost                │ 59.86000061035156       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 110.0                   │\n",
       "│ Train/Entropy                 │ 0.7069821953773499      │\n",
       "│ Train/KL                      │ 0.013639459386467934    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0027416944503784      │\n",
       "│ Train/PolicyRatio/Min         │ 1.0027416944503784      │\n",
       "│ Train/PolicyRatio/Max         │ 1.0027416944503784      │\n",
       "│ Train/PolicyRatio/Std         │ 0.0176052488386631      │\n",
       "│ Train/LR                      │ 0.0002334000018890947   │\n",
       "│ Train/PolicyStd               │ 0.49082255363464355     │\n",
       "│ TotalEnvSteps                 │ 227328.0                │\n",
       "│ Loss/Loss_pi                  │ -0.01202234998345375    │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00012085027992725372 │\n",
       "│ Value/Adv                     │ 0.2000351846218109      │\n",
       "│ Loss/Loss_reward_critic       │ 0.01992296427488327     │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0015950091183185577   │\n",
       "│ Value/reward                  │ 1.8485548496246338      │\n",
       "│ Time/Total                    │ 1494.9853515625         │\n",
       "│ Time/Rollout                  │ 11.834282875061035      │\n",
       "│ Time/Update                   │ 2.080585479736328       │\n",
       "│ Time/Epoch                    │ 13.914922714233398      │\n",
       "│ Time/FPS                      │ 147.18014526367188      │\n",
       "└───────────────────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.781009674072266      │\n",
       "│ Metrics/EpCost                │ 59.86000061035156       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 110.0                   │\n",
       "│ Train/Entropy                 │ 0.7069821953773499      │\n",
       "│ Train/KL                      │ 0.013639459386467934    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0027416944503784      │\n",
       "│ Train/PolicyRatio/Min         │ 1.0027416944503784      │\n",
       "│ Train/PolicyRatio/Max         │ 1.0027416944503784      │\n",
       "│ Train/PolicyRatio/Std         │ 0.0176052488386631      │\n",
       "│ Train/LR                      │ 0.0002334000018890947   │\n",
       "│ Train/PolicyStd               │ 0.49082255363464355     │\n",
       "│ TotalEnvSteps                 │ 227328.0                │\n",
       "│ Loss/Loss_pi                  │ -0.01202234998345375    │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00012085027992725372 │\n",
       "│ Value/Adv                     │ 0.2000351846218109      │\n",
       "│ Loss/Loss_reward_critic       │ 0.01992296427488327     │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0015950091183185577   │\n",
       "│ Value/reward                  │ 1.8485548496246338      │\n",
       "│ Time/Total                    │ 1494.9853515625         │\n",
       "│ Time/Rollout                  │ 11.834282875061035      │\n",
       "│ Time/Update                   │ 2.080585479736328       │\n",
       "│ Time/Epoch                    │ 13.914922714233398      │\n",
       "│ Time/FPS                      │ 147.18014526367188      │\n",
       "└───────────────────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.737781524658203    │\n",
       "│ Metrics/EpCost                │ 58.779998779296875    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 111.0                 │\n",
       "│ Train/Entropy                 │ 0.7035563588142395    │\n",
       "│ Train/KL                      │ 0.01754407398402691   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9957584142684937    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9957584142684937    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9957584142684937    │\n",
       "│ Train/PolicyRatio/Std         │ 0.02068319544196129   │\n",
       "│ Train/LR                      │ 0.0002327999973203987 │\n",
       "│ Train/PolicyStd               │ 0.489239364862442     │\n",
       "│ TotalEnvSteps                 │ 229376.0              │\n",
       "│ Loss/Loss_pi                  │ -0.017198210582137108 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.005175860598683357 │\n",
       "│ Value/Adv                     │ -0.1013450101017952   │\n",
       "│ Loss/Loss_reward_critic       │ 0.023030295968055725  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.003107331693172455  │\n",
       "│ Value/reward                  │ 1.7685437202453613    │\n",
       "│ Time/Total                    │ 1509.0657958984375    │\n",
       "│ Time/Rollout                  │ 11.928648948669434    │\n",
       "│ Time/Update                   │ 2.1377859115600586    │\n",
       "│ Time/Epoch                    │ 14.066497802734375    │\n",
       "│ Time/FPS                      │ 145.59417724609375    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.737781524658203    │\n",
       "│ Metrics/EpCost                │ 58.779998779296875    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 111.0                 │\n",
       "│ Train/Entropy                 │ 0.7035563588142395    │\n",
       "│ Train/KL                      │ 0.01754407398402691   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9957584142684937    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9957584142684937    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9957584142684937    │\n",
       "│ Train/PolicyRatio/Std         │ 0.02068319544196129   │\n",
       "│ Train/LR                      │ 0.0002327999973203987 │\n",
       "│ Train/PolicyStd               │ 0.489239364862442     │\n",
       "│ TotalEnvSteps                 │ 229376.0              │\n",
       "│ Loss/Loss_pi                  │ -0.017198210582137108 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.005175860598683357 │\n",
       "│ Value/Adv                     │ -0.1013450101017952   │\n",
       "│ Loss/Loss_reward_critic       │ 0.023030295968055725  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.003107331693172455  │\n",
       "│ Value/reward                  │ 1.7685437202453613    │\n",
       "│ Time/Total                    │ 1509.0657958984375    │\n",
       "│ Time/Rollout                  │ 11.928648948669434    │\n",
       "│ Time/Update                   │ 2.1377859115600586    │\n",
       "│ Time/Epoch                    │ 14.066497802734375    │\n",
       "│ Time/FPS                      │ 145.59417724609375    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.558534622192383     │\n",
       "│ Metrics/EpCost                │ 58.439998626708984     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 112.0                  │\n",
       "│ Train/Entropy                 │ 0.6976739764213562     │\n",
       "│ Train/KL                      │ 0.012659493833780289   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0044997930526733     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0044997930526733     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0044997930526733     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018870137631893158   │\n",
       "│ Train/LR                      │ 0.00023219999275170267 │\n",
       "│ Train/PolicyStd               │ 0.48641854524612427    │\n",
       "│ TotalEnvSteps                 │ 231424.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014953821897506714  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002244388684630394   │\n",
       "│ Value/Adv                     │ 0.09322656691074371    │\n",
       "│ Loss/Loss_reward_critic       │ 0.0157681442797184     │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.007262151688337326  │\n",
       "│ Value/reward                  │ 1.7689496278762817     │\n",
       "│ Time/Total                    │ 1523.2236328125        │\n",
       "│ Time/Rollout                  │ 12.04690933227539      │\n",
       "│ Time/Update                   │ 2.0953025817871094     │\n",
       "│ Time/Epoch                    │ 14.142260551452637     │\n",
       "│ Time/FPS                      │ 144.81419372558594     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.558534622192383     │\n",
       "│ Metrics/EpCost                │ 58.439998626708984     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 112.0                  │\n",
       "│ Train/Entropy                 │ 0.6976739764213562     │\n",
       "│ Train/KL                      │ 0.012659493833780289   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0044997930526733     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0044997930526733     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0044997930526733     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018870137631893158   │\n",
       "│ Train/LR                      │ 0.00023219999275170267 │\n",
       "│ Train/PolicyStd               │ 0.48641854524612427    │\n",
       "│ TotalEnvSteps                 │ 231424.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014953821897506714  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002244388684630394   │\n",
       "│ Value/Adv                     │ 0.09322656691074371    │\n",
       "│ Loss/Loss_reward_critic       │ 0.0157681442797184     │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.007262151688337326  │\n",
       "│ Value/reward                  │ 1.7689496278762817     │\n",
       "│ Time/Total                    │ 1523.2236328125        │\n",
       "│ Time/Rollout                  │ 12.04690933227539      │\n",
       "│ Time/Update                   │ 2.0953025817871094     │\n",
       "│ Time/Epoch                    │ 14.142260551452637     │\n",
       "│ Time/FPS                      │ 144.81419372558594     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.5628604888916       │\n",
       "│ Metrics/EpCost                │ 56.040000915527344     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 113.0                  │\n",
       "│ Train/Entropy                 │ 0.691694438457489      │\n",
       "│ Train/KL                      │ 0.018595609813928604   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9952573776245117     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9952573776245117     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9952573776245117     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02253548987209797    │\n",
       "│ Train/LR                      │ 0.00023160000273492187 │\n",
       "│ Train/PolicyStd               │ 0.48350849747657776    │\n",
       "│ TotalEnvSteps                 │ 233472.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014562586322426796  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0003912355750799179  │\n",
       "│ Value/Adv                     │ 0.21807608008384705    │\n",
       "│ Loss/Loss_reward_critic       │ 0.0279233418405056     │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.012155197560787201   │\n",
       "│ Value/reward                  │ 1.7559822797775269     │\n",
       "│ Time/Total                    │ 1537.3883056640625     │\n",
       "│ Time/Rollout                  │ 12.101066589355469     │\n",
       "│ Time/Update                   │ 2.050642490386963      │\n",
       "│ Time/Epoch                    │ 14.151754379272461     │\n",
       "│ Time/FPS                      │ 144.717041015625       │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.5628604888916       │\n",
       "│ Metrics/EpCost                │ 56.040000915527344     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 113.0                  │\n",
       "│ Train/Entropy                 │ 0.691694438457489      │\n",
       "│ Train/KL                      │ 0.018595609813928604   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9952573776245117     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9952573776245117     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9952573776245117     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02253548987209797    │\n",
       "│ Train/LR                      │ 0.00023160000273492187 │\n",
       "│ Train/PolicyStd               │ 0.48350849747657776    │\n",
       "│ TotalEnvSteps                 │ 233472.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014562586322426796  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0003912355750799179  │\n",
       "│ Value/Adv                     │ 0.21807608008384705    │\n",
       "│ Loss/Loss_reward_critic       │ 0.0279233418405056     │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.012155197560787201   │\n",
       "│ Value/reward                  │ 1.7559822797775269     │\n",
       "│ Time/Total                    │ 1537.3883056640625     │\n",
       "│ Time/Rollout                  │ 12.101066589355469     │\n",
       "│ Time/Update                   │ 2.050642490386963      │\n",
       "│ Time/Epoch                    │ 14.151754379272461     │\n",
       "│ Time/FPS                      │ 144.717041015625       │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.472156524658203     │\n",
       "│ Metrics/EpCost                │ 56.7599983215332       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 114.0                  │\n",
       "│ Train/Entropy                 │ 0.6916016340255737     │\n",
       "│ Train/KL                      │ 0.012228209525346756   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9985052347183228     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9985052347183228     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9985052347183228     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02078608050942421    │\n",
       "│ Train/LR                      │ 0.00023099999816622585 │\n",
       "│ Train/PolicyStd               │ 0.4834810793399811     │\n",
       "│ TotalEnvSteps                 │ 235520.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011452840641140938  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.003109745681285858   │\n",
       "│ Value/Adv                     │ -0.10627405345439911   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01581602171063423    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.012107320129871368  │\n",
       "│ Value/reward                  │ 1.7588472366333008     │\n",
       "│ Time/Total                    │ 1551.2523193359375     │\n",
       "│ Time/Rollout                  │ 11.822126388549805     │\n",
       "│ Time/Update                   │ 2.0282511711120605     │\n",
       "│ Time/Epoch                    │ 13.85042953491211      │\n",
       "│ Time/FPS                      │ 147.86546325683594     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.472156524658203     │\n",
       "│ Metrics/EpCost                │ 56.7599983215332       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 114.0                  │\n",
       "│ Train/Entropy                 │ 0.6916016340255737     │\n",
       "│ Train/KL                      │ 0.012228209525346756   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9985052347183228     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9985052347183228     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9985052347183228     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02078608050942421    │\n",
       "│ Train/LR                      │ 0.00023099999816622585 │\n",
       "│ Train/PolicyStd               │ 0.4834810793399811     │\n",
       "│ TotalEnvSteps                 │ 235520.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011452840641140938  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.003109745681285858   │\n",
       "│ Value/Adv                     │ -0.10627405345439911   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01581602171063423    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.012107320129871368  │\n",
       "│ Value/reward                  │ 1.7588472366333008     │\n",
       "│ Time/Total                    │ 1551.2523193359375     │\n",
       "│ Time/Rollout                  │ 11.822126388549805     │\n",
       "│ Time/Update                   │ 2.0282511711120605     │\n",
       "│ Time/Epoch                    │ 13.85042953491211      │\n",
       "│ Time/FPS                      │ 147.86546325683594     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.46682357788086      │\n",
       "│ Metrics/EpCost                │ 56.41999816894531      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 115.0                  │\n",
       "│ Train/Entropy                 │ 0.694756805896759      │\n",
       "│ Train/KL                      │ 0.014411019161343575   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9936180114746094     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9936180114746094     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9936180114746094     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018528563901782036   │\n",
       "│ Train/LR                      │ 0.00023039999359752983 │\n",
       "│ Train/PolicyStd               │ 0.4850315451622009     │\n",
       "│ TotalEnvSteps                 │ 237568.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014515196904540062  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.003062356263399124  │\n",
       "│ Value/Adv                     │ 0.20062828063964844    │\n",
       "│ Loss/Loss_reward_critic       │ 0.015839897096157074   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 2.3875385522842407e-05 │\n",
       "│ Value/reward                  │ 1.7582348585128784     │\n",
       "│ Time/Total                    │ 1565.5269775390625     │\n",
       "│ Time/Rollout                  │ 12.180461883544922     │\n",
       "│ Time/Update                   │ 2.0807857513427734     │\n",
       "│ Time/Epoch                    │ 14.261292457580566     │\n",
       "│ Time/FPS                      │ 143.6055145263672      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.46682357788086      │\n",
       "│ Metrics/EpCost                │ 56.41999816894531      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 115.0                  │\n",
       "│ Train/Entropy                 │ 0.694756805896759      │\n",
       "│ Train/KL                      │ 0.014411019161343575   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9936180114746094     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9936180114746094     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9936180114746094     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018528563901782036   │\n",
       "│ Train/LR                      │ 0.00023039999359752983 │\n",
       "│ Train/PolicyStd               │ 0.4850315451622009     │\n",
       "│ TotalEnvSteps                 │ 237568.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014515196904540062  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.003062356263399124  │\n",
       "│ Value/Adv                     │ 0.20062828063964844    │\n",
       "│ Loss/Loss_reward_critic       │ 0.015839897096157074   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 2.3875385522842407e-05 │\n",
       "│ Value/reward                  │ 1.7582348585128784     │\n",
       "│ Time/Total                    │ 1565.5269775390625     │\n",
       "│ Time/Rollout                  │ 12.180461883544922     │\n",
       "│ Time/Update                   │ 2.0807857513427734     │\n",
       "│ Time/Epoch                    │ 14.261292457580566     │\n",
       "│ Time/FPS                      │ 143.6055145263672      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.54027557373047      │\n",
       "│ Metrics/EpCost                │ 56.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 116.0                  │\n",
       "│ Train/Entropy                 │ 0.6919997334480286     │\n",
       "│ Train/KL                      │ 0.015098001807928085   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9981949925422668     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9981949925422668     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9981949925422668     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01814328506588936    │\n",
       "│ Train/LR                      │ 0.00022980000358074903 │\n",
       "│ Train/PolicyStd               │ 0.4838160574436188     │\n",
       "│ TotalEnvSteps                 │ 239616.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013748598285019398  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0007665986195206642  │\n",
       "│ Value/Adv                     │ -0.02125987783074379   │\n",
       "│ Loss/Loss_reward_critic       │ 0.026423180475831032   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.010583283379673958   │\n",
       "│ Value/reward                  │ 1.7229307889938354     │\n",
       "│ Time/Total                    │ 1579.3507080078125     │\n",
       "│ Time/Rollout                  │ 11.752731323242188     │\n",
       "│ Time/Update                   │ 2.0580546855926514     │\n",
       "│ Time/Epoch                    │ 13.810839653015137     │\n",
       "│ Time/FPS                      │ 148.28932189941406     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.54027557373047      │\n",
       "│ Metrics/EpCost                │ 56.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 116.0                  │\n",
       "│ Train/Entropy                 │ 0.6919997334480286     │\n",
       "│ Train/KL                      │ 0.015098001807928085   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9981949925422668     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9981949925422668     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9981949925422668     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01814328506588936    │\n",
       "│ Train/LR                      │ 0.00022980000358074903 │\n",
       "│ Train/PolicyStd               │ 0.4838160574436188     │\n",
       "│ TotalEnvSteps                 │ 239616.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013748598285019398  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0007665986195206642  │\n",
       "│ Value/Adv                     │ -0.02125987783074379   │\n",
       "│ Loss/Loss_reward_critic       │ 0.026423180475831032   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.010583283379673958   │\n",
       "│ Value/reward                  │ 1.7229307889938354     │\n",
       "│ Time/Total                    │ 1579.3507080078125     │\n",
       "│ Time/Rollout                  │ 11.752731323242188     │\n",
       "│ Time/Update                   │ 2.0580546855926514     │\n",
       "│ Time/Epoch                    │ 13.810839653015137     │\n",
       "│ Time/FPS                      │ 148.28932189941406     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.630382537841797     │\n",
       "│ Metrics/EpCost                │ 57.7400016784668       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 117.0                  │\n",
       "│ Train/Entropy                 │ 0.6899481415748596     │\n",
       "│ Train/KL                      │ 0.010654900223016739   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9978370666503906     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9978370666503906     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9978370666503906     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017754318192601204   │\n",
       "│ Train/LR                      │ 0.000229199999012053   │\n",
       "│ Train/PolicyStd               │ 0.482893705368042      │\n",
       "│ TotalEnvSteps                 │ 241664.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01395735889673233   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0002087606117129326 │\n",
       "│ Value/Adv                     │ -0.07971429079771042   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02801460400223732    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0015914235264062881  │\n",
       "│ Value/reward                  │ 1.9043244123458862     │\n",
       "│ Time/Total                    │ 1593.44677734375       │\n",
       "│ Time/Rollout                  │ 11.986543655395508     │\n",
       "│ Time/Update                   │ 2.096400022506714      │\n",
       "│ Time/Epoch                    │ 14.082986831665039     │\n",
       "│ Time/FPS                      │ 145.4237060546875      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.630382537841797     │\n",
       "│ Metrics/EpCost                │ 57.7400016784668       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 117.0                  │\n",
       "│ Train/Entropy                 │ 0.6899481415748596     │\n",
       "│ Train/KL                      │ 0.010654900223016739   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9978370666503906     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9978370666503906     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9978370666503906     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017754318192601204   │\n",
       "│ Train/LR                      │ 0.000229199999012053   │\n",
       "│ Train/PolicyStd               │ 0.482893705368042      │\n",
       "│ TotalEnvSteps                 │ 241664.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01395735889673233   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0002087606117129326 │\n",
       "│ Value/Adv                     │ -0.07971429079771042   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02801460400223732    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0015914235264062881  │\n",
       "│ Value/reward                  │ 1.9043244123458862     │\n",
       "│ Time/Total                    │ 1593.44677734375       │\n",
       "│ Time/Rollout                  │ 11.986543655395508     │\n",
       "│ Time/Update                   │ 2.096400022506714      │\n",
       "│ Time/Epoch                    │ 14.082986831665039     │\n",
       "│ Time/FPS                      │ 145.4237060546875      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.52549934387207       │\n",
       "│ Metrics/EpCost                │ 57.5                    │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 118.0                   │\n",
       "│ Train/Entropy                 │ 0.6850554347038269      │\n",
       "│ Train/KL                      │ 0.015239126980304718    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9990876317024231      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9990876317024231      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9990876317024231      │\n",
       "│ Train/PolicyRatio/Std         │ 0.02061626873910427     │\n",
       "│ Train/LR                      │ 0.000228599994443357    │\n",
       "│ Train/PolicyStd               │ 0.4804565906524658      │\n",
       "│ TotalEnvSteps                 │ 243712.0                │\n",
       "│ Loss/Loss_pi                  │ -0.014433180913329124   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00047582201659679413 │\n",
       "│ Value/Adv                     │ 0.13525018095970154     │\n",
       "│ Loss/Loss_reward_critic       │ 0.018293267115950584    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.009721336886286736   │\n",
       "│ Value/reward                  │ 1.721212387084961       │\n",
       "│ Time/Total                    │ 1607.6732177734375      │\n",
       "│ Time/Rollout                  │ 12.02726936340332       │\n",
       "│ Time/Update                   │ 2.1845626831054688      │\n",
       "│ Time/Epoch                    │ 14.211881637573242      │\n",
       "│ Time/FPS                      │ 144.1047821044922       │\n",
       "└───────────────────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.52549934387207       │\n",
       "│ Metrics/EpCost                │ 57.5                    │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 118.0                   │\n",
       "│ Train/Entropy                 │ 0.6850554347038269      │\n",
       "│ Train/KL                      │ 0.015239126980304718    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9990876317024231      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9990876317024231      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9990876317024231      │\n",
       "│ Train/PolicyRatio/Std         │ 0.02061626873910427     │\n",
       "│ Train/LR                      │ 0.000228599994443357    │\n",
       "│ Train/PolicyStd               │ 0.4804565906524658      │\n",
       "│ TotalEnvSteps                 │ 243712.0                │\n",
       "│ Loss/Loss_pi                  │ -0.014433180913329124   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00047582201659679413 │\n",
       "│ Value/Adv                     │ 0.13525018095970154     │\n",
       "│ Loss/Loss_reward_critic       │ 0.018293267115950584    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.009721336886286736   │\n",
       "│ Value/reward                  │ 1.721212387084961       │\n",
       "│ Time/Total                    │ 1607.6732177734375      │\n",
       "│ Time/Rollout                  │ 12.02726936340332       │\n",
       "│ Time/Update                   │ 2.1845626831054688      │\n",
       "│ Time/Epoch                    │ 14.211881637573242      │\n",
       "│ Time/FPS                      │ 144.1047821044922       │\n",
       "└───────────────────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.389738082885742    │\n",
       "│ Metrics/EpCost                │ 60.2400016784668      │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 119.0                 │\n",
       "│ Train/Entropy                 │ 0.6760562658309937    │\n",
       "│ Train/KL                      │ 0.014417598955333233  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9933478236198425    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9933478236198425    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9933478236198425    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01667560450732708   │\n",
       "│ Train/LR                      │ 0.0002280000044265762 │\n",
       "│ Train/PolicyStd               │ 0.4760185778141022    │\n",
       "│ TotalEnvSteps                 │ 245760.0              │\n",
       "│ Loss/Loss_pi                  │ -0.012842255644500256 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0015909252688288689 │\n",
       "│ Value/Adv                     │ 0.08473499864339828   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01633806899189949   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.001955198124051094 │\n",
       "│ Value/reward                  │ 1.7250561714172363    │\n",
       "│ Time/Total                    │ 1622.5096435546875    │\n",
       "│ Time/Rollout                  │ 12.719024658203125    │\n",
       "│ Time/Update                   │ 2.1038873195648193    │\n",
       "│ Time/Epoch                    │ 14.822956085205078    │\n",
       "│ Time/FPS                      │ 138.16407775878906    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.389738082885742    │\n",
       "│ Metrics/EpCost                │ 60.2400016784668      │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 119.0                 │\n",
       "│ Train/Entropy                 │ 0.6760562658309937    │\n",
       "│ Train/KL                      │ 0.014417598955333233  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9933478236198425    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9933478236198425    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9933478236198425    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01667560450732708   │\n",
       "│ Train/LR                      │ 0.0002280000044265762 │\n",
       "│ Train/PolicyStd               │ 0.4760185778141022    │\n",
       "│ TotalEnvSteps                 │ 245760.0              │\n",
       "│ Loss/Loss_pi                  │ -0.012842255644500256 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0015909252688288689 │\n",
       "│ Value/Adv                     │ 0.08473499864339828   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01633806899189949   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.001955198124051094 │\n",
       "│ Value/reward                  │ 1.7250561714172363    │\n",
       "│ Time/Total                    │ 1622.5096435546875    │\n",
       "│ Time/Rollout                  │ 12.719024658203125    │\n",
       "│ Time/Update                   │ 2.1038873195648193    │\n",
       "│ Time/Epoch                    │ 14.822956085205078    │\n",
       "│ Time/FPS                      │ 138.16407775878906    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.14672088623047      │\n",
       "│ Metrics/EpCost                │ 59.459999084472656     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 120.0                  │\n",
       "│ Train/Entropy                 │ 0.6745284199714661     │\n",
       "│ Train/KL                      │ 0.015352010726928711   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9992559552192688     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9992559552192688     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9992559552192688     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018582982942461967   │\n",
       "│ Train/LR                      │ 0.00022739999985788018 │\n",
       "│ Train/PolicyStd               │ 0.4752573072910309     │\n",
       "│ TotalEnvSteps                 │ 247808.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014353608712553978  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0015113530680537224 │\n",
       "│ Value/Adv                     │ 0.03664481267333031    │\n",
       "│ Loss/Loss_reward_critic       │ 0.014769608154892921   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.001568460837006569  │\n",
       "│ Value/reward                  │ 1.4429389238357544     │\n",
       "│ Time/Total                    │ 1636.947021484375      │\n",
       "│ Time/Rollout                  │ 12.270009994506836     │\n",
       "│ Time/Update                   │ 2.152702569961548      │\n",
       "│ Time/Epoch                    │ 14.422782897949219     │\n",
       "│ Time/FPS                      │ 141.99757385253906     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.14672088623047      │\n",
       "│ Metrics/EpCost                │ 59.459999084472656     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 120.0                  │\n",
       "│ Train/Entropy                 │ 0.6745284199714661     │\n",
       "│ Train/KL                      │ 0.015352010726928711   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9992559552192688     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9992559552192688     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9992559552192688     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018582982942461967   │\n",
       "│ Train/LR                      │ 0.00022739999985788018 │\n",
       "│ Train/PolicyStd               │ 0.4752573072910309     │\n",
       "│ TotalEnvSteps                 │ 247808.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014353608712553978  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0015113530680537224 │\n",
       "│ Value/Adv                     │ 0.03664481267333031    │\n",
       "│ Loss/Loss_reward_critic       │ 0.014769608154892921   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.001568460837006569  │\n",
       "│ Value/reward                  │ 1.4429389238357544     │\n",
       "│ Time/Total                    │ 1636.947021484375      │\n",
       "│ Time/Rollout                  │ 12.270009994506836     │\n",
       "│ Time/Update                   │ 2.152702569961548      │\n",
       "│ Time/Epoch                    │ 14.422782897949219     │\n",
       "│ Time/FPS                      │ 141.99757385253906     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.168149948120117     │\n",
       "│ Metrics/EpCost                │ 58.18000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 121.0                  │\n",
       "│ Train/Entropy                 │ 0.6702300906181335     │\n",
       "│ Train/KL                      │ 0.014834855683147907   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.00038743019104       │\n",
       "│ Train/PolicyRatio/Min         │ 1.00038743019104       │\n",
       "│ Train/PolicyRatio/Max         │ 1.00038743019104       │\n",
       "│ Train/PolicyRatio/Std         │ 0.01804042048752308    │\n",
       "│ Train/LR                      │ 0.00022679999528918415 │\n",
       "│ Train/PolicyStd               │ 0.4732294976711273     │\n",
       "│ TotalEnvSteps                 │ 249856.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018153518438339233  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0037999097257852554 │\n",
       "│ Value/Adv                     │ -0.07750695943832397   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02189689502120018    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.007127286866307259   │\n",
       "│ Value/reward                  │ 1.8456685543060303     │\n",
       "│ Time/Total                    │ 1651.3106689453125     │\n",
       "│ Time/Rollout                  │ 12.292346954345703     │\n",
       "│ Time/Update                   │ 2.057866096496582      │\n",
       "│ Time/Epoch                    │ 14.350284576416016     │\n",
       "│ Time/FPS                      │ 142.71495056152344     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.168149948120117     │\n",
       "│ Metrics/EpCost                │ 58.18000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 121.0                  │\n",
       "│ Train/Entropy                 │ 0.6702300906181335     │\n",
       "│ Train/KL                      │ 0.014834855683147907   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.00038743019104       │\n",
       "│ Train/PolicyRatio/Min         │ 1.00038743019104       │\n",
       "│ Train/PolicyRatio/Max         │ 1.00038743019104       │\n",
       "│ Train/PolicyRatio/Std         │ 0.01804042048752308    │\n",
       "│ Train/LR                      │ 0.00022679999528918415 │\n",
       "│ Train/PolicyStd               │ 0.4732294976711273     │\n",
       "│ TotalEnvSteps                 │ 249856.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018153518438339233  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0037999097257852554 │\n",
       "│ Value/Adv                     │ -0.07750695943832397   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02189689502120018    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.007127286866307259   │\n",
       "│ Value/reward                  │ 1.8456685543060303     │\n",
       "│ Time/Total                    │ 1651.3106689453125     │\n",
       "│ Time/Rollout                  │ 12.292346954345703     │\n",
       "│ Time/Update                   │ 2.057866096496582      │\n",
       "│ Time/Epoch                    │ 14.350284576416016     │\n",
       "│ Time/FPS                      │ 142.71495056152344     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m7\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.098487854003906      │\n",
       "│ Metrics/EpCost                │ 62.34000015258789       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 122.0                   │\n",
       "│ Train/Entropy                 │ 0.6656293869018555      │\n",
       "│ Train/KL                      │ 0.020760567858815193    │\n",
       "│ Train/StopIter                │ 7.0                     │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9962785840034485      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9962785840034485      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9962785840034485      │\n",
       "│ Train/PolicyRatio/Std         │ 0.020789850503206253    │\n",
       "│ Train/LR                      │ 0.00022620000527240336  │\n",
       "│ Train/PolicyStd               │ 0.4710374176502228      │\n",
       "│ TotalEnvSteps                 │ 251904.0                │\n",
       "│ Loss/Loss_pi                  │ -0.013514800928533077   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004638717509806156    │\n",
       "│ Value/Adv                     │ 0.09362676739692688     │\n",
       "│ Loss/Loss_reward_critic       │ 0.021446367725729942    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00045052729547023773 │\n",
       "│ Value/reward                  │ 1.6824613809585571      │\n",
       "│ Time/Total                    │ 1666.151123046875       │\n",
       "│ Time/Rollout                  │ 13.286410331726074      │\n",
       "│ Time/Update                   │ 1.5409479141235352      │\n",
       "│ Time/Epoch                    │ 14.827410697937012      │\n",
       "│ Time/FPS                      │ 138.12257385253906      │\n",
       "└───────────────────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.098487854003906      │\n",
       "│ Metrics/EpCost                │ 62.34000015258789       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 122.0                   │\n",
       "│ Train/Entropy                 │ 0.6656293869018555      │\n",
       "│ Train/KL                      │ 0.020760567858815193    │\n",
       "│ Train/StopIter                │ 7.0                     │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9962785840034485      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9962785840034485      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9962785840034485      │\n",
       "│ Train/PolicyRatio/Std         │ 0.020789850503206253    │\n",
       "│ Train/LR                      │ 0.00022620000527240336  │\n",
       "│ Train/PolicyStd               │ 0.4710374176502228      │\n",
       "│ TotalEnvSteps                 │ 251904.0                │\n",
       "│ Loss/Loss_pi                  │ -0.013514800928533077   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004638717509806156    │\n",
       "│ Value/Adv                     │ 0.09362676739692688     │\n",
       "│ Loss/Loss_reward_critic       │ 0.021446367725729942    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00045052729547023773 │\n",
       "│ Value/reward                  │ 1.6824613809585571      │\n",
       "│ Time/Total                    │ 1666.151123046875       │\n",
       "│ Time/Rollout                  │ 13.286410331726074      │\n",
       "│ Time/Update                   │ 1.5409479141235352      │\n",
       "│ Time/Epoch                    │ 14.827410697937012      │\n",
       "│ Time/FPS                      │ 138.12257385253906      │\n",
       "└───────────────────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 16.999547958374023     │\n",
       "│ Metrics/EpCost                │ 62.720001220703125     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 123.0                  │\n",
       "│ Train/Entropy                 │ 0.6599856019020081     │\n",
       "│ Train/KL                      │ 0.012978038750588894   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9954879879951477     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9954879879951477     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9954879879951477     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016954367980360985   │\n",
       "│ Train/LR                      │ 0.00022560000070370734 │\n",
       "│ Train/PolicyStd               │ 0.4684561789035797     │\n",
       "│ TotalEnvSteps                 │ 253952.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01584884151816368   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002334040589630604  │\n",
       "│ Value/Adv                     │ 0.08190900087356567    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02426939085125923    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0028230231255292892  │\n",
       "│ Value/reward                  │ 1.8104052543640137     │\n",
       "│ Time/Total                    │ 1683.050537109375      │\n",
       "│ Time/Rollout                  │ 14.282734870910645     │\n",
       "│ Time/Update                   │ 2.5997707843780518     │\n",
       "│ Time/Epoch                    │ 16.882583618164062     │\n",
       "│ Time/FPS                      │ 121.30846405029297     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 16.999547958374023     │\n",
       "│ Metrics/EpCost                │ 62.720001220703125     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 123.0                  │\n",
       "│ Train/Entropy                 │ 0.6599856019020081     │\n",
       "│ Train/KL                      │ 0.012978038750588894   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9954879879951477     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9954879879951477     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9954879879951477     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016954367980360985   │\n",
       "│ Train/LR                      │ 0.00022560000070370734 │\n",
       "│ Train/PolicyStd               │ 0.4684561789035797     │\n",
       "│ TotalEnvSteps                 │ 253952.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01584884151816368   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002334040589630604  │\n",
       "│ Value/Adv                     │ 0.08190900087356567    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02426939085125923    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0028230231255292892  │\n",
       "│ Value/reward                  │ 1.8104052543640137     │\n",
       "│ Time/Total                    │ 1683.050537109375      │\n",
       "│ Time/Rollout                  │ 14.282734870910645     │\n",
       "│ Time/Update                   │ 2.5997707843780518     │\n",
       "│ Time/Epoch                    │ 16.882583618164062     │\n",
       "│ Time/FPS                      │ 121.30846405029297     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.0583553314209       │\n",
       "│ Metrics/EpCost                │ 67.0                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 124.0                  │\n",
       "│ Train/Entropy                 │ 0.6554757356643677     │\n",
       "│ Train/KL                      │ 0.014516577124595642   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9961276054382324     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9961276054382324     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9961276054382324     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019338520243763924   │\n",
       "│ Train/LR                      │ 0.00022499999613501132 │\n",
       "│ Train/PolicyStd               │ 0.46637171506881714    │\n",
       "│ TotalEnvSteps                 │ 256000.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01708275079727173   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0012339092791080475 │\n",
       "│ Value/Adv                     │ 0.05997828021645546    │\n",
       "│ Loss/Loss_reward_critic       │ 0.03325330838561058    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.008983917534351349   │\n",
       "│ Value/reward                  │ 1.9659446477890015     │\n",
       "│ Time/Total                    │ 1699.527587890625      │\n",
       "│ Time/Rollout                  │ 13.842150688171387     │\n",
       "│ Time/Update                   │ 2.612628698348999      │\n",
       "│ Time/Epoch                    │ 16.454833984375        │\n",
       "│ Time/FPS                      │ 124.46190643310547     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.0583553314209       │\n",
       "│ Metrics/EpCost                │ 67.0                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 124.0                  │\n",
       "│ Train/Entropy                 │ 0.6554757356643677     │\n",
       "│ Train/KL                      │ 0.014516577124595642   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9961276054382324     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9961276054382324     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9961276054382324     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019338520243763924   │\n",
       "│ Train/LR                      │ 0.00022499999613501132 │\n",
       "│ Train/PolicyStd               │ 0.46637171506881714    │\n",
       "│ TotalEnvSteps                 │ 256000.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01708275079727173   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0012339092791080475 │\n",
       "│ Value/Adv                     │ 0.05997828021645546    │\n",
       "│ Loss/Loss_reward_critic       │ 0.03325330838561058    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.008983917534351349   │\n",
       "│ Value/reward                  │ 1.9659446477890015     │\n",
       "│ Time/Total                    │ 1699.527587890625      │\n",
       "│ Time/Rollout                  │ 13.842150688171387     │\n",
       "│ Time/Update                   │ 2.612628698348999      │\n",
       "│ Time/Epoch                    │ 16.454833984375        │\n",
       "│ Time/FPS                      │ 124.46190643310547     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.10559844970703      │\n",
       "│ Metrics/EpCost                │ 68.37999725341797      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 125.0                  │\n",
       "│ Train/Entropy                 │ 0.6477245688438416     │\n",
       "│ Train/KL                      │ 0.009332980029284954   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0039151906967163     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0039151906967163     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0039151906967163     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01692866161465645    │\n",
       "│ Train/LR                      │ 0.00022440000611823052 │\n",
       "│ Train/PolicyStd               │ 0.46281856298446655    │\n",
       "│ TotalEnvSteps                 │ 258048.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014979643747210503  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002103107050061226   │\n",
       "│ Value/Adv                     │ -0.15570136904716492   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01748357154428959    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.01576973684132099   │\n",
       "│ Value/reward                  │ 2.0134212970733643     │\n",
       "│ Time/Total                    │ 1713.4619140625        │\n",
       "│ Time/Rollout                  │ 11.999917984008789     │\n",
       "│ Time/Update                   │ 1.9182722568511963     │\n",
       "│ Time/Epoch                    │ 13.918235778808594     │\n",
       "│ Time/FPS                      │ 147.1450958251953      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.10559844970703      │\n",
       "│ Metrics/EpCost                │ 68.37999725341797      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 125.0                  │\n",
       "│ Train/Entropy                 │ 0.6477245688438416     │\n",
       "│ Train/KL                      │ 0.009332980029284954   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0039151906967163     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0039151906967163     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0039151906967163     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01692866161465645    │\n",
       "│ Train/LR                      │ 0.00022440000611823052 │\n",
       "│ Train/PolicyStd               │ 0.46281856298446655    │\n",
       "│ TotalEnvSteps                 │ 258048.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014979643747210503  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002103107050061226   │\n",
       "│ Value/Adv                     │ -0.15570136904716492   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01748357154428959    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.01576973684132099   │\n",
       "│ Value/reward                  │ 2.0134212970733643     │\n",
       "│ Time/Total                    │ 1713.4619140625        │\n",
       "│ Time/Rollout                  │ 11.999917984008789     │\n",
       "│ Time/Update                   │ 1.9182722568511963     │\n",
       "│ Time/Epoch                    │ 13.918235778808594     │\n",
       "│ Time/FPS                      │ 147.1450958251953      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.20108413696289      │\n",
       "│ Metrics/EpCost                │ 67.0                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 126.0                  │\n",
       "│ Train/Entropy                 │ 0.6398928165435791     │\n",
       "│ Train/KL                      │ 0.017576567828655243   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0004067420959473     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0004067420959473     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0004067420959473     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01992315612733364    │\n",
       "│ Train/LR                      │ 0.0002238000015495345  │\n",
       "│ Train/PolicyStd               │ 0.4592202603816986     │\n",
       "│ TotalEnvSteps                 │ 260096.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01454752217978239   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00043212156742811203 │\n",
       "│ Value/Adv                     │ -0.031453996896743774  │\n",
       "│ Loss/Loss_reward_critic       │ 0.026274260133504868   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.008790688589215279   │\n",
       "│ Value/reward                  │ 1.9854413270950317     │\n",
       "│ Time/Total                    │ 1727.0816650390625     │\n",
       "│ Time/Rollout                  │ 11.773080825805664     │\n",
       "│ Time/Update                   │ 1.8327293395996094     │\n",
       "│ Time/Epoch                    │ 13.60584831237793      │\n",
       "│ Time/FPS                      │ 150.5235137939453      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.20108413696289      │\n",
       "│ Metrics/EpCost                │ 67.0                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 126.0                  │\n",
       "│ Train/Entropy                 │ 0.6398928165435791     │\n",
       "│ Train/KL                      │ 0.017576567828655243   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0004067420959473     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0004067420959473     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0004067420959473     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01992315612733364    │\n",
       "│ Train/LR                      │ 0.0002238000015495345  │\n",
       "│ Train/PolicyStd               │ 0.4592202603816986     │\n",
       "│ TotalEnvSteps                 │ 260096.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01454752217978239   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00043212156742811203 │\n",
       "│ Value/Adv                     │ -0.031453996896743774  │\n",
       "│ Loss/Loss_reward_critic       │ 0.026274260133504868   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.008790688589215279   │\n",
       "│ Value/reward                  │ 1.9854413270950317     │\n",
       "│ Time/Total                    │ 1727.0816650390625     │\n",
       "│ Time/Rollout                  │ 11.773080825805664     │\n",
       "│ Time/Update                   │ 1.8327293395996094     │\n",
       "│ Time/Epoch                    │ 13.60584831237793      │\n",
       "│ Time/FPS                      │ 150.5235137939453      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 16.991594314575195     │\n",
       "│ Metrics/EpCost                │ 67.37999725341797      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 127.0                  │\n",
       "│ Train/Entropy                 │ 0.6379390954971313     │\n",
       "│ Train/KL                      │ 0.011673197150230408   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0013740062713623     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0013740062713623     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0013740062713623     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01759949140250683    │\n",
       "│ Train/LR                      │ 0.00022319999698083848 │\n",
       "│ Train/PolicyStd               │ 0.4582439064979553     │\n",
       "│ TotalEnvSteps                 │ 262144.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014466394670307636  │\n",
       "│ Loss/Loss_pi/Delta            │ 8.112750947475433e-05  │\n",
       "│ Value/Adv                     │ -0.10478959232568741   │\n",
       "│ Loss/Loss_reward_critic       │ 0.023955807089805603   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0023184530436992645 │\n",
       "│ Value/reward                  │ 1.8359211683273315     │\n",
       "│ Time/Total                    │ 1740.55126953125       │\n",
       "│ Time/Rollout                  │ 11.570034980773926     │\n",
       "│ Time/Update                   │ 1.8803410530090332     │\n",
       "│ Time/Epoch                    │ 13.450431823730469     │\n",
       "│ Time/FPS                      │ 152.26278686523438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 16.991594314575195     │\n",
       "│ Metrics/EpCost                │ 67.37999725341797      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 127.0                  │\n",
       "│ Train/Entropy                 │ 0.6379390954971313     │\n",
       "│ Train/KL                      │ 0.011673197150230408   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0013740062713623     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0013740062713623     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0013740062713623     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01759949140250683    │\n",
       "│ Train/LR                      │ 0.00022319999698083848 │\n",
       "│ Train/PolicyStd               │ 0.4582439064979553     │\n",
       "│ TotalEnvSteps                 │ 262144.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014466394670307636  │\n",
       "│ Loss/Loss_pi/Delta            │ 8.112750947475433e-05  │\n",
       "│ Value/Adv                     │ -0.10478959232568741   │\n",
       "│ Loss/Loss_reward_critic       │ 0.023955807089805603   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0023184530436992645 │\n",
       "│ Value/reward                  │ 1.8359211683273315     │\n",
       "│ Time/Total                    │ 1740.55126953125       │\n",
       "│ Time/Rollout                  │ 11.570034980773926     │\n",
       "│ Time/Update                   │ 1.8803410530090332     │\n",
       "│ Time/Epoch                    │ 13.450431823730469     │\n",
       "│ Time/FPS                      │ 152.26278686523438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.159910202026367     │\n",
       "│ Metrics/EpCost                │ 65.22000122070312      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 128.0                  │\n",
       "│ Train/Entropy                 │ 0.6357096433639526     │\n",
       "│ Train/KL                      │ 0.014550000429153442   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9967061281204224     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9967061281204224     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9967061281204224     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018695680424571037   │\n",
       "│ Train/LR                      │ 0.00022260000696405768 │\n",
       "│ Train/PolicyStd               │ 0.45722341537475586    │\n",
       "│ TotalEnvSteps                 │ 264192.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01646791771054268   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0020015230402350426 │\n",
       "│ Value/Adv                     │ -0.04504765197634697   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02154570259153843    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0024101044982671738 │\n",
       "│ Value/reward                  │ 1.973125696182251      │\n",
       "│ Time/Total                    │ 1753.87841796875       │\n",
       "│ Time/Rollout                  │ 11.51521110534668      │\n",
       "│ Time/Update                   │ 1.7992498874664307     │\n",
       "│ Time/Epoch                    │ 13.31450080871582      │\n",
       "│ Time/FPS                      │ 153.8172607421875      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.159910202026367     │\n",
       "│ Metrics/EpCost                │ 65.22000122070312      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 128.0                  │\n",
       "│ Train/Entropy                 │ 0.6357096433639526     │\n",
       "│ Train/KL                      │ 0.014550000429153442   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9967061281204224     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9967061281204224     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9967061281204224     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018695680424571037   │\n",
       "│ Train/LR                      │ 0.00022260000696405768 │\n",
       "│ Train/PolicyStd               │ 0.45722341537475586    │\n",
       "│ TotalEnvSteps                 │ 264192.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01646791771054268   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0020015230402350426 │\n",
       "│ Value/Adv                     │ -0.04504765197634697   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02154570259153843    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0024101044982671738 │\n",
       "│ Value/reward                  │ 1.973125696182251      │\n",
       "│ Time/Total                    │ 1753.87841796875       │\n",
       "│ Time/Rollout                  │ 11.51521110534668      │\n",
       "│ Time/Update                   │ 1.7992498874664307     │\n",
       "│ Time/Epoch                    │ 13.31450080871582      │\n",
       "│ Time/FPS                      │ 153.8172607421875      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.22285270690918      │\n",
       "│ Metrics/EpCost                │ 67.08000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 129.0                  │\n",
       "│ Train/Entropy                 │ 0.6349121332168579     │\n",
       "│ Train/KL                      │ 0.012670536525547504   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9962223768234253     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9962223768234253     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9962223768234253     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020633786916732788   │\n",
       "│ Train/LR                      │ 0.00022200000239536166 │\n",
       "│ Train/PolicyStd               │ 0.4570086896419525     │\n",
       "│ TotalEnvSteps                 │ 266240.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014382216148078442  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002085701562464237   │\n",
       "│ Value/Adv                     │ 0.08596248924732208    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01645563170313835    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005090070888400078  │\n",
       "│ Value/reward                  │ 1.9347363710403442     │\n",
       "│ Time/Total                    │ 1767.14111328125       │\n",
       "│ Time/Rollout                  │ 11.409719467163086     │\n",
       "│ Time/Update                   │ 1.838592290878296      │\n",
       "│ Time/Epoch                    │ 13.248350143432617     │\n",
       "│ Time/FPS                      │ 154.58529663085938     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.22285270690918      │\n",
       "│ Metrics/EpCost                │ 67.08000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 129.0                  │\n",
       "│ Train/Entropy                 │ 0.6349121332168579     │\n",
       "│ Train/KL                      │ 0.012670536525547504   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9962223768234253     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9962223768234253     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9962223768234253     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020633786916732788   │\n",
       "│ Train/LR                      │ 0.00022200000239536166 │\n",
       "│ Train/PolicyStd               │ 0.4570086896419525     │\n",
       "│ TotalEnvSteps                 │ 266240.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014382216148078442  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002085701562464237   │\n",
       "│ Value/Adv                     │ 0.08596248924732208    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01645563170313835    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005090070888400078  │\n",
       "│ Value/reward                  │ 1.9347363710403442     │\n",
       "│ Time/Total                    │ 1767.14111328125       │\n",
       "│ Time/Rollout                  │ 11.409719467163086     │\n",
       "│ Time/Update                   │ 1.838592290878296      │\n",
       "│ Time/Epoch                    │ 13.248350143432617     │\n",
       "│ Time/FPS                      │ 154.58529663085938     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.529138565063477     │\n",
       "│ Metrics/EpCost                │ 69.31999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 130.0                  │\n",
       "│ Train/Entropy                 │ 0.6328586339950562     │\n",
       "│ Train/KL                      │ 0.01809418760240078    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9936920404434204     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9936920404434204     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9936920404434204     │\n",
       "│ Train/PolicyRatio/Std         │ 0.021338680759072304   │\n",
       "│ Train/LR                      │ 0.00022139999782666564 │\n",
       "│ Train/PolicyStd               │ 0.4561921954154968     │\n",
       "│ TotalEnvSteps                 │ 268288.0               │\n",
       "│ Loss/Loss_pi                  │ -0.0170811228454113    │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002698906697332859  │\n",
       "│ Value/Adv                     │ -0.1086292564868927    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02316642552614212    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006710793823003769   │\n",
       "│ Value/reward                  │ 2.0038366317749023     │\n",
       "│ Time/Total                    │ 1780.4339599609375     │\n",
       "│ Time/Rollout                  │ 11.441228866577148     │\n",
       "│ Time/Update                   │ 1.8366138935089111     │\n",
       "│ Time/Epoch                    │ 13.277886390686035     │\n",
       "│ Time/FPS                      │ 154.24142456054688     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.529138565063477     │\n",
       "│ Metrics/EpCost                │ 69.31999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 130.0                  │\n",
       "│ Train/Entropy                 │ 0.6328586339950562     │\n",
       "│ Train/KL                      │ 0.01809418760240078    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9936920404434204     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9936920404434204     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9936920404434204     │\n",
       "│ Train/PolicyRatio/Std         │ 0.021338680759072304   │\n",
       "│ Train/LR                      │ 0.00022139999782666564 │\n",
       "│ Train/PolicyStd               │ 0.4561921954154968     │\n",
       "│ TotalEnvSteps                 │ 268288.0               │\n",
       "│ Loss/Loss_pi                  │ -0.0170811228454113    │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002698906697332859  │\n",
       "│ Value/Adv                     │ -0.1086292564868927    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02316642552614212    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006710793823003769   │\n",
       "│ Value/reward                  │ 2.0038366317749023     │\n",
       "│ Time/Total                    │ 1780.4339599609375     │\n",
       "│ Time/Rollout                  │ 11.441228866577148     │\n",
       "│ Time/Update                   │ 1.8366138935089111     │\n",
       "│ Time/Epoch                    │ 13.277886390686035     │\n",
       "│ Time/FPS                      │ 154.24142456054688     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.399097442626953     │\n",
       "│ Metrics/EpCost                │ 69.26000213623047      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 131.0                  │\n",
       "│ Train/Entropy                 │ 0.6284653544425964     │\n",
       "│ Train/KL                      │ 0.01642158254981041    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0057605504989624     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0057605504989624     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0057605504989624     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019870245829224586   │\n",
       "│ Train/LR                      │ 0.00022079999325796962 │\n",
       "│ Train/PolicyStd               │ 0.45426616072654724    │\n",
       "│ TotalEnvSteps                 │ 270336.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013652145862579346  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.003428976982831955   │\n",
       "│ Value/Adv                     │ 0.02163616754114628    │\n",
       "│ Loss/Loss_reward_critic       │ 0.015871018171310425   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0072954073548316956 │\n",
       "│ Value/reward                  │ 1.8250056505203247     │\n",
       "│ Time/Total                    │ 1793.7508544921875     │\n",
       "│ Time/Rollout                  │ 11.392130851745605     │\n",
       "│ Time/Update                   │ 1.9111602306365967     │\n",
       "│ Time/Epoch                    │ 13.303345680236816     │\n",
       "│ Time/FPS                      │ 153.9462432861328      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.399097442626953     │\n",
       "│ Metrics/EpCost                │ 69.26000213623047      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 131.0                  │\n",
       "│ Train/Entropy                 │ 0.6284653544425964     │\n",
       "│ Train/KL                      │ 0.01642158254981041    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0057605504989624     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0057605504989624     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0057605504989624     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019870245829224586   │\n",
       "│ Train/LR                      │ 0.00022079999325796962 │\n",
       "│ Train/PolicyStd               │ 0.45426616072654724    │\n",
       "│ TotalEnvSteps                 │ 270336.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013652145862579346  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.003428976982831955   │\n",
       "│ Value/Adv                     │ 0.02163616754114628    │\n",
       "│ Loss/Loss_reward_critic       │ 0.015871018171310425   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0072954073548316956 │\n",
       "│ Value/reward                  │ 1.8250056505203247     │\n",
       "│ Time/Total                    │ 1793.7508544921875     │\n",
       "│ Time/Rollout                  │ 11.392130851745605     │\n",
       "│ Time/Update                   │ 1.9111602306365967     │\n",
       "│ Time/Epoch                    │ 13.303345680236816     │\n",
       "│ Time/FPS                      │ 153.9462432861328      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.409940719604492     │\n",
       "│ Metrics/EpCost                │ 69.94000244140625      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 132.0                  │\n",
       "│ Train/Entropy                 │ 0.6268116235733032     │\n",
       "│ Train/KL                      │ 0.01903105527162552    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9947335124015808     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9947335124015808     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9947335124015808     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01954921893775463    │\n",
       "│ Train/LR                      │ 0.00022020000324118882 │\n",
       "│ Train/PolicyStd               │ 0.45346203446388245    │\n",
       "│ TotalEnvSteps                 │ 272384.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016308587044477463  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002656441181898117  │\n",
       "│ Value/Adv                     │ 0.033555347472429276   │\n",
       "│ Loss/Loss_reward_critic       │ 0.020759334787726402   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0048883166164159775  │\n",
       "│ Value/reward                  │ 2.0306873321533203     │\n",
       "│ Time/Total                    │ 1807.1473388671875     │\n",
       "│ Time/Rollout                  │ 11.494400024414062     │\n",
       "│ Time/Update                   │ 1.8871173858642578     │\n",
       "│ Time/Epoch                    │ 13.381569862365723     │\n",
       "│ Time/FPS                      │ 153.04632568359375     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.409940719604492     │\n",
       "│ Metrics/EpCost                │ 69.94000244140625      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 132.0                  │\n",
       "│ Train/Entropy                 │ 0.6268116235733032     │\n",
       "│ Train/KL                      │ 0.01903105527162552    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9947335124015808     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9947335124015808     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9947335124015808     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01954921893775463    │\n",
       "│ Train/LR                      │ 0.00022020000324118882 │\n",
       "│ Train/PolicyStd               │ 0.45346203446388245    │\n",
       "│ TotalEnvSteps                 │ 272384.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016308587044477463  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002656441181898117  │\n",
       "│ Value/Adv                     │ 0.033555347472429276   │\n",
       "│ Loss/Loss_reward_critic       │ 0.020759334787726402   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0048883166164159775  │\n",
       "│ Value/reward                  │ 2.0306873321533203     │\n",
       "│ Time/Total                    │ 1807.1473388671875     │\n",
       "│ Time/Rollout                  │ 11.494400024414062     │\n",
       "│ Time/Update                   │ 1.8871173858642578     │\n",
       "│ Time/Epoch                    │ 13.381569862365723     │\n",
       "│ Time/FPS                      │ 153.04632568359375     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.908235549926758    │\n",
       "│ Metrics/EpCost                │ 70.36000061035156     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 133.0                 │\n",
       "│ Train/Entropy                 │ 0.6201797723770142    │\n",
       "│ Train/KL                      │ 0.01693412847816944   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9961006045341492    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9961006045341492    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9961006045341492    │\n",
       "│ Train/PolicyRatio/Std         │ 0.018720116466283798  │\n",
       "│ Train/LR                      │ 0.0002195999986724928 │\n",
       "│ Train/PolicyStd               │ 0.4504028856754303    │\n",
       "│ TotalEnvSteps                 │ 274432.0              │\n",
       "│ Loss/Loss_pi                  │ -0.013507435098290443 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0028011519461870193 │\n",
       "│ Value/Adv                     │ -0.03462864086031914  │\n",
       "│ Loss/Loss_reward_critic       │ 0.02162705920636654   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0008677244186401367 │\n",
       "│ Value/reward                  │ 2.0421054363250732    │\n",
       "│ Time/Total                    │ 1820.6944580078125    │\n",
       "│ Time/Rollout                  │ 11.615823745727539    │\n",
       "│ Time/Update                   │ 1.9186429977416992    │\n",
       "│ Time/Epoch                    │ 13.534516334533691    │\n",
       "│ Time/FPS                      │ 151.31683349609375    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.908235549926758    │\n",
       "│ Metrics/EpCost                │ 70.36000061035156     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 133.0                 │\n",
       "│ Train/Entropy                 │ 0.6201797723770142    │\n",
       "│ Train/KL                      │ 0.01693412847816944   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9961006045341492    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9961006045341492    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9961006045341492    │\n",
       "│ Train/PolicyRatio/Std         │ 0.018720116466283798  │\n",
       "│ Train/LR                      │ 0.0002195999986724928 │\n",
       "│ Train/PolicyStd               │ 0.4504028856754303    │\n",
       "│ TotalEnvSteps                 │ 274432.0              │\n",
       "│ Loss/Loss_pi                  │ -0.013507435098290443 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0028011519461870193 │\n",
       "│ Value/Adv                     │ -0.03462864086031914  │\n",
       "│ Loss/Loss_reward_critic       │ 0.02162705920636654   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0008677244186401367 │\n",
       "│ Value/reward                  │ 2.0421054363250732    │\n",
       "│ Time/Total                    │ 1820.6944580078125    │\n",
       "│ Time/Rollout                  │ 11.615823745727539    │\n",
       "│ Time/Update                   │ 1.9186429977416992    │\n",
       "│ Time/Epoch                    │ 13.534516334533691    │\n",
       "│ Time/FPS                      │ 151.31683349609375    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.137788772583008     │\n",
       "│ Metrics/EpCost                │ 65.77999877929688      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 134.0                  │\n",
       "│ Train/Entropy                 │ 0.6110047101974487     │\n",
       "│ Train/KL                      │ 0.017619330435991287   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9998227953910828     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9998227953910828     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9998227953910828     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020147033035755157   │\n",
       "│ Train/LR                      │ 0.00021899999410379678 │\n",
       "│ Train/PolicyStd               │ 0.4461939334869385     │\n",
       "│ TotalEnvSteps                 │ 276480.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014809605665504932  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.001302170567214489  │\n",
       "│ Value/Adv                     │ 0.07498457282781601    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017201222479343414   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.004425836727023125  │\n",
       "│ Value/reward                  │ 1.9028711318969727     │\n",
       "│ Time/Total                    │ 1834.0318603515625     │\n",
       "│ Time/Rollout                  │ 11.446495056152344     │\n",
       "│ Time/Update                   │ 1.8788166046142578     │\n",
       "│ Time/Epoch                    │ 13.325353622436523     │\n",
       "│ Time/FPS                      │ 153.69198608398438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.137788772583008     │\n",
       "│ Metrics/EpCost                │ 65.77999877929688      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 134.0                  │\n",
       "│ Train/Entropy                 │ 0.6110047101974487     │\n",
       "│ Train/KL                      │ 0.017619330435991287   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9998227953910828     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9998227953910828     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9998227953910828     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020147033035755157   │\n",
       "│ Train/LR                      │ 0.00021899999410379678 │\n",
       "│ Train/PolicyStd               │ 0.4461939334869385     │\n",
       "│ TotalEnvSteps                 │ 276480.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014809605665504932  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.001302170567214489  │\n",
       "│ Value/Adv                     │ 0.07498457282781601    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017201222479343414   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.004425836727023125  │\n",
       "│ Value/reward                  │ 1.9028711318969727     │\n",
       "│ Time/Total                    │ 1834.0318603515625     │\n",
       "│ Time/Rollout                  │ 11.446495056152344     │\n",
       "│ Time/Update                   │ 1.8788166046142578     │\n",
       "│ Time/Epoch                    │ 13.325353622436523     │\n",
       "│ Time/FPS                      │ 153.69198608398438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.34160804748535      │\n",
       "│ Metrics/EpCost                │ 67.5                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 135.0                  │\n",
       "│ Train/Entropy                 │ 0.6084364652633667     │\n",
       "│ Train/KL                      │ 0.012975713238120079   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9958868026733398     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9958868026733398     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9958868026733398     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01718137413263321    │\n",
       "│ Train/LR                      │ 0.00021840000408701599 │\n",
       "│ Train/PolicyStd               │ 0.444922536611557      │\n",
       "│ TotalEnvSteps                 │ 278528.0               │\n",
       "│ Loss/Loss_pi                  │ -0.009727710857987404  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0050818948075175285  │\n",
       "│ Value/Adv                     │ 0.11365509778261185    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02198074385523796    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0047795213758945465  │\n",
       "│ Value/reward                  │ 2.0411553382873535     │\n",
       "│ Time/Total                    │ 1847.262939453125      │\n",
       "│ Time/Rollout                  │ 11.433769226074219     │\n",
       "│ Time/Update                   │ 1.7825202941894531     │\n",
       "│ Time/Epoch                    │ 13.216336250305176     │\n",
       "│ Time/FPS                      │ 154.95974731445312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.34160804748535      │\n",
       "│ Metrics/EpCost                │ 67.5                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 135.0                  │\n",
       "│ Train/Entropy                 │ 0.6084364652633667     │\n",
       "│ Train/KL                      │ 0.012975713238120079   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9958868026733398     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9958868026733398     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9958868026733398     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01718137413263321    │\n",
       "│ Train/LR                      │ 0.00021840000408701599 │\n",
       "│ Train/PolicyStd               │ 0.444922536611557      │\n",
       "│ TotalEnvSteps                 │ 278528.0               │\n",
       "│ Loss/Loss_pi                  │ -0.009727710857987404  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0050818948075175285  │\n",
       "│ Value/Adv                     │ 0.11365509778261185    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02198074385523796    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0047795213758945465  │\n",
       "│ Value/reward                  │ 2.0411553382873535     │\n",
       "│ Time/Total                    │ 1847.262939453125      │\n",
       "│ Time/Rollout                  │ 11.433769226074219     │\n",
       "│ Time/Update                   │ 1.7825202941894531     │\n",
       "│ Time/Epoch                    │ 13.216336250305176     │\n",
       "│ Time/FPS                      │ 154.95974731445312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m10\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.363313674926758     │\n",
       "│ Metrics/EpCost                │ 68.45999908447266      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 136.0                  │\n",
       "│ Train/Entropy                 │ 0.6082474589347839     │\n",
       "│ Train/KL                      │ 0.02107522264122963    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.000759482383728      │\n",
       "│ Train/PolicyRatio/Min         │ 1.000759482383728      │\n",
       "│ Train/PolicyRatio/Max         │ 1.000759482383728      │\n",
       "│ Train/PolicyRatio/Std         │ 0.020915541797876358   │\n",
       "│ Train/LR                      │ 0.00021779999951831996 │\n",
       "│ Train/PolicyStd               │ 0.4448612630367279     │\n",
       "│ TotalEnvSteps                 │ 280576.0               │\n",
       "│ Loss/Loss_pi                  │ -0.02084929123520851   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.011121580377221107  │\n",
       "│ Value/Adv                     │ -0.09014773368835449   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018587084487080574   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0033936593681573868 │\n",
       "│ Value/reward                  │ 2.020836353302002      │\n",
       "│ Time/Total                    │ 1860.6226806640625     │\n",
       "│ Time/Rollout                  │ 11.414900779724121     │\n",
       "│ Time/Update                   │ 1.9322142601013184     │\n",
       "│ Time/Epoch                    │ 13.347162246704102     │\n",
       "│ Time/FPS                      │ 153.44085693359375     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.363313674926758     │\n",
       "│ Metrics/EpCost                │ 68.45999908447266      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 136.0                  │\n",
       "│ Train/Entropy                 │ 0.6082474589347839     │\n",
       "│ Train/KL                      │ 0.02107522264122963    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.000759482383728      │\n",
       "│ Train/PolicyRatio/Min         │ 1.000759482383728      │\n",
       "│ Train/PolicyRatio/Max         │ 1.000759482383728      │\n",
       "│ Train/PolicyRatio/Std         │ 0.020915541797876358   │\n",
       "│ Train/LR                      │ 0.00021779999951831996 │\n",
       "│ Train/PolicyStd               │ 0.4448612630367279     │\n",
       "│ TotalEnvSteps                 │ 280576.0               │\n",
       "│ Loss/Loss_pi                  │ -0.02084929123520851   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.011121580377221107  │\n",
       "│ Value/Adv                     │ -0.09014773368835449   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018587084487080574   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0033936593681573868 │\n",
       "│ Value/reward                  │ 2.020836353302002      │\n",
       "│ Time/Total                    │ 1860.6226806640625     │\n",
       "│ Time/Rollout                  │ 11.414900779724121     │\n",
       "│ Time/Update                   │ 1.9322142601013184     │\n",
       "│ Time/Epoch                    │ 13.347162246704102     │\n",
       "│ Time/FPS                      │ 153.44085693359375     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.160118103027344     │\n",
       "│ Metrics/EpCost                │ 67.80000305175781      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 137.0                  │\n",
       "│ Train/Entropy                 │ 0.6040491461753845     │\n",
       "│ Train/KL                      │ 0.014188362285494804   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0037773847579956     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0037773847579956     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0037773847579956     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01779170148074627    │\n",
       "│ Train/LR                      │ 0.00021719999494962394 │\n",
       "│ Train/PolicyStd               │ 0.4430467486381531     │\n",
       "│ TotalEnvSteps                 │ 282624.0               │\n",
       "│ Loss/Loss_pi                  │ -0.006293301470577717  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.014555989764630795   │\n",
       "│ Value/Adv                     │ 0.014581257477402687   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015197774395346642   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0033893100917339325 │\n",
       "│ Value/reward                  │ 1.7925786972045898     │\n",
       "│ Time/Total                    │ 1874.294189453125      │\n",
       "│ Time/Rollout                  │ 11.830872535705566     │\n",
       "│ Time/Update                   │ 1.828676462173462      │\n",
       "│ Time/Epoch                    │ 13.65959644317627      │\n",
       "│ Time/FPS                      │ 149.9312286376953      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.160118103027344     │\n",
       "│ Metrics/EpCost                │ 67.80000305175781      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 137.0                  │\n",
       "│ Train/Entropy                 │ 0.6040491461753845     │\n",
       "│ Train/KL                      │ 0.014188362285494804   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0037773847579956     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0037773847579956     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0037773847579956     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01779170148074627    │\n",
       "│ Train/LR                      │ 0.00021719999494962394 │\n",
       "│ Train/PolicyStd               │ 0.4430467486381531     │\n",
       "│ TotalEnvSteps                 │ 282624.0               │\n",
       "│ Loss/Loss_pi                  │ -0.006293301470577717  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.014555989764630795   │\n",
       "│ Value/Adv                     │ 0.014581257477402687   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015197774395346642   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0033893100917339325 │\n",
       "│ Value/reward                  │ 1.7925786972045898     │\n",
       "│ Time/Total                    │ 1874.294189453125      │\n",
       "│ Time/Rollout                  │ 11.830872535705566     │\n",
       "│ Time/Update                   │ 1.828676462173462      │\n",
       "│ Time/Epoch                    │ 13.65959644317627      │\n",
       "│ Time/FPS                      │ 149.9312286376953      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.720863342285156     │\n",
       "│ Metrics/EpCost                │ 67.26000213623047      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 138.0                  │\n",
       "│ Train/Entropy                 │ 0.5965093970298767     │\n",
       "│ Train/KL                      │ 0.012085783295333385   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0025389194488525     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0025389194488525     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0025389194488525     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01724790222942829    │\n",
       "│ Train/LR                      │ 0.00021660000493284315 │\n",
       "│ Train/PolicyStd               │ 0.43960970640182495    │\n",
       "│ TotalEnvSteps                 │ 284672.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01018744707107544   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0038941456004977226 │\n",
       "│ Value/Adv                     │ -0.04116412624716759   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014136604964733124   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0010611694306135178 │\n",
       "│ Value/reward                  │ 1.7336111068725586     │\n",
       "│ Time/Total                    │ 1887.6524658203125     │\n",
       "│ Time/Rollout                  │ 11.457813262939453     │\n",
       "│ Time/Update                   │ 1.886836290359497      │\n",
       "│ Time/Epoch                    │ 13.34469223022461      │\n",
       "│ Time/FPS                      │ 153.46925354003906     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.720863342285156     │\n",
       "│ Metrics/EpCost                │ 67.26000213623047      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 138.0                  │\n",
       "│ Train/Entropy                 │ 0.5965093970298767     │\n",
       "│ Train/KL                      │ 0.012085783295333385   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0025389194488525     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0025389194488525     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0025389194488525     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01724790222942829    │\n",
       "│ Train/LR                      │ 0.00021660000493284315 │\n",
       "│ Train/PolicyStd               │ 0.43960970640182495    │\n",
       "│ TotalEnvSteps                 │ 284672.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01018744707107544   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0038941456004977226 │\n",
       "│ Value/Adv                     │ -0.04116412624716759   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014136604964733124   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0010611694306135178 │\n",
       "│ Value/reward                  │ 1.7336111068725586     │\n",
       "│ Time/Total                    │ 1887.6524658203125     │\n",
       "│ Time/Rollout                  │ 11.457813262939453     │\n",
       "│ Time/Update                   │ 1.886836290359497      │\n",
       "│ Time/Epoch                    │ 13.34469223022461      │\n",
       "│ Time/FPS                      │ 153.46925354003906     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.048568725585938     │\n",
       "│ Metrics/EpCost                │ 67.16000366210938      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 139.0                  │\n",
       "│ Train/Entropy                 │ 0.5891808271408081     │\n",
       "│ Train/KL                      │ 0.01430469285696745    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.996738076210022      │\n",
       "│ Train/PolicyRatio/Min         │ 0.996738076210022      │\n",
       "│ Train/PolicyRatio/Max         │ 0.996738076210022      │\n",
       "│ Train/PolicyRatio/Std         │ 0.017172524705529213   │\n",
       "│ Train/LR                      │ 0.00021600000036414713 │\n",
       "│ Train/PolicyStd               │ 0.43631333112716675    │\n",
       "│ TotalEnvSteps                 │ 286720.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014150785282254219  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00396333821117878   │\n",
       "│ Value/Adv                     │ -0.0009895432740449905 │\n",
       "│ Loss/Loss_reward_critic       │ 0.019504345953464508   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.005367740988731384   │\n",
       "│ Value/reward                  │ 1.9618642330169678     │\n",
       "│ Time/Total                    │ 1900.8662109375        │\n",
       "│ Time/Rollout                  │ 11.36313533782959      │\n",
       "│ Time/Update                   │ 1.838679313659668      │\n",
       "│ Time/Epoch                    │ 13.201859474182129     │\n",
       "│ Time/FPS                      │ 155.12966918945312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.048568725585938     │\n",
       "│ Metrics/EpCost                │ 67.16000366210938      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 139.0                  │\n",
       "│ Train/Entropy                 │ 0.5891808271408081     │\n",
       "│ Train/KL                      │ 0.01430469285696745    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.996738076210022      │\n",
       "│ Train/PolicyRatio/Min         │ 0.996738076210022      │\n",
       "│ Train/PolicyRatio/Max         │ 0.996738076210022      │\n",
       "│ Train/PolicyRatio/Std         │ 0.017172524705529213   │\n",
       "│ Train/LR                      │ 0.00021600000036414713 │\n",
       "│ Train/PolicyStd               │ 0.43631333112716675    │\n",
       "│ TotalEnvSteps                 │ 286720.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014150785282254219  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00396333821117878   │\n",
       "│ Value/Adv                     │ -0.0009895432740449905 │\n",
       "│ Loss/Loss_reward_critic       │ 0.019504345953464508   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.005367740988731384   │\n",
       "│ Value/reward                  │ 1.9618642330169678     │\n",
       "│ Time/Total                    │ 1900.8662109375        │\n",
       "│ Time/Rollout                  │ 11.36313533782959      │\n",
       "│ Time/Update                   │ 1.838679313659668      │\n",
       "│ Time/Epoch                    │ 13.201859474182129     │\n",
       "│ Time/FPS                      │ 155.12966918945312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.078033447265625    │\n",
       "│ Metrics/EpCost                │ 66.69999694824219     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 140.0                 │\n",
       "│ Train/Entropy                 │ 0.5831502079963684    │\n",
       "│ Train/KL                      │ 0.014318006113171577  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.997027575969696     │\n",
       "│ Train/PolicyRatio/Min         │ 0.997027575969696     │\n",
       "│ Train/PolicyRatio/Max         │ 0.997027575969696     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01928856037557125   │\n",
       "│ Train/LR                      │ 0.0002153999957954511 │\n",
       "│ Train/PolicyStd               │ 0.4336826205253601    │\n",
       "│ TotalEnvSteps                 │ 288768.0              │\n",
       "│ Loss/Loss_pi                  │ -0.015732182189822197 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.001581396907567978 │\n",
       "│ Value/Adv                     │ -0.2725774049758911   │\n",
       "│ Loss/Loss_reward_critic       │ 0.026473695412278175  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006969349458813667  │\n",
       "│ Value/reward                  │ 1.9109117984771729    │\n",
       "│ Time/Total                    │ 1914.34228515625      │\n",
       "│ Time/Rollout                  │ 11.454773902893066    │\n",
       "│ Time/Update                   │ 2.0064761638641357    │\n",
       "│ Time/Epoch                    │ 13.461294174194336    │\n",
       "│ Time/FPS                      │ 152.13992309570312    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.078033447265625    │\n",
       "│ Metrics/EpCost                │ 66.69999694824219     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 140.0                 │\n",
       "│ Train/Entropy                 │ 0.5831502079963684    │\n",
       "│ Train/KL                      │ 0.014318006113171577  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.997027575969696     │\n",
       "│ Train/PolicyRatio/Min         │ 0.997027575969696     │\n",
       "│ Train/PolicyRatio/Max         │ 0.997027575969696     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01928856037557125   │\n",
       "│ Train/LR                      │ 0.0002153999957954511 │\n",
       "│ Train/PolicyStd               │ 0.4336826205253601    │\n",
       "│ TotalEnvSteps                 │ 288768.0              │\n",
       "│ Loss/Loss_pi                  │ -0.015732182189822197 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.001581396907567978 │\n",
       "│ Value/Adv                     │ -0.2725774049758911   │\n",
       "│ Loss/Loss_reward_critic       │ 0.026473695412278175  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006969349458813667  │\n",
       "│ Value/reward                  │ 1.9109117984771729    │\n",
       "│ Time/Total                    │ 1914.34228515625      │\n",
       "│ Time/Rollout                  │ 11.454773902893066    │\n",
       "│ Time/Update                   │ 2.0064761638641357    │\n",
       "│ Time/Epoch                    │ 13.461294174194336    │\n",
       "│ Time/FPS                      │ 152.13992309570312    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.07758140563965      │\n",
       "│ Metrics/EpCost                │ 65.30000305175781      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 141.0                  │\n",
       "│ Train/Entropy                 │ 0.5828713178634644     │\n",
       "│ Train/KL                      │ 0.014651362784206867   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.006103277206421      │\n",
       "│ Train/PolicyRatio/Min         │ 1.006103277206421      │\n",
       "│ Train/PolicyRatio/Max         │ 1.006103277206421      │\n",
       "│ Train/PolicyRatio/Std         │ 0.019480012357234955   │\n",
       "│ Train/LR                      │ 0.0002148000057786703  │\n",
       "│ Train/PolicyStd               │ 0.4335496425628662     │\n",
       "│ TotalEnvSteps                 │ 290816.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014849573373794556  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0008826088160276413  │\n",
       "│ Value/Adv                     │ -0.03236571326851845   │\n",
       "│ Loss/Loss_reward_critic       │ 0.023612940683960915   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0028607547283172607 │\n",
       "│ Value/reward                  │ 1.885518193244934      │\n",
       "│ Time/Total                    │ 1927.65625             │\n",
       "│ Time/Rollout                  │ 11.48678207397461      │\n",
       "│ Time/Update                   │ 1.8144583702087402     │\n",
       "│ Time/Epoch                    │ 13.301288604736328     │\n",
       "│ Time/FPS                      │ 153.97006225585938     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.07758140563965      │\n",
       "│ Metrics/EpCost                │ 65.30000305175781      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 141.0                  │\n",
       "│ Train/Entropy                 │ 0.5828713178634644     │\n",
       "│ Train/KL                      │ 0.014651362784206867   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.006103277206421      │\n",
       "│ Train/PolicyRatio/Min         │ 1.006103277206421      │\n",
       "│ Train/PolicyRatio/Max         │ 1.006103277206421      │\n",
       "│ Train/PolicyRatio/Std         │ 0.019480012357234955   │\n",
       "│ Train/LR                      │ 0.0002148000057786703  │\n",
       "│ Train/PolicyStd               │ 0.4335496425628662     │\n",
       "│ TotalEnvSteps                 │ 290816.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014849573373794556  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0008826088160276413  │\n",
       "│ Value/Adv                     │ -0.03236571326851845   │\n",
       "│ Loss/Loss_reward_critic       │ 0.023612940683960915   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0028607547283172607 │\n",
       "│ Value/reward                  │ 1.885518193244934      │\n",
       "│ Time/Total                    │ 1927.65625             │\n",
       "│ Time/Rollout                  │ 11.48678207397461      │\n",
       "│ Time/Update                   │ 1.8144583702087402     │\n",
       "│ Time/Epoch                    │ 13.301288604736328     │\n",
       "│ Time/FPS                      │ 153.97006225585938     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m9\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.795372009277344     │\n",
       "│ Metrics/EpCost                │ 62.880001068115234     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 142.0                  │\n",
       "│ Train/Entropy                 │ 0.5864899754524231     │\n",
       "│ Train/KL                      │ 0.025762053206562996   │\n",
       "│ Train/StopIter                │ 9.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.001594066619873      │\n",
       "│ Train/PolicyRatio/Min         │ 1.001594066619873      │\n",
       "│ Train/PolicyRatio/Max         │ 1.001594066619873      │\n",
       "│ Train/PolicyRatio/Std         │ 0.01723429001867771    │\n",
       "│ Train/LR                      │ 0.0002142000012099743  │\n",
       "│ Train/PolicyStd               │ 0.4350900948047638     │\n",
       "│ TotalEnvSteps                 │ 292864.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012072456069290638  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0027771173045039177  │\n",
       "│ Value/Adv                     │ 0.004789412021636963   │\n",
       "│ Loss/Loss_reward_critic       │ 0.022348513826727867   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0012644268572330475 │\n",
       "│ Value/reward                  │ 1.7024681568145752     │\n",
       "│ Time/Total                    │ 1940.8314208984375     │\n",
       "│ Time/Rollout                  │ 11.50299072265625      │\n",
       "│ Time/Update                   │ 1.6582391262054443     │\n",
       "│ Time/Epoch                    │ 13.161275863647461     │\n",
       "│ Time/FPS                      │ 155.60801696777344     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.795372009277344     │\n",
       "│ Metrics/EpCost                │ 62.880001068115234     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 142.0                  │\n",
       "│ Train/Entropy                 │ 0.5864899754524231     │\n",
       "│ Train/KL                      │ 0.025762053206562996   │\n",
       "│ Train/StopIter                │ 9.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.001594066619873      │\n",
       "│ Train/PolicyRatio/Min         │ 1.001594066619873      │\n",
       "│ Train/PolicyRatio/Max         │ 1.001594066619873      │\n",
       "│ Train/PolicyRatio/Std         │ 0.01723429001867771    │\n",
       "│ Train/LR                      │ 0.0002142000012099743  │\n",
       "│ Train/PolicyStd               │ 0.4350900948047638     │\n",
       "│ TotalEnvSteps                 │ 292864.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012072456069290638  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0027771173045039177  │\n",
       "│ Value/Adv                     │ 0.004789412021636963   │\n",
       "│ Loss/Loss_reward_critic       │ 0.022348513826727867   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0012644268572330475 │\n",
       "│ Value/reward                  │ 1.7024681568145752     │\n",
       "│ Time/Total                    │ 1940.8314208984375     │\n",
       "│ Time/Rollout                  │ 11.50299072265625      │\n",
       "│ Time/Update                   │ 1.6582391262054443     │\n",
       "│ Time/Epoch                    │ 13.161275863647461     │\n",
       "│ Time/FPS                      │ 155.60801696777344     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.050539016723633     │\n",
       "│ Metrics/EpCost                │ 64.23999786376953      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 143.0                  │\n",
       "│ Train/Entropy                 │ 0.5796761512756348     │\n",
       "│ Train/KL                      │ 0.01605699583888054    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9987983703613281     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9987983703613281     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9987983703613281     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018415067344903946   │\n",
       "│ Train/LR                      │ 0.00021359999664127827 │\n",
       "│ Train/PolicyStd               │ 0.4321507513523102     │\n",
       "│ TotalEnvSteps                 │ 294912.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014600366353988647  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0025279102846980095 │\n",
       "│ Value/Adv                     │ 0.1223837360739708     │\n",
       "│ Loss/Loss_reward_critic       │ 0.015784624963998795   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.006563888862729073  │\n",
       "│ Value/reward                  │ 2.0406618118286133     │\n",
       "│ Time/Total                    │ 1954.21484375          │\n",
       "│ Time/Rollout                  │ 11.487136840820312     │\n",
       "│ Time/Update                   │ 1.873518943786621      │\n",
       "│ Time/Epoch                    │ 13.360706329345703     │\n",
       "│ Time/FPS                      │ 153.28530883789062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.050539016723633     │\n",
       "│ Metrics/EpCost                │ 64.23999786376953      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 143.0                  │\n",
       "│ Train/Entropy                 │ 0.5796761512756348     │\n",
       "│ Train/KL                      │ 0.01605699583888054    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9987983703613281     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9987983703613281     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9987983703613281     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018415067344903946   │\n",
       "│ Train/LR                      │ 0.00021359999664127827 │\n",
       "│ Train/PolicyStd               │ 0.4321507513523102     │\n",
       "│ TotalEnvSteps                 │ 294912.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014600366353988647  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0025279102846980095 │\n",
       "│ Value/Adv                     │ 0.1223837360739708     │\n",
       "│ Loss/Loss_reward_critic       │ 0.015784624963998795   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.006563888862729073  │\n",
       "│ Value/reward                  │ 2.0406618118286133     │\n",
       "│ Time/Total                    │ 1954.21484375          │\n",
       "│ Time/Rollout                  │ 11.487136840820312     │\n",
       "│ Time/Update                   │ 1.873518943786621      │\n",
       "│ Time/Epoch                    │ 13.360706329345703     │\n",
       "│ Time/FPS                      │ 153.28530883789062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.9464168548584       │\n",
       "│ Metrics/EpCost                │ 62.439998626708984     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 144.0                  │\n",
       "│ Train/Entropy                 │ 0.5671707391738892     │\n",
       "│ Train/KL                      │ 0.013225782662630081   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0038870573043823     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0038870573043823     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0038870573043823     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01762065850198269    │\n",
       "│ Train/LR                      │ 0.00021300000662449747 │\n",
       "│ Train/PolicyStd               │ 0.42679375410079956    │\n",
       "│ TotalEnvSteps                 │ 296960.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013425740413367748  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0011746259406208992  │\n",
       "│ Value/Adv                     │ -0.10561167448759079   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02544679306447506    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.009662168100476265   │\n",
       "│ Value/reward                  │ 1.7138820886611938     │\n",
       "│ Time/Total                    │ 1967.62158203125       │\n",
       "│ Time/Rollout                  │ 11.583822250366211     │\n",
       "│ Time/Update                   │ 1.8059744834899902     │\n",
       "│ Time/Epoch                    │ 13.389850616455078     │\n",
       "│ Time/FPS                      │ 152.95167541503906     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.9464168548584       │\n",
       "│ Metrics/EpCost                │ 62.439998626708984     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 144.0                  │\n",
       "│ Train/Entropy                 │ 0.5671707391738892     │\n",
       "│ Train/KL                      │ 0.013225782662630081   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0038870573043823     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0038870573043823     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0038870573043823     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01762065850198269    │\n",
       "│ Train/LR                      │ 0.00021300000662449747 │\n",
       "│ Train/PolicyStd               │ 0.42679375410079956    │\n",
       "│ TotalEnvSteps                 │ 296960.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013425740413367748  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0011746259406208992  │\n",
       "│ Value/Adv                     │ -0.10561167448759079   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02544679306447506    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.009662168100476265   │\n",
       "│ Value/reward                  │ 1.7138820886611938     │\n",
       "│ Time/Total                    │ 1967.62158203125       │\n",
       "│ Time/Rollout                  │ 11.583822250366211     │\n",
       "│ Time/Update                   │ 1.8059744834899902     │\n",
       "│ Time/Epoch                    │ 13.389850616455078     │\n",
       "│ Time/FPS                      │ 152.95167541503906     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.99594497680664      │\n",
       "│ Metrics/EpCost                │ 63.36000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 145.0                  │\n",
       "│ Train/Entropy                 │ 0.557096540927887      │\n",
       "│ Train/KL                      │ 0.013407330960035324   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0035579204559326     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0035579204559326     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0035579204559326     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017790326848626137   │\n",
       "│ Train/LR                      │ 0.00021240000205580145 │\n",
       "│ Train/PolicyStd               │ 0.42255502939224243    │\n",
       "│ TotalEnvSteps                 │ 299008.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012755215167999268  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0006705252453684807  │\n",
       "│ Value/Adv                     │ -0.029176633805036545  │\n",
       "│ Loss/Loss_reward_critic       │ 0.01890691928565502    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.006539873778820038  │\n",
       "│ Value/reward                  │ 1.7112045288085938     │\n",
       "│ Time/Total                    │ 1980.9893798828125     │\n",
       "│ Time/Rollout                  │ 11.438615798950195     │\n",
       "│ Time/Update                   │ 1.9169549942016602     │\n",
       "│ Time/Epoch                    │ 13.355622291564941     │\n",
       "│ Time/FPS                      │ 153.34365844726562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.99594497680664      │\n",
       "│ Metrics/EpCost                │ 63.36000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 145.0                  │\n",
       "│ Train/Entropy                 │ 0.557096540927887      │\n",
       "│ Train/KL                      │ 0.013407330960035324   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0035579204559326     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0035579204559326     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0035579204559326     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017790326848626137   │\n",
       "│ Train/LR                      │ 0.00021240000205580145 │\n",
       "│ Train/PolicyStd               │ 0.42255502939224243    │\n",
       "│ TotalEnvSteps                 │ 299008.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012755215167999268  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0006705252453684807  │\n",
       "│ Value/Adv                     │ -0.029176633805036545  │\n",
       "│ Loss/Loss_reward_critic       │ 0.01890691928565502    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.006539873778820038  │\n",
       "│ Value/reward                  │ 1.7112045288085938     │\n",
       "│ Time/Total                    │ 1980.9893798828125     │\n",
       "│ Time/Rollout                  │ 11.438615798950195     │\n",
       "│ Time/Update                   │ 1.9169549942016602     │\n",
       "│ Time/Epoch                    │ 13.355622291564941     │\n",
       "│ Time/FPS                      │ 153.34365844726562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.11875343322754      │\n",
       "│ Metrics/EpCost                │ 65.08000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 146.0                  │\n",
       "│ Train/Entropy                 │ 0.5543957352638245     │\n",
       "│ Train/KL                      │ 0.01362374983727932    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9996353983879089     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9996353983879089     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9996353983879089     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018310798332095146   │\n",
       "│ Train/LR                      │ 0.00021179999748710543 │\n",
       "│ Train/PolicyStd               │ 0.42147302627563477    │\n",
       "│ TotalEnvSteps                 │ 301056.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01485377550125122   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002098560333251953  │\n",
       "│ Value/Adv                     │ -0.17369048297405243   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02891685627400875    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.01000993698835373    │\n",
       "│ Value/reward                  │ 2.008396625518799      │\n",
       "│ Time/Total                    │ 1994.3724365234375     │\n",
       "│ Time/Rollout                  │ 11.451234817504883     │\n",
       "│ Time/Update                   │ 1.920057773590088      │\n",
       "│ Time/Epoch                    │ 13.371343612670898     │\n",
       "│ Time/FPS                      │ 153.1633758544922      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.11875343322754      │\n",
       "│ Metrics/EpCost                │ 65.08000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 146.0                  │\n",
       "│ Train/Entropy                 │ 0.5543957352638245     │\n",
       "│ Train/KL                      │ 0.01362374983727932    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9996353983879089     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9996353983879089     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9996353983879089     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018310798332095146   │\n",
       "│ Train/LR                      │ 0.00021179999748710543 │\n",
       "│ Train/PolicyStd               │ 0.42147302627563477    │\n",
       "│ TotalEnvSteps                 │ 301056.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01485377550125122   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002098560333251953  │\n",
       "│ Value/Adv                     │ -0.17369048297405243   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02891685627400875    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.01000993698835373    │\n",
       "│ Value/reward                  │ 2.008396625518799      │\n",
       "│ Time/Total                    │ 1994.3724365234375     │\n",
       "│ Time/Rollout                  │ 11.451234817504883     │\n",
       "│ Time/Update                   │ 1.920057773590088      │\n",
       "│ Time/Epoch                    │ 13.371343612670898     │\n",
       "│ Time/FPS                      │ 153.1633758544922      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.255306243896484    │\n",
       "│ Metrics/EpCost                │ 61.18000030517578     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 147.0                 │\n",
       "│ Train/Entropy                 │ 0.5543419718742371    │\n",
       "│ Train/KL                      │ 0.015577162615954876  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.00244140625         │\n",
       "│ Train/PolicyRatio/Min         │ 1.00244140625         │\n",
       "│ Train/PolicyRatio/Max         │ 1.00244140625         │\n",
       "│ Train/PolicyRatio/Std         │ 0.018318355083465576  │\n",
       "│ Train/LR                      │ 0.0002111999929184094 │\n",
       "│ Train/PolicyStd               │ 0.42160043120384216   │\n",
       "│ TotalEnvSteps                 │ 303104.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01422479934990406  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0006289761513471603 │\n",
       "│ Value/Adv                     │ -0.04658437892794609  │\n",
       "│ Loss/Loss_reward_critic       │ 0.02281380631029606   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.006103049963712692 │\n",
       "│ Value/reward                  │ 1.9420835971832275    │\n",
       "│ Time/Total                    │ 2007.753173828125     │\n",
       "│ Time/Rollout                  │ 11.504678726196289    │\n",
       "│ Time/Update                   │ 1.8643012046813965    │\n",
       "│ Time/Epoch                    │ 13.369047164916992    │\n",
       "│ Time/FPS                      │ 153.189697265625      │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.255306243896484    │\n",
       "│ Metrics/EpCost                │ 61.18000030517578     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 147.0                 │\n",
       "│ Train/Entropy                 │ 0.5543419718742371    │\n",
       "│ Train/KL                      │ 0.015577162615954876  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.00244140625         │\n",
       "│ Train/PolicyRatio/Min         │ 1.00244140625         │\n",
       "│ Train/PolicyRatio/Max         │ 1.00244140625         │\n",
       "│ Train/PolicyRatio/Std         │ 0.018318355083465576  │\n",
       "│ Train/LR                      │ 0.0002111999929184094 │\n",
       "│ Train/PolicyStd               │ 0.42160043120384216   │\n",
       "│ TotalEnvSteps                 │ 303104.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01422479934990406  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0006289761513471603 │\n",
       "│ Value/Adv                     │ -0.04658437892794609  │\n",
       "│ Loss/Loss_reward_critic       │ 0.02281380631029606   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.006103049963712692 │\n",
       "│ Value/reward                  │ 1.9420835971832275    │\n",
       "│ Time/Total                    │ 2007.753173828125     │\n",
       "│ Time/Rollout                  │ 11.504678726196289    │\n",
       "│ Time/Update                   │ 1.8643012046813965    │\n",
       "│ Time/Epoch                    │ 13.369047164916992    │\n",
       "│ Time/FPS                      │ 153.189697265625      │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.14847183227539     │\n",
       "│ Metrics/EpCost                │ 60.7400016784668      │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 148.0                 │\n",
       "│ Train/Entropy                 │ 0.5488902926445007    │\n",
       "│ Train/KL                      │ 0.010162122547626495  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0031511783599854    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0031511783599854    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0031511783599854    │\n",
       "│ Train/PolicyRatio/Std         │ 0.017970019951462746  │\n",
       "│ Train/LR                      │ 0.0002106000029016286 │\n",
       "│ Train/PolicyStd               │ 0.4194123148918152    │\n",
       "│ TotalEnvSteps                 │ 305152.0              │\n",
       "│ Loss/Loss_pi                  │ -0.010576439090073109 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0036483602598309517 │\n",
       "│ Value/Adv                     │ -0.06449967622756958  │\n",
       "│ Loss/Loss_reward_critic       │ 0.014643870294094086  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.008169936016201973 │\n",
       "│ Value/reward                  │ 1.7188904285430908    │\n",
       "│ Time/Total                    │ 2021.202392578125     │\n",
       "│ Time/Rollout                  │ 11.592252731323242    │\n",
       "│ Time/Update                   │ 1.8448209762573242    │\n",
       "│ Time/Epoch                    │ 13.437134742736816    │\n",
       "│ Time/FPS                      │ 152.4134521484375     │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.14847183227539     │\n",
       "│ Metrics/EpCost                │ 60.7400016784668      │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 148.0                 │\n",
       "│ Train/Entropy                 │ 0.5488902926445007    │\n",
       "│ Train/KL                      │ 0.010162122547626495  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0031511783599854    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0031511783599854    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0031511783599854    │\n",
       "│ Train/PolicyRatio/Std         │ 0.017970019951462746  │\n",
       "│ Train/LR                      │ 0.0002106000029016286 │\n",
       "│ Train/PolicyStd               │ 0.4194123148918152    │\n",
       "│ TotalEnvSteps                 │ 305152.0              │\n",
       "│ Loss/Loss_pi                  │ -0.010576439090073109 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0036483602598309517 │\n",
       "│ Value/Adv                     │ -0.06449967622756958  │\n",
       "│ Loss/Loss_reward_critic       │ 0.014643870294094086  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.008169936016201973 │\n",
       "│ Value/reward                  │ 1.7188904285430908    │\n",
       "│ Time/Total                    │ 2021.202392578125     │\n",
       "│ Time/Rollout                  │ 11.592252731323242    │\n",
       "│ Time/Update                   │ 1.8448209762573242    │\n",
       "│ Time/Epoch                    │ 13.437134742736816    │\n",
       "│ Time/FPS                      │ 152.4134521484375     │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m9\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.160011291503906    │\n",
       "│ Metrics/EpCost                │ 57.119998931884766    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 149.0                 │\n",
       "│ Train/Entropy                 │ 0.5410277247428894    │\n",
       "│ Train/KL                      │ 0.021023737266659737  │\n",
       "│ Train/StopIter                │ 9.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9926798343658447    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9926798343658447    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9926798343658447    │\n",
       "│ Train/PolicyRatio/Std         │ 0.018503908067941666  │\n",
       "│ Train/LR                      │ 0.0002099999983329326 │\n",
       "│ Train/PolicyStd               │ 0.4160052537918091    │\n",
       "│ TotalEnvSteps                 │ 307200.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01850864291191101  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.007932203821837902 │\n",
       "│ Value/Adv                     │ -0.11066828668117523  │\n",
       "│ Loss/Loss_reward_critic       │ 0.018842486664652824  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004198616370558739  │\n",
       "│ Value/reward                  │ 1.8395894765853882    │\n",
       "│ Time/Total                    │ 2034.3822021484375    │\n",
       "│ Time/Rollout                  │ 11.509532928466797    │\n",
       "│ Time/Update                   │ 1.6580657958984375    │\n",
       "│ Time/Epoch                    │ 13.167652130126953    │\n",
       "│ Time/FPS                      │ 155.53268432617188    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.160011291503906    │\n",
       "│ Metrics/EpCost                │ 57.119998931884766    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 149.0                 │\n",
       "│ Train/Entropy                 │ 0.5410277247428894    │\n",
       "│ Train/KL                      │ 0.021023737266659737  │\n",
       "│ Train/StopIter                │ 9.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9926798343658447    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9926798343658447    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9926798343658447    │\n",
       "│ Train/PolicyRatio/Std         │ 0.018503908067941666  │\n",
       "│ Train/LR                      │ 0.0002099999983329326 │\n",
       "│ Train/PolicyStd               │ 0.4160052537918091    │\n",
       "│ TotalEnvSteps                 │ 307200.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01850864291191101  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.007932203821837902 │\n",
       "│ Value/Adv                     │ -0.11066828668117523  │\n",
       "│ Loss/Loss_reward_critic       │ 0.018842486664652824  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004198616370558739  │\n",
       "│ Value/reward                  │ 1.8395894765853882    │\n",
       "│ Time/Total                    │ 2034.3822021484375    │\n",
       "│ Time/Rollout                  │ 11.509532928466797    │\n",
       "│ Time/Update                   │ 1.6580657958984375    │\n",
       "│ Time/Epoch                    │ 13.167652130126953    │\n",
       "│ Time/FPS                      │ 155.53268432617188    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.973772048950195     │\n",
       "│ Metrics/EpCost                │ 53.720001220703125     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 150.0                  │\n",
       "│ Train/Entropy                 │ 0.539934515953064      │\n",
       "│ Train/KL                      │ 0.015063748694956303   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9985224008560181     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9985224008560181     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9985224008560181     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019903048872947693   │\n",
       "│ Train/LR                      │ 0.00020939999376423657 │\n",
       "│ Train/PolicyStd               │ 0.41544824838638306    │\n",
       "│ TotalEnvSteps                 │ 309248.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015424815937876701  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0030838269740343094  │\n",
       "│ Value/Adv                     │ -0.1416008472442627    │\n",
       "│ Loss/Loss_reward_critic       │ 0.012182448990643024   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0066600376740098    │\n",
       "│ Value/reward                  │ 1.908064603805542      │\n",
       "│ Time/Total                    │ 2047.73876953125       │\n",
       "│ Time/Rollout                  │ 11.500344276428223     │\n",
       "│ Time/Update                   │ 1.8361632823944092     │\n",
       "│ Time/Epoch                    │ 13.336546897888184     │\n",
       "│ Time/FPS                      │ 153.56298828125        │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.973772048950195     │\n",
       "│ Metrics/EpCost                │ 53.720001220703125     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 150.0                  │\n",
       "│ Train/Entropy                 │ 0.539934515953064      │\n",
       "│ Train/KL                      │ 0.015063748694956303   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9985224008560181     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9985224008560181     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9985224008560181     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019903048872947693   │\n",
       "│ Train/LR                      │ 0.00020939999376423657 │\n",
       "│ Train/PolicyStd               │ 0.41544824838638306    │\n",
       "│ TotalEnvSteps                 │ 309248.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015424815937876701  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0030838269740343094  │\n",
       "│ Value/Adv                     │ -0.1416008472442627    │\n",
       "│ Loss/Loss_reward_critic       │ 0.012182448990643024   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0066600376740098    │\n",
       "│ Value/reward                  │ 1.908064603805542      │\n",
       "│ Time/Total                    │ 2047.73876953125       │\n",
       "│ Time/Rollout                  │ 11.500344276428223     │\n",
       "│ Time/Update                   │ 1.8361632823944092     │\n",
       "│ Time/Epoch                    │ 13.336546897888184     │\n",
       "│ Time/FPS                      │ 153.56298828125        │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.639110565185547     │\n",
       "│ Metrics/EpCost                │ 54.47999954223633      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 151.0                  │\n",
       "│ Train/Entropy                 │ 0.5380093455314636     │\n",
       "│ Train/KL                      │ 0.013259093277156353   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0047343969345093     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0047343969345093     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0047343969345093     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018895383924245834   │\n",
       "│ Train/LR                      │ 0.00020880000374745578 │\n",
       "│ Train/PolicyStd               │ 0.41472020745277405    │\n",
       "│ TotalEnvSteps                 │ 311296.0               │\n",
       "│ Loss/Loss_pi                  │ -0.010488664731383324  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004936151206493378   │\n",
       "│ Value/Adv                     │ -0.07478544116020203   │\n",
       "│ Loss/Loss_reward_critic       │ 0.019549023360013962   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.007366574369370937   │\n",
       "│ Value/reward                  │ 1.7841929197311401     │\n",
       "│ Time/Total                    │ 2060.995849609375      │\n",
       "│ Time/Rollout                  │ 11.404979705810547     │\n",
       "│ Time/Update                   │ 1.8398244380950928     │\n",
       "│ Time/Epoch                    │ 13.244871139526367     │\n",
       "│ Time/FPS                      │ 154.6259002685547      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.639110565185547     │\n",
       "│ Metrics/EpCost                │ 54.47999954223633      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 151.0                  │\n",
       "│ Train/Entropy                 │ 0.5380093455314636     │\n",
       "│ Train/KL                      │ 0.013259093277156353   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0047343969345093     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0047343969345093     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0047343969345093     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018895383924245834   │\n",
       "│ Train/LR                      │ 0.00020880000374745578 │\n",
       "│ Train/PolicyStd               │ 0.41472020745277405    │\n",
       "│ TotalEnvSteps                 │ 311296.0               │\n",
       "│ Loss/Loss_pi                  │ -0.010488664731383324  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004936151206493378   │\n",
       "│ Value/Adv                     │ -0.07478544116020203   │\n",
       "│ Loss/Loss_reward_critic       │ 0.019549023360013962   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.007366574369370937   │\n",
       "│ Value/reward                  │ 1.7841929197311401     │\n",
       "│ Time/Total                    │ 2060.995849609375      │\n",
       "│ Time/Rollout                  │ 11.404979705810547     │\n",
       "│ Time/Update                   │ 1.8398244380950928     │\n",
       "│ Time/Epoch                    │ 13.244871139526367     │\n",
       "│ Time/FPS                      │ 154.6259002685547      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.942853927612305     │\n",
       "│ Metrics/EpCost                │ 54.040000915527344     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 152.0                  │\n",
       "│ Train/Entropy                 │ 0.5329976081848145     │\n",
       "│ Train/KL                      │ 0.014563878066837788   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9945231676101685     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9945231676101685     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9945231676101685     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018034640699625015   │\n",
       "│ Train/LR                      │ 0.00020819999917875975 │\n",
       "│ Train/PolicyStd               │ 0.4127437472343445     │\n",
       "│ TotalEnvSteps                 │ 313344.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013470808044075966  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002982143312692642  │\n",
       "│ Value/Adv                     │ 0.28433647751808167    │\n",
       "│ Loss/Loss_reward_critic       │ 0.018844367936253548   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0007046554237604141 │\n",
       "│ Value/reward                  │ 2.0602452754974365     │\n",
       "│ Time/Total                    │ 2074.223876953125      │\n",
       "│ Time/Rollout                  │ 11.401192665100098     │\n",
       "│ Time/Update                   │ 1.8149714469909668     │\n",
       "│ Time/Epoch                    │ 13.216209411621094     │\n",
       "│ Time/FPS                      │ 154.96124267578125     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.942853927612305     │\n",
       "│ Metrics/EpCost                │ 54.040000915527344     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 152.0                  │\n",
       "│ Train/Entropy                 │ 0.5329976081848145     │\n",
       "│ Train/KL                      │ 0.014563878066837788   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9945231676101685     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9945231676101685     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9945231676101685     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018034640699625015   │\n",
       "│ Train/LR                      │ 0.00020819999917875975 │\n",
       "│ Train/PolicyStd               │ 0.4127437472343445     │\n",
       "│ TotalEnvSteps                 │ 313344.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013470808044075966  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002982143312692642  │\n",
       "│ Value/Adv                     │ 0.28433647751808167    │\n",
       "│ Loss/Loss_reward_critic       │ 0.018844367936253548   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0007046554237604141 │\n",
       "│ Value/reward                  │ 2.0602452754974365     │\n",
       "│ Time/Total                    │ 2074.223876953125      │\n",
       "│ Time/Rollout                  │ 11.401192665100098     │\n",
       "│ Time/Update                   │ 1.8149714469909668     │\n",
       "│ Time/Epoch                    │ 13.216209411621094     │\n",
       "│ Time/FPS                      │ 154.96124267578125     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m9\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.843273162841797     │\n",
       "│ Metrics/EpCost                │ 54.70000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 153.0                  │\n",
       "│ Train/Entropy                 │ 0.525346040725708      │\n",
       "│ Train/KL                      │ 0.02130207046866417    │\n",
       "│ Train/StopIter                │ 9.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9938120245933533     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9938120245933533     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9938120245933533     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018091553822159767   │\n",
       "│ Train/LR                      │ 0.00020759999461006373 │\n",
       "│ Train/PolicyStd               │ 0.40956664085388184    │\n",
       "│ TotalEnvSteps                 │ 315392.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01959611289203167   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.006125304847955704  │\n",
       "│ Value/Adv                     │ -0.026099251583218575  │\n",
       "│ Loss/Loss_reward_critic       │ 0.019212739542126656   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0003683716058731079  │\n",
       "│ Value/reward                  │ 1.9693679809570312     │\n",
       "│ Time/Total                    │ 2087.3974609375        │\n",
       "│ Time/Rollout                  │ 11.468612670898438     │\n",
       "│ Time/Update                   │ 1.6927096843719482     │\n",
       "│ Time/Epoch                    │ 13.161367416381836     │\n",
       "│ Time/FPS                      │ 155.60694885253906     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.843273162841797     │\n",
       "│ Metrics/EpCost                │ 54.70000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 153.0                  │\n",
       "│ Train/Entropy                 │ 0.525346040725708      │\n",
       "│ Train/KL                      │ 0.02130207046866417    │\n",
       "│ Train/StopIter                │ 9.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9938120245933533     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9938120245933533     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9938120245933533     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018091553822159767   │\n",
       "│ Train/LR                      │ 0.00020759999461006373 │\n",
       "│ Train/PolicyStd               │ 0.40956664085388184    │\n",
       "│ TotalEnvSteps                 │ 315392.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01959611289203167   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.006125304847955704  │\n",
       "│ Value/Adv                     │ -0.026099251583218575  │\n",
       "│ Loss/Loss_reward_critic       │ 0.019212739542126656   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0003683716058731079  │\n",
       "│ Value/reward                  │ 1.9693679809570312     │\n",
       "│ Time/Total                    │ 2087.3974609375        │\n",
       "│ Time/Rollout                  │ 11.468612670898438     │\n",
       "│ Time/Update                   │ 1.6927096843719482     │\n",
       "│ Time/Epoch                    │ 13.161367416381836     │\n",
       "│ Time/FPS                      │ 155.60694885253906     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.693735122680664     │\n",
       "│ Metrics/EpCost                │ 51.91999816894531      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 154.0                  │\n",
       "│ Train/Entropy                 │ 0.5157352685928345     │\n",
       "│ Train/KL                      │ 0.01632021740078926    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.003095269203186      │\n",
       "│ Train/PolicyRatio/Min         │ 1.003095269203186      │\n",
       "│ Train/PolicyRatio/Max         │ 1.003095269203186      │\n",
       "│ Train/PolicyRatio/Std         │ 0.020830705761909485   │\n",
       "│ Train/LR                      │ 0.00020700000459328294 │\n",
       "│ Train/PolicyStd               │ 0.4055953621864319     │\n",
       "│ TotalEnvSteps                 │ 317440.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01430791150778532   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005288201384246349   │\n",
       "│ Value/Adv                     │ 0.024333864450454712   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01914997026324272    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -6.276927888393402e-05 │\n",
       "│ Value/reward                  │ 1.966091275215149      │\n",
       "│ Time/Total                    │ 2100.874755859375      │\n",
       "│ Time/Rollout                  │ 11.596150398254395     │\n",
       "│ Time/Update                   │ 1.867903470993042      │\n",
       "│ Time/Epoch                    │ 13.464103698730469     │\n",
       "│ Time/FPS                      │ 152.10816955566406     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.693735122680664     │\n",
       "│ Metrics/EpCost                │ 51.91999816894531      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 154.0                  │\n",
       "│ Train/Entropy                 │ 0.5157352685928345     │\n",
       "│ Train/KL                      │ 0.01632021740078926    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.003095269203186      │\n",
       "│ Train/PolicyRatio/Min         │ 1.003095269203186      │\n",
       "│ Train/PolicyRatio/Max         │ 1.003095269203186      │\n",
       "│ Train/PolicyRatio/Std         │ 0.020830705761909485   │\n",
       "│ Train/LR                      │ 0.00020700000459328294 │\n",
       "│ Train/PolicyStd               │ 0.4055953621864319     │\n",
       "│ TotalEnvSteps                 │ 317440.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01430791150778532   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005288201384246349   │\n",
       "│ Value/Adv                     │ 0.024333864450454712   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01914997026324272    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -6.276927888393402e-05 │\n",
       "│ Value/reward                  │ 1.966091275215149      │\n",
       "│ Time/Total                    │ 2100.874755859375      │\n",
       "│ Time/Rollout                  │ 11.596150398254395     │\n",
       "│ Time/Update                   │ 1.867903470993042      │\n",
       "│ Time/Epoch                    │ 13.464103698730469     │\n",
       "│ Time/FPS                      │ 152.10816955566406     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.830089569091797     │\n",
       "│ Metrics/EpCost                │ 51.939998626708984     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 155.0                  │\n",
       "│ Train/Entropy                 │ 0.5095537900924683     │\n",
       "│ Train/KL                      │ 0.014016378670930862   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.999393105506897      │\n",
       "│ Train/PolicyRatio/Min         │ 0.999393105506897      │\n",
       "│ Train/PolicyRatio/Max         │ 0.999393105506897      │\n",
       "│ Train/PolicyRatio/Std         │ 0.020007535815238953   │\n",
       "│ Train/LR                      │ 0.00020640000002458692 │\n",
       "│ Train/PolicyStd               │ 0.40307265520095825    │\n",
       "│ TotalEnvSteps                 │ 319488.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016272658482193947  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0019647469744086266 │\n",
       "│ Value/Adv                     │ 0.07164334505796432    │\n",
       "│ Loss/Loss_reward_critic       │ 0.028845753520727158   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.009695783257484436   │\n",
       "│ Value/reward                  │ 1.9789268970489502     │\n",
       "│ Time/Total                    │ 2114.423583984375      │\n",
       "│ Time/Rollout                  │ 11.631306648254395     │\n",
       "│ Time/Update                   │ 1.905714750289917      │\n",
       "│ Time/Epoch                    │ 13.537069320678711     │\n",
       "│ Time/FPS                      │ 151.2882843017578      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.830089569091797     │\n",
       "│ Metrics/EpCost                │ 51.939998626708984     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 155.0                  │\n",
       "│ Train/Entropy                 │ 0.5095537900924683     │\n",
       "│ Train/KL                      │ 0.014016378670930862   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.999393105506897      │\n",
       "│ Train/PolicyRatio/Min         │ 0.999393105506897      │\n",
       "│ Train/PolicyRatio/Max         │ 0.999393105506897      │\n",
       "│ Train/PolicyRatio/Std         │ 0.020007535815238953   │\n",
       "│ Train/LR                      │ 0.00020640000002458692 │\n",
       "│ Train/PolicyStd               │ 0.40307265520095825    │\n",
       "│ TotalEnvSteps                 │ 319488.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016272658482193947  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0019647469744086266 │\n",
       "│ Value/Adv                     │ 0.07164334505796432    │\n",
       "│ Loss/Loss_reward_critic       │ 0.028845753520727158   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.009695783257484436   │\n",
       "│ Value/reward                  │ 1.9789268970489502     │\n",
       "│ Time/Total                    │ 2114.423583984375      │\n",
       "│ Time/Rollout                  │ 11.631306648254395     │\n",
       "│ Time/Update                   │ 1.905714750289917      │\n",
       "│ Time/Epoch                    │ 13.537069320678711     │\n",
       "│ Time/FPS                      │ 151.2882843017578      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m8\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.102067947387695    │\n",
       "│ Metrics/EpCost                │ 50.7400016784668      │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 156.0                 │\n",
       "│ Train/Entropy                 │ 0.5075693726539612    │\n",
       "│ Train/KL                      │ 0.020677901804447174  │\n",
       "│ Train/StopIter                │ 8.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9973412752151489    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9973412752151489    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9973412752151489    │\n",
       "│ Train/PolicyRatio/Std         │ 0.020143214613199234  │\n",
       "│ Train/LR                      │ 0.0002057999954558909 │\n",
       "│ Train/PolicyStd               │ 0.4022830128669739    │\n",
       "│ TotalEnvSteps                 │ 321536.0              │\n",
       "│ Loss/Loss_pi                  │ -0.012033068574965    │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004239589907228947  │\n",
       "│ Value/Adv                     │ 0.36047887802124023   │\n",
       "│ Loss/Loss_reward_critic       │ 0.023467207327485085  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005378546193242073 │\n",
       "│ Value/reward                  │ 2.0080504417419434    │\n",
       "│ Time/Total                    │ 2127.399169921875     │\n",
       "│ Time/Rollout                  │ 11.463948249816895    │\n",
       "│ Time/Update                   │ 1.499770164489746     │\n",
       "│ Time/Epoch                    │ 12.963759422302246    │\n",
       "│ Time/FPS                      │ 157.9788818359375     │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.102067947387695    │\n",
       "│ Metrics/EpCost                │ 50.7400016784668      │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 156.0                 │\n",
       "│ Train/Entropy                 │ 0.5075693726539612    │\n",
       "│ Train/KL                      │ 0.020677901804447174  │\n",
       "│ Train/StopIter                │ 8.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9973412752151489    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9973412752151489    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9973412752151489    │\n",
       "│ Train/PolicyRatio/Std         │ 0.020143214613199234  │\n",
       "│ Train/LR                      │ 0.0002057999954558909 │\n",
       "│ Train/PolicyStd               │ 0.4022830128669739    │\n",
       "│ TotalEnvSteps                 │ 321536.0              │\n",
       "│ Loss/Loss_pi                  │ -0.012033068574965    │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004239589907228947  │\n",
       "│ Value/Adv                     │ 0.36047887802124023   │\n",
       "│ Loss/Loss_reward_critic       │ 0.023467207327485085  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005378546193242073 │\n",
       "│ Value/reward                  │ 2.0080504417419434    │\n",
       "│ Time/Total                    │ 2127.399169921875     │\n",
       "│ Time/Rollout                  │ 11.463948249816895    │\n",
       "│ Time/Update                   │ 1.499770164489746     │\n",
       "│ Time/Epoch                    │ 12.963759422302246    │\n",
       "│ Time/FPS                      │ 157.9788818359375     │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.000885009765625     │\n",
       "│ Metrics/EpCost                │ 51.2400016784668       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 157.0                  │\n",
       "│ Train/Entropy                 │ 0.5034661293029785     │\n",
       "│ Train/KL                      │ 0.01571262814104557    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9961692690849304     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9961692690849304     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9961692690849304     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01861441321671009    │\n",
       "│ Train/LR                      │ 0.0002052000054391101  │\n",
       "│ Train/PolicyStd               │ 0.40061283111572266    │\n",
       "│ TotalEnvSteps                 │ 323584.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015019910410046577  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0029868418350815773 │\n",
       "│ Value/Adv                     │ -0.05105223134160042   │\n",
       "│ Loss/Loss_reward_critic       │ 0.020645374432206154   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0028218328952789307 │\n",
       "│ Value/reward                  │ 1.983039379119873      │\n",
       "│ Time/Total                    │ 2140.77978515625       │\n",
       "│ Time/Rollout                  │ 11.466901779174805     │\n",
       "│ Time/Update                   │ 1.8912837505340576     │\n",
       "│ Time/Epoch                    │ 13.358233451843262     │\n",
       "│ Time/FPS                      │ 153.31369018554688     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.000885009765625     │\n",
       "│ Metrics/EpCost                │ 51.2400016784668       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 157.0                  │\n",
       "│ Train/Entropy                 │ 0.5034661293029785     │\n",
       "│ Train/KL                      │ 0.01571262814104557    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9961692690849304     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9961692690849304     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9961692690849304     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01861441321671009    │\n",
       "│ Train/LR                      │ 0.0002052000054391101  │\n",
       "│ Train/PolicyStd               │ 0.40061283111572266    │\n",
       "│ TotalEnvSteps                 │ 323584.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015019910410046577  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0029868418350815773 │\n",
       "│ Value/Adv                     │ -0.05105223134160042   │\n",
       "│ Loss/Loss_reward_critic       │ 0.020645374432206154   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0028218328952789307 │\n",
       "│ Value/reward                  │ 1.983039379119873      │\n",
       "│ Time/Total                    │ 2140.77978515625       │\n",
       "│ Time/Rollout                  │ 11.466901779174805     │\n",
       "│ Time/Update                   │ 1.8912837505340576     │\n",
       "│ Time/Epoch                    │ 13.358233451843262     │\n",
       "│ Time/FPS                      │ 153.31369018554688     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.949071884155273     │\n",
       "│ Metrics/EpCost                │ 50.7599983215332       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 158.0                  │\n",
       "│ Train/Entropy                 │ 0.4990275800228119     │\n",
       "│ Train/KL                      │ 0.015694202855229378   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0024360418319702     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0024360418319702     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0024360418319702     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01847369223833084    │\n",
       "│ Train/LR                      │ 0.00020460000087041408 │\n",
       "│ Train/PolicyStd               │ 0.39876794815063477    │\n",
       "│ TotalEnvSteps                 │ 325632.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01337957102805376   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.001640339381992817   │\n",
       "│ Value/Adv                     │ 0.17398937046527863    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01731865108013153    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.003326723352074623  │\n",
       "│ Value/reward                  │ 1.8804707527160645     │\n",
       "│ Time/Total                    │ 2154.164306640625      │\n",
       "│ Time/Rollout                  │ 11.489815711975098     │\n",
       "│ Time/Update                   │ 1.8812267780303955     │\n",
       "│ Time/Epoch                    │ 13.371106147766113     │\n",
       "│ Time/FPS                      │ 153.16610717773438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.949071884155273     │\n",
       "│ Metrics/EpCost                │ 50.7599983215332       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 158.0                  │\n",
       "│ Train/Entropy                 │ 0.4990275800228119     │\n",
       "│ Train/KL                      │ 0.015694202855229378   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0024360418319702     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0024360418319702     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0024360418319702     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01847369223833084    │\n",
       "│ Train/LR                      │ 0.00020460000087041408 │\n",
       "│ Train/PolicyStd               │ 0.39876794815063477    │\n",
       "│ TotalEnvSteps                 │ 325632.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01337957102805376   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.001640339381992817   │\n",
       "│ Value/Adv                     │ 0.17398937046527863    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01731865108013153    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.003326723352074623  │\n",
       "│ Value/reward                  │ 1.8804707527160645     │\n",
       "│ Time/Total                    │ 2154.164306640625      │\n",
       "│ Time/Rollout                  │ 11.489815711975098     │\n",
       "│ Time/Update                   │ 1.8812267780303955     │\n",
       "│ Time/Epoch                    │ 13.371106147766113     │\n",
       "│ Time/FPS                      │ 153.16610717773438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.88535499572754      │\n",
       "│ Metrics/EpCost                │ 50.20000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 159.0                  │\n",
       "│ Train/Entropy                 │ 0.4971369802951813     │\n",
       "│ Train/KL                      │ 0.008958103135228157   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9986268281936646     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9986268281936646     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9986268281936646     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016153134405612946   │\n",
       "│ Train/LR                      │ 0.00020399999630171806 │\n",
       "│ Train/PolicyStd               │ 0.3979721665382385     │\n",
       "│ TotalEnvSteps                 │ 327680.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011164173483848572  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0022153975442051888  │\n",
       "│ Value/Adv                     │ -0.009338505566120148  │\n",
       "│ Loss/Loss_reward_critic       │ 0.02341323345899582    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006094582378864288   │\n",
       "│ Value/reward                  │ 1.7426824569702148     │\n",
       "│ Time/Total                    │ 2167.42822265625       │\n",
       "│ Time/Rollout                  │ 11.41504955291748      │\n",
       "│ Time/Update                   │ 1.8362655639648438     │\n",
       "│ Time/Epoch                    │ 13.25135612487793      │\n",
       "│ Time/FPS                      │ 154.5502166748047      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.88535499572754      │\n",
       "│ Metrics/EpCost                │ 50.20000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 159.0                  │\n",
       "│ Train/Entropy                 │ 0.4971369802951813     │\n",
       "│ Train/KL                      │ 0.008958103135228157   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9986268281936646     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9986268281936646     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9986268281936646     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016153134405612946   │\n",
       "│ Train/LR                      │ 0.00020399999630171806 │\n",
       "│ Train/PolicyStd               │ 0.3979721665382385     │\n",
       "│ TotalEnvSteps                 │ 327680.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011164173483848572  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0022153975442051888  │\n",
       "│ Value/Adv                     │ -0.009338505566120148  │\n",
       "│ Loss/Loss_reward_critic       │ 0.02341323345899582    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006094582378864288   │\n",
       "│ Value/reward                  │ 1.7426824569702148     │\n",
       "│ Time/Total                    │ 2167.42822265625       │\n",
       "│ Time/Rollout                  │ 11.41504955291748      │\n",
       "│ Time/Update                   │ 1.8362655639648438     │\n",
       "│ Time/Epoch                    │ 13.25135612487793      │\n",
       "│ Time/FPS                      │ 154.5502166748047      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.756671905517578     │\n",
       "│ Metrics/EpCost                │ 51.560001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 160.0                  │\n",
       "│ Train/Entropy                 │ 0.49724310636520386    │\n",
       "│ Train/KL                      │ 0.018868310377001762   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9927434921264648     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9927434921264648     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9927434921264648     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02085532434284687    │\n",
       "│ Train/LR                      │ 0.00020340000628493726 │\n",
       "│ Train/PolicyStd               │ 0.39799705147743225    │\n",
       "│ TotalEnvSteps                 │ 329728.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013561832718551159  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002397659234702587  │\n",
       "│ Value/Adv                     │ 0.1079578548669815     │\n",
       "│ Loss/Loss_reward_critic       │ 0.020268548280000687   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0031446851789951324 │\n",
       "│ Value/reward                  │ 1.8661983013153076     │\n",
       "│ Time/Total                    │ 2180.6806640625        │\n",
       "│ Time/Rollout                  │ 11.362811088562012     │\n",
       "│ Time/Update                   │ 1.8745677471160889     │\n",
       "│ Time/Epoch                    │ 13.237441062927246     │\n",
       "│ Time/FPS                      │ 154.71270751953125     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.756671905517578     │\n",
       "│ Metrics/EpCost                │ 51.560001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 160.0                  │\n",
       "│ Train/Entropy                 │ 0.49724310636520386    │\n",
       "│ Train/KL                      │ 0.018868310377001762   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9927434921264648     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9927434921264648     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9927434921264648     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02085532434284687    │\n",
       "│ Train/LR                      │ 0.00020340000628493726 │\n",
       "│ Train/PolicyStd               │ 0.39799705147743225    │\n",
       "│ TotalEnvSteps                 │ 329728.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013561832718551159  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002397659234702587  │\n",
       "│ Value/Adv                     │ 0.1079578548669815     │\n",
       "│ Loss/Loss_reward_critic       │ 0.020268548280000687   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0031446851789951324 │\n",
       "│ Value/reward                  │ 1.8661983013153076     │\n",
       "│ Time/Total                    │ 2180.6806640625        │\n",
       "│ Time/Rollout                  │ 11.362811088562012     │\n",
       "│ Time/Update                   │ 1.8745677471160889     │\n",
       "│ Time/Epoch                    │ 13.237441062927246     │\n",
       "│ Time/FPS                      │ 154.71270751953125     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.51041603088379      │\n",
       "│ Metrics/EpCost                │ 53.060001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 161.0                  │\n",
       "│ Train/Entropy                 │ 0.492304265499115      │\n",
       "│ Train/KL                      │ 0.012832407839596272   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0037202835083008     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0037202835083008     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0037202835083008     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01780265010893345    │\n",
       "│ Train/LR                      │ 0.00020280000171624124 │\n",
       "│ Train/PolicyStd               │ 0.39603742957115173    │\n",
       "│ TotalEnvSteps                 │ 331776.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012269946746528149  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0012918859720230103  │\n",
       "│ Value/Adv                     │ -0.09310837090015411   │\n",
       "│ Loss/Loss_reward_critic       │ 0.019108757376670837   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0011597909033298492 │\n",
       "│ Value/reward                  │ 1.7030961513519287     │\n",
       "│ Time/Total                    │ 2193.94677734375       │\n",
       "│ Time/Rollout                  │ 11.429208755493164     │\n",
       "│ Time/Update                   │ 1.822859287261963      │\n",
       "│ Time/Epoch                    │ 13.25211238861084      │\n",
       "│ Time/FPS                      │ 154.54141235351562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.51041603088379      │\n",
       "│ Metrics/EpCost                │ 53.060001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 161.0                  │\n",
       "│ Train/Entropy                 │ 0.492304265499115      │\n",
       "│ Train/KL                      │ 0.012832407839596272   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0037202835083008     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0037202835083008     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0037202835083008     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01780265010893345    │\n",
       "│ Train/LR                      │ 0.00020280000171624124 │\n",
       "│ Train/PolicyStd               │ 0.39603742957115173    │\n",
       "│ TotalEnvSteps                 │ 331776.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012269946746528149  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0012918859720230103  │\n",
       "│ Value/Adv                     │ -0.09310837090015411   │\n",
       "│ Loss/Loss_reward_critic       │ 0.019108757376670837   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0011597909033298492 │\n",
       "│ Value/reward                  │ 1.7030961513519287     │\n",
       "│ Time/Total                    │ 2193.94677734375       │\n",
       "│ Time/Rollout                  │ 11.429208755493164     │\n",
       "│ Time/Update                   │ 1.822859287261963      │\n",
       "│ Time/Epoch                    │ 13.25211238861084      │\n",
       "│ Time/FPS                      │ 154.54141235351562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.836286544799805     │\n",
       "│ Metrics/EpCost                │ 53.79999923706055      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 162.0                  │\n",
       "│ Train/Entropy                 │ 0.4820510745048523     │\n",
       "│ Train/KL                      │ 0.015645870938897133   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0003849267959595     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0003849267959595     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0003849267959595     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017352797091007233   │\n",
       "│ Train/LR                      │ 0.00020219999714754522 │\n",
       "│ Train/PolicyStd               │ 0.3920220732688904     │\n",
       "│ TotalEnvSteps                 │ 333824.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014650669880211353  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0023807231336832047 │\n",
       "│ Value/Adv                     │ 0.1707012802362442     │\n",
       "│ Loss/Loss_reward_critic       │ 0.01956234499812126    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0004535876214504242  │\n",
       "│ Value/reward                  │ 1.8897156715393066     │\n",
       "│ Time/Total                    │ 2207.171630859375      │\n",
       "│ Time/Rollout                  │ 11.409956932067871     │\n",
       "│ Time/Update                   │ 1.803359031677246      │\n",
       "│ Time/Epoch                    │ 13.213363647460938     │\n",
       "│ Time/FPS                      │ 154.99459838867188     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 17.836286544799805     │\n",
       "│ Metrics/EpCost                │ 53.79999923706055      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 162.0                  │\n",
       "│ Train/Entropy                 │ 0.4820510745048523     │\n",
       "│ Train/KL                      │ 0.015645870938897133   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0003849267959595     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0003849267959595     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0003849267959595     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017352797091007233   │\n",
       "│ Train/LR                      │ 0.00020219999714754522 │\n",
       "│ Train/PolicyStd               │ 0.3920220732688904     │\n",
       "│ TotalEnvSteps                 │ 333824.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014650669880211353  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0023807231336832047 │\n",
       "│ Value/Adv                     │ 0.1707012802362442     │\n",
       "│ Loss/Loss_reward_critic       │ 0.01956234499812126    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0004535876214504242  │\n",
       "│ Value/reward                  │ 1.8897156715393066     │\n",
       "│ Time/Total                    │ 2207.171630859375      │\n",
       "│ Time/Rollout                  │ 11.409956932067871     │\n",
       "│ Time/Update                   │ 1.803359031677246      │\n",
       "│ Time/Epoch                    │ 13.213363647460938     │\n",
       "│ Time/FPS                      │ 154.99459838867188     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.263221740722656     │\n",
       "│ Metrics/EpCost                │ 56.58000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 163.0                  │\n",
       "│ Train/Entropy                 │ 0.4746752679347992     │\n",
       "│ Train/KL                      │ 0.012927482835948467   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9978847503662109     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9978847503662109     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9978847503662109     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01843065209686756    │\n",
       "│ Train/LR                      │ 0.00020160000713076442 │\n",
       "│ Train/PolicyStd               │ 0.3891220986843109     │\n",
       "│ TotalEnvSteps                 │ 335872.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013679233379662037  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0009714365005493164  │\n",
       "│ Value/Adv                     │ -0.020721031352877617  │\n",
       "│ Loss/Loss_reward_critic       │ 0.01229835208505392    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.007263992913067341  │\n",
       "│ Value/reward                  │ 1.8680616617202759     │\n",
       "│ Time/Total                    │ 2220.575439453125      │\n",
       "│ Time/Rollout                  │ 11.530540466308594     │\n",
       "│ Time/Update                   │ 1.8608973026275635     │\n",
       "│ Time/Epoch                    │ 13.3914794921875       │\n",
       "│ Time/FPS                      │ 152.93307495117188     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.263221740722656     │\n",
       "│ Metrics/EpCost                │ 56.58000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 163.0                  │\n",
       "│ Train/Entropy                 │ 0.4746752679347992     │\n",
       "│ Train/KL                      │ 0.012927482835948467   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9978847503662109     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9978847503662109     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9978847503662109     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01843065209686756    │\n",
       "│ Train/LR                      │ 0.00020160000713076442 │\n",
       "│ Train/PolicyStd               │ 0.3891220986843109     │\n",
       "│ TotalEnvSteps                 │ 335872.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013679233379662037  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0009714365005493164  │\n",
       "│ Value/Adv                     │ -0.020721031352877617  │\n",
       "│ Loss/Loss_reward_critic       │ 0.01229835208505392    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.007263992913067341  │\n",
       "│ Value/reward                  │ 1.8680616617202759     │\n",
       "│ Time/Total                    │ 2220.575439453125      │\n",
       "│ Time/Rollout                  │ 11.530540466308594     │\n",
       "│ Time/Update                   │ 1.8608973026275635     │\n",
       "│ Time/Epoch                    │ 13.3914794921875       │\n",
       "│ Time/FPS                      │ 152.93307495117188     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.273042678833008     │\n",
       "│ Metrics/EpCost                │ 56.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 164.0                  │\n",
       "│ Train/Entropy                 │ 0.4685536324977875     │\n",
       "│ Train/KL                      │ 0.014269341714680195   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9959703683853149     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9959703683853149     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9959703683853149     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019432801753282547   │\n",
       "│ Train/LR                      │ 0.0002010000025620684  │\n",
       "│ Train/PolicyStd               │ 0.38670507073402405    │\n",
       "│ TotalEnvSteps                 │ 337920.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014020277187228203  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0003410438075661659 │\n",
       "│ Value/Adv                     │ 0.08146075904369354    │\n",
       "│ Loss/Loss_reward_critic       │ 0.020013678818941116   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.007715326733887196   │\n",
       "│ Value/reward                  │ 1.869613528251648      │\n",
       "│ Time/Total                    │ 2233.98388671875       │\n",
       "│ Time/Rollout                  │ 11.492347717285156     │\n",
       "│ Time/Update                   │ 1.9038727283477783     │\n",
       "│ Time/Epoch                    │ 13.396263122558594     │\n",
       "│ Time/FPS                      │ 152.8784637451172      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.273042678833008     │\n",
       "│ Metrics/EpCost                │ 56.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 164.0                  │\n",
       "│ Train/Entropy                 │ 0.4685536324977875     │\n",
       "│ Train/KL                      │ 0.014269341714680195   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9959703683853149     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9959703683853149     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9959703683853149     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019432801753282547   │\n",
       "│ Train/LR                      │ 0.0002010000025620684  │\n",
       "│ Train/PolicyStd               │ 0.38670507073402405    │\n",
       "│ TotalEnvSteps                 │ 337920.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014020277187228203  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0003410438075661659 │\n",
       "│ Value/Adv                     │ 0.08146075904369354    │\n",
       "│ Loss/Loss_reward_critic       │ 0.020013678818941116   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.007715326733887196   │\n",
       "│ Value/reward                  │ 1.869613528251648      │\n",
       "│ Time/Total                    │ 2233.98388671875       │\n",
       "│ Time/Rollout                  │ 11.492347717285156     │\n",
       "│ Time/Update                   │ 1.9038727283477783     │\n",
       "│ Time/Epoch                    │ 13.396263122558594     │\n",
       "│ Time/FPS                      │ 152.8784637451172      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.304506301879883     │\n",
       "│ Metrics/EpCost                │ 56.86000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 165.0                  │\n",
       "│ Train/Entropy                 │ 0.4580457806587219     │\n",
       "│ Train/KL                      │ 0.01831471174955368    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9930264353752136     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9930264353752136     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9930264353752136     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01933787390589714    │\n",
       "│ Train/LR                      │ 0.00020039999799337238 │\n",
       "│ Train/PolicyStd               │ 0.3826407790184021     │\n",
       "│ TotalEnvSteps                 │ 339968.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01737167313694954   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0033513959497213364 │\n",
       "│ Value/Adv                     │ -0.1421160101890564    │\n",
       "│ Loss/Loss_reward_critic       │ 0.028622597455978394   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.008608918637037277   │\n",
       "│ Value/reward                  │ 1.8757117986679077     │\n",
       "│ Time/Total                    │ 2247.361083984375      │\n",
       "│ Time/Rollout                  │ 11.49216365814209      │\n",
       "│ Time/Update                   │ 1.872211217880249      │\n",
       "│ Time/Epoch                    │ 13.364418983459473     │\n",
       "│ Time/FPS                      │ 153.24273681640625     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.304506301879883     │\n",
       "│ Metrics/EpCost                │ 56.86000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 165.0                  │\n",
       "│ Train/Entropy                 │ 0.4580457806587219     │\n",
       "│ Train/KL                      │ 0.01831471174955368    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9930264353752136     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9930264353752136     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9930264353752136     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01933787390589714    │\n",
       "│ Train/LR                      │ 0.00020039999799337238 │\n",
       "│ Train/PolicyStd               │ 0.3826407790184021     │\n",
       "│ TotalEnvSteps                 │ 339968.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01737167313694954   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0033513959497213364 │\n",
       "│ Value/Adv                     │ -0.1421160101890564    │\n",
       "│ Loss/Loss_reward_critic       │ 0.028622597455978394   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.008608918637037277   │\n",
       "│ Value/reward                  │ 1.8757117986679077     │\n",
       "│ Time/Total                    │ 2247.361083984375      │\n",
       "│ Time/Rollout                  │ 11.49216365814209      │\n",
       "│ Time/Update                   │ 1.872211217880249      │\n",
       "│ Time/Epoch                    │ 13.364418983459473     │\n",
       "│ Time/FPS                      │ 153.24273681640625     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.36690330505371      │\n",
       "│ Metrics/EpCost                │ 56.84000015258789      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 166.0                  │\n",
       "│ Train/Entropy                 │ 0.44713348150253296    │\n",
       "│ Train/KL                      │ 0.014866264536976814   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9957817792892456     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9957817792892456     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9957817792892456     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018227344378829002   │\n",
       "│ Train/LR                      │ 0.00019979999342467636 │\n",
       "│ Train/PolicyStd               │ 0.37850135564804077    │\n",
       "│ TotalEnvSteps                 │ 342016.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016247982159256935  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.001123690977692604   │\n",
       "│ Value/Adv                     │ 0.020742354914546013   │\n",
       "│ Loss/Loss_reward_critic       │ 0.030372893437743187   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0017502959817647934  │\n",
       "│ Value/reward                  │ 1.971024513244629      │\n",
       "│ Time/Total                    │ 2260.62255859375       │\n",
       "│ Time/Rollout                  │ 11.370828628540039     │\n",
       "│ Time/Update                   │ 1.8791418075561523     │\n",
       "│ Time/Epoch                    │ 13.250030517578125     │\n",
       "│ Time/FPS                      │ 154.56570434570312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.36690330505371      │\n",
       "│ Metrics/EpCost                │ 56.84000015258789      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 166.0                  │\n",
       "│ Train/Entropy                 │ 0.44713348150253296    │\n",
       "│ Train/KL                      │ 0.014866264536976814   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9957817792892456     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9957817792892456     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9957817792892456     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018227344378829002   │\n",
       "│ Train/LR                      │ 0.00019979999342467636 │\n",
       "│ Train/PolicyStd               │ 0.37850135564804077    │\n",
       "│ TotalEnvSteps                 │ 342016.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016247982159256935  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.001123690977692604   │\n",
       "│ Value/Adv                     │ 0.020742354914546013   │\n",
       "│ Loss/Loss_reward_critic       │ 0.030372893437743187   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0017502959817647934  │\n",
       "│ Value/reward                  │ 1.971024513244629      │\n",
       "│ Time/Total                    │ 2260.62255859375       │\n",
       "│ Time/Rollout                  │ 11.370828628540039     │\n",
       "│ Time/Update                   │ 1.8791418075561523     │\n",
       "│ Time/Epoch                    │ 13.250030517578125     │\n",
       "│ Time/FPS                      │ 154.56570434570312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.6259765625          │\n",
       "│ Metrics/EpCost                │ 59.7400016784668       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 167.0                  │\n",
       "│ Train/Entropy                 │ 0.43982449173927307    │\n",
       "│ Train/KL                      │ 0.01390005461871624    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9985545873641968     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9985545873641968     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9985545873641968     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01944698579609394    │\n",
       "│ Train/LR                      │ 0.00019920000340789557 │\n",
       "│ Train/PolicyStd               │ 0.37573543190956116    │\n",
       "│ TotalEnvSteps                 │ 344064.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015369229018688202  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0008787531405687332  │\n",
       "│ Value/Adv                     │ -0.1435500532388687    │\n",
       "│ Loss/Loss_reward_critic       │ 0.015847207978367805   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.014525685459375381  │\n",
       "│ Value/reward                  │ 2.024244785308838      │\n",
       "│ Time/Total                    │ 2273.939208984375      │\n",
       "│ Time/Rollout                  │ 11.445534706115723     │\n",
       "│ Time/Update                   │ 1.8590497970581055     │\n",
       "│ Time/Epoch                    │ 13.304628372192383     │\n",
       "│ Time/FPS                      │ 153.93141174316406     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.6259765625          │\n",
       "│ Metrics/EpCost                │ 59.7400016784668       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 167.0                  │\n",
       "│ Train/Entropy                 │ 0.43982449173927307    │\n",
       "│ Train/KL                      │ 0.01390005461871624    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9985545873641968     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9985545873641968     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9985545873641968     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01944698579609394    │\n",
       "│ Train/LR                      │ 0.00019920000340789557 │\n",
       "│ Train/PolicyStd               │ 0.37573543190956116    │\n",
       "│ TotalEnvSteps                 │ 344064.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015369229018688202  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0008787531405687332  │\n",
       "│ Value/Adv                     │ -0.1435500532388687    │\n",
       "│ Loss/Loss_reward_critic       │ 0.015847207978367805   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.014525685459375381  │\n",
       "│ Value/reward                  │ 2.024244785308838      │\n",
       "│ Time/Total                    │ 2273.939208984375      │\n",
       "│ Time/Rollout                  │ 11.445534706115723     │\n",
       "│ Time/Update                   │ 1.8590497970581055     │\n",
       "│ Time/Epoch                    │ 13.304628372192383     │\n",
       "│ Time/FPS                      │ 153.93141174316406     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.18518829345703      │\n",
       "│ Metrics/EpCost                │ 58.08000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 168.0                  │\n",
       "│ Train/Entropy                 │ 0.4339565634727478     │\n",
       "│ Train/KL                      │ 0.014709590934216976   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.003981351852417      │\n",
       "│ Train/PolicyRatio/Min         │ 1.003981351852417      │\n",
       "│ Train/PolicyRatio/Max         │ 1.003981351852417      │\n",
       "│ Train/PolicyRatio/Std         │ 0.020356465131044388   │\n",
       "│ Train/LR                      │ 0.00019859999883919954 │\n",
       "│ Train/PolicyStd               │ 0.3735838532447815     │\n",
       "│ TotalEnvSteps                 │ 346112.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013234123587608337  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0021351054310798645  │\n",
       "│ Value/Adv                     │ -0.11263389885425568   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01243954710662365    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.003407660871744156  │\n",
       "│ Value/reward                  │ 1.6577937602996826     │\n",
       "│ Time/Total                    │ 2287.615478515625      │\n",
       "│ Time/Rollout                  │ 11.711243629455566     │\n",
       "│ Time/Update                   │ 1.9533355236053467     │\n",
       "│ Time/Epoch                    │ 13.66462230682373      │\n",
       "│ Time/FPS                      │ 149.87608337402344     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.18518829345703      │\n",
       "│ Metrics/EpCost                │ 58.08000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 168.0                  │\n",
       "│ Train/Entropy                 │ 0.4339565634727478     │\n",
       "│ Train/KL                      │ 0.014709590934216976   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.003981351852417      │\n",
       "│ Train/PolicyRatio/Min         │ 1.003981351852417      │\n",
       "│ Train/PolicyRatio/Max         │ 1.003981351852417      │\n",
       "│ Train/PolicyRatio/Std         │ 0.020356465131044388   │\n",
       "│ Train/LR                      │ 0.00019859999883919954 │\n",
       "│ Train/PolicyStd               │ 0.3735838532447815     │\n",
       "│ TotalEnvSteps                 │ 346112.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013234123587608337  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0021351054310798645  │\n",
       "│ Value/Adv                     │ -0.11263389885425568   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01243954710662365    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.003407660871744156  │\n",
       "│ Value/reward                  │ 1.6577937602996826     │\n",
       "│ Time/Total                    │ 2287.615478515625      │\n",
       "│ Time/Rollout                  │ 11.711243629455566     │\n",
       "│ Time/Update                   │ 1.9533355236053467     │\n",
       "│ Time/Epoch                    │ 13.66462230682373      │\n",
       "│ Time/FPS                      │ 149.87608337402344     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m7\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.4982967376709       │\n",
       "│ Metrics/EpCost                │ 58.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 169.0                  │\n",
       "│ Train/Entropy                 │ 0.42880386114120483    │\n",
       "│ Train/KL                      │ 0.020679647102952003   │\n",
       "│ Train/StopIter                │ 7.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9946008324623108     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9946008324623108     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9946008324623108     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017323464155197144   │\n",
       "│ Train/LR                      │ 0.00019799999427050352 │\n",
       "│ Train/PolicyStd               │ 0.3717367351055145     │\n",
       "│ TotalEnvSteps                 │ 348160.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011334138922393322  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0018999846652150154  │\n",
       "│ Value/Adv                     │ 0.009098701179027557   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01473574060946703    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00229619350284338    │\n",
       "│ Value/reward                  │ 2.011284112930298      │\n",
       "│ Time/Total                    │ 2300.616455078125      │\n",
       "│ Time/Rollout                  │ 11.640806198120117     │\n",
       "│ Time/Update                   │ 1.34785795211792       │\n",
       "│ Time/Epoch                    │ 12.988714218139648     │\n",
       "│ Time/FPS                      │ 157.67535400390625     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.4982967376709       │\n",
       "│ Metrics/EpCost                │ 58.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 169.0                  │\n",
       "│ Train/Entropy                 │ 0.42880386114120483    │\n",
       "│ Train/KL                      │ 0.020679647102952003   │\n",
       "│ Train/StopIter                │ 7.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9946008324623108     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9946008324623108     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9946008324623108     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017323464155197144   │\n",
       "│ Train/LR                      │ 0.00019799999427050352 │\n",
       "│ Train/PolicyStd               │ 0.3717367351055145     │\n",
       "│ TotalEnvSteps                 │ 348160.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011334138922393322  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0018999846652150154  │\n",
       "│ Value/Adv                     │ 0.009098701179027557   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01473574060946703    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00229619350284338    │\n",
       "│ Value/reward                  │ 2.011284112930298      │\n",
       "│ Time/Total                    │ 2300.616455078125      │\n",
       "│ Time/Rollout                  │ 11.640806198120117     │\n",
       "│ Time/Update                   │ 1.34785795211792       │\n",
       "│ Time/Epoch                    │ 12.988714218139648     │\n",
       "│ Time/FPS                      │ 157.67535400390625     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.762094497680664     │\n",
       "│ Metrics/EpCost                │ 58.5                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 170.0                  │\n",
       "│ Train/Entropy                 │ 0.42376285791397095    │\n",
       "│ Train/KL                      │ 0.01616710051894188    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9998670816421509     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9998670816421509     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9998670816421509     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018816038966178894   │\n",
       "│ Train/LR                      │ 0.00019740000425372273 │\n",
       "│ Train/PolicyStd               │ 0.36989158391952515    │\n",
       "│ TotalEnvSteps                 │ 350208.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014348332770168781  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0030141938477754593 │\n",
       "│ Value/Adv                     │ -0.045058347284793854  │\n",
       "│ Loss/Loss_reward_critic       │ 0.021330583840608597   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006594843231141567   │\n",
       "│ Value/reward                  │ 2.0612874031066895     │\n",
       "│ Time/Total                    │ 2314.097412109375      │\n",
       "│ Time/Rollout                  │ 11.603473663330078     │\n",
       "│ Time/Update                   │ 1.8543057441711426     │\n",
       "│ Time/Epoch                    │ 13.45782470703125      │\n",
       "│ Time/FPS                      │ 152.1791229248047      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.762094497680664     │\n",
       "│ Metrics/EpCost                │ 58.5                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 170.0                  │\n",
       "│ Train/Entropy                 │ 0.42376285791397095    │\n",
       "│ Train/KL                      │ 0.01616710051894188    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9998670816421509     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9998670816421509     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9998670816421509     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018816038966178894   │\n",
       "│ Train/LR                      │ 0.00019740000425372273 │\n",
       "│ Train/PolicyStd               │ 0.36989158391952515    │\n",
       "│ TotalEnvSteps                 │ 350208.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014348332770168781  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0030141938477754593 │\n",
       "│ Value/Adv                     │ -0.045058347284793854  │\n",
       "│ Loss/Loss_reward_critic       │ 0.021330583840608597   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006594843231141567   │\n",
       "│ Value/reward                  │ 2.0612874031066895     │\n",
       "│ Time/Total                    │ 2314.097412109375      │\n",
       "│ Time/Rollout                  │ 11.603473663330078     │\n",
       "│ Time/Update                   │ 1.8543057441711426     │\n",
       "│ Time/Epoch                    │ 13.45782470703125      │\n",
       "│ Time/FPS                      │ 152.1791229248047      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.736377716064453      │\n",
       "│ Metrics/EpCost                │ 60.52000045776367       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 171.0                   │\n",
       "│ Train/Entropy                 │ 0.41732773184776306     │\n",
       "│ Train/KL                      │ 0.01643546111881733     │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.000343680381775       │\n",
       "│ Train/PolicyRatio/Min         │ 1.000343680381775       │\n",
       "│ Train/PolicyRatio/Max         │ 1.000343680381775       │\n",
       "│ Train/PolicyRatio/Std         │ 0.019862808287143707    │\n",
       "│ Train/LR                      │ 0.0001967999996850267   │\n",
       "│ Train/PolicyStd               │ 0.3675881028175354      │\n",
       "│ TotalEnvSteps                 │ 352256.0                │\n",
       "│ Loss/Loss_pi                  │ -0.014571502804756165   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00022317003458738327 │\n",
       "│ Value/Adv                     │ 0.06430712342262268     │\n",
       "│ Loss/Loss_reward_critic       │ 0.016115467995405197    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0052151158452034     │\n",
       "│ Value/reward                  │ 1.9870103597640991      │\n",
       "│ Time/Total                    │ 2327.371337890625       │\n",
       "│ Time/Rollout                  │ 11.411931991577148      │\n",
       "│ Time/Update                   │ 1.849914312362671       │\n",
       "│ Time/Epoch                    │ 13.261895179748535      │\n",
       "│ Time/FPS                      │ 154.42739868164062      │\n",
       "└───────────────────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.736377716064453      │\n",
       "│ Metrics/EpCost                │ 60.52000045776367       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 171.0                   │\n",
       "│ Train/Entropy                 │ 0.41732773184776306     │\n",
       "│ Train/KL                      │ 0.01643546111881733     │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.000343680381775       │\n",
       "│ Train/PolicyRatio/Min         │ 1.000343680381775       │\n",
       "│ Train/PolicyRatio/Max         │ 1.000343680381775       │\n",
       "│ Train/PolicyRatio/Std         │ 0.019862808287143707    │\n",
       "│ Train/LR                      │ 0.0001967999996850267   │\n",
       "│ Train/PolicyStd               │ 0.3675881028175354      │\n",
       "│ TotalEnvSteps                 │ 352256.0                │\n",
       "│ Loss/Loss_pi                  │ -0.014571502804756165   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00022317003458738327 │\n",
       "│ Value/Adv                     │ 0.06430712342262268     │\n",
       "│ Loss/Loss_reward_critic       │ 0.016115467995405197    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0052151158452034     │\n",
       "│ Value/reward                  │ 1.9870103597640991      │\n",
       "│ Time/Total                    │ 2327.371337890625       │\n",
       "│ Time/Rollout                  │ 11.411931991577148      │\n",
       "│ Time/Update                   │ 1.849914312362671       │\n",
       "│ Time/Epoch                    │ 13.261895179748535      │\n",
       "│ Time/FPS                      │ 154.42739868164062      │\n",
       "└───────────────────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m2\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.76001739501953      │\n",
       "│ Metrics/EpCost                │ 62.060001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 172.0                  │\n",
       "│ Train/Entropy                 │ 0.41371726989746094    │\n",
       "│ Train/KL                      │ 0.020298682153224945   │\n",
       "│ Train/StopIter                │ 2.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9969263076782227     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9969263076782227     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9969263076782227     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01735246181488037    │\n",
       "│ Train/LR                      │ 0.00019619999511633068 │\n",
       "│ Train/PolicyStd               │ 0.3663220703601837     │\n",
       "│ TotalEnvSteps                 │ 354304.0               │\n",
       "│ Loss/Loss_pi                  │ -0.008645014837384224  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005926487967371941   │\n",
       "│ Value/Adv                     │ 0.05358356982469559    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01841726154088974    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002301793545484543   │\n",
       "│ Value/reward                  │ 2.02655291557312       │\n",
       "│ Time/Total                    │ 2339.267822265625      │\n",
       "│ Time/Rollout                  │ 11.473101615905762     │\n",
       "│ Time/Update                   │ 0.4095313549041748     │\n",
       "│ Time/Epoch                    │ 11.882678985595703     │\n",
       "│ Time/FPS                      │ 172.3517303466797      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.76001739501953      │\n",
       "│ Metrics/EpCost                │ 62.060001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 172.0                  │\n",
       "│ Train/Entropy                 │ 0.41371726989746094    │\n",
       "│ Train/KL                      │ 0.020298682153224945   │\n",
       "│ Train/StopIter                │ 2.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9969263076782227     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9969263076782227     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9969263076782227     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01735246181488037    │\n",
       "│ Train/LR                      │ 0.00019619999511633068 │\n",
       "│ Train/PolicyStd               │ 0.3663220703601837     │\n",
       "│ TotalEnvSteps                 │ 354304.0               │\n",
       "│ Loss/Loss_pi                  │ -0.008645014837384224  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005926487967371941   │\n",
       "│ Value/Adv                     │ 0.05358356982469559    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01841726154088974    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002301793545484543   │\n",
       "│ Value/reward                  │ 2.02655291557312       │\n",
       "│ Time/Total                    │ 2339.267822265625      │\n",
       "│ Time/Rollout                  │ 11.473101615905762     │\n",
       "│ Time/Update                   │ 0.4095313549041748     │\n",
       "│ Time/Epoch                    │ 11.882678985595703     │\n",
       "│ Time/FPS                      │ 172.3517303466797      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.94708824157715      │\n",
       "│ Metrics/EpCost                │ 64.04000091552734      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 173.0                  │\n",
       "│ Train/Entropy                 │ 0.4117113947868347     │\n",
       "│ Train/KL                      │ 0.016871260479092598   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9970195889472961     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9970195889472961     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9970195889472961     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018895799294114113   │\n",
       "│ Train/LR                      │ 0.0001956000050995499  │\n",
       "│ Train/PolicyStd               │ 0.36549681425094604    │\n",
       "│ TotalEnvSteps                 │ 356352.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016872873529791832  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.008227858692407608  │\n",
       "│ Value/Adv                     │ 0.24546538293361664    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017235441133379936   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0011818204075098038 │\n",
       "│ Value/reward                  │ 1.892032265663147      │\n",
       "│ Time/Total                    │ 2352.750244140625      │\n",
       "│ Time/Rollout                  │ 11.527533531188965     │\n",
       "│ Time/Update                   │ 1.9421744346618652     │\n",
       "│ Time/Epoch                    │ 13.469747543334961     │\n",
       "│ Time/FPS                      │ 152.04443359375        │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.94708824157715      │\n",
       "│ Metrics/EpCost                │ 64.04000091552734      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 173.0                  │\n",
       "│ Train/Entropy                 │ 0.4117113947868347     │\n",
       "│ Train/KL                      │ 0.016871260479092598   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9970195889472961     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9970195889472961     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9970195889472961     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018895799294114113   │\n",
       "│ Train/LR                      │ 0.0001956000050995499  │\n",
       "│ Train/PolicyStd               │ 0.36549681425094604    │\n",
       "│ TotalEnvSteps                 │ 356352.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016872873529791832  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.008227858692407608  │\n",
       "│ Value/Adv                     │ 0.24546538293361664    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017235441133379936   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0011818204075098038 │\n",
       "│ Value/reward                  │ 1.892032265663147      │\n",
       "│ Time/Total                    │ 2352.750244140625      │\n",
       "│ Time/Rollout                  │ 11.527533531188965     │\n",
       "│ Time/Update                   │ 1.9421744346618652     │\n",
       "│ Time/Epoch                    │ 13.469747543334961     │\n",
       "│ Time/FPS                      │ 152.04443359375        │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.963834762573242     │\n",
       "│ Metrics/EpCost                │ 63.900001525878906     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 174.0                  │\n",
       "│ Train/Entropy                 │ 0.40821418166160583    │\n",
       "│ Train/KL                      │ 0.01497822068631649    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9968472719192505     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9968472719192505     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9968472719192505     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019438480958342552   │\n",
       "│ Train/LR                      │ 0.00019500000053085387 │\n",
       "│ Train/PolicyStd               │ 0.3641461730003357     │\n",
       "│ TotalEnvSteps                 │ 358400.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014540845528244972  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0023320280015468597  │\n",
       "│ Value/Adv                     │ -0.06924748420715332   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018844377249479294   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0016089361160993576  │\n",
       "│ Value/reward                  │ 2.0603675842285156     │\n",
       "│ Time/Total                    │ 2366.053955078125      │\n",
       "│ Time/Rollout                  │ 11.432784080505371     │\n",
       "│ Time/Update                   │ 1.858428716659546      │\n",
       "│ Time/Epoch                    │ 13.291254997253418     │\n",
       "│ Time/FPS                      │ 154.08628845214844     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.963834762573242     │\n",
       "│ Metrics/EpCost                │ 63.900001525878906     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 174.0                  │\n",
       "│ Train/Entropy                 │ 0.40821418166160583    │\n",
       "│ Train/KL                      │ 0.01497822068631649    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9968472719192505     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9968472719192505     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9968472719192505     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019438480958342552   │\n",
       "│ Train/LR                      │ 0.00019500000053085387 │\n",
       "│ Train/PolicyStd               │ 0.3641461730003357     │\n",
       "│ TotalEnvSteps                 │ 358400.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014540845528244972  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0023320280015468597  │\n",
       "│ Value/Adv                     │ -0.06924748420715332   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018844377249479294   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0016089361160993576  │\n",
       "│ Value/reward                  │ 2.0603675842285156     │\n",
       "│ Time/Total                    │ 2366.053955078125      │\n",
       "│ Time/Rollout                  │ 11.432784080505371     │\n",
       "│ Time/Update                   │ 1.858428716659546      │\n",
       "│ Time/Epoch                    │ 13.291254997253418     │\n",
       "│ Time/FPS                      │ 154.08628845214844     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.0550479888916       │\n",
       "│ Metrics/EpCost                │ 63.36000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 175.0                  │\n",
       "│ Train/Entropy                 │ 0.4048083424568176     │\n",
       "│ Train/KL                      │ 0.014458490535616875   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0005637407302856     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0005637407302856     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0005637407302856     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018652917817234993   │\n",
       "│ Train/LR                      │ 0.00019439999596215785 │\n",
       "│ Train/PolicyStd               │ 0.3629475235939026     │\n",
       "│ TotalEnvSteps                 │ 360448.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01578253135085106   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0012416858226060867 │\n",
       "│ Value/Adv                     │ 0.024771826341748238   │\n",
       "│ Loss/Loss_reward_critic       │ 0.020412085577845573   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0015677083283662796  │\n",
       "│ Value/reward                  │ 1.9784412384033203     │\n",
       "│ Time/Total                    │ 2379.509765625         │\n",
       "│ Time/Rollout                  │ 11.535928726196289     │\n",
       "│ Time/Update                   │ 1.9012212753295898     │\n",
       "│ Time/Epoch                    │ 13.437196731567383     │\n",
       "│ Time/FPS                      │ 152.41275024414062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.0550479888916       │\n",
       "│ Metrics/EpCost                │ 63.36000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 175.0                  │\n",
       "│ Train/Entropy                 │ 0.4048083424568176     │\n",
       "│ Train/KL                      │ 0.014458490535616875   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0005637407302856     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0005637407302856     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0005637407302856     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018652917817234993   │\n",
       "│ Train/LR                      │ 0.00019439999596215785 │\n",
       "│ Train/PolicyStd               │ 0.3629475235939026     │\n",
       "│ TotalEnvSteps                 │ 360448.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01578253135085106   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0012416858226060867 │\n",
       "│ Value/Adv                     │ 0.024771826341748238   │\n",
       "│ Loss/Loss_reward_critic       │ 0.020412085577845573   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0015677083283662796  │\n",
       "│ Value/reward                  │ 1.9784412384033203     │\n",
       "│ Time/Total                    │ 2379.509765625         │\n",
       "│ Time/Rollout                  │ 11.535928726196289     │\n",
       "│ Time/Update                   │ 1.9012212753295898     │\n",
       "│ Time/Epoch                    │ 13.437196731567383     │\n",
       "│ Time/FPS                      │ 152.41275024414062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.306442260742188     │\n",
       "│ Metrics/EpCost                │ 62.36000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 176.0                  │\n",
       "│ Train/Entropy                 │ 0.40581029653549194    │\n",
       "│ Train/KL                      │ 0.01929229125380516    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9963699579238892     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9963699579238892     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9963699579238892     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020892014726996422   │\n",
       "│ Train/LR                      │ 0.00019380000594537705 │\n",
       "│ Train/PolicyStd               │ 0.36329227685928345    │\n",
       "│ TotalEnvSteps                 │ 362496.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01869499310851097   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002912461757659912  │\n",
       "│ Value/Adv                     │ -0.059398241341114044  │\n",
       "│ Loss/Loss_reward_critic       │ 0.021223310381174088   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0008112248033285141  │\n",
       "│ Value/reward                  │ 2.0172016620635986     │\n",
       "│ Time/Total                    │ 2392.896484375         │\n",
       "│ Time/Rollout                  │ 11.482941627502441     │\n",
       "│ Time/Update                   │ 1.8916115760803223     │\n",
       "│ Time/Epoch                    │ 13.374595642089844     │\n",
       "│ Time/FPS                      │ 153.12612915039062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.306442260742188     │\n",
       "│ Metrics/EpCost                │ 62.36000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 176.0                  │\n",
       "│ Train/Entropy                 │ 0.40581029653549194    │\n",
       "│ Train/KL                      │ 0.01929229125380516    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9963699579238892     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9963699579238892     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9963699579238892     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020892014726996422   │\n",
       "│ Train/LR                      │ 0.00019380000594537705 │\n",
       "│ Train/PolicyStd               │ 0.36329227685928345    │\n",
       "│ TotalEnvSteps                 │ 362496.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01869499310851097   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002912461757659912  │\n",
       "│ Value/Adv                     │ -0.059398241341114044  │\n",
       "│ Loss/Loss_reward_critic       │ 0.021223310381174088   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0008112248033285141  │\n",
       "│ Value/reward                  │ 2.0172016620635986     │\n",
       "│ Time/Total                    │ 2392.896484375         │\n",
       "│ Time/Rollout                  │ 11.482941627502441     │\n",
       "│ Time/Update                   │ 1.8916115760803223     │\n",
       "│ Time/Epoch                    │ 13.374595642089844     │\n",
       "│ Time/FPS                      │ 153.12612915039062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.24296760559082      │\n",
       "│ Metrics/EpCost                │ 61.58000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 177.0                  │\n",
       "│ Train/Entropy                 │ 0.40525197982788086    │\n",
       "│ Train/KL                      │ 0.015068728476762772   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9991361498832703     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9991361498832703     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9991361498832703     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017353350296616554   │\n",
       "│ Train/LR                      │ 0.00019320000137668103 │\n",
       "│ Train/PolicyStd               │ 0.36303383111953735    │\n",
       "│ TotalEnvSteps                 │ 364544.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017044711858034134  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0016502812504768372  │\n",
       "│ Value/Adv                     │ 0.11594418436288834    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01882275566458702    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0024005547165870667 │\n",
       "│ Value/reward                  │ 2.0127806663513184     │\n",
       "│ Time/Total                    │ 2406.140625            │\n",
       "│ Time/Rollout                  │ 11.392684936523438     │\n",
       "│ Time/Update                   │ 1.8383047580718994     │\n",
       "│ Time/Epoch                    │ 13.231046676635742     │\n",
       "│ Time/FPS                      │ 154.7874755859375      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.24296760559082      │\n",
       "│ Metrics/EpCost                │ 61.58000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 177.0                  │\n",
       "│ Train/Entropy                 │ 0.40525197982788086    │\n",
       "│ Train/KL                      │ 0.015068728476762772   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9991361498832703     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9991361498832703     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9991361498832703     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017353350296616554   │\n",
       "│ Train/LR                      │ 0.00019320000137668103 │\n",
       "│ Train/PolicyStd               │ 0.36303383111953735    │\n",
       "│ TotalEnvSteps                 │ 364544.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017044711858034134  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0016502812504768372  │\n",
       "│ Value/Adv                     │ 0.11594418436288834    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01882275566458702    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0024005547165870667 │\n",
       "│ Value/reward                  │ 2.0127806663513184     │\n",
       "│ Time/Total                    │ 2406.140625            │\n",
       "│ Time/Rollout                  │ 11.392684936523438     │\n",
       "│ Time/Update                   │ 1.8383047580718994     │\n",
       "│ Time/Epoch                    │ 13.231046676635742     │\n",
       "│ Time/FPS                      │ 154.7874755859375      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m8\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.334096908569336    │\n",
       "│ Metrics/EpCost                │ 60.41999816894531     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 178.0                 │\n",
       "│ Train/Entropy                 │ 0.40060505270957947   │\n",
       "│ Train/KL                      │ 0.02023918367922306   │\n",
       "│ Train/StopIter                │ 8.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9909249544143677    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9909249544143677    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9909249544143677    │\n",
       "│ Train/PolicyRatio/Std         │ 0.019394217059016228  │\n",
       "│ Train/LR                      │ 0.000192599996807985  │\n",
       "│ Train/PolicyStd               │ 0.36133331060409546   │\n",
       "│ TotalEnvSteps                 │ 366592.0              │\n",
       "│ Loss/Loss_pi                  │ -0.016965573653578758 │\n",
       "│ Loss/Loss_pi/Delta            │ 7.913820445537567e-05 │\n",
       "│ Value/Adv                     │ 0.004965383559465408  │\n",
       "│ Loss/Loss_reward_critic       │ 0.024851106107234955  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006028350442647934  │\n",
       "│ Value/reward                  │ 1.9963340759277344    │\n",
       "│ Time/Total                    │ 2419.177734375        │\n",
       "│ Time/Rollout                  │ 11.477864265441895    │\n",
       "│ Time/Update                   │ 1.544386863708496     │\n",
       "│ Time/Epoch                    │ 13.022317886352539    │\n",
       "│ Time/FPS                      │ 157.26849365234375    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.334096908569336    │\n",
       "│ Metrics/EpCost                │ 60.41999816894531     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 178.0                 │\n",
       "│ Train/Entropy                 │ 0.40060505270957947   │\n",
       "│ Train/KL                      │ 0.02023918367922306   │\n",
       "│ Train/StopIter                │ 8.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9909249544143677    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9909249544143677    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9909249544143677    │\n",
       "│ Train/PolicyRatio/Std         │ 0.019394217059016228  │\n",
       "│ Train/LR                      │ 0.000192599996807985  │\n",
       "│ Train/PolicyStd               │ 0.36133331060409546   │\n",
       "│ TotalEnvSteps                 │ 366592.0              │\n",
       "│ Loss/Loss_pi                  │ -0.016965573653578758 │\n",
       "│ Loss/Loss_pi/Delta            │ 7.913820445537567e-05 │\n",
       "│ Value/Adv                     │ 0.004965383559465408  │\n",
       "│ Loss/Loss_reward_critic       │ 0.024851106107234955  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006028350442647934  │\n",
       "│ Value/reward                  │ 1.9963340759277344    │\n",
       "│ Time/Total                    │ 2419.177734375        │\n",
       "│ Time/Rollout                  │ 11.477864265441895    │\n",
       "│ Time/Update                   │ 1.544386863708496     │\n",
       "│ Time/Epoch                    │ 13.022317886352539    │\n",
       "│ Time/FPS                      │ 157.26849365234375    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.483484268188477     │\n",
       "│ Metrics/EpCost                │ 64.13999938964844      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 179.0                  │\n",
       "│ Train/Entropy                 │ 0.4000362455844879     │\n",
       "│ Train/KL                      │ 0.013477976433932781   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0020461082458496     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0020461082458496     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0020461082458496     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018669286742806435   │\n",
       "│ Train/LR                      │ 0.00019200000679120421 │\n",
       "│ Train/PolicyStd               │ 0.36113080382347107    │\n",
       "│ TotalEnvSteps                 │ 368640.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016697006300091743  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00026856735348701477 │\n",
       "│ Value/Adv                     │ 0.01802820712327957    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02111959271132946    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0037315133959054947 │\n",
       "│ Value/reward                  │ 2.008730888366699      │\n",
       "│ Time/Total                    │ 2432.8076171875        │\n",
       "│ Time/Rollout                  │ 11.654391288757324     │\n",
       "│ Time/Update                   │ 1.959177017211914      │\n",
       "│ Time/Epoch                    │ 13.613615036010742     │\n",
       "│ Time/FPS                      │ 150.43763732910156     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.483484268188477     │\n",
       "│ Metrics/EpCost                │ 64.13999938964844      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 179.0                  │\n",
       "│ Train/Entropy                 │ 0.4000362455844879     │\n",
       "│ Train/KL                      │ 0.013477976433932781   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0020461082458496     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0020461082458496     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0020461082458496     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018669286742806435   │\n",
       "│ Train/LR                      │ 0.00019200000679120421 │\n",
       "│ Train/PolicyStd               │ 0.36113080382347107    │\n",
       "│ TotalEnvSteps                 │ 368640.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016697006300091743  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00026856735348701477 │\n",
       "│ Value/Adv                     │ 0.01802820712327957    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02111959271132946    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0037315133959054947 │\n",
       "│ Value/reward                  │ 2.008730888366699      │\n",
       "│ Time/Total                    │ 2432.8076171875        │\n",
       "│ Time/Rollout                  │ 11.654391288757324     │\n",
       "│ Time/Update                   │ 1.959177017211914      │\n",
       "│ Time/Epoch                    │ 13.613615036010742     │\n",
       "│ Time/FPS                      │ 150.43763732910156     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.094558715820312    │\n",
       "│ Metrics/EpCost                │ 63.18000030517578     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 180.0                 │\n",
       "│ Train/Entropy                 │ 0.3983564078807831    │\n",
       "│ Train/KL                      │ 0.012643290683627129  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0089186429977417    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0089186429977417    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0089186429977417    │\n",
       "│ Train/PolicyRatio/Std         │ 0.020132526755332947  │\n",
       "│ Train/LR                      │ 0.0001914000022225082 │\n",
       "│ Train/PolicyStd               │ 0.3605108857154846    │\n",
       "│ TotalEnvSteps                 │ 370688.0              │\n",
       "│ Loss/Loss_pi                  │ -0.009436091408133507 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.007260914891958237  │\n",
       "│ Value/Adv                     │ 0.1641632467508316    │\n",
       "│ Loss/Loss_reward_critic       │ 0.011795328930020332  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.009324263781309128 │\n",
       "│ Value/reward                  │ 1.8077775239944458    │\n",
       "│ Time/Total                    │ 2445.354736328125     │\n",
       "│ Time/Rollout                  │ 10.843795776367188    │\n",
       "│ Time/Update                   │ 1.6892306804656982    │\n",
       "│ Time/Epoch                    │ 12.53306770324707     │\n",
       "│ Time/FPS                      │ 163.40773010253906    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.094558715820312    │\n",
       "│ Metrics/EpCost                │ 63.18000030517578     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 180.0                 │\n",
       "│ Train/Entropy                 │ 0.3983564078807831    │\n",
       "│ Train/KL                      │ 0.012643290683627129  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0089186429977417    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0089186429977417    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0089186429977417    │\n",
       "│ Train/PolicyRatio/Std         │ 0.020132526755332947  │\n",
       "│ Train/LR                      │ 0.0001914000022225082 │\n",
       "│ Train/PolicyStd               │ 0.3605108857154846    │\n",
       "│ TotalEnvSteps                 │ 370688.0              │\n",
       "│ Loss/Loss_pi                  │ -0.009436091408133507 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.007260914891958237  │\n",
       "│ Value/Adv                     │ 0.1641632467508316    │\n",
       "│ Loss/Loss_reward_critic       │ 0.011795328930020332  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.009324263781309128 │\n",
       "│ Value/reward                  │ 1.8077775239944458    │\n",
       "│ Time/Total                    │ 2445.354736328125     │\n",
       "│ Time/Rollout                  │ 10.843795776367188    │\n",
       "│ Time/Update                   │ 1.6892306804656982    │\n",
       "│ Time/Epoch                    │ 12.53306770324707     │\n",
       "│ Time/FPS                      │ 163.40773010253906    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.036802291870117     │\n",
       "│ Metrics/EpCost                │ 64.68000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 181.0                  │\n",
       "│ Train/Entropy                 │ 0.3922256827354431     │\n",
       "│ Train/KL                      │ 0.01588415540754795    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.002852201461792      │\n",
       "│ Train/PolicyRatio/Min         │ 1.002852201461792      │\n",
       "│ Train/PolicyRatio/Max         │ 1.002852201461792      │\n",
       "│ Train/PolicyRatio/Std         │ 0.01887936145067215    │\n",
       "│ Train/LR                      │ 0.00019079999765381217 │\n",
       "│ Train/PolicyStd               │ 0.3582810163497925     │\n",
       "│ TotalEnvSteps                 │ 372736.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01410492043942213   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004668829031288624  │\n",
       "│ Value/Adv                     │ 0.06277504563331604    │\n",
       "│ Loss/Loss_reward_critic       │ 0.014861921779811382   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00306659284979105    │\n",
       "│ Value/reward                  │ 1.9261449575424194     │\n",
       "│ Time/Total                    │ 2457.773681640625      │\n",
       "│ Time/Rollout                  │ 10.721071243286133     │\n",
       "│ Time/Update                   │ 1.6864190101623535     │\n",
       "│ Time/Epoch                    │ 12.407533645629883     │\n",
       "│ Time/FPS                      │ 165.06101989746094     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.036802291870117     │\n",
       "│ Metrics/EpCost                │ 64.68000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 181.0                  │\n",
       "│ Train/Entropy                 │ 0.3922256827354431     │\n",
       "│ Train/KL                      │ 0.01588415540754795    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.002852201461792      │\n",
       "│ Train/PolicyRatio/Min         │ 1.002852201461792      │\n",
       "│ Train/PolicyRatio/Max         │ 1.002852201461792      │\n",
       "│ Train/PolicyRatio/Std         │ 0.01887936145067215    │\n",
       "│ Train/LR                      │ 0.00019079999765381217 │\n",
       "│ Train/PolicyStd               │ 0.3582810163497925     │\n",
       "│ TotalEnvSteps                 │ 372736.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01410492043942213   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004668829031288624  │\n",
       "│ Value/Adv                     │ 0.06277504563331604    │\n",
       "│ Loss/Loss_reward_critic       │ 0.014861921779811382   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00306659284979105    │\n",
       "│ Value/reward                  │ 1.9261449575424194     │\n",
       "│ Time/Total                    │ 2457.773681640625      │\n",
       "│ Time/Rollout                  │ 10.721071243286133     │\n",
       "│ Time/Update                   │ 1.6864190101623535     │\n",
       "│ Time/Epoch                    │ 12.407533645629883     │\n",
       "│ Time/FPS                      │ 165.06101989746094     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m8\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.996356964111328     │\n",
       "│ Metrics/EpCost                │ 65.23999786376953      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 182.0                  │\n",
       "│ Train/Entropy                 │ 0.38577818870544434    │\n",
       "│ Train/KL                      │ 0.02073834091424942    │\n",
       "│ Train/StopIter                │ 8.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9942731857299805     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9942731857299805     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9942731857299805     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019760116934776306   │\n",
       "│ Train/LR                      │ 0.00019019999308511615 │\n",
       "│ Train/PolicyStd               │ 0.3559686243534088     │\n",
       "│ TotalEnvSteps                 │ 374784.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017188785597682     │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0030838651582598686 │\n",
       "│ Value/Adv                     │ 0.11114269495010376    │\n",
       "│ Loss/Loss_reward_critic       │ 0.016094990074634552   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0012330682948231697  │\n",
       "│ Value/reward                  │ 1.8906713724136353     │\n",
       "│ Time/Total                    │ 2469.892578125         │\n",
       "│ Time/Rollout                  │ 10.784565925598145     │\n",
       "│ Time/Update                   │ 1.3228299617767334     │\n",
       "│ Time/Epoch                    │ 12.10744571685791      │\n",
       "│ Time/FPS                      │ 169.15213012695312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.996356964111328     │\n",
       "│ Metrics/EpCost                │ 65.23999786376953      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 182.0                  │\n",
       "│ Train/Entropy                 │ 0.38577818870544434    │\n",
       "│ Train/KL                      │ 0.02073834091424942    │\n",
       "│ Train/StopIter                │ 8.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9942731857299805     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9942731857299805     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9942731857299805     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019760116934776306   │\n",
       "│ Train/LR                      │ 0.00019019999308511615 │\n",
       "│ Train/PolicyStd               │ 0.3559686243534088     │\n",
       "│ TotalEnvSteps                 │ 374784.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017188785597682     │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0030838651582598686 │\n",
       "│ Value/Adv                     │ 0.11114269495010376    │\n",
       "│ Loss/Loss_reward_critic       │ 0.016094990074634552   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0012330682948231697  │\n",
       "│ Value/reward                  │ 1.8906713724136353     │\n",
       "│ Time/Total                    │ 2469.892578125         │\n",
       "│ Time/Rollout                  │ 10.784565925598145     │\n",
       "│ Time/Update                   │ 1.3228299617767334     │\n",
       "│ Time/Epoch                    │ 12.10744571685791      │\n",
       "│ Time/FPS                      │ 169.15213012695312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.809898376464844     │\n",
       "│ Metrics/EpCost                │ 65.05999755859375      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 183.0                  │\n",
       "│ Train/Entropy                 │ 0.3842668831348419     │\n",
       "│ Train/KL                      │ 0.01177377812564373    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9957334399223328     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9957334399223328     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9957334399223328     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01870904117822647    │\n",
       "│ Train/LR                      │ 0.00018960000306833535 │\n",
       "│ Train/PolicyStd               │ 0.3554709553718567     │\n",
       "│ TotalEnvSteps                 │ 376832.0               │\n",
       "│ Loss/Loss_pi                  │ -0.010045749135315418  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.007143036462366581   │\n",
       "│ Value/Adv                     │ -0.07469336688518524   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014617906883358955   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0014770831912755966 │\n",
       "│ Value/reward                  │ 1.6943161487579346     │\n",
       "│ Time/Total                    │ 2482.42236328125       │\n",
       "│ Time/Rollout                  │ 10.841630935668945     │\n",
       "│ Time/Update                   │ 1.6757688522338867     │\n",
       "│ Time/Epoch                    │ 12.517452239990234     │\n",
       "│ Time/FPS                      │ 163.611572265625       │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.809898376464844     │\n",
       "│ Metrics/EpCost                │ 65.05999755859375      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 183.0                  │\n",
       "│ Train/Entropy                 │ 0.3842668831348419     │\n",
       "│ Train/KL                      │ 0.01177377812564373    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9957334399223328     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9957334399223328     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9957334399223328     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01870904117822647    │\n",
       "│ Train/LR                      │ 0.00018960000306833535 │\n",
       "│ Train/PolicyStd               │ 0.3554709553718567     │\n",
       "│ TotalEnvSteps                 │ 376832.0               │\n",
       "│ Loss/Loss_pi                  │ -0.010045749135315418  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.007143036462366581   │\n",
       "│ Value/Adv                     │ -0.07469336688518524   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014617906883358955   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0014770831912755966 │\n",
       "│ Value/reward                  │ 1.6943161487579346     │\n",
       "│ Time/Total                    │ 2482.42236328125       │\n",
       "│ Time/Rollout                  │ 10.841630935668945     │\n",
       "│ Time/Update                   │ 1.6757688522338867     │\n",
       "│ Time/Epoch                    │ 12.517452239990234     │\n",
       "│ Time/FPS                      │ 163.611572265625       │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.846925735473633     │\n",
       "│ Metrics/EpCost                │ 65.31999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 184.0                  │\n",
       "│ Train/Entropy                 │ 0.38231077790260315    │\n",
       "│ Train/KL                      │ 0.014847616665065289   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.998776912689209      │\n",
       "│ Train/PolicyRatio/Min         │ 0.998776912689209      │\n",
       "│ Train/PolicyRatio/Max         │ 0.998776912689209      │\n",
       "│ Train/PolicyRatio/Std         │ 0.018215954303741455   │\n",
       "│ Train/LR                      │ 0.00018899999849963933 │\n",
       "│ Train/PolicyStd               │ 0.35479074716567993    │\n",
       "│ TotalEnvSteps                 │ 378880.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014033274725079536  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.003987525589764118  │\n",
       "│ Value/Adv                     │ 0.10575798898935318    │\n",
       "│ Loss/Loss_reward_critic       │ 0.015438690781593323   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0008207838982343674  │\n",
       "│ Value/reward                  │ 1.74810791015625       │\n",
       "│ Time/Total                    │ 2494.897705078125      │\n",
       "│ Time/Rollout                  │ 10.731721878051758     │\n",
       "│ Time/Update                   │ 1.7321889400482178     │\n",
       "│ Time/Epoch                    │ 12.463953018188477     │\n",
       "│ Time/FPS                      │ 164.31385803222656     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.846925735473633     │\n",
       "│ Metrics/EpCost                │ 65.31999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 184.0                  │\n",
       "│ Train/Entropy                 │ 0.38231077790260315    │\n",
       "│ Train/KL                      │ 0.014847616665065289   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.998776912689209      │\n",
       "│ Train/PolicyRatio/Min         │ 0.998776912689209      │\n",
       "│ Train/PolicyRatio/Max         │ 0.998776912689209      │\n",
       "│ Train/PolicyRatio/Std         │ 0.018215954303741455   │\n",
       "│ Train/LR                      │ 0.00018899999849963933 │\n",
       "│ Train/PolicyStd               │ 0.35479074716567993    │\n",
       "│ TotalEnvSteps                 │ 378880.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014033274725079536  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.003987525589764118  │\n",
       "│ Value/Adv                     │ 0.10575798898935318    │\n",
       "│ Loss/Loss_reward_critic       │ 0.015438690781593323   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0008207838982343674  │\n",
       "│ Value/reward                  │ 1.74810791015625       │\n",
       "│ Time/Total                    │ 2494.897705078125      │\n",
       "│ Time/Rollout                  │ 10.731721878051758     │\n",
       "│ Time/Update                   │ 1.7321889400482178     │\n",
       "│ Time/Epoch                    │ 12.463953018188477     │\n",
       "│ Time/FPS                      │ 164.31385803222656     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.917512893676758     │\n",
       "│ Metrics/EpCost                │ 63.29999923706055      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 185.0                  │\n",
       "│ Train/Entropy                 │ 0.3768491744995117     │\n",
       "│ Train/KL                      │ 0.014816505834460258   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9999017715454102     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9999017715454102     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9999017715454102     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020054765045642853   │\n",
       "│ Train/LR                      │ 0.0001883999939309433  │\n",
       "│ Train/PolicyStd               │ 0.3528251051902771     │\n",
       "│ TotalEnvSteps                 │ 380928.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016073724254965782  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0020404495298862457 │\n",
       "│ Value/Adv                     │ 0.08953915536403656    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02187911793589592    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006440427154302597   │\n",
       "│ Value/reward                  │ 1.9515395164489746     │\n",
       "│ Time/Total                    │ 2507.3310546875        │\n",
       "│ Time/Rollout                  │ 10.766372680664062     │\n",
       "│ Time/Update                   │ 1.6553337574005127     │\n",
       "│ Time/Epoch                    │ 12.421754837036133     │\n",
       "│ Time/FPS                      │ 164.87203979492188     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 18.917512893676758     │\n",
       "│ Metrics/EpCost                │ 63.29999923706055      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 185.0                  │\n",
       "│ Train/Entropy                 │ 0.3768491744995117     │\n",
       "│ Train/KL                      │ 0.014816505834460258   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9999017715454102     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9999017715454102     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9999017715454102     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020054765045642853   │\n",
       "│ Train/LR                      │ 0.0001883999939309433  │\n",
       "│ Train/PolicyStd               │ 0.3528251051902771     │\n",
       "│ TotalEnvSteps                 │ 380928.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016073724254965782  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0020404495298862457 │\n",
       "│ Value/Adv                     │ 0.08953915536403656    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02187911793589592    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006440427154302597   │\n",
       "│ Value/reward                  │ 1.9515395164489746     │\n",
       "│ Time/Total                    │ 2507.3310546875        │\n",
       "│ Time/Rollout                  │ 10.766372680664062     │\n",
       "│ Time/Update                   │ 1.6553337574005127     │\n",
       "│ Time/Epoch                    │ 12.421754837036133     │\n",
       "│ Time/FPS                      │ 164.87203979492188     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.24421501159668      │\n",
       "│ Metrics/EpCost                │ 61.81999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 186.0                  │\n",
       "│ Train/Entropy                 │ 0.37258267402648926    │\n",
       "│ Train/KL                      │ 0.01368868537247181    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0020779371261597     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0020779371261597     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0020779371261597     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01918935589492321    │\n",
       "│ Train/LR                      │ 0.00018780000391416252 │\n",
       "│ Train/PolicyStd               │ 0.3512951731681824     │\n",
       "│ TotalEnvSteps                 │ 382976.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013731533661484718  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002342190593481064   │\n",
       "│ Value/Adv                     │ -0.14222240447998047   │\n",
       "│ Loss/Loss_reward_critic       │ 0.019542310386896133   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0023368075489997864 │\n",
       "│ Value/reward                  │ 2.1137583255767822     │\n",
       "│ Time/Total                    │ 2519.83544921875       │\n",
       "│ Time/Rollout                  │ 10.838275909423828     │\n",
       "│ Time/Update                   │ 1.654144048690796      │\n",
       "│ Time/Epoch                    │ 12.492469787597656     │\n",
       "│ Time/FPS                      │ 163.93878173828125     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.24421501159668      │\n",
       "│ Metrics/EpCost                │ 61.81999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 186.0                  │\n",
       "│ Train/Entropy                 │ 0.37258267402648926    │\n",
       "│ Train/KL                      │ 0.01368868537247181    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0020779371261597     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0020779371261597     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0020779371261597     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01918935589492321    │\n",
       "│ Train/LR                      │ 0.00018780000391416252 │\n",
       "│ Train/PolicyStd               │ 0.3512951731681824     │\n",
       "│ TotalEnvSteps                 │ 382976.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013731533661484718  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002342190593481064   │\n",
       "│ Value/Adv                     │ -0.14222240447998047   │\n",
       "│ Loss/Loss_reward_critic       │ 0.019542310386896133   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0023368075489997864 │\n",
       "│ Value/reward                  │ 2.1137583255767822     │\n",
       "│ Time/Total                    │ 2519.83544921875       │\n",
       "│ Time/Rollout                  │ 10.838275909423828     │\n",
       "│ Time/Update                   │ 1.654144048690796      │\n",
       "│ Time/Epoch                    │ 12.492469787597656     │\n",
       "│ Time/FPS                      │ 163.93878173828125     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.278831481933594     │\n",
       "│ Metrics/EpCost                │ 61.36000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 187.0                  │\n",
       "│ Train/Entropy                 │ 0.36651962995529175    │\n",
       "│ Train/KL                      │ 0.013220313936471939   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9990077018737793     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9990077018737793     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9990077018737793     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01829148270189762    │\n",
       "│ Train/LR                      │ 0.0001871999993454665  │\n",
       "│ Train/PolicyStd               │ 0.3491443693637848     │\n",
       "│ TotalEnvSteps                 │ 385024.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013823133893311024  │\n",
       "│ Loss/Loss_pi/Delta            │ -9.160023182630539e-05 │\n",
       "│ Value/Adv                     │ 0.02123156748712063    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01809949427843094    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0014428161084651947 │\n",
       "│ Value/reward                  │ 2.0480904579162598     │\n",
       "│ Time/Total                    │ 2532.373779296875      │\n",
       "│ Time/Rollout                  │ 10.816712379455566     │\n",
       "│ Time/Update                   │ 1.709892749786377      │\n",
       "│ Time/Epoch                    │ 12.526647567749023     │\n",
       "│ Time/FPS                      │ 163.49147033691406     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.278831481933594     │\n",
       "│ Metrics/EpCost                │ 61.36000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 187.0                  │\n",
       "│ Train/Entropy                 │ 0.36651962995529175    │\n",
       "│ Train/KL                      │ 0.013220313936471939   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9990077018737793     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9990077018737793     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9990077018737793     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01829148270189762    │\n",
       "│ Train/LR                      │ 0.0001871999993454665  │\n",
       "│ Train/PolicyStd               │ 0.3491443693637848     │\n",
       "│ TotalEnvSteps                 │ 385024.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013823133893311024  │\n",
       "│ Loss/Loss_pi/Delta            │ -9.160023182630539e-05 │\n",
       "│ Value/Adv                     │ 0.02123156748712063    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01809949427843094    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0014428161084651947 │\n",
       "│ Value/reward                  │ 2.0480904579162598     │\n",
       "│ Time/Total                    │ 2532.373779296875      │\n",
       "│ Time/Rollout                  │ 10.816712379455566     │\n",
       "│ Time/Update                   │ 1.709892749786377      │\n",
       "│ Time/Epoch                    │ 12.526647567749023     │\n",
       "│ Time/FPS                      │ 163.49147033691406     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.224712371826172     │\n",
       "│ Metrics/EpCost                │ 60.099998474121094     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 188.0                  │\n",
       "│ Train/Entropy                 │ 0.3553312122821808     │\n",
       "│ Train/KL                      │ 0.011845656670629978   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9987077713012695     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9987077713012695     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9987077713012695     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017274118959903717   │\n",
       "│ Train/LR                      │ 0.00018659999477677047 │\n",
       "│ Train/PolicyStd               │ 0.34524276852607727    │\n",
       "│ TotalEnvSteps                 │ 387072.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01583067700266838   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002007543109357357  │\n",
       "│ Value/Adv                     │ -0.031306080520153046  │\n",
       "│ Loss/Loss_reward_critic       │ 0.013685139827430248   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0044143544510006905 │\n",
       "│ Value/reward                  │ 2.0367181301116943     │\n",
       "│ Time/Total                    │ 2544.810302734375      │\n",
       "│ Time/Rollout                  │ 10.755857467651367     │\n",
       "│ Time/Update                   │ 1.6692421436309814     │\n",
       "│ Time/Epoch                    │ 12.42514419555664      │\n",
       "│ Time/FPS                      │ 164.8270721435547      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.224712371826172     │\n",
       "│ Metrics/EpCost                │ 60.099998474121094     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 188.0                  │\n",
       "│ Train/Entropy                 │ 0.3553312122821808     │\n",
       "│ Train/KL                      │ 0.011845656670629978   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9987077713012695     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9987077713012695     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9987077713012695     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017274118959903717   │\n",
       "│ Train/LR                      │ 0.00018659999477677047 │\n",
       "│ Train/PolicyStd               │ 0.34524276852607727    │\n",
       "│ TotalEnvSteps                 │ 387072.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01583067700266838   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002007543109357357  │\n",
       "│ Value/Adv                     │ -0.031306080520153046  │\n",
       "│ Loss/Loss_reward_critic       │ 0.013685139827430248   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0044143544510006905 │\n",
       "│ Value/reward                  │ 2.0367181301116943     │\n",
       "│ Time/Total                    │ 2544.810302734375      │\n",
       "│ Time/Rollout                  │ 10.755857467651367     │\n",
       "│ Time/Update                   │ 1.6692421436309814     │\n",
       "│ Time/Epoch                    │ 12.42514419555664      │\n",
       "│ Time/FPS                      │ 164.8270721435547      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.319135665893555     │\n",
       "│ Metrics/EpCost                │ 59.900001525878906     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 189.0                  │\n",
       "│ Train/Entropy                 │ 0.34646931290626526    │\n",
       "│ Train/KL                      │ 0.016413036733865738   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9958537220954895     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9958537220954895     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9958537220954895     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018218809738755226   │\n",
       "│ Train/LR                      │ 0.00018600000475998968 │\n",
       "│ Train/PolicyStd               │ 0.3422123193740845     │\n",
       "│ TotalEnvSteps                 │ 389120.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014295436441898346  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0015352405607700348  │\n",
       "│ Value/Adv                     │ 0.1751924753189087     │\n",
       "│ Loss/Loss_reward_critic       │ 0.01942424103617668    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.005739101208746433   │\n",
       "│ Value/reward                  │ 2.101694107055664      │\n",
       "│ Time/Total                    │ 2557.302978515625      │\n",
       "│ Time/Rollout                  │ 10.77690601348877      │\n",
       "│ Time/Update                   │ 1.7039520740509033     │\n",
       "│ Time/Epoch                    │ 12.480899810791016     │\n",
       "│ Time/FPS                      │ 164.0907440185547      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.319135665893555     │\n",
       "│ Metrics/EpCost                │ 59.900001525878906     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 189.0                  │\n",
       "│ Train/Entropy                 │ 0.34646931290626526    │\n",
       "│ Train/KL                      │ 0.016413036733865738   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9958537220954895     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9958537220954895     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9958537220954895     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018218809738755226   │\n",
       "│ Train/LR                      │ 0.00018600000475998968 │\n",
       "│ Train/PolicyStd               │ 0.3422123193740845     │\n",
       "│ TotalEnvSteps                 │ 389120.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014295436441898346  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0015352405607700348  │\n",
       "│ Value/Adv                     │ 0.1751924753189087     │\n",
       "│ Loss/Loss_reward_critic       │ 0.01942424103617668    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.005739101208746433   │\n",
       "│ Value/reward                  │ 2.101694107055664      │\n",
       "│ Time/Total                    │ 2557.302978515625      │\n",
       "│ Time/Rollout                  │ 10.77690601348877      │\n",
       "│ Time/Update                   │ 1.7039520740509033     │\n",
       "│ Time/Epoch                    │ 12.480899810791016     │\n",
       "│ Time/FPS                      │ 164.0907440185547      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.384872436523438     │\n",
       "│ Metrics/EpCost                │ 58.380001068115234     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 190.0                  │\n",
       "│ Train/Entropy                 │ 0.3407679796218872     │\n",
       "│ Train/KL                      │ 0.015041520819067955   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9955713152885437     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9955713152885437     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9955713152885437     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019722197204828262   │\n",
       "│ Train/LR                      │ 0.00018540000019129366 │\n",
       "│ Train/PolicyStd               │ 0.3402829170227051     │\n",
       "│ TotalEnvSteps                 │ 391168.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01372529100626707   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0005701454356312752  │\n",
       "│ Value/Adv                     │ -0.02259369194507599   │\n",
       "│ Loss/Loss_reward_critic       │ 0.021371325477957726   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.001947084441781044   │\n",
       "│ Value/reward                  │ 2.1095635890960693     │\n",
       "│ Time/Total                    │ 2569.72216796875       │\n",
       "│ Time/Rollout                  │ 10.759881973266602     │\n",
       "│ Time/Update                   │ 1.646533727645874      │\n",
       "│ Time/Epoch                    │ 12.40645980834961      │\n",
       "│ Time/FPS                      │ 165.07530212402344     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.384872436523438     │\n",
       "│ Metrics/EpCost                │ 58.380001068115234     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 190.0                  │\n",
       "│ Train/Entropy                 │ 0.3407679796218872     │\n",
       "│ Train/KL                      │ 0.015041520819067955   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9955713152885437     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9955713152885437     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9955713152885437     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019722197204828262   │\n",
       "│ Train/LR                      │ 0.00018540000019129366 │\n",
       "│ Train/PolicyStd               │ 0.3402829170227051     │\n",
       "│ TotalEnvSteps                 │ 391168.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01372529100626707   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0005701454356312752  │\n",
       "│ Value/Adv                     │ -0.02259369194507599   │\n",
       "│ Loss/Loss_reward_critic       │ 0.021371325477957726   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.001947084441781044   │\n",
       "│ Value/reward                  │ 2.1095635890960693     │\n",
       "│ Time/Total                    │ 2569.72216796875       │\n",
       "│ Time/Rollout                  │ 10.759881973266602     │\n",
       "│ Time/Update                   │ 1.646533727645874      │\n",
       "│ Time/Epoch                    │ 12.40645980834961      │\n",
       "│ Time/FPS                      │ 165.07530212402344     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m8\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.40802001953125      │\n",
       "│ Metrics/EpCost                │ 57.380001068115234     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 191.0                  │\n",
       "│ Train/Entropy                 │ 0.33381155133247375    │\n",
       "│ Train/KL                      │ 0.0207130778580904     │\n",
       "│ Train/StopIter                │ 8.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9957500696182251     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9957500696182251     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9957500696182251     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020156417042016983   │\n",
       "│ Train/LR                      │ 0.00018479999562259763 │\n",
       "│ Train/PolicyStd               │ 0.33793607354164124    │\n",
       "│ TotalEnvSteps                 │ 393216.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012740099802613258  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0009851912036538124  │\n",
       "│ Value/Adv                     │ -0.09592238068580627   │\n",
       "│ Loss/Loss_reward_critic       │ 0.028638241812586784   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.007266916334629059   │\n",
       "│ Value/reward                  │ 2.0308339595794678     │\n",
       "│ Time/Total                    │ 2581.9052734375        │\n",
       "│ Time/Rollout                  │ 10.797100067138672     │\n",
       "│ Time/Update                   │ 1.3744194507598877     │\n",
       "│ Time/Epoch                    │ 12.171579360961914     │\n",
       "│ Time/FPS                      │ 168.26084899902344     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.40802001953125      │\n",
       "│ Metrics/EpCost                │ 57.380001068115234     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 191.0                  │\n",
       "│ Train/Entropy                 │ 0.33381155133247375    │\n",
       "│ Train/KL                      │ 0.0207130778580904     │\n",
       "│ Train/StopIter                │ 8.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9957500696182251     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9957500696182251     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9957500696182251     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020156417042016983   │\n",
       "│ Train/LR                      │ 0.00018479999562259763 │\n",
       "│ Train/PolicyStd               │ 0.33793607354164124    │\n",
       "│ TotalEnvSteps                 │ 393216.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012740099802613258  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0009851912036538124  │\n",
       "│ Value/Adv                     │ -0.09592238068580627   │\n",
       "│ Loss/Loss_reward_critic       │ 0.028638241812586784   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.007266916334629059   │\n",
       "│ Value/reward                  │ 2.0308339595794678     │\n",
       "│ Time/Total                    │ 2581.9052734375        │\n",
       "│ Time/Rollout                  │ 10.797100067138672     │\n",
       "│ Time/Update                   │ 1.3744194507598877     │\n",
       "│ Time/Epoch                    │ 12.171579360961914     │\n",
       "│ Time/FPS                      │ 168.26084899902344     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.10619354248047      │\n",
       "│ Metrics/EpCost                │ 54.900001525878906     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 192.0                  │\n",
       "│ Train/Entropy                 │ 0.32330071926116943    │\n",
       "│ Train/KL                      │ 0.01610976830124855    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0044915676116943     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0044915676116943     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0044915676116943     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018754376098513603   │\n",
       "│ Train/LR                      │ 0.00018420000560581684 │\n",
       "│ Train/PolicyStd               │ 0.33441033959388733    │\n",
       "│ TotalEnvSteps                 │ 395264.0               │\n",
       "│ Loss/Loss_pi                  │ -0.008801104500889778  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00393899530172348    │\n",
       "│ Value/Adv                     │ 0.10371644794940948    │\n",
       "│ Loss/Loss_reward_critic       │ 0.016544250771403313   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.012093991041183472  │\n",
       "│ Value/reward                  │ 1.7684885263442993     │\n",
       "│ Time/Total                    │ 2594.3291015625        │\n",
       "│ Time/Rollout                  │ 10.774240493774414     │\n",
       "│ Time/Update                   │ 1.637364387512207      │\n",
       "│ Time/Epoch                    │ 12.411648750305176     │\n",
       "│ Time/FPS                      │ 165.00628662109375     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.10619354248047      │\n",
       "│ Metrics/EpCost                │ 54.900001525878906     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 192.0                  │\n",
       "│ Train/Entropy                 │ 0.32330071926116943    │\n",
       "│ Train/KL                      │ 0.01610976830124855    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0044915676116943     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0044915676116943     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0044915676116943     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018754376098513603   │\n",
       "│ Train/LR                      │ 0.00018420000560581684 │\n",
       "│ Train/PolicyStd               │ 0.33441033959388733    │\n",
       "│ TotalEnvSteps                 │ 395264.0               │\n",
       "│ Loss/Loss_pi                  │ -0.008801104500889778  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00393899530172348    │\n",
       "│ Value/Adv                     │ 0.10371644794940948    │\n",
       "│ Loss/Loss_reward_critic       │ 0.016544250771403313   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.012093991041183472  │\n",
       "│ Value/reward                  │ 1.7684885263442993     │\n",
       "│ Time/Total                    │ 2594.3291015625        │\n",
       "│ Time/Rollout                  │ 10.774240493774414     │\n",
       "│ Time/Update                   │ 1.637364387512207      │\n",
       "│ Time/Epoch                    │ 12.411648750305176     │\n",
       "│ Time/FPS                      │ 165.00628662109375     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.48880386352539      │\n",
       "│ Metrics/EpCost                │ 54.619998931884766     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 193.0                  │\n",
       "│ Train/Entropy                 │ 0.3158549666404724     │\n",
       "│ Train/KL                      │ 0.018276169896125793   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0038821697235107     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0038821697235107     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0038821697235107     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020341869443655014   │\n",
       "│ Train/LR                      │ 0.00018360000103712082 │\n",
       "│ Train/PolicyStd               │ 0.33189600706100464    │\n",
       "│ TotalEnvSteps                 │ 397312.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016072146594524384  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.007271042093634605  │\n",
       "│ Value/Adv                     │ -0.06809203326702118   │\n",
       "│ Loss/Loss_reward_critic       │ 0.017739316448569298   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.001195065677165985   │\n",
       "│ Value/reward                  │ 2.0860342979431152     │\n",
       "│ Time/Total                    │ 2606.742919921875      │\n",
       "│ Time/Rollout                  │ 10.736291885375977     │\n",
       "│ Time/Update                   │ 1.6660182476043701     │\n",
       "│ Time/Epoch                    │ 12.40235424041748      │\n",
       "│ Time/FPS                      │ 165.1299591064453      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.48880386352539      │\n",
       "│ Metrics/EpCost                │ 54.619998931884766     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 193.0                  │\n",
       "│ Train/Entropy                 │ 0.3158549666404724     │\n",
       "│ Train/KL                      │ 0.018276169896125793   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0038821697235107     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0038821697235107     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0038821697235107     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020341869443655014   │\n",
       "│ Train/LR                      │ 0.00018360000103712082 │\n",
       "│ Train/PolicyStd               │ 0.33189600706100464    │\n",
       "│ TotalEnvSteps                 │ 397312.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016072146594524384  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.007271042093634605  │\n",
       "│ Value/Adv                     │ -0.06809203326702118   │\n",
       "│ Loss/Loss_reward_critic       │ 0.017739316448569298   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.001195065677165985   │\n",
       "│ Value/reward                  │ 2.0860342979431152     │\n",
       "│ Time/Total                    │ 2606.742919921875      │\n",
       "│ Time/Rollout                  │ 10.736291885375977     │\n",
       "│ Time/Update                   │ 1.6660182476043701     │\n",
       "│ Time/Epoch                    │ 12.40235424041748      │\n",
       "│ Time/FPS                      │ 165.1299591064453      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.355682373046875     │\n",
       "│ Metrics/EpCost                │ 52.84000015258789      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 194.0                  │\n",
       "│ Train/Entropy                 │ 0.31331655383110046    │\n",
       "│ Train/KL                      │ 0.010501500219106674   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0042023658752441     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0042023658752441     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0042023658752441     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01603005640208721    │\n",
       "│ Train/LR                      │ 0.0001829999964684248  │\n",
       "│ Train/PolicyStd               │ 0.33102908730506897    │\n",
       "│ TotalEnvSteps                 │ 399360.0               │\n",
       "│ Loss/Loss_pi                  │ -0.010940153151750565  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005131993442773819   │\n",
       "│ Value/Adv                     │ -0.12539242208003998   │\n",
       "│ Loss/Loss_reward_critic       │ 0.016859937459230423   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0008793789893388748 │\n",
       "│ Value/reward                  │ 1.908819317817688      │\n",
       "│ Time/Total                    │ 2619.18798828125       │\n",
       "│ Time/Rollout                  │ 10.785877227783203     │\n",
       "│ Time/Update                   │ 1.64750075340271       │\n",
       "│ Time/Epoch                    │ 12.433430671691895     │\n",
       "│ Time/FPS                      │ 164.71722412109375     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.355682373046875     │\n",
       "│ Metrics/EpCost                │ 52.84000015258789      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 194.0                  │\n",
       "│ Train/Entropy                 │ 0.31331655383110046    │\n",
       "│ Train/KL                      │ 0.010501500219106674   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0042023658752441     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0042023658752441     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0042023658752441     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01603005640208721    │\n",
       "│ Train/LR                      │ 0.0001829999964684248  │\n",
       "│ Train/PolicyStd               │ 0.33102908730506897    │\n",
       "│ TotalEnvSteps                 │ 399360.0               │\n",
       "│ Loss/Loss_pi                  │ -0.010940153151750565  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005131993442773819   │\n",
       "│ Value/Adv                     │ -0.12539242208003998   │\n",
       "│ Loss/Loss_reward_critic       │ 0.016859937459230423   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0008793789893388748 │\n",
       "│ Value/reward                  │ 1.908819317817688      │\n",
       "│ Time/Total                    │ 2619.18798828125       │\n",
       "│ Time/Rollout                  │ 10.785877227783203     │\n",
       "│ Time/Update                   │ 1.64750075340271       │\n",
       "│ Time/Epoch                    │ 12.433430671691895     │\n",
       "│ Time/FPS                      │ 164.71722412109375     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.486099243164062    │\n",
       "│ Metrics/EpCost                │ 54.08000183105469     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 195.0                 │\n",
       "│ Train/Entropy                 │ 0.31061798334121704   │\n",
       "│ Train/KL                      │ 0.01701204665005207   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9988853335380554    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9988853335380554    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9988853335380554    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01966492272913456   │\n",
       "│ Train/LR                      │ 0.000182400006451644  │\n",
       "│ Train/PolicyStd               │ 0.3301277756690979    │\n",
       "│ TotalEnvSteps                 │ 401408.0              │\n",
       "│ Loss/Loss_pi                  │ -0.02022797241806984  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.009287819266319275 │\n",
       "│ Value/Adv                     │ 0.1484183967113495    │\n",
       "│ Loss/Loss_reward_critic       │ 0.022399717941880226  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.005539780482649803  │\n",
       "│ Value/reward                  │ 2.172093391418457     │\n",
       "│ Time/Total                    │ 2631.7119140625       │\n",
       "│ Time/Rollout                  │ 10.810405731201172    │\n",
       "│ Time/Update                   │ 1.7013511657714844    │\n",
       "│ Time/Epoch                    │ 12.511807441711426    │\n",
       "│ Time/FPS                      │ 163.68539428710938    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.486099243164062    │\n",
       "│ Metrics/EpCost                │ 54.08000183105469     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 195.0                 │\n",
       "│ Train/Entropy                 │ 0.31061798334121704   │\n",
       "│ Train/KL                      │ 0.01701204665005207   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9988853335380554    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9988853335380554    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9988853335380554    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01966492272913456   │\n",
       "│ Train/LR                      │ 0.000182400006451644  │\n",
       "│ Train/PolicyStd               │ 0.3301277756690979    │\n",
       "│ TotalEnvSteps                 │ 401408.0              │\n",
       "│ Loss/Loss_pi                  │ -0.02022797241806984  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.009287819266319275 │\n",
       "│ Value/Adv                     │ 0.1484183967113495    │\n",
       "│ Loss/Loss_reward_critic       │ 0.022399717941880226  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.005539780482649803  │\n",
       "│ Value/reward                  │ 2.172093391418457     │\n",
       "│ Time/Total                    │ 2631.7119140625       │\n",
       "│ Time/Rollout                  │ 10.810405731201172    │\n",
       "│ Time/Update                   │ 1.7013511657714844    │\n",
       "│ Time/Epoch                    │ 12.511807441711426    │\n",
       "│ Time/FPS                      │ 163.68539428710938    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.67613983154297      │\n",
       "│ Metrics/EpCost                │ 51.79999923706055      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 196.0                  │\n",
       "│ Train/Entropy                 │ 0.30703410506248474    │\n",
       "│ Train/KL                      │ 0.01201079972088337    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9924005270004272     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9924005270004272     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9924005270004272     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018574513494968414   │\n",
       "│ Train/LR                      │ 0.00018180000188294798 │\n",
       "│ Train/PolicyStd               │ 0.3289436399936676     │\n",
       "│ TotalEnvSteps                 │ 403456.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014656019397079945  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005571953020989895   │\n",
       "│ Value/Adv                     │ -0.029067134484648705  │\n",
       "│ Loss/Loss_reward_critic       │ 0.02627946436405182    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0038797464221715927  │\n",
       "│ Value/reward                  │ 2.1099865436553955     │\n",
       "│ Time/Total                    │ 2644.20556640625       │\n",
       "│ Time/Rollout                  │ 10.800329208374023     │\n",
       "│ Time/Update                   │ 1.6816864013671875     │\n",
       "│ Time/Epoch                    │ 12.482060432434082     │\n",
       "│ Time/FPS                      │ 164.0754852294922      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.67613983154297      │\n",
       "│ Metrics/EpCost                │ 51.79999923706055      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 196.0                  │\n",
       "│ Train/Entropy                 │ 0.30703410506248474    │\n",
       "│ Train/KL                      │ 0.01201079972088337    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9924005270004272     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9924005270004272     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9924005270004272     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018574513494968414   │\n",
       "│ Train/LR                      │ 0.00018180000188294798 │\n",
       "│ Train/PolicyStd               │ 0.3289436399936676     │\n",
       "│ TotalEnvSteps                 │ 403456.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014656019397079945  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005571953020989895   │\n",
       "│ Value/Adv                     │ -0.029067134484648705  │\n",
       "│ Loss/Loss_reward_critic       │ 0.02627946436405182    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0038797464221715927  │\n",
       "│ Value/reward                  │ 2.1099865436553955     │\n",
       "│ Time/Total                    │ 2644.20556640625       │\n",
       "│ Time/Rollout                  │ 10.800329208374023     │\n",
       "│ Time/Update                   │ 1.6816864013671875     │\n",
       "│ Time/Epoch                    │ 12.482060432434082     │\n",
       "│ Time/FPS                      │ 164.0754852294922      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m10\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.64557456970215      │\n",
       "│ Metrics/EpCost                │ 51.02000045776367      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 197.0                  │\n",
       "│ Train/Entropy                 │ 0.30247998237609863    │\n",
       "│ Train/KL                      │ 0.021430421620607376   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9983137249946594     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9983137249946594     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9983137249946594     │\n",
       "│ Train/PolicyRatio/Std         │ 0.021159294992685318   │\n",
       "│ Train/LR                      │ 0.00018119999731425196 │\n",
       "│ Train/PolicyStd               │ 0.3274456858634949     │\n",
       "│ TotalEnvSteps                 │ 405504.0               │\n",
       "│ Loss/Loss_pi                  │ -0.019602397456765175  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00494637805968523   │\n",
       "│ Value/Adv                     │ -0.08071155101060867   │\n",
       "│ Loss/Loss_reward_critic       │ 0.019061703234910965   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.007217761129140854  │\n",
       "│ Value/reward                  │ 1.9846735000610352     │\n",
       "│ Time/Total                    │ 2656.72802734375       │\n",
       "│ Time/Rollout                  │ 10.787137985229492     │\n",
       "│ Time/Update                   │ 1.723968505859375      │\n",
       "│ Time/Epoch                    │ 12.511157989501953     │\n",
       "│ Time/FPS                      │ 163.6938934326172      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.64557456970215      │\n",
       "│ Metrics/EpCost                │ 51.02000045776367      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 197.0                  │\n",
       "│ Train/Entropy                 │ 0.30247998237609863    │\n",
       "│ Train/KL                      │ 0.021430421620607376   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9983137249946594     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9983137249946594     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9983137249946594     │\n",
       "│ Train/PolicyRatio/Std         │ 0.021159294992685318   │\n",
       "│ Train/LR                      │ 0.00018119999731425196 │\n",
       "│ Train/PolicyStd               │ 0.3274456858634949     │\n",
       "│ TotalEnvSteps                 │ 405504.0               │\n",
       "│ Loss/Loss_pi                  │ -0.019602397456765175  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00494637805968523   │\n",
       "│ Value/Adv                     │ -0.08071155101060867   │\n",
       "│ Loss/Loss_reward_critic       │ 0.019061703234910965   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.007217761129140854  │\n",
       "│ Value/reward                  │ 1.9846735000610352     │\n",
       "│ Time/Total                    │ 2656.72802734375       │\n",
       "│ Time/Rollout                  │ 10.787137985229492     │\n",
       "│ Time/Update                   │ 1.723968505859375      │\n",
       "│ Time/Epoch                    │ 12.511157989501953     │\n",
       "│ Time/FPS                      │ 163.6938934326172      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.61943817138672      │\n",
       "│ Metrics/EpCost                │ 50.13999938964844      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 198.0                  │\n",
       "│ Train/Entropy                 │ 0.29841119050979614    │\n",
       "│ Train/KL                      │ 0.01655735820531845    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9975816607475281     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9975816607475281     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9975816607475281     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020837871357798576   │\n",
       "│ Train/LR                      │ 0.00018059999274555594 │\n",
       "│ Train/PolicyStd               │ 0.3261181712150574     │\n",
       "│ TotalEnvSteps                 │ 407552.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017419494688510895  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00218290276825428    │\n",
       "│ Value/Adv                     │ 0.12891122698783875    │\n",
       "│ Loss/Loss_reward_critic       │ 0.020447243005037308   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0013855397701263428  │\n",
       "│ Value/reward                  │ 2.0368592739105225     │\n",
       "│ Time/Total                    │ 2669.20751953125       │\n",
       "│ Time/Rollout                  │ 10.767175674438477     │\n",
       "│ Time/Update                   │ 1.700483798980713      │\n",
       "│ Time/Epoch                    │ 12.467700004577637     │\n",
       "│ Time/FPS                      │ 164.26446533203125     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.61943817138672      │\n",
       "│ Metrics/EpCost                │ 50.13999938964844      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 198.0                  │\n",
       "│ Train/Entropy                 │ 0.29841119050979614    │\n",
       "│ Train/KL                      │ 0.01655735820531845    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9975816607475281     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9975816607475281     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9975816607475281     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020837871357798576   │\n",
       "│ Train/LR                      │ 0.00018059999274555594 │\n",
       "│ Train/PolicyStd               │ 0.3261181712150574     │\n",
       "│ TotalEnvSteps                 │ 407552.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017419494688510895  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00218290276825428    │\n",
       "│ Value/Adv                     │ 0.12891122698783875    │\n",
       "│ Loss/Loss_reward_critic       │ 0.020447243005037308   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0013855397701263428  │\n",
       "│ Value/reward                  │ 2.0368592739105225     │\n",
       "│ Time/Total                    │ 2669.20751953125       │\n",
       "│ Time/Rollout                  │ 10.767175674438477     │\n",
       "│ Time/Update                   │ 1.700483798980713      │\n",
       "│ Time/Epoch                    │ 12.467700004577637     │\n",
       "│ Time/FPS                      │ 164.26446533203125     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m7\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.591381072998047     │\n",
       "│ Metrics/EpCost                │ 49.7599983215332       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 199.0                  │\n",
       "│ Train/Entropy                 │ 0.29468366503715515    │\n",
       "│ Train/KL                      │ 0.020515330135822296   │\n",
       "│ Train/StopIter                │ 7.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0023647546768188     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0023647546768188     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0023647546768188     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01902404986321926    │\n",
       "│ Train/LR                      │ 0.00018000000272877514 │\n",
       "│ Train/PolicyStd               │ 0.3249020278453827     │\n",
       "│ TotalEnvSteps                 │ 409600.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01747705042362213   │\n",
       "│ Loss/Loss_pi/Delta            │ -5.755573511123657e-05 │\n",
       "│ Value/Adv                     │ 0.1699518859386444     │\n",
       "│ Loss/Loss_reward_critic       │ 0.02778124436736107    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.007334001362323761   │\n",
       "│ Value/reward                  │ 2.0048604011535645     │\n",
       "│ Time/Total                    │ 2681.2412109375        │\n",
       "│ Time/Rollout                  │ 10.819677352905273     │\n",
       "│ Time/Update                   │ 1.2023146152496338     │\n",
       "│ Time/Epoch                    │ 12.022038459777832     │\n",
       "│ Time/FPS                      │ 170.3538055419922      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.591381072998047     │\n",
       "│ Metrics/EpCost                │ 49.7599983215332       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 199.0                  │\n",
       "│ Train/Entropy                 │ 0.29468366503715515    │\n",
       "│ Train/KL                      │ 0.020515330135822296   │\n",
       "│ Train/StopIter                │ 7.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0023647546768188     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0023647546768188     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0023647546768188     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01902404986321926    │\n",
       "│ Train/LR                      │ 0.00018000000272877514 │\n",
       "│ Train/PolicyStd               │ 0.3249020278453827     │\n",
       "│ TotalEnvSteps                 │ 409600.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01747705042362213   │\n",
       "│ Loss/Loss_pi/Delta            │ -5.755573511123657e-05 │\n",
       "│ Value/Adv                     │ 0.1699518859386444     │\n",
       "│ Loss/Loss_reward_critic       │ 0.02778124436736107    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.007334001362323761   │\n",
       "│ Value/reward                  │ 2.0048604011535645     │\n",
       "│ Time/Total                    │ 2681.2412109375        │\n",
       "│ Time/Rollout                  │ 10.819677352905273     │\n",
       "│ Time/Update                   │ 1.2023146152496338     │\n",
       "│ Time/Epoch                    │ 12.022038459777832     │\n",
       "│ Time/FPS                      │ 170.3538055419922      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.5792293548584       │\n",
       "│ Metrics/EpCost                │ 51.13999938964844      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 200.0                  │\n",
       "│ Train/Entropy                 │ 0.29659873247146606    │\n",
       "│ Train/KL                      │ 0.015075244009494781   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0001753568649292     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0001753568649292     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0001753568649292     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02087402157485485    │\n",
       "│ Train/LR                      │ 0.00017939999816007912 │\n",
       "│ Train/PolicyStd               │ 0.32553988695144653    │\n",
       "│ TotalEnvSteps                 │ 411648.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01976529136300087   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0022882409393787384 │\n",
       "│ Value/Adv                     │ 0.0019770218059420586  │\n",
       "│ Loss/Loss_reward_critic       │ 0.016374070197343826   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.011407174170017242  │\n",
       "│ Value/reward                  │ 2.0187885761260986     │\n",
       "│ Time/Total                    │ 2693.7958984375        │\n",
       "│ Time/Rollout                  │ 10.854434967041016     │\n",
       "│ Time/Update                   │ 1.6854698657989502     │\n",
       "│ Time/Epoch                    │ 12.539958953857422     │\n",
       "│ Time/FPS                      │ 163.31793212890625     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.5792293548584       │\n",
       "│ Metrics/EpCost                │ 51.13999938964844      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 200.0                  │\n",
       "│ Train/Entropy                 │ 0.29659873247146606    │\n",
       "│ Train/KL                      │ 0.015075244009494781   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0001753568649292     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0001753568649292     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0001753568649292     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02087402157485485    │\n",
       "│ Train/LR                      │ 0.00017939999816007912 │\n",
       "│ Train/PolicyStd               │ 0.32553988695144653    │\n",
       "│ TotalEnvSteps                 │ 411648.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01976529136300087   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0022882409393787384 │\n",
       "│ Value/Adv                     │ 0.0019770218059420586  │\n",
       "│ Loss/Loss_reward_critic       │ 0.016374070197343826   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.011407174170017242  │\n",
       "│ Value/reward                  │ 2.0187885761260986     │\n",
       "│ Time/Total                    │ 2693.7958984375        │\n",
       "│ Time/Rollout                  │ 10.854434967041016     │\n",
       "│ Time/Update                   │ 1.6854698657989502     │\n",
       "│ Time/Epoch                    │ 12.539958953857422     │\n",
       "│ Time/FPS                      │ 163.31793212890625     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.61906623840332     │\n",
       "│ Metrics/EpCost                │ 52.58000183105469     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 201.0                 │\n",
       "│ Train/Entropy                 │ 0.2987266182899475    │\n",
       "│ Train/KL                      │ 0.014751089736819267  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9965066909790039    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9965066909790039    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9965066909790039    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01752871833741665   │\n",
       "│ Train/LR                      │ 0.0001787999935913831 │\n",
       "│ Train/PolicyStd               │ 0.3262496590614319    │\n",
       "│ TotalEnvSteps                 │ 413696.0              │\n",
       "│ Loss/Loss_pi                  │ -0.014199048280715942 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005566243082284927  │\n",
       "│ Value/Adv                     │ -0.008740939199924469 │\n",
       "│ Loss/Loss_reward_critic       │ 0.019425759091973305  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0030516888946294785 │\n",
       "│ Value/reward                  │ 2.0640790462493896    │\n",
       "│ Time/Total                    │ 2706.266845703125     │\n",
       "│ Time/Rollout                  │ 10.766844749450684    │\n",
       "│ Time/Update                   │ 1.692577600479126     │\n",
       "│ Time/Epoch                    │ 12.459463119506836    │\n",
       "│ Time/FPS                      │ 164.373046875         │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.61906623840332     │\n",
       "│ Metrics/EpCost                │ 52.58000183105469     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 201.0                 │\n",
       "│ Train/Entropy                 │ 0.2987266182899475    │\n",
       "│ Train/KL                      │ 0.014751089736819267  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9965066909790039    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9965066909790039    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9965066909790039    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01752871833741665   │\n",
       "│ Train/LR                      │ 0.0001787999935913831 │\n",
       "│ Train/PolicyStd               │ 0.3262496590614319    │\n",
       "│ TotalEnvSteps                 │ 413696.0              │\n",
       "│ Loss/Loss_pi                  │ -0.014199048280715942 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005566243082284927  │\n",
       "│ Value/Adv                     │ -0.008740939199924469 │\n",
       "│ Loss/Loss_reward_critic       │ 0.019425759091973305  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0030516888946294785 │\n",
       "│ Value/reward                  │ 2.0640790462493896    │\n",
       "│ Time/Total                    │ 2706.266845703125     │\n",
       "│ Time/Rollout                  │ 10.766844749450684    │\n",
       "│ Time/Update                   │ 1.692577600479126     │\n",
       "│ Time/Epoch                    │ 12.459463119506836    │\n",
       "│ Time/FPS                      │ 164.373046875         │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.7514591217041      │\n",
       "│ Metrics/EpCost                │ 52.599998474121094    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 202.0                 │\n",
       "│ Train/Entropy                 │ 0.2958003580570221    │\n",
       "│ Train/KL                      │ 0.016141118481755257  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.003258228302002     │\n",
       "│ Train/PolicyRatio/Min         │ 1.003258228302002     │\n",
       "│ Train/PolicyRatio/Max         │ 1.003258228302002     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017317337915301323  │\n",
       "│ Train/LR                      │ 0.0001782000035746023 │\n",
       "│ Train/PolicyStd               │ 0.325300931930542     │\n",
       "│ TotalEnvSteps                 │ 415744.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01495759654790163  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.000758548267185688 │\n",
       "│ Value/Adv                     │ 0.02716078609228134   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02554594911634922   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0061201900243759155 │\n",
       "│ Value/reward                  │ 2.1452765464782715    │\n",
       "│ Time/Total                    │ 2718.7333984375       │\n",
       "│ Time/Rollout                  │ 10.74613094329834     │\n",
       "│ Time/Update                   │ 1.707458257675171     │\n",
       "│ Time/Epoch                    │ 12.45363998413086     │\n",
       "│ Time/FPS                      │ 164.44992065429688    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.7514591217041      │\n",
       "│ Metrics/EpCost                │ 52.599998474121094    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 202.0                 │\n",
       "│ Train/Entropy                 │ 0.2958003580570221    │\n",
       "│ Train/KL                      │ 0.016141118481755257  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.003258228302002     │\n",
       "│ Train/PolicyRatio/Min         │ 1.003258228302002     │\n",
       "│ Train/PolicyRatio/Max         │ 1.003258228302002     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017317337915301323  │\n",
       "│ Train/LR                      │ 0.0001782000035746023 │\n",
       "│ Train/PolicyStd               │ 0.325300931930542     │\n",
       "│ TotalEnvSteps                 │ 415744.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01495759654790163  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.000758548267185688 │\n",
       "│ Value/Adv                     │ 0.02716078609228134   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02554594911634922   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0061201900243759155 │\n",
       "│ Value/reward                  │ 2.1452765464782715    │\n",
       "│ Time/Total                    │ 2718.7333984375       │\n",
       "│ Time/Rollout                  │ 10.74613094329834     │\n",
       "│ Time/Update                   │ 1.707458257675171     │\n",
       "│ Time/Epoch                    │ 12.45363998413086     │\n",
       "│ Time/FPS                      │ 164.44992065429688    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.767271041870117     │\n",
       "│ Metrics/EpCost                │ 53.7400016784668       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 203.0                  │\n",
       "│ Train/Entropy                 │ 0.2903361916542053     │\n",
       "│ Train/KL                      │ 0.015369296073913574   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9967617988586426     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9967617988586426     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9967617988586426     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018000144511461258   │\n",
       "│ Train/LR                      │ 0.00017759999900590628 │\n",
       "│ Train/PolicyStd               │ 0.32352107763290405    │\n",
       "│ TotalEnvSteps                 │ 417792.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013904553838074207  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.001053042709827423   │\n",
       "│ Value/Adv                     │ 0.16120916604995728    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017541173845529556   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.008004775270819664  │\n",
       "│ Value/reward                  │ 2.124561309814453      │\n",
       "│ Time/Total                    │ 2731.153564453125      │\n",
       "│ Time/Rollout                  │ 10.745349884033203     │\n",
       "│ Time/Update                   │ 1.6634840965270996     │\n",
       "│ Time/Epoch                    │ 12.408876419067383     │\n",
       "│ Time/FPS                      │ 165.04315185546875     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.767271041870117     │\n",
       "│ Metrics/EpCost                │ 53.7400016784668       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 203.0                  │\n",
       "│ Train/Entropy                 │ 0.2903361916542053     │\n",
       "│ Train/KL                      │ 0.015369296073913574   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9967617988586426     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9967617988586426     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9967617988586426     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018000144511461258   │\n",
       "│ Train/LR                      │ 0.00017759999900590628 │\n",
       "│ Train/PolicyStd               │ 0.32352107763290405    │\n",
       "│ TotalEnvSteps                 │ 417792.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013904553838074207  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.001053042709827423   │\n",
       "│ Value/Adv                     │ 0.16120916604995728    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017541173845529556   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.008004775270819664  │\n",
       "│ Value/reward                  │ 2.124561309814453      │\n",
       "│ Time/Total                    │ 2731.153564453125      │\n",
       "│ Time/Rollout                  │ 10.745349884033203     │\n",
       "│ Time/Update                   │ 1.6634840965270996     │\n",
       "│ Time/Epoch                    │ 12.408876419067383     │\n",
       "│ Time/FPS                      │ 165.04315185546875     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m7\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.812664031982422     │\n",
       "│ Metrics/EpCost                │ 50.58000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 204.0                  │\n",
       "│ Train/Entropy                 │ 0.28448304533958435    │\n",
       "│ Train/KL                      │ 0.020220870152115822   │\n",
       "│ Train/StopIter                │ 7.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9923658967018127     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9923658967018127     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9923658967018127     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018332134932279587   │\n",
       "│ Train/LR                      │ 0.00017699999443721026 │\n",
       "│ Train/PolicyStd               │ 0.3216250240802765     │\n",
       "│ TotalEnvSteps                 │ 419840.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013473876751959324  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0004306770861148834  │\n",
       "│ Value/Adv                     │ -0.12313845753669739   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02890821173787117    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.011367037892341614   │\n",
       "│ Value/reward                  │ 2.1593070030212402     │\n",
       "│ Time/Total                    │ 2743.170166015625      │\n",
       "│ Time/Rollout                  │ 10.843024253845215     │\n",
       "│ Time/Update                   │ 1.1621332168579102     │\n",
       "│ Time/Epoch                    │ 12.005205154418945     │\n",
       "│ Time/FPS                      │ 170.59268188476562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.812664031982422     │\n",
       "│ Metrics/EpCost                │ 50.58000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 204.0                  │\n",
       "│ Train/Entropy                 │ 0.28448304533958435    │\n",
       "│ Train/KL                      │ 0.020220870152115822   │\n",
       "│ Train/StopIter                │ 7.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9923658967018127     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9923658967018127     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9923658967018127     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018332134932279587   │\n",
       "│ Train/LR                      │ 0.00017699999443721026 │\n",
       "│ Train/PolicyStd               │ 0.3216250240802765     │\n",
       "│ TotalEnvSteps                 │ 419840.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013473876751959324  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0004306770861148834  │\n",
       "│ Value/Adv                     │ -0.12313845753669739   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02890821173787117    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.011367037892341614   │\n",
       "│ Value/reward                  │ 2.1593070030212402     │\n",
       "│ Time/Total                    │ 2743.170166015625      │\n",
       "│ Time/Rollout                  │ 10.843024253845215     │\n",
       "│ Time/Update                   │ 1.1621332168579102     │\n",
       "│ Time/Epoch                    │ 12.005205154418945     │\n",
       "│ Time/FPS                      │ 170.59268188476562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.084253311157227     │\n",
       "│ Metrics/EpCost                │ 51.2400016784668       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 205.0                  │\n",
       "│ Train/Entropy                 │ 0.27942395210266113    │\n",
       "│ Train/KL                      │ 0.016319015994668007   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9938225746154785     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9938225746154785     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9938225746154785     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01884150505065918    │\n",
       "│ Train/LR                      │ 0.00017640000442042947 │\n",
       "│ Train/PolicyStd               │ 0.3200276494026184     │\n",
       "│ TotalEnvSteps                 │ 421888.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017256874591112137  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.003782997839152813  │\n",
       "│ Value/Adv                     │ -0.20829367637634277   │\n",
       "│ Loss/Loss_reward_critic       │ 0.022084031254053116   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.006824180483818054  │\n",
       "│ Value/reward                  │ 2.130647659301758      │\n",
       "│ Time/Total                    │ 2755.7001953125        │\n",
       "│ Time/Rollout                  │ 10.74392318725586      │\n",
       "│ Time/Update                   │ 1.7694001197814941     │\n",
       "│ Time/Epoch                    │ 12.513374328613281     │\n",
       "│ Time/FPS                      │ 163.66490173339844     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.084253311157227     │\n",
       "│ Metrics/EpCost                │ 51.2400016784668       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 205.0                  │\n",
       "│ Train/Entropy                 │ 0.27942395210266113    │\n",
       "│ Train/KL                      │ 0.016319015994668007   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9938225746154785     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9938225746154785     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9938225746154785     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01884150505065918    │\n",
       "│ Train/LR                      │ 0.00017640000442042947 │\n",
       "│ Train/PolicyStd               │ 0.3200276494026184     │\n",
       "│ TotalEnvSteps                 │ 421888.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017256874591112137  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.003782997839152813  │\n",
       "│ Value/Adv                     │ -0.20829367637634277   │\n",
       "│ Loss/Loss_reward_critic       │ 0.022084031254053116   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.006824180483818054  │\n",
       "│ Value/reward                  │ 2.130647659301758      │\n",
       "│ Time/Total                    │ 2755.7001953125        │\n",
       "│ Time/Rollout                  │ 10.74392318725586      │\n",
       "│ Time/Update                   │ 1.7694001197814941     │\n",
       "│ Time/Epoch                    │ 12.513374328613281     │\n",
       "│ Time/FPS                      │ 163.66490173339844     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m10\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.13660430908203      │\n",
       "│ Metrics/EpCost                │ 50.959999084472656     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 206.0                  │\n",
       "│ Train/Entropy                 │ 0.2841242849826813     │\n",
       "│ Train/KL                      │ 0.02304399013519287    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9984270334243774     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9984270334243774     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9984270334243774     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02237573079764843    │\n",
       "│ Train/LR                      │ 0.00017579999985173345 │\n",
       "│ Train/PolicyStd               │ 0.3215706944465637     │\n",
       "│ TotalEnvSteps                 │ 423936.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017548348754644394  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0002914741635322571 │\n",
       "│ Value/Adv                     │ 0.055432431399822235   │\n",
       "│ Loss/Loss_reward_critic       │ 0.022727522999048233   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0006434917449951172  │\n",
       "│ Value/reward                  │ 2.0613315105438232     │\n",
       "│ Time/Total                    │ 2768.150634765625      │\n",
       "│ Time/Rollout                  │ 10.793753623962402     │\n",
       "│ Time/Update                   │ 1.6424145698547363     │\n",
       "│ Time/Epoch                    │ 12.436212539672852     │\n",
       "│ Time/FPS                      │ 164.6803741455078      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.13660430908203      │\n",
       "│ Metrics/EpCost                │ 50.959999084472656     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 206.0                  │\n",
       "│ Train/Entropy                 │ 0.2841242849826813     │\n",
       "│ Train/KL                      │ 0.02304399013519287    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9984270334243774     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9984270334243774     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9984270334243774     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02237573079764843    │\n",
       "│ Train/LR                      │ 0.00017579999985173345 │\n",
       "│ Train/PolicyStd               │ 0.3215706944465637     │\n",
       "│ TotalEnvSteps                 │ 423936.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017548348754644394  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0002914741635322571 │\n",
       "│ Value/Adv                     │ 0.055432431399822235   │\n",
       "│ Loss/Loss_reward_critic       │ 0.022727522999048233   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0006434917449951172  │\n",
       "│ Value/reward                  │ 2.0613315105438232     │\n",
       "│ Time/Total                    │ 2768.150634765625      │\n",
       "│ Time/Rollout                  │ 10.793753623962402     │\n",
       "│ Time/Update                   │ 1.6424145698547363     │\n",
       "│ Time/Epoch                    │ 12.436212539672852     │\n",
       "│ Time/FPS                      │ 164.6803741455078      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m1\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.7919864654541       │\n",
       "│ Metrics/EpCost                │ 49.08000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 207.0                  │\n",
       "│ Train/Entropy                 │ 0.2896682620048523     │\n",
       "│ Train/KL                      │ 0.030891483649611473   │\n",
       "│ Train/StopIter                │ 1.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0035209655761719     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0035209655761719     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0035209655761719     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017973938956856728   │\n",
       "│ Train/LR                      │ 0.00017519999528303742 │\n",
       "│ Train/PolicyStd               │ 0.32336872816085815    │\n",
       "│ TotalEnvSteps                 │ 425984.0               │\n",
       "│ Loss/Loss_pi                  │ 0.003137586871162057   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.02068593562580645    │\n",
       "│ Value/Adv                     │ -0.06796836853027344   │\n",
       "│ Loss/Loss_reward_critic       │ 0.03608482703566551    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.013357304036617279   │\n",
       "│ Value/reward                  │ 1.7708361148834229     │\n",
       "│ Time/Total                    │ 2779.2294921875        │\n",
       "│ Time/Rollout                  │ 10.896768569946289     │\n",
       "│ Time/Update                   │ 0.17089009284973145    │\n",
       "│ Time/Epoch                    │ 11.067716598510742     │\n",
       "│ Time/FPS                      │ 185.04270935058594     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.7919864654541       │\n",
       "│ Metrics/EpCost                │ 49.08000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 207.0                  │\n",
       "│ Train/Entropy                 │ 0.2896682620048523     │\n",
       "│ Train/KL                      │ 0.030891483649611473   │\n",
       "│ Train/StopIter                │ 1.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0035209655761719     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0035209655761719     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0035209655761719     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017973938956856728   │\n",
       "│ Train/LR                      │ 0.00017519999528303742 │\n",
       "│ Train/PolicyStd               │ 0.32336872816085815    │\n",
       "│ TotalEnvSteps                 │ 425984.0               │\n",
       "│ Loss/Loss_pi                  │ 0.003137586871162057   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.02068593562580645    │\n",
       "│ Value/Adv                     │ -0.06796836853027344   │\n",
       "│ Loss/Loss_reward_critic       │ 0.03608482703566551    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.013357304036617279   │\n",
       "│ Value/reward                  │ 1.7708361148834229     │\n",
       "│ Time/Total                    │ 2779.2294921875        │\n",
       "│ Time/Rollout                  │ 10.896768569946289     │\n",
       "│ Time/Update                   │ 0.17089009284973145    │\n",
       "│ Time/Epoch                    │ 11.067716598510742     │\n",
       "│ Time/FPS                      │ 185.04270935058594     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.08538818359375      │\n",
       "│ Metrics/EpCost                │ 49.08000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 208.0                  │\n",
       "│ Train/Entropy                 │ 0.2890589237213135     │\n",
       "│ Train/KL                      │ 0.016904819756746292   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9946300387382507     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9946300387382507     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9946300387382507     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02012350596487522    │\n",
       "│ Train/LR                      │ 0.00017460000526625663 │\n",
       "│ Train/PolicyStd               │ 0.3231675624847412     │\n",
       "│ TotalEnvSteps                 │ 428032.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01576867513358593   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.018906262004747987  │\n",
       "│ Value/Adv                     │ 0.10428688675165176    │\n",
       "│ Loss/Loss_reward_critic       │ 0.022648394107818604   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.013436432927846909  │\n",
       "│ Value/reward                  │ 1.9805269241333008     │\n",
       "│ Time/Total                    │ 2791.715576171875      │\n",
       "│ Time/Rollout                  │ 10.799722671508789     │\n",
       "│ Time/Update                   │ 1.6740779876708984     │\n",
       "│ Time/Epoch                    │ 12.47384262084961      │\n",
       "│ Time/FPS                      │ 164.18357849121094     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.08538818359375      │\n",
       "│ Metrics/EpCost                │ 49.08000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 208.0                  │\n",
       "│ Train/Entropy                 │ 0.2890589237213135     │\n",
       "│ Train/KL                      │ 0.016904819756746292   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9946300387382507     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9946300387382507     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9946300387382507     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02012350596487522    │\n",
       "│ Train/LR                      │ 0.00017460000526625663 │\n",
       "│ Train/PolicyStd               │ 0.3231675624847412     │\n",
       "│ TotalEnvSteps                 │ 428032.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01576867513358593   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.018906262004747987  │\n",
       "│ Value/Adv                     │ 0.10428688675165176    │\n",
       "│ Loss/Loss_reward_critic       │ 0.022648394107818604   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.013436432927846909  │\n",
       "│ Value/reward                  │ 1.9805269241333008     │\n",
       "│ Time/Total                    │ 2791.715576171875      │\n",
       "│ Time/Rollout                  │ 10.799722671508789     │\n",
       "│ Time/Update                   │ 1.6740779876708984     │\n",
       "│ Time/Epoch                    │ 12.47384262084961      │\n",
       "│ Time/FPS                      │ 164.18357849121094     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.319644927978516     │\n",
       "│ Metrics/EpCost                │ 51.47999954223633      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 209.0                  │\n",
       "│ Train/Entropy                 │ 0.28619062900543213    │\n",
       "│ Train/KL                      │ 0.01637491025030613    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9959872961044312     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9959872961044312     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9959872961044312     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018911587074398994   │\n",
       "│ Train/LR                      │ 0.0001740000006975606  │\n",
       "│ Train/PolicyStd               │ 0.3222716450691223     │\n",
       "│ TotalEnvSteps                 │ 430080.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015671512112021446  │\n",
       "│ Loss/Loss_pi/Delta            │ 9.716302156448364e-05  │\n",
       "│ Value/Adv                     │ 0.14092999696731567    │\n",
       "│ Loss/Loss_reward_critic       │ 0.020621076226234436   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0020273178815841675 │\n",
       "│ Value/reward                  │ 2.001138687133789      │\n",
       "│ Time/Total                    │ 2804.13427734375       │\n",
       "│ Time/Rollout                  │ 10.76694107055664      │\n",
       "│ Time/Update                   │ 1.6402406692504883     │\n",
       "│ Time/Epoch                    │ 12.407234191894531     │\n",
       "│ Time/FPS                      │ 165.0650177001953      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.319644927978516     │\n",
       "│ Metrics/EpCost                │ 51.47999954223633      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 209.0                  │\n",
       "│ Train/Entropy                 │ 0.28619062900543213    │\n",
       "│ Train/KL                      │ 0.01637491025030613    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9959872961044312     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9959872961044312     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9959872961044312     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018911587074398994   │\n",
       "│ Train/LR                      │ 0.0001740000006975606  │\n",
       "│ Train/PolicyStd               │ 0.3222716450691223     │\n",
       "│ TotalEnvSteps                 │ 430080.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015671512112021446  │\n",
       "│ Loss/Loss_pi/Delta            │ 9.716302156448364e-05  │\n",
       "│ Value/Adv                     │ 0.14092999696731567    │\n",
       "│ Loss/Loss_reward_critic       │ 0.020621076226234436   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0020273178815841675 │\n",
       "│ Value/reward                  │ 2.001138687133789      │\n",
       "│ Time/Total                    │ 2804.13427734375       │\n",
       "│ Time/Rollout                  │ 10.76694107055664      │\n",
       "│ Time/Update                   │ 1.6402406692504883     │\n",
       "│ Time/Epoch                    │ 12.407234191894531     │\n",
       "│ Time/FPS                      │ 165.0650177001953      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.393840789794922     │\n",
       "│ Metrics/EpCost                │ 52.0                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 210.0                  │\n",
       "│ Train/Entropy                 │ 0.2844748795032501     │\n",
       "│ Train/KL                      │ 0.015725446864962578   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9971103668212891     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9971103668212891     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9971103668212891     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01872284710407257    │\n",
       "│ Train/LR                      │ 0.00017339999612886459 │\n",
       "│ Train/PolicyStd               │ 0.3217466473579407     │\n",
       "│ TotalEnvSteps                 │ 432128.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01376565732061863   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0019058547914028168  │\n",
       "│ Value/Adv                     │ 0.0458267517387867     │\n",
       "│ Loss/Loss_reward_critic       │ 0.021503768861293793   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0008826926350593567  │\n",
       "│ Value/reward                  │ 2.0520308017730713     │\n",
       "│ Time/Total                    │ 2816.626708984375      │\n",
       "│ Time/Rollout                  │ 10.838512420654297     │\n",
       "│ Time/Update                   │ 1.6401433944702148     │\n",
       "│ Time/Epoch                    │ 12.478699684143066     │\n",
       "│ Time/FPS                      │ 164.1196746826172      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.393840789794922     │\n",
       "│ Metrics/EpCost                │ 52.0                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 210.0                  │\n",
       "│ Train/Entropy                 │ 0.2844748795032501     │\n",
       "│ Train/KL                      │ 0.015725446864962578   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9971103668212891     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9971103668212891     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9971103668212891     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01872284710407257    │\n",
       "│ Train/LR                      │ 0.00017339999612886459 │\n",
       "│ Train/PolicyStd               │ 0.3217466473579407     │\n",
       "│ TotalEnvSteps                 │ 432128.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01376565732061863   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0019058547914028168  │\n",
       "│ Value/Adv                     │ 0.0458267517387867     │\n",
       "│ Loss/Loss_reward_critic       │ 0.021503768861293793   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0008826926350593567  │\n",
       "│ Value/reward                  │ 2.0520308017730713     │\n",
       "│ Time/Total                    │ 2816.626708984375      │\n",
       "│ Time/Rollout                  │ 10.838512420654297     │\n",
       "│ Time/Update                   │ 1.6401433944702148     │\n",
       "│ Time/Epoch                    │ 12.478699684143066     │\n",
       "│ Time/FPS                      │ 164.1196746826172      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.47372055053711     │\n",
       "│ Metrics/EpCost                │ 53.34000015258789     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 211.0                 │\n",
       "│ Train/Entropy                 │ 0.2802085280418396    │\n",
       "│ Train/KL                      │ 0.016813354566693306  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9892412424087524    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9892412424087524    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9892412424087524    │\n",
       "│ Train/PolicyRatio/Std         │ 0.02007688768208027   │\n",
       "│ Train/LR                      │ 0.0001728000061120838 │\n",
       "│ Train/PolicyStd               │ 0.3203350007534027    │\n",
       "│ TotalEnvSteps                 │ 434176.0              │\n",
       "│ Loss/Loss_pi                  │ -0.021845931187272072 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.008080273866653442 │\n",
       "│ Value/Adv                     │ -0.12824603915214539  │\n",
       "│ Loss/Loss_reward_critic       │ 0.014757704921066761  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.006746063940227032 │\n",
       "│ Value/reward                  │ 2.0471725463867188    │\n",
       "│ Time/Total                    │ 2829.11767578125      │\n",
       "│ Time/Rollout                  │ 10.845612525939941    │\n",
       "│ Time/Update                   │ 1.633880615234375     │\n",
       "│ Time/Epoch                    │ 12.479548454284668    │\n",
       "│ Time/FPS                      │ 164.1085205078125     │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.47372055053711     │\n",
       "│ Metrics/EpCost                │ 53.34000015258789     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 211.0                 │\n",
       "│ Train/Entropy                 │ 0.2802085280418396    │\n",
       "│ Train/KL                      │ 0.016813354566693306  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9892412424087524    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9892412424087524    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9892412424087524    │\n",
       "│ Train/PolicyRatio/Std         │ 0.02007688768208027   │\n",
       "│ Train/LR                      │ 0.0001728000061120838 │\n",
       "│ Train/PolicyStd               │ 0.3203350007534027    │\n",
       "│ TotalEnvSteps                 │ 434176.0              │\n",
       "│ Loss/Loss_pi                  │ -0.021845931187272072 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.008080273866653442 │\n",
       "│ Value/Adv                     │ -0.12824603915214539  │\n",
       "│ Loss/Loss_reward_critic       │ 0.014757704921066761  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.006746063940227032 │\n",
       "│ Value/reward                  │ 2.0471725463867188    │\n",
       "│ Time/Total                    │ 2829.11767578125      │\n",
       "│ Time/Rollout                  │ 10.845612525939941    │\n",
       "│ Time/Update                   │ 1.633880615234375     │\n",
       "│ Time/Epoch                    │ 12.479548454284668    │\n",
       "│ Time/FPS                      │ 164.1085205078125     │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.55431365966797      │\n",
       "│ Metrics/EpCost                │ 52.099998474121094     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 212.0                  │\n",
       "│ Train/Entropy                 │ 0.2711852192878723     │\n",
       "│ Train/KL                      │ 0.0181159395724535     │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.990268886089325      │\n",
       "│ Train/PolicyRatio/Min         │ 0.990268886089325      │\n",
       "│ Train/PolicyRatio/Max         │ 0.990268886089325      │\n",
       "│ Train/PolicyRatio/Std         │ 0.020097138360142708   │\n",
       "│ Train/LR                      │ 0.00017220000154338777 │\n",
       "│ Train/PolicyStd               │ 0.31743523478507996    │\n",
       "│ TotalEnvSteps                 │ 436224.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01568807102739811   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.006157860159873962   │\n",
       "│ Value/Adv                     │ 0.08228933066129684    │\n",
       "│ Loss/Loss_reward_critic       │ 0.024413203820586205   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.009655498899519444   │\n",
       "│ Value/reward                  │ 2.1237971782684326     │\n",
       "│ Time/Total                    │ 2841.554931640625      │\n",
       "│ Time/Rollout                  │ 10.777984619140625     │\n",
       "│ Time/Update                   │ 1.6475534439086914     │\n",
       "│ Time/Epoch                    │ 12.425580024719238     │\n",
       "│ Time/FPS                      │ 164.8212890625         │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.55431365966797      │\n",
       "│ Metrics/EpCost                │ 52.099998474121094     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 212.0                  │\n",
       "│ Train/Entropy                 │ 0.2711852192878723     │\n",
       "│ Train/KL                      │ 0.0181159395724535     │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.990268886089325      │\n",
       "│ Train/PolicyRatio/Min         │ 0.990268886089325      │\n",
       "│ Train/PolicyRatio/Max         │ 0.990268886089325      │\n",
       "│ Train/PolicyRatio/Std         │ 0.020097138360142708   │\n",
       "│ Train/LR                      │ 0.00017220000154338777 │\n",
       "│ Train/PolicyStd               │ 0.31743523478507996    │\n",
       "│ TotalEnvSteps                 │ 436224.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01568807102739811   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.006157860159873962   │\n",
       "│ Value/Adv                     │ 0.08228933066129684    │\n",
       "│ Loss/Loss_reward_critic       │ 0.024413203820586205   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.009655498899519444   │\n",
       "│ Value/reward                  │ 2.1237971782684326     │\n",
       "│ Time/Total                    │ 2841.554931640625      │\n",
       "│ Time/Rollout                  │ 10.777984619140625     │\n",
       "│ Time/Update                   │ 1.6475534439086914     │\n",
       "│ Time/Epoch                    │ 12.425580024719238     │\n",
       "│ Time/FPS                      │ 164.8212890625         │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.663013458251953     │\n",
       "│ Metrics/EpCost                │ 52.880001068115234     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 213.0                  │\n",
       "│ Train/Entropy                 │ 0.2715422511100769     │\n",
       "│ Train/KL                      │ 0.018714558333158493   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9949474334716797     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9949474334716797     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9949474334716797     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020415721461176872   │\n",
       "│ Train/LR                      │ 0.00017159999697469175 │\n",
       "│ Train/PolicyStd               │ 0.3175331950187683     │\n",
       "│ TotalEnvSteps                 │ 438272.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017483031377196312  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0017949603497982025 │\n",
       "│ Value/Adv                     │ 0.06114790588617325    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02218082919716835    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0022323746234178543 │\n",
       "│ Value/reward                  │ 2.1294100284576416     │\n",
       "│ Time/Total                    │ 2854.039794921875      │\n",
       "│ Time/Rollout                  │ 10.822896957397461     │\n",
       "│ Time/Update                   │ 1.6500890254974365     │\n",
       "│ Time/Epoch                    │ 12.473033905029297     │\n",
       "│ Time/FPS                      │ 164.19422912597656     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.663013458251953     │\n",
       "│ Metrics/EpCost                │ 52.880001068115234     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 213.0                  │\n",
       "│ Train/Entropy                 │ 0.2715422511100769     │\n",
       "│ Train/KL                      │ 0.018714558333158493   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9949474334716797     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9949474334716797     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9949474334716797     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020415721461176872   │\n",
       "│ Train/LR                      │ 0.00017159999697469175 │\n",
       "│ Train/PolicyStd               │ 0.3175331950187683     │\n",
       "│ TotalEnvSteps                 │ 438272.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017483031377196312  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0017949603497982025 │\n",
       "│ Value/Adv                     │ 0.06114790588617325    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02218082919716835    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0022323746234178543 │\n",
       "│ Value/reward                  │ 2.1294100284576416     │\n",
       "│ Time/Total                    │ 2854.039794921875      │\n",
       "│ Time/Rollout                  │ 10.822896957397461     │\n",
       "│ Time/Update                   │ 1.6500890254974365     │\n",
       "│ Time/Epoch                    │ 12.473033905029297     │\n",
       "│ Time/FPS                      │ 164.19422912597656     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.573240280151367     │\n",
       "│ Metrics/EpCost                │ 52.68000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 214.0                  │\n",
       "│ Train/Entropy                 │ 0.2727474570274353     │\n",
       "│ Train/KL                      │ 0.016917578876018524   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9971214532852173     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9971214532852173     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9971214532852173     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018284788355231285   │\n",
       "│ Train/LR                      │ 0.00017100000695791095 │\n",
       "│ Train/PolicyStd               │ 0.3178860545158386     │\n",
       "│ TotalEnvSteps                 │ 440320.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018188878893852234  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0007058475166559219 │\n",
       "│ Value/Adv                     │ -0.15182512998580933   │\n",
       "│ Loss/Loss_reward_critic       │ 0.013126472942531109   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.009054356254637241  │\n",
       "│ Value/reward                  │ 2.0915169715881348     │\n",
       "│ Time/Total                    │ 2866.456787109375      │\n",
       "│ Time/Rollout                  │ 10.77495002746582      │\n",
       "│ Time/Update                   │ 1.630561113357544      │\n",
       "│ Time/Epoch                    │ 12.405555725097656     │\n",
       "│ Time/FPS                      │ 165.0873260498047      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.573240280151367     │\n",
       "│ Metrics/EpCost                │ 52.68000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 214.0                  │\n",
       "│ Train/Entropy                 │ 0.2727474570274353     │\n",
       "│ Train/KL                      │ 0.016917578876018524   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9971214532852173     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9971214532852173     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9971214532852173     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018284788355231285   │\n",
       "│ Train/LR                      │ 0.00017100000695791095 │\n",
       "│ Train/PolicyStd               │ 0.3178860545158386     │\n",
       "│ TotalEnvSteps                 │ 440320.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018188878893852234  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0007058475166559219 │\n",
       "│ Value/Adv                     │ -0.15182512998580933   │\n",
       "│ Loss/Loss_reward_critic       │ 0.013126472942531109   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.009054356254637241  │\n",
       "│ Value/reward                  │ 2.0915169715881348     │\n",
       "│ Time/Total                    │ 2866.456787109375      │\n",
       "│ Time/Rollout                  │ 10.77495002746582      │\n",
       "│ Time/Update                   │ 1.630561113357544      │\n",
       "│ Time/Epoch                    │ 12.405555725097656     │\n",
       "│ Time/FPS                      │ 165.0873260498047      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m6\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.686634063720703     │\n",
       "│ Metrics/EpCost                │ 53.41999816894531      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 215.0                  │\n",
       "│ Train/Entropy                 │ 0.270620733499527      │\n",
       "│ Train/KL                      │ 0.020633574575185776   │\n",
       "│ Train/StopIter                │ 6.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0008395910263062     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0008395910263062     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0008395910263062     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019153261557221413   │\n",
       "│ Train/LR                      │ 0.00017040000238921493 │\n",
       "│ Train/PolicyStd               │ 0.3172006607055664     │\n",
       "│ TotalEnvSteps                 │ 442368.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016998978331685066  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0011899005621671677  │\n",
       "│ Value/Adv                     │ -0.14486834406852722   │\n",
       "│ Loss/Loss_reward_critic       │ 0.025590451434254646   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.012463978491723537   │\n",
       "│ Value/reward                  │ 2.1627535820007324     │\n",
       "│ Time/Total                    │ 2878.318603515625      │\n",
       "│ Time/Rollout                  │ 10.82517147064209      │\n",
       "│ Time/Update                   │ 1.0251507759094238     │\n",
       "│ Time/Epoch                    │ 11.850364685058594     │\n",
       "│ Time/FPS                      │ 172.8217010498047      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.686634063720703     │\n",
       "│ Metrics/EpCost                │ 53.41999816894531      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 215.0                  │\n",
       "│ Train/Entropy                 │ 0.270620733499527      │\n",
       "│ Train/KL                      │ 0.020633574575185776   │\n",
       "│ Train/StopIter                │ 6.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0008395910263062     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0008395910263062     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0008395910263062     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019153261557221413   │\n",
       "│ Train/LR                      │ 0.00017040000238921493 │\n",
       "│ Train/PolicyStd               │ 0.3172006607055664     │\n",
       "│ TotalEnvSteps                 │ 442368.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016998978331685066  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0011899005621671677  │\n",
       "│ Value/Adv                     │ -0.14486834406852722   │\n",
       "│ Loss/Loss_reward_critic       │ 0.025590451434254646   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.012463978491723537   │\n",
       "│ Value/reward                  │ 2.1627535820007324     │\n",
       "│ Time/Total                    │ 2878.318603515625      │\n",
       "│ Time/Rollout                  │ 10.82517147064209      │\n",
       "│ Time/Update                   │ 1.0251507759094238     │\n",
       "│ Time/Epoch                    │ 11.850364685058594     │\n",
       "│ Time/FPS                      │ 172.8217010498047      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.654834747314453    │\n",
       "│ Metrics/EpCost                │ 53.84000015258789     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 216.0                 │\n",
       "│ Train/Entropy                 │ 0.27262505888938904   │\n",
       "│ Train/KL                      │ 0.01680854521691799   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0014699697494507    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0014699697494507    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0014699697494507    │\n",
       "│ Train/PolicyRatio/Std         │ 0.018623394891619682  │\n",
       "│ Train/LR                      │ 0.0001697999978205189 │\n",
       "│ Train/PolicyStd               │ 0.31782570481300354   │\n",
       "│ TotalEnvSteps                 │ 444416.0              │\n",
       "│ Loss/Loss_pi                  │ -0.014416342601180077 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0025826357305049896 │\n",
       "│ Value/Adv                     │ 0.10579845309257507   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015811501070857048  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.009778950363397598 │\n",
       "│ Value/reward                  │ 2.131563186645508     │\n",
       "│ Time/Total                    │ 2890.851806640625     │\n",
       "│ Time/Rollout                  │ 10.876891136169434    │\n",
       "│ Time/Update                   │ 1.6447713375091553    │\n",
       "│ Time/Epoch                    │ 12.52170467376709     │\n",
       "│ Time/FPS                      │ 163.55601501464844    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.654834747314453    │\n",
       "│ Metrics/EpCost                │ 53.84000015258789     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 216.0                 │\n",
       "│ Train/Entropy                 │ 0.27262505888938904   │\n",
       "│ Train/KL                      │ 0.01680854521691799   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0014699697494507    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0014699697494507    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0014699697494507    │\n",
       "│ Train/PolicyRatio/Std         │ 0.018623394891619682  │\n",
       "│ Train/LR                      │ 0.0001697999978205189 │\n",
       "│ Train/PolicyStd               │ 0.31782570481300354   │\n",
       "│ TotalEnvSteps                 │ 444416.0              │\n",
       "│ Loss/Loss_pi                  │ -0.014416342601180077 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0025826357305049896 │\n",
       "│ Value/Adv                     │ 0.10579845309257507   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015811501070857048  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.009778950363397598 │\n",
       "│ Value/reward                  │ 2.131563186645508     │\n",
       "│ Time/Total                    │ 2890.851806640625     │\n",
       "│ Time/Rollout                  │ 10.876891136169434    │\n",
       "│ Time/Update                   │ 1.6447713375091553    │\n",
       "│ Time/Epoch                    │ 12.52170467376709     │\n",
       "│ Time/FPS                      │ 163.55601501464844    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.919879913330078     │\n",
       "│ Metrics/EpCost                │ 53.36000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 217.0                  │\n",
       "│ Train/Entropy                 │ 0.2755546569824219     │\n",
       "│ Train/KL                      │ 0.013310825452208519   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9957454800605774     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9957454800605774     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9957454800605774     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01938316598534584    │\n",
       "│ Train/LR                      │ 0.0001691999932518229  │\n",
       "│ Train/PolicyStd               │ 0.31875792145729065    │\n",
       "│ TotalEnvSteps                 │ 446464.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016278410330414772  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0018620677292346954 │\n",
       "│ Value/Adv                     │ 0.054721299558877945   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02027684450149536    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004465343430638313   │\n",
       "│ Value/reward                  │ 2.0939860343933105     │\n",
       "│ Time/Total                    │ 2903.344482421875      │\n",
       "│ Time/Rollout                  │ 10.821554183959961     │\n",
       "│ Time/Update                   │ 1.6530859470367432     │\n",
       "│ Time/Epoch                    │ 12.47468376159668      │\n",
       "│ Time/FPS                      │ 164.17250061035156     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.919879913330078     │\n",
       "│ Metrics/EpCost                │ 53.36000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 217.0                  │\n",
       "│ Train/Entropy                 │ 0.2755546569824219     │\n",
       "│ Train/KL                      │ 0.013310825452208519   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9957454800605774     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9957454800605774     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9957454800605774     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01938316598534584    │\n",
       "│ Train/LR                      │ 0.0001691999932518229  │\n",
       "│ Train/PolicyStd               │ 0.31875792145729065    │\n",
       "│ TotalEnvSteps                 │ 446464.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016278410330414772  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0018620677292346954 │\n",
       "│ Value/Adv                     │ 0.054721299558877945   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02027684450149536    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004465343430638313   │\n",
       "│ Value/reward                  │ 2.0939860343933105     │\n",
       "│ Time/Total                    │ 2903.344482421875      │\n",
       "│ Time/Rollout                  │ 10.821554183959961     │\n",
       "│ Time/Update                   │ 1.6530859470367432     │\n",
       "│ Time/Epoch                    │ 12.47468376159668      │\n",
       "│ Time/FPS                      │ 164.17250061035156     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.042831420898438     │\n",
       "│ Metrics/EpCost                │ 54.400001525878906     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 218.0                  │\n",
       "│ Train/Entropy                 │ 0.27328163385391235    │\n",
       "│ Train/KL                      │ 0.015318583697080612   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9975360631942749     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9975360631942749     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9975360631942749     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017952358350157738   │\n",
       "│ Train/LR                      │ 0.0001686000032350421  │\n",
       "│ Train/PolicyStd               │ 0.3180353045463562     │\n",
       "│ TotalEnvSteps                 │ 448512.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01608855649828911   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00018985383212566376 │\n",
       "│ Value/Adv                     │ -0.10464711487293243   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02142031490802765    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0011434704065322876  │\n",
       "│ Value/reward                  │ 2.192387819290161      │\n",
       "│ Time/Total                    │ 2915.776611328125      │\n",
       "│ Time/Rollout                  │ 10.781147003173828     │\n",
       "│ Time/Update                   │ 1.6391410827636719     │\n",
       "│ Time/Epoch                    │ 12.420329093933105     │\n",
       "│ Time/FPS                      │ 164.89096069335938     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.042831420898438     │\n",
       "│ Metrics/EpCost                │ 54.400001525878906     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 218.0                  │\n",
       "│ Train/Entropy                 │ 0.27328163385391235    │\n",
       "│ Train/KL                      │ 0.015318583697080612   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9975360631942749     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9975360631942749     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9975360631942749     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017952358350157738   │\n",
       "│ Train/LR                      │ 0.0001686000032350421  │\n",
       "│ Train/PolicyStd               │ 0.3180353045463562     │\n",
       "│ TotalEnvSteps                 │ 448512.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01608855649828911   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00018985383212566376 │\n",
       "│ Value/Adv                     │ -0.10464711487293243   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02142031490802765    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0011434704065322876  │\n",
       "│ Value/reward                  │ 2.192387819290161      │\n",
       "│ Time/Total                    │ 2915.776611328125      │\n",
       "│ Time/Rollout                  │ 10.781147003173828     │\n",
       "│ Time/Update                   │ 1.6391410827636719     │\n",
       "│ Time/Epoch                    │ 12.420329093933105     │\n",
       "│ Time/FPS                      │ 164.89096069335938     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.935712814331055     │\n",
       "│ Metrics/EpCost                │ 54.02000045776367      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 219.0                  │\n",
       "│ Train/Entropy                 │ 0.27183905243873596    │\n",
       "│ Train/KL                      │ 0.013941612094640732   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9976094961166382     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9976094961166382     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9976094961166382     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01800999790430069    │\n",
       "│ Train/LR                      │ 0.00016799999866634607 │\n",
       "│ Train/PolicyStd               │ 0.3175749182701111     │\n",
       "│ TotalEnvSteps                 │ 450560.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013358211144804955  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0027303453534841537  │\n",
       "│ Value/Adv                     │ 0.07004492729902267    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017727749422192574   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0036925654858350754 │\n",
       "│ Value/reward                  │ 2.0292649269104004     │\n",
       "│ Time/Total                    │ 2928.24755859375       │\n",
       "│ Time/Rollout                  │ 10.790398597717285     │\n",
       "│ Time/Update                   │ 1.6685359477996826     │\n",
       "│ Time/Epoch                    │ 12.458978652954102     │\n",
       "│ Time/FPS                      │ 164.37945556640625     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.935712814331055     │\n",
       "│ Metrics/EpCost                │ 54.02000045776367      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 219.0                  │\n",
       "│ Train/Entropy                 │ 0.27183905243873596    │\n",
       "│ Train/KL                      │ 0.013941612094640732   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9976094961166382     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9976094961166382     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9976094961166382     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01800999790430069    │\n",
       "│ Train/LR                      │ 0.00016799999866634607 │\n",
       "│ Train/PolicyStd               │ 0.3175749182701111     │\n",
       "│ TotalEnvSteps                 │ 450560.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013358211144804955  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0027303453534841537  │\n",
       "│ Value/Adv                     │ 0.07004492729902267    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017727749422192574   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0036925654858350754 │\n",
       "│ Value/reward                  │ 2.0292649269104004     │\n",
       "│ Time/Total                    │ 2928.24755859375       │\n",
       "│ Time/Rollout                  │ 10.790398597717285     │\n",
       "│ Time/Update                   │ 1.6685359477996826     │\n",
       "│ Time/Epoch                    │ 12.458978652954102     │\n",
       "│ Time/FPS                      │ 164.37945556640625     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.777982711791992     │\n",
       "│ Metrics/EpCost                │ 54.0                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 220.0                  │\n",
       "│ Train/Entropy                 │ 0.26736992597579956    │\n",
       "│ Train/KL                      │ 0.015391292981803417   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0042518377304077     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0042518377304077     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0042518377304077     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01754787750542164    │\n",
       "│ Train/LR                      │ 0.00016739999409765005 │\n",
       "│ Train/PolicyStd               │ 0.3161599040031433     │\n",
       "│ TotalEnvSteps                 │ 452608.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017262045294046402  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0039038341492414474 │\n",
       "│ Value/Adv                     │ -0.03203805163502693   │\n",
       "│ Loss/Loss_reward_critic       │ 0.019568149000406265   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0018403995782136917  │\n",
       "│ Value/reward                  │ 2.0347530841827393     │\n",
       "│ Time/Total                    │ 2940.726318359375      │\n",
       "│ Time/Rollout                  │ 10.729938507080078     │\n",
       "│ Time/Update                   │ 1.7355875968933105     │\n",
       "│ Time/Epoch                    │ 12.465577125549316     │\n",
       "│ Time/FPS                      │ 164.29244995117188     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.777982711791992     │\n",
       "│ Metrics/EpCost                │ 54.0                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 220.0                  │\n",
       "│ Train/Entropy                 │ 0.26736992597579956    │\n",
       "│ Train/KL                      │ 0.015391292981803417   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0042518377304077     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0042518377304077     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0042518377304077     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01754787750542164    │\n",
       "│ Train/LR                      │ 0.00016739999409765005 │\n",
       "│ Train/PolicyStd               │ 0.3161599040031433     │\n",
       "│ TotalEnvSteps                 │ 452608.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017262045294046402  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0039038341492414474 │\n",
       "│ Value/Adv                     │ -0.03203805163502693   │\n",
       "│ Loss/Loss_reward_critic       │ 0.019568149000406265   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0018403995782136917  │\n",
       "│ Value/reward                  │ 2.0347530841827393     │\n",
       "│ Time/Total                    │ 2940.726318359375      │\n",
       "│ Time/Rollout                  │ 10.729938507080078     │\n",
       "│ Time/Update                   │ 1.7355875968933105     │\n",
       "│ Time/Epoch                    │ 12.465577125549316     │\n",
       "│ Time/FPS                      │ 164.29244995117188     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.68731689453125      │\n",
       "│ Metrics/EpCost                │ 53.52000045776367      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 221.0                  │\n",
       "│ Train/Entropy                 │ 0.25956305861473083    │\n",
       "│ Train/KL                      │ 0.01290361862629652    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9958494305610657     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9958494305610657     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9958494305610657     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017083145678043365   │\n",
       "│ Train/LR                      │ 0.00016680000408086926 │\n",
       "│ Train/PolicyStd               │ 0.3136926293373108     │\n",
       "│ TotalEnvSteps                 │ 454656.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01816364750266075   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0009016022086143494 │\n",
       "│ Value/Adv                     │ -0.05635731667280197   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02656935714185238    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.007001208141446114   │\n",
       "│ Value/reward                  │ 2.019620895385742      │\n",
       "│ Time/Total                    │ 2953.38134765625       │\n",
       "│ Time/Rollout                  │ 10.880830764770508     │\n",
       "│ Time/Update                   │ 1.7623989582061768     │\n",
       "│ Time/Epoch                    │ 12.643289566040039     │\n",
       "│ Time/FPS                      │ 161.98316955566406     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.68731689453125      │\n",
       "│ Metrics/EpCost                │ 53.52000045776367      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 221.0                  │\n",
       "│ Train/Entropy                 │ 0.25956305861473083    │\n",
       "│ Train/KL                      │ 0.01290361862629652    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9958494305610657     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9958494305610657     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9958494305610657     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017083145678043365   │\n",
       "│ Train/LR                      │ 0.00016680000408086926 │\n",
       "│ Train/PolicyStd               │ 0.3136926293373108     │\n",
       "│ TotalEnvSteps                 │ 454656.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01816364750266075   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0009016022086143494 │\n",
       "│ Value/Adv                     │ -0.05635731667280197   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02656935714185238    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.007001208141446114   │\n",
       "│ Value/reward                  │ 2.019620895385742      │\n",
       "│ Time/Total                    │ 2953.38134765625       │\n",
       "│ Time/Rollout                  │ 10.880830764770508     │\n",
       "│ Time/Update                   │ 1.7623989582061768     │\n",
       "│ Time/Epoch                    │ 12.643289566040039     │\n",
       "│ Time/FPS                      │ 161.98316955566406     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.739849090576172     │\n",
       "│ Metrics/EpCost                │ 53.36000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 222.0                  │\n",
       "│ Train/Entropy                 │ 0.2526366710662842     │\n",
       "│ Train/KL                      │ 0.01424887590110302    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9939811825752258     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9939811825752258     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9939811825752258     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01792255975306034    │\n",
       "│ Train/LR                      │ 0.00016619999951217324 │\n",
       "│ Train/PolicyStd               │ 0.31151920557022095    │\n",
       "│ TotalEnvSteps                 │ 456704.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015945373103022575  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002218274399638176   │\n",
       "│ Value/Adv                     │ 0.014799038879573345   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018821433186531067   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.007747923955321312  │\n",
       "│ Value/reward                  │ 2.0498294830322266     │\n",
       "│ Time/Total                    │ 2965.865478515625      │\n",
       "│ Time/Rollout                  │ 10.822810173034668     │\n",
       "│ Time/Update                   │ 1.6498003005981445     │\n",
       "│ Time/Epoch                    │ 12.472655296325684     │\n",
       "│ Time/FPS                      │ 164.19920349121094     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.739849090576172     │\n",
       "│ Metrics/EpCost                │ 53.36000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 222.0                  │\n",
       "│ Train/Entropy                 │ 0.2526366710662842     │\n",
       "│ Train/KL                      │ 0.01424887590110302    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9939811825752258     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9939811825752258     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9939811825752258     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01792255975306034    │\n",
       "│ Train/LR                      │ 0.00016619999951217324 │\n",
       "│ Train/PolicyStd               │ 0.31151920557022095    │\n",
       "│ TotalEnvSteps                 │ 456704.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015945373103022575  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002218274399638176   │\n",
       "│ Value/Adv                     │ 0.014799038879573345   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018821433186531067   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.007747923955321312  │\n",
       "│ Value/reward                  │ 2.0498294830322266     │\n",
       "│ Time/Total                    │ 2965.865478515625      │\n",
       "│ Time/Rollout                  │ 10.822810173034668     │\n",
       "│ Time/Update                   │ 1.6498003005981445     │\n",
       "│ Time/Epoch                    │ 12.472655296325684     │\n",
       "│ Time/FPS                      │ 164.19920349121094     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.894319534301758     │\n",
       "│ Metrics/EpCost                │ 52.47999954223633      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 223.0                  │\n",
       "│ Train/Entropy                 │ 0.2547972500324249     │\n",
       "│ Train/KL                      │ 0.016816120594739914   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9907233119010925     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9907233119010925     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9907233119010925     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019655032083392143   │\n",
       "│ Train/LR                      │ 0.0001655999949434772  │\n",
       "│ Train/PolicyStd               │ 0.3121931552886963     │\n",
       "│ TotalEnvSteps                 │ 458752.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017551634460687637  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.001606261357665062  │\n",
       "│ Value/Adv                     │ -0.01634007692337036   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018511943519115448   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0003094896674156189 │\n",
       "│ Value/reward                  │ 2.049278974533081      │\n",
       "│ Time/Total                    │ 2978.361083984375      │\n",
       "│ Time/Rollout                  │ 10.811626434326172     │\n",
       "│ Time/Update                   │ 1.672450304031372      │\n",
       "│ Time/Epoch                    │ 12.484122276306152     │\n",
       "│ Time/FPS                      │ 164.0483856201172      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.894319534301758     │\n",
       "│ Metrics/EpCost                │ 52.47999954223633      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 223.0                  │\n",
       "│ Train/Entropy                 │ 0.2547972500324249     │\n",
       "│ Train/KL                      │ 0.016816120594739914   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9907233119010925     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9907233119010925     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9907233119010925     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019655032083392143   │\n",
       "│ Train/LR                      │ 0.0001655999949434772  │\n",
       "│ Train/PolicyStd               │ 0.3121931552886963     │\n",
       "│ TotalEnvSteps                 │ 458752.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017551634460687637  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.001606261357665062  │\n",
       "│ Value/Adv                     │ -0.01634007692337036   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018511943519115448   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0003094896674156189 │\n",
       "│ Value/reward                  │ 2.049278974533081      │\n",
       "│ Time/Total                    │ 2978.361083984375      │\n",
       "│ Time/Rollout                  │ 10.811626434326172     │\n",
       "│ Time/Update                   │ 1.672450304031372      │\n",
       "│ Time/Epoch                    │ 12.484122276306152     │\n",
       "│ Time/FPS                      │ 164.0483856201172      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.807870864868164     │\n",
       "│ Metrics/EpCost                │ 53.70000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 224.0                  │\n",
       "│ Train/Entropy                 │ 0.25821954011917114    │\n",
       "│ Train/KL                      │ 0.012229615822434425   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0024794340133667     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0024794340133667     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0024794340133667     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016684364527463913   │\n",
       "│ Train/LR                      │ 0.00016500000492669642 │\n",
       "│ Train/PolicyStd               │ 0.3132625222206116     │\n",
       "│ TotalEnvSteps                 │ 460800.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016829514876008034  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0007221195846796036  │\n",
       "│ Value/Adv                     │ 0.022603102028369904   │\n",
       "│ Loss/Loss_reward_critic       │ 0.013350510969758034   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005161432549357414  │\n",
       "│ Value/reward                  │ 2.0124738216400146     │\n",
       "│ Time/Total                    │ 2990.941162109375      │\n",
       "│ Time/Rollout                  │ 10.849188804626465     │\n",
       "│ Time/Update                   │ 1.7195188999176025     │\n",
       "│ Time/Epoch                    │ 12.568753242492676     │\n",
       "│ Time/FPS                      │ 162.9437713623047      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.807870864868164     │\n",
       "│ Metrics/EpCost                │ 53.70000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 224.0                  │\n",
       "│ Train/Entropy                 │ 0.25821954011917114    │\n",
       "│ Train/KL                      │ 0.012229615822434425   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0024794340133667     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0024794340133667     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0024794340133667     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016684364527463913   │\n",
       "│ Train/LR                      │ 0.00016500000492669642 │\n",
       "│ Train/PolicyStd               │ 0.3132625222206116     │\n",
       "│ TotalEnvSteps                 │ 460800.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016829514876008034  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0007221195846796036  │\n",
       "│ Value/Adv                     │ 0.022603102028369904   │\n",
       "│ Loss/Loss_reward_critic       │ 0.013350510969758034   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005161432549357414  │\n",
       "│ Value/reward                  │ 2.0124738216400146     │\n",
       "│ Time/Total                    │ 2990.941162109375      │\n",
       "│ Time/Rollout                  │ 10.849188804626465     │\n",
       "│ Time/Update                   │ 1.7195188999176025     │\n",
       "│ Time/Epoch                    │ 12.568753242492676     │\n",
       "│ Time/FPS                      │ 162.9437713623047      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.812021255493164    │\n",
       "│ Metrics/EpCost                │ 52.68000030517578     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 225.0                 │\n",
       "│ Train/Entropy                 │ 0.2534489333629608    │\n",
       "│ Train/KL                      │ 0.015140218660235405  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9938721656799316    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9938721656799316    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9938721656799316    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01751362904906273   │\n",
       "│ Train/LR                      │ 0.0001644000003580004 │\n",
       "│ Train/PolicyStd               │ 0.31177228689193726   │\n",
       "│ TotalEnvSteps                 │ 462848.0              │\n",
       "│ Loss/Loss_pi                  │ -0.014649292454123497 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0021802224218845367 │\n",
       "│ Value/Adv                     │ 0.11698134988546371   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02115868404507637   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0078081730753183365 │\n",
       "│ Value/reward                  │ 2.0280861854553223    │\n",
       "│ Time/Total                    │ 3004.72216796875      │\n",
       "│ Time/Rollout                  │ 11.814021110534668    │\n",
       "│ Time/Update                   │ 1.9553136825561523    │\n",
       "│ Time/Epoch                    │ 13.76937484741211     │\n",
       "│ Time/FPS                      │ 148.7358856201172     │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.812021255493164    │\n",
       "│ Metrics/EpCost                │ 52.68000030517578     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 225.0                 │\n",
       "│ Train/Entropy                 │ 0.2534489333629608    │\n",
       "│ Train/KL                      │ 0.015140218660235405  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9938721656799316    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9938721656799316    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9938721656799316    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01751362904906273   │\n",
       "│ Train/LR                      │ 0.0001644000003580004 │\n",
       "│ Train/PolicyStd               │ 0.31177228689193726   │\n",
       "│ TotalEnvSteps                 │ 462848.0              │\n",
       "│ Loss/Loss_pi                  │ -0.014649292454123497 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0021802224218845367 │\n",
       "│ Value/Adv                     │ 0.11698134988546371   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02115868404507637   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0078081730753183365 │\n",
       "│ Value/reward                  │ 2.0280861854553223    │\n",
       "│ Time/Total                    │ 3004.72216796875      │\n",
       "│ Time/Rollout                  │ 11.814021110534668    │\n",
       "│ Time/Update                   │ 1.9553136825561523    │\n",
       "│ Time/Epoch                    │ 13.76937484741211     │\n",
       "│ Time/FPS                      │ 148.7358856201172     │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.61871910095215      │\n",
       "│ Metrics/EpCost                │ 52.040000915527344     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 226.0                  │\n",
       "│ Train/Entropy                 │ 0.2431090772151947     │\n",
       "│ Train/KL                      │ 0.01424249168485403    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0013855695724487     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0013855695724487     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0013855695724487     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018486952409148216   │\n",
       "│ Train/LR                      │ 0.00016379999578930438 │\n",
       "│ Train/PolicyStd               │ 0.3085686266422272     │\n",
       "│ TotalEnvSteps                 │ 464896.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018696900457143784  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0040476080030202866 │\n",
       "│ Value/Adv                     │ -0.07983780652284622   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01604675129055977    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0051119327545166016 │\n",
       "│ Value/reward                  │ 2.01237416267395       │\n",
       "│ Time/Total                    │ 3019.16259765625       │\n",
       "│ Time/Rollout                  │ 12.486763954162598     │\n",
       "│ Time/Update                   │ 1.9386775493621826     │\n",
       "│ Time/Epoch                    │ 14.425491333007812     │\n",
       "│ Time/FPS                      │ 141.9709014892578      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.61871910095215      │\n",
       "│ Metrics/EpCost                │ 52.040000915527344     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 226.0                  │\n",
       "│ Train/Entropy                 │ 0.2431090772151947     │\n",
       "│ Train/KL                      │ 0.01424249168485403    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0013855695724487     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0013855695724487     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0013855695724487     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018486952409148216   │\n",
       "│ Train/LR                      │ 0.00016379999578930438 │\n",
       "│ Train/PolicyStd               │ 0.3085686266422272     │\n",
       "│ TotalEnvSteps                 │ 464896.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018696900457143784  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0040476080030202866 │\n",
       "│ Value/Adv                     │ -0.07983780652284622   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01604675129055977    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0051119327545166016 │\n",
       "│ Value/reward                  │ 2.01237416267395       │\n",
       "│ Time/Total                    │ 3019.16259765625       │\n",
       "│ Time/Rollout                  │ 12.486763954162598     │\n",
       "│ Time/Update                   │ 1.9386775493621826     │\n",
       "│ Time/Epoch                    │ 14.425491333007812     │\n",
       "│ Time/FPS                      │ 141.9709014892578      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.50403594970703      │\n",
       "│ Metrics/EpCost                │ 51.7599983215332       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 227.0                  │\n",
       "│ Train/Entropy                 │ 0.23575444519519806    │\n",
       "│ Train/KL                      │ 0.019711006432771683   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9927259683609009     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9927259683609009     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9927259683609009     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018766799941658974   │\n",
       "│ Train/LR                      │ 0.00016320000577252358 │\n",
       "│ Train/PolicyStd               │ 0.3063090741634369     │\n",
       "│ TotalEnvSteps                 │ 466944.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01806889846920967   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0006280019879341125  │\n",
       "│ Value/Adv                     │ -0.05880887061357498   │\n",
       "│ Loss/Loss_reward_critic       │ 0.0141192227602005     │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0019275285303592682 │\n",
       "│ Value/reward                  │ 2.1263864040374756     │\n",
       "│ Time/Total                    │ 3033.185791015625      │\n",
       "│ Time/Rollout                  │ 11.976218223571777     │\n",
       "│ Time/Update                   │ 2.0302369594573975     │\n",
       "│ Time/Epoch                    │ 14.00650405883789      │\n",
       "│ Time/FPS                      │ 146.21778869628906     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.50403594970703      │\n",
       "│ Metrics/EpCost                │ 51.7599983215332       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 227.0                  │\n",
       "│ Train/Entropy                 │ 0.23575444519519806    │\n",
       "│ Train/KL                      │ 0.019711006432771683   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9927259683609009     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9927259683609009     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9927259683609009     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018766799941658974   │\n",
       "│ Train/LR                      │ 0.00016320000577252358 │\n",
       "│ Train/PolicyStd               │ 0.3063090741634369     │\n",
       "│ TotalEnvSteps                 │ 466944.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01806889846920967   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0006280019879341125  │\n",
       "│ Value/Adv                     │ -0.05880887061357498   │\n",
       "│ Loss/Loss_reward_critic       │ 0.0141192227602005     │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0019275285303592682 │\n",
       "│ Value/reward                  │ 2.1263864040374756     │\n",
       "│ Time/Total                    │ 3033.185791015625      │\n",
       "│ Time/Rollout                  │ 11.976218223571777     │\n",
       "│ Time/Update                   │ 2.0302369594573975     │\n",
       "│ Time/Epoch                    │ 14.00650405883789      │\n",
       "│ Time/FPS                      │ 146.21778869628906     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.46763038635254      │\n",
       "│ Metrics/EpCost                │ 51.220001220703125     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 228.0                  │\n",
       "│ Train/Entropy                 │ 0.23387710750102997    │\n",
       "│ Train/KL                      │ 0.01709853857755661    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9963696599006653     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9963696599006653     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9963696599006653     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019531473517417908   │\n",
       "│ Train/LR                      │ 0.00016260000120382756 │\n",
       "│ Train/PolicyStd               │ 0.3057289123535156     │\n",
       "│ TotalEnvSteps                 │ 468992.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017856048420071602  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00021285004913806915 │\n",
       "│ Value/Adv                     │ 0.23998618125915527    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01860160566866398    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004482382908463478   │\n",
       "│ Value/reward                  │ 2.065798759460449      │\n",
       "│ Time/Total                    │ 3047.119140625         │\n",
       "│ Time/Rollout                  │ 11.844614028930664     │\n",
       "│ Time/Update                   │ 2.0757999420166016     │\n",
       "│ Time/Epoch                    │ 13.920458793640137     │\n",
       "│ Time/FPS                      │ 147.12159729003906     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.46763038635254      │\n",
       "│ Metrics/EpCost                │ 51.220001220703125     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 228.0                  │\n",
       "│ Train/Entropy                 │ 0.23387710750102997    │\n",
       "│ Train/KL                      │ 0.01709853857755661    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9963696599006653     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9963696599006653     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9963696599006653     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019531473517417908   │\n",
       "│ Train/LR                      │ 0.00016260000120382756 │\n",
       "│ Train/PolicyStd               │ 0.3057289123535156     │\n",
       "│ TotalEnvSteps                 │ 468992.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017856048420071602  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00021285004913806915 │\n",
       "│ Value/Adv                     │ 0.23998618125915527    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01860160566866398    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004482382908463478   │\n",
       "│ Value/reward                  │ 2.065798759460449      │\n",
       "│ Time/Total                    │ 3047.119140625         │\n",
       "│ Time/Rollout                  │ 11.844614028930664     │\n",
       "│ Time/Update                   │ 2.0757999420166016     │\n",
       "│ Time/Epoch                    │ 13.920458793640137     │\n",
       "│ Time/FPS                      │ 147.12159729003906     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.368083953857422     │\n",
       "│ Metrics/EpCost                │ 50.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 229.0                  │\n",
       "│ Train/Entropy                 │ 0.2257588803768158     │\n",
       "│ Train/KL                      │ 0.019426127895712852   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9944143295288086     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9944143295288086     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9944143295288086     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01886126585304737    │\n",
       "│ Train/LR                      │ 0.00016199999663513154 │\n",
       "│ Train/PolicyStd               │ 0.3032602369785309     │\n",
       "│ TotalEnvSteps                 │ 471040.0               │\n",
       "│ Loss/Loss_pi                  │ -0.02208070084452629   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004224652424454689  │\n",
       "│ Value/Adv                     │ -0.06487186253070831   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01921454444527626    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0006129387766122818  │\n",
       "│ Value/reward                  │ 2.0168395042419434     │\n",
       "│ Time/Total                    │ 3060.647705078125      │\n",
       "│ Time/Rollout                  │ 11.621933937072754     │\n",
       "│ Time/Update                   │ 1.891979455947876      │\n",
       "│ Time/Epoch                    │ 13.51396369934082      │\n",
       "│ Time/FPS                      │ 151.54696655273438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.368083953857422     │\n",
       "│ Metrics/EpCost                │ 50.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 229.0                  │\n",
       "│ Train/Entropy                 │ 0.2257588803768158     │\n",
       "│ Train/KL                      │ 0.019426127895712852   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9944143295288086     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9944143295288086     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9944143295288086     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01886126585304737    │\n",
       "│ Train/LR                      │ 0.00016199999663513154 │\n",
       "│ Train/PolicyStd               │ 0.3032602369785309     │\n",
       "│ TotalEnvSteps                 │ 471040.0               │\n",
       "│ Loss/Loss_pi                  │ -0.02208070084452629   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004224652424454689  │\n",
       "│ Value/Adv                     │ -0.06487186253070831   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01921454444527626    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0006129387766122818  │\n",
       "│ Value/reward                  │ 2.0168395042419434     │\n",
       "│ Time/Total                    │ 3060.647705078125      │\n",
       "│ Time/Rollout                  │ 11.621933937072754     │\n",
       "│ Time/Update                   │ 1.891979455947876      │\n",
       "│ Time/Epoch                    │ 13.51396369934082      │\n",
       "│ Time/FPS                      │ 151.54696655273438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.362892150878906     │\n",
       "│ Metrics/EpCost                │ 49.70000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 230.0                  │\n",
       "│ Train/Entropy                 │ 0.2143324315547943     │\n",
       "│ Train/KL                      │ 0.017576182261109352   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9957389831542969     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9957389831542969     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9957389831542969     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020726125687360764   │\n",
       "│ Train/LR                      │ 0.00016140000661835074 │\n",
       "│ Train/PolicyStd               │ 0.29982128739356995    │\n",
       "│ TotalEnvSteps                 │ 473088.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01551691722124815   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.006563783623278141   │\n",
       "│ Value/Adv                     │ 0.03997278958559036    │\n",
       "│ Loss/Loss_reward_critic       │ 0.015957649797201157   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0032568946480751038 │\n",
       "│ Value/reward                  │ 2.01137113571167       │\n",
       "│ Time/Total                    │ 3074.449951171875      │\n",
       "│ Time/Rollout                  │ 11.754156112670898     │\n",
       "│ Time/Update                   │ 2.0332460403442383     │\n",
       "│ Time/Epoch                    │ 13.787449836730957     │\n",
       "│ Time/FPS                      │ 148.5408935546875      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.362892150878906     │\n",
       "│ Metrics/EpCost                │ 49.70000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 230.0                  │\n",
       "│ Train/Entropy                 │ 0.2143324315547943     │\n",
       "│ Train/KL                      │ 0.017576182261109352   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9957389831542969     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9957389831542969     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9957389831542969     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020726125687360764   │\n",
       "│ Train/LR                      │ 0.00016140000661835074 │\n",
       "│ Train/PolicyStd               │ 0.29982128739356995    │\n",
       "│ TotalEnvSteps                 │ 473088.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01551691722124815   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.006563783623278141   │\n",
       "│ Value/Adv                     │ 0.03997278958559036    │\n",
       "│ Loss/Loss_reward_critic       │ 0.015957649797201157   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0032568946480751038 │\n",
       "│ Value/reward                  │ 2.01137113571167       │\n",
       "│ Time/Total                    │ 3074.449951171875      │\n",
       "│ Time/Rollout                  │ 11.754156112670898     │\n",
       "│ Time/Update                   │ 2.0332460403442383     │\n",
       "│ Time/Epoch                    │ 13.787449836730957     │\n",
       "│ Time/FPS                      │ 148.5408935546875      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.26770782470703      │\n",
       "│ Metrics/EpCost                │ 51.65999984741211      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 231.0                  │\n",
       "│ Train/Entropy                 │ 0.21132846176624298    │\n",
       "│ Train/KL                      │ 0.016326123848557472   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.995406985282898      │\n",
       "│ Train/PolicyRatio/Min         │ 0.995406985282898      │\n",
       "│ Train/PolicyRatio/Max         │ 0.995406985282898      │\n",
       "│ Train/PolicyRatio/Std         │ 0.02029580809175968    │\n",
       "│ Train/LR                      │ 0.00016080000204965472 │\n",
       "│ Train/PolicyStd               │ 0.2989233434200287     │\n",
       "│ TotalEnvSteps                 │ 475136.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016746152192354202  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0012292349711060524 │\n",
       "│ Value/Adv                     │ 0.1799018681049347     │\n",
       "│ Loss/Loss_reward_critic       │ 0.01229005679488182    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.003667593002319336  │\n",
       "│ Value/reward                  │ 1.9492363929748535     │\n",
       "│ Time/Total                    │ 3088.308349609375      │\n",
       "│ Time/Rollout                  │ 11.843162536621094     │\n",
       "│ Time/Update                   │ 2.0012052059173584     │\n",
       "│ Time/Epoch                    │ 13.8444185256958       │\n",
       "│ Time/FPS                      │ 147.92965698242188     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.26770782470703      │\n",
       "│ Metrics/EpCost                │ 51.65999984741211      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 231.0                  │\n",
       "│ Train/Entropy                 │ 0.21132846176624298    │\n",
       "│ Train/KL                      │ 0.016326123848557472   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.995406985282898      │\n",
       "│ Train/PolicyRatio/Min         │ 0.995406985282898      │\n",
       "│ Train/PolicyRatio/Max         │ 0.995406985282898      │\n",
       "│ Train/PolicyRatio/Std         │ 0.02029580809175968    │\n",
       "│ Train/LR                      │ 0.00016080000204965472 │\n",
       "│ Train/PolicyStd               │ 0.2989233434200287     │\n",
       "│ TotalEnvSteps                 │ 475136.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016746152192354202  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0012292349711060524 │\n",
       "│ Value/Adv                     │ 0.1799018681049347     │\n",
       "│ Loss/Loss_reward_critic       │ 0.01229005679488182    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.003667593002319336  │\n",
       "│ Value/reward                  │ 1.9492363929748535     │\n",
       "│ Time/Total                    │ 3088.308349609375      │\n",
       "│ Time/Rollout                  │ 11.843162536621094     │\n",
       "│ Time/Update                   │ 2.0012052059173584     │\n",
       "│ Time/Epoch                    │ 13.8444185256958       │\n",
       "│ Time/FPS                      │ 147.92965698242188     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m4\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.382789611816406    │\n",
       "│ Metrics/EpCost                │ 56.880001068115234    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 232.0                 │\n",
       "│ Train/Entropy                 │ 0.21312196552753448   │\n",
       "│ Train/KL                      │ 0.027673393487930298  │\n",
       "│ Train/StopIter                │ 4.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9982839822769165    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9982839822769165    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9982839822769165    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01860964484512806   │\n",
       "│ Train/LR                      │ 0.0001601999974809587 │\n",
       "│ Train/PolicyStd               │ 0.2994617223739624    │\n",
       "│ TotalEnvSteps                 │ 477184.0              │\n",
       "│ Loss/Loss_pi                  │ -0.003399861743673682 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.01334629044868052   │\n",
       "│ Value/Adv                     │ 0.23086309432983398   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01740121841430664   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00511116161942482   │\n",
       "│ Value/reward                  │ 1.8726654052734375    │\n",
       "│ Time/Total                    │ 3101.019775390625     │\n",
       "│ Time/Rollout                  │ 11.935789108276367    │\n",
       "│ Time/Update                   │ 0.7620103359222412    │\n",
       "│ Time/Epoch                    │ 12.697843551635742    │\n",
       "│ Time/FPS                      │ 161.2872314453125     │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.382789611816406    │\n",
       "│ Metrics/EpCost                │ 56.880001068115234    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 232.0                 │\n",
       "│ Train/Entropy                 │ 0.21312196552753448   │\n",
       "│ Train/KL                      │ 0.027673393487930298  │\n",
       "│ Train/StopIter                │ 4.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9982839822769165    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9982839822769165    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9982839822769165    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01860964484512806   │\n",
       "│ Train/LR                      │ 0.0001601999974809587 │\n",
       "│ Train/PolicyStd               │ 0.2994617223739624    │\n",
       "│ TotalEnvSteps                 │ 477184.0              │\n",
       "│ Loss/Loss_pi                  │ -0.003399861743673682 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.01334629044868052   │\n",
       "│ Value/Adv                     │ 0.23086309432983398   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01740121841430664   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00511116161942482   │\n",
       "│ Value/reward                  │ 1.8726654052734375    │\n",
       "│ Time/Total                    │ 3101.019775390625     │\n",
       "│ Time/Rollout                  │ 11.935789108276367    │\n",
       "│ Time/Update                   │ 0.7620103359222412    │\n",
       "│ Time/Epoch                    │ 12.697843551635742    │\n",
       "│ Time/FPS                      │ 161.2872314453125     │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.368894577026367      │\n",
       "│ Metrics/EpCost                │ 58.0                    │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 233.0                   │\n",
       "│ Train/Entropy                 │ 0.21011118590831757     │\n",
       "│ Train/KL                      │ 0.014956144616007805    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0017621517181396      │\n",
       "│ Train/PolicyRatio/Min         │ 1.0017621517181396      │\n",
       "│ Train/PolicyRatio/Max         │ 1.0017621517181396      │\n",
       "│ Train/PolicyRatio/Std         │ 0.01935848593711853     │\n",
       "│ Train/LR                      │ 0.00015959999291226268  │\n",
       "│ Train/PolicyStd               │ 0.29858332872390747     │\n",
       "│ TotalEnvSteps                 │ 479232.0                │\n",
       "│ Loss/Loss_pi                  │ -0.019799966365098953   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.01640010462142527    │\n",
       "│ Value/Adv                     │ 0.005661822855472565    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017390744760632515    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -1.0473653674125671e-05 │\n",
       "│ Value/reward                  │ 2.0090250968933105      │\n",
       "│ Time/Total                    │ 3114.648193359375       │\n",
       "│ Time/Rollout                  │ 11.71420955657959       │\n",
       "│ Time/Update                   │ 1.9016156196594238      │\n",
       "│ Time/Epoch                    │ 13.615877151489258      │\n",
       "│ Time/FPS                      │ 150.4126434326172       │\n",
       "└───────────────────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.368894577026367      │\n",
       "│ Metrics/EpCost                │ 58.0                    │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 233.0                   │\n",
       "│ Train/Entropy                 │ 0.21011118590831757     │\n",
       "│ Train/KL                      │ 0.014956144616007805    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0017621517181396      │\n",
       "│ Train/PolicyRatio/Min         │ 1.0017621517181396      │\n",
       "│ Train/PolicyRatio/Max         │ 1.0017621517181396      │\n",
       "│ Train/PolicyRatio/Std         │ 0.01935848593711853     │\n",
       "│ Train/LR                      │ 0.00015959999291226268  │\n",
       "│ Train/PolicyStd               │ 0.29858332872390747     │\n",
       "│ TotalEnvSteps                 │ 479232.0                │\n",
       "│ Loss/Loss_pi                  │ -0.019799966365098953   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.01640010462142527    │\n",
       "│ Value/Adv                     │ 0.005661822855472565    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017390744760632515    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -1.0473653674125671e-05 │\n",
       "│ Value/reward                  │ 2.0090250968933105      │\n",
       "│ Time/Total                    │ 3114.648193359375       │\n",
       "│ Time/Rollout                  │ 11.71420955657959       │\n",
       "│ Time/Update                   │ 1.9016156196594238      │\n",
       "│ Time/Epoch                    │ 13.615877151489258      │\n",
       "│ Time/FPS                      │ 150.4126434326172       │\n",
       "└───────────────────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m10\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.35805320739746       │\n",
       "│ Metrics/EpCost                │ 55.2599983215332        │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 234.0                   │\n",
       "│ Train/Entropy                 │ 0.20085899531841278     │\n",
       "│ Train/KL                      │ 0.020751995965838432    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9966635704040527      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9966635704040527      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9966635704040527      │\n",
       "│ Train/PolicyRatio/Std         │ 0.020103827118873596    │\n",
       "│ Train/LR                      │ 0.00015900000289548188  │\n",
       "│ Train/PolicyStd               │ 0.29583796858787537     │\n",
       "│ TotalEnvSteps                 │ 481280.0                │\n",
       "│ Loss/Loss_pi                  │ -0.020009920001029968   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00020995363593101501 │\n",
       "│ Value/Adv                     │ 0.07838398218154907     │\n",
       "│ Loss/Loss_reward_critic       │ 0.018977701663970947    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0015869569033384323   │\n",
       "│ Value/reward                  │ 2.004882574081421       │\n",
       "│ Time/Total                    │ 3128.367431640625       │\n",
       "│ Time/Rollout                  │ 11.814070701599121      │\n",
       "│ Time/Update                   │ 1.893296718597412       │\n",
       "│ Time/Epoch                    │ 13.70742416381836       │\n",
       "│ Time/FPS                      │ 149.40809631347656      │\n",
       "└───────────────────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.35805320739746       │\n",
       "│ Metrics/EpCost                │ 55.2599983215332        │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 234.0                   │\n",
       "│ Train/Entropy                 │ 0.20085899531841278     │\n",
       "│ Train/KL                      │ 0.020751995965838432    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9966635704040527      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9966635704040527      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9966635704040527      │\n",
       "│ Train/PolicyRatio/Std         │ 0.020103827118873596    │\n",
       "│ Train/LR                      │ 0.00015900000289548188  │\n",
       "│ Train/PolicyStd               │ 0.29583796858787537     │\n",
       "│ TotalEnvSteps                 │ 481280.0                │\n",
       "│ Loss/Loss_pi                  │ -0.020009920001029968   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00020995363593101501 │\n",
       "│ Value/Adv                     │ 0.07838398218154907     │\n",
       "│ Loss/Loss_reward_critic       │ 0.018977701663970947    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0015869569033384323   │\n",
       "│ Value/reward                  │ 2.004882574081421       │\n",
       "│ Time/Total                    │ 3128.367431640625       │\n",
       "│ Time/Rollout                  │ 11.814070701599121      │\n",
       "│ Time/Update                   │ 1.893296718597412       │\n",
       "│ Time/Epoch                    │ 13.70742416381836       │\n",
       "│ Time/FPS                      │ 149.40809631347656      │\n",
       "└───────────────────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m9\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.300477981567383     │\n",
       "│ Metrics/EpCost                │ 54.5                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 235.0                  │\n",
       "│ Train/Entropy                 │ 0.1907619684934616     │\n",
       "│ Train/KL                      │ 0.020383324474096298   │\n",
       "│ Train/StopIter                │ 9.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9937504529953003     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9937504529953003     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9937504529953003     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02163758873939514    │\n",
       "│ Train/LR                      │ 0.00015839999832678586 │\n",
       "│ Train/PolicyStd               │ 0.29285433888435364    │\n",
       "│ TotalEnvSteps                 │ 483328.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017258159816265106  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002751760184764862   │\n",
       "│ Value/Adv                     │ 0.08055125921964645    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01957804150879383    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0006003398448228836  │\n",
       "│ Value/reward                  │ 2.011756658554077      │\n",
       "│ Time/Total                    │ 3141.915771484375      │\n",
       "│ Time/Rollout                  │ 11.766983032226562     │\n",
       "│ Time/Update                   │ 1.7687840461730957     │\n",
       "│ Time/Epoch                    │ 13.535810470581055     │\n",
       "│ Time/FPS                      │ 151.30235290527344     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.300477981567383     │\n",
       "│ Metrics/EpCost                │ 54.5                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 235.0                  │\n",
       "│ Train/Entropy                 │ 0.1907619684934616     │\n",
       "│ Train/KL                      │ 0.020383324474096298   │\n",
       "│ Train/StopIter                │ 9.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9937504529953003     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9937504529953003     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9937504529953003     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02163758873939514    │\n",
       "│ Train/LR                      │ 0.00015839999832678586 │\n",
       "│ Train/PolicyStd               │ 0.29285433888435364    │\n",
       "│ TotalEnvSteps                 │ 483328.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017258159816265106  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002751760184764862   │\n",
       "│ Value/Adv                     │ 0.08055125921964645    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01957804150879383    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0006003398448228836  │\n",
       "│ Value/reward                  │ 2.011756658554077      │\n",
       "│ Time/Total                    │ 3141.915771484375      │\n",
       "│ Time/Rollout                  │ 11.766983032226562     │\n",
       "│ Time/Update                   │ 1.7687840461730957     │\n",
       "│ Time/Epoch                    │ 13.535810470581055     │\n",
       "│ Time/FPS                      │ 151.30235290527344     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.223106384277344     │\n",
       "│ Metrics/EpCost                │ 53.52000045776367      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 236.0                  │\n",
       "│ Train/Entropy                 │ 0.1846400499343872     │\n",
       "│ Train/KL                      │ 0.018571900203824043   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9949361085891724     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9949361085891724     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9949361085891724     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020432069897651672   │\n",
       "│ Train/LR                      │ 0.00015779999375808984 │\n",
       "│ Train/PolicyStd               │ 0.2910621464252472     │\n",
       "│ TotalEnvSteps                 │ 485376.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017306853085756302  │\n",
       "│ Loss/Loss_pi/Delta            │ -4.869326949119568e-05 │\n",
       "│ Value/Adv                     │ 0.1665731817483902     │\n",
       "│ Loss/Loss_reward_critic       │ 0.014401140622794628   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005176900885999203  │\n",
       "│ Value/reward                  │ 2.073594093322754      │\n",
       "│ Time/Total                    │ 3155.74267578125       │\n",
       "│ Time/Rollout                  │ 11.768065452575684     │\n",
       "│ Time/Update                   │ 2.046992063522339      │\n",
       "│ Time/Epoch                    │ 13.815105438232422     │\n",
       "│ Time/FPS                      │ 148.24354553222656     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.223106384277344     │\n",
       "│ Metrics/EpCost                │ 53.52000045776367      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 236.0                  │\n",
       "│ Train/Entropy                 │ 0.1846400499343872     │\n",
       "│ Train/KL                      │ 0.018571900203824043   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9949361085891724     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9949361085891724     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9949361085891724     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020432069897651672   │\n",
       "│ Train/LR                      │ 0.00015779999375808984 │\n",
       "│ Train/PolicyStd               │ 0.2910621464252472     │\n",
       "│ TotalEnvSteps                 │ 485376.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017306853085756302  │\n",
       "│ Loss/Loss_pi/Delta            │ -4.869326949119568e-05 │\n",
       "│ Value/Adv                     │ 0.1665731817483902     │\n",
       "│ Loss/Loss_reward_critic       │ 0.014401140622794628   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005176900885999203  │\n",
       "│ Value/reward                  │ 2.073594093322754      │\n",
       "│ Time/Total                    │ 3155.74267578125       │\n",
       "│ Time/Rollout                  │ 11.768065452575684     │\n",
       "│ Time/Update                   │ 2.046992063522339      │\n",
       "│ Time/Epoch                    │ 13.815105438232422     │\n",
       "│ Time/FPS                      │ 148.24354553222656     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.138568878173828     │\n",
       "│ Metrics/EpCost                │ 54.459999084472656     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 237.0                  │\n",
       "│ Train/Entropy                 │ 0.1840246617794037     │\n",
       "│ Train/KL                      │ 0.01615522988140583    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0046436786651611     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0046436786651611     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0046436786651611     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019044263288378716   │\n",
       "│ Train/LR                      │ 0.00015720000374130905 │\n",
       "│ Train/PolicyStd               │ 0.2908697724342346     │\n",
       "│ TotalEnvSteps                 │ 487424.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015698730945587158  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0016081221401691437  │\n",
       "│ Value/Adv                     │ -0.08998434990644455   │\n",
       "│ Loss/Loss_reward_critic       │ 0.016177702695131302   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0017765620723366737  │\n",
       "│ Value/reward                  │ 2.048372745513916      │\n",
       "│ Time/Total                    │ 3169.77001953125       │\n",
       "│ Time/Rollout                  │ 11.951253890991211     │\n",
       "│ Time/Update                   │ 2.0640838146209717     │\n",
       "│ Time/Epoch                    │ 14.01537799835205      │\n",
       "│ Time/FPS                      │ 146.12521362304688     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.138568878173828     │\n",
       "│ Metrics/EpCost                │ 54.459999084472656     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 237.0                  │\n",
       "│ Train/Entropy                 │ 0.1840246617794037     │\n",
       "│ Train/KL                      │ 0.01615522988140583    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0046436786651611     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0046436786651611     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0046436786651611     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019044263288378716   │\n",
       "│ Train/LR                      │ 0.00015720000374130905 │\n",
       "│ Train/PolicyStd               │ 0.2908697724342346     │\n",
       "│ TotalEnvSteps                 │ 487424.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015698730945587158  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0016081221401691437  │\n",
       "│ Value/Adv                     │ -0.08998434990644455   │\n",
       "│ Loss/Loss_reward_critic       │ 0.016177702695131302   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0017765620723366737  │\n",
       "│ Value/reward                  │ 2.048372745513916      │\n",
       "│ Time/Total                    │ 3169.77001953125       │\n",
       "│ Time/Rollout                  │ 11.951253890991211     │\n",
       "│ Time/Update                   │ 2.0640838146209717     │\n",
       "│ Time/Epoch                    │ 14.01537799835205      │\n",
       "│ Time/FPS                      │ 146.12521362304688     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.983356475830078     │\n",
       "│ Metrics/EpCost                │ 52.7400016784668       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 238.0                  │\n",
       "│ Train/Entropy                 │ 0.1817598193883896     │\n",
       "│ Train/KL                      │ 0.015362675301730633   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0020129680633545     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0020129680633545     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0020129680633545     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019179627299308777   │\n",
       "│ Train/LR                      │ 0.00015659999917261302 │\n",
       "│ Train/PolicyStd               │ 0.2902107238769531     │\n",
       "│ TotalEnvSteps                 │ 489472.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015784788876771927  │\n",
       "│ Loss/Loss_pi/Delta            │ -8.605793118476868e-05 │\n",
       "│ Value/Adv                     │ -0.07805538922548294   │\n",
       "│ Loss/Loss_reward_critic       │ 0.010723980143666267   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0054537225514650345 │\n",
       "│ Value/reward                  │ 2.0046308040618896     │\n",
       "│ Time/Total                    │ 3183.774658203125      │\n",
       "│ Time/Rollout                  │ 11.966649055480957     │\n",
       "│ Time/Update                   │ 2.022681713104248      │\n",
       "│ Time/Epoch                    │ 13.989377975463867     │\n",
       "│ Time/FPS                      │ 146.39678955078125     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.983356475830078     │\n",
       "│ Metrics/EpCost                │ 52.7400016784668       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 238.0                  │\n",
       "│ Train/Entropy                 │ 0.1817598193883896     │\n",
       "│ Train/KL                      │ 0.015362675301730633   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0020129680633545     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0020129680633545     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0020129680633545     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019179627299308777   │\n",
       "│ Train/LR                      │ 0.00015659999917261302 │\n",
       "│ Train/PolicyStd               │ 0.2902107238769531     │\n",
       "│ TotalEnvSteps                 │ 489472.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015784788876771927  │\n",
       "│ Loss/Loss_pi/Delta            │ -8.605793118476868e-05 │\n",
       "│ Value/Adv                     │ -0.07805538922548294   │\n",
       "│ Loss/Loss_reward_critic       │ 0.010723980143666267   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0054537225514650345 │\n",
       "│ Value/reward                  │ 2.0046308040618896     │\n",
       "│ Time/Total                    │ 3183.774658203125      │\n",
       "│ Time/Rollout                  │ 11.966649055480957     │\n",
       "│ Time/Update                   │ 2.022681713104248      │\n",
       "│ Time/Epoch                    │ 13.989377975463867     │\n",
       "│ Time/FPS                      │ 146.39678955078125     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.022106170654297     │\n",
       "│ Metrics/EpCost                │ 53.84000015258789      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 239.0                  │\n",
       "│ Train/Entropy                 │ 0.17762720584869385    │\n",
       "│ Train/KL                      │ 0.01507378090173006    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9956563711166382     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9956563711166382     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9956563711166382     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019392596557736397   │\n",
       "│ Train/LR                      │ 0.000155999994603917   │\n",
       "│ Train/PolicyStd               │ 0.28902509808540344    │\n",
       "│ TotalEnvSteps                 │ 491520.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015640782192349434  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00014400668442249298 │\n",
       "│ Value/Adv                     │ -0.17378893494606018   │\n",
       "│ Loss/Loss_reward_critic       │ 0.020923873409628868   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0101998932659626     │\n",
       "│ Value/reward                  │ 1.98408043384552       │\n",
       "│ Time/Total                    │ 3197.400390625         │\n",
       "│ Time/Rollout                  │ 11.686654090881348     │\n",
       "│ Time/Update                   │ 1.9267373085021973     │\n",
       "│ Time/Epoch                    │ 13.613443374633789     │\n",
       "│ Time/FPS                      │ 150.4395294189453      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.022106170654297     │\n",
       "│ Metrics/EpCost                │ 53.84000015258789      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 239.0                  │\n",
       "│ Train/Entropy                 │ 0.17762720584869385    │\n",
       "│ Train/KL                      │ 0.01507378090173006    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9956563711166382     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9956563711166382     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9956563711166382     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019392596557736397   │\n",
       "│ Train/LR                      │ 0.000155999994603917   │\n",
       "│ Train/PolicyStd               │ 0.28902509808540344    │\n",
       "│ TotalEnvSteps                 │ 491520.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015640782192349434  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00014400668442249298 │\n",
       "│ Value/Adv                     │ -0.17378893494606018   │\n",
       "│ Loss/Loss_reward_critic       │ 0.020923873409628868   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0101998932659626     │\n",
       "│ Value/reward                  │ 1.98408043384552       │\n",
       "│ Time/Total                    │ 3197.400390625         │\n",
       "│ Time/Rollout                  │ 11.686654090881348     │\n",
       "│ Time/Update                   │ 1.9267373085021973     │\n",
       "│ Time/Epoch                    │ 13.613443374633789     │\n",
       "│ Time/FPS                      │ 150.4395294189453      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.892560958862305     │\n",
       "│ Metrics/EpCost                │ 53.459999084472656     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 240.0                  │\n",
       "│ Train/Entropy                 │ 0.1708422750234604     │\n",
       "│ Train/KL                      │ 0.015550017356872559   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9958151578903198     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9958151578903198     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9958151578903198     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019259799271821976   │\n",
       "│ Train/LR                      │ 0.0001554000045871362  │\n",
       "│ Train/PolicyStd               │ 0.28709179162979126    │\n",
       "│ TotalEnvSteps                 │ 493568.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017866134643554688  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0022253524512052536 │\n",
       "│ Value/Adv                     │ -0.028961103409528732  │\n",
       "│ Loss/Loss_reward_critic       │ 0.022602416574954987   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0016785431653261185  │\n",
       "│ Value/reward                  │ 1.9947540760040283     │\n",
       "│ Time/Total                    │ 3211.150146484375      │\n",
       "│ Time/Rollout                  │ 11.72791862487793      │\n",
       "│ Time/Update                   │ 2.006394624710083      │\n",
       "│ Time/Epoch                    │ 13.734356880187988     │\n",
       "│ Time/FPS                      │ 149.1151123046875      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.892560958862305     │\n",
       "│ Metrics/EpCost                │ 53.459999084472656     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 240.0                  │\n",
       "│ Train/Entropy                 │ 0.1708422750234604     │\n",
       "│ Train/KL                      │ 0.015550017356872559   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9958151578903198     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9958151578903198     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9958151578903198     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019259799271821976   │\n",
       "│ Train/LR                      │ 0.0001554000045871362  │\n",
       "│ Train/PolicyStd               │ 0.28709179162979126    │\n",
       "│ TotalEnvSteps                 │ 493568.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017866134643554688  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0022253524512052536 │\n",
       "│ Value/Adv                     │ -0.028961103409528732  │\n",
       "│ Loss/Loss_reward_critic       │ 0.022602416574954987   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0016785431653261185  │\n",
       "│ Value/reward                  │ 1.9947540760040283     │\n",
       "│ Time/Total                    │ 3211.150146484375      │\n",
       "│ Time/Rollout                  │ 11.72791862487793      │\n",
       "│ Time/Update                   │ 2.006394624710083      │\n",
       "│ Time/Epoch                    │ 13.734356880187988     │\n",
       "│ Time/FPS                      │ 149.1151123046875      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.939424514770508    │\n",
       "│ Metrics/EpCost                │ 52.599998474121094    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 241.0                 │\n",
       "│ Train/Entropy                 │ 0.16466449201107025   │\n",
       "│ Train/KL                      │ 0.0187143012881279    │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9985498189926147    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9985498189926147    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9985498189926147    │\n",
       "│ Train/PolicyRatio/Std         │ 0.019798850640654564  │\n",
       "│ Train/LR                      │ 0.0001548000000184402 │\n",
       "│ Train/PolicyStd               │ 0.2853401303291321    │\n",
       "│ TotalEnvSteps                 │ 495616.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01751004531979561  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.000356089323759079  │\n",
       "│ Value/Adv                     │ 0.09868720918893814   │\n",
       "│ Loss/Loss_reward_critic       │ 0.017587080597877502  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005015335977077484 │\n",
       "│ Value/reward                  │ 1.9929556846618652    │\n",
       "│ Time/Total                    │ 3225.447509765625     │\n",
       "│ Time/Rollout                  │ 12.225329399108887    │\n",
       "│ Time/Update                   │ 2.0598206520080566    │\n",
       "│ Time/Epoch                    │ 14.285192489624023    │\n",
       "│ Time/FPS                      │ 143.36524963378906    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.939424514770508    │\n",
       "│ Metrics/EpCost                │ 52.599998474121094    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 241.0                 │\n",
       "│ Train/Entropy                 │ 0.16466449201107025   │\n",
       "│ Train/KL                      │ 0.0187143012881279    │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9985498189926147    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9985498189926147    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9985498189926147    │\n",
       "│ Train/PolicyRatio/Std         │ 0.019798850640654564  │\n",
       "│ Train/LR                      │ 0.0001548000000184402 │\n",
       "│ Train/PolicyStd               │ 0.2853401303291321    │\n",
       "│ TotalEnvSteps                 │ 495616.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01751004531979561  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.000356089323759079  │\n",
       "│ Value/Adv                     │ 0.09868720918893814   │\n",
       "│ Loss/Loss_reward_critic       │ 0.017587080597877502  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005015335977077484 │\n",
       "│ Value/reward                  │ 1.9929556846618652    │\n",
       "│ Time/Total                    │ 3225.447509765625     │\n",
       "│ Time/Rollout                  │ 12.225329399108887    │\n",
       "│ Time/Update                   │ 2.0598206520080566    │\n",
       "│ Time/Epoch                    │ 14.285192489624023    │\n",
       "│ Time/FPS                      │ 143.36524963378906    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.056652069091797     │\n",
       "│ Metrics/EpCost                │ 55.52000045776367      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 242.0                  │\n",
       "│ Train/Entropy                 │ 0.16350461542606354    │\n",
       "│ Train/KL                      │ 0.014342177659273148   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9982021450996399     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9982021450996399     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9982021450996399     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01885802671313286    │\n",
       "│ Train/LR                      │ 0.00015419999544974416 │\n",
       "│ Train/PolicyStd               │ 0.2850244343280792     │\n",
       "│ TotalEnvSteps                 │ 497664.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01878475956618786   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00127471424639225   │\n",
       "│ Value/Adv                     │ -0.036154862493276596  │\n",
       "│ Loss/Loss_reward_critic       │ 0.018899571150541306   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.001312490552663803   │\n",
       "│ Value/reward                  │ 2.035726547241211      │\n",
       "│ Time/Total                    │ 3239.46044921875       │\n",
       "│ Time/Rollout                  │ 12.046368598937988     │\n",
       "│ Time/Update                   │ 1.9534282684326172     │\n",
       "│ Time/Epoch                    │ 13.999850273132324     │\n",
       "│ Time/FPS                      │ 146.2872772216797      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.056652069091797     │\n",
       "│ Metrics/EpCost                │ 55.52000045776367      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 242.0                  │\n",
       "│ Train/Entropy                 │ 0.16350461542606354    │\n",
       "│ Train/KL                      │ 0.014342177659273148   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9982021450996399     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9982021450996399     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9982021450996399     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01885802671313286    │\n",
       "│ Train/LR                      │ 0.00015419999544974416 │\n",
       "│ Train/PolicyStd               │ 0.2850244343280792     │\n",
       "│ TotalEnvSteps                 │ 497664.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01878475956618786   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00127471424639225   │\n",
       "│ Value/Adv                     │ -0.036154862493276596  │\n",
       "│ Loss/Loss_reward_critic       │ 0.018899571150541306   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.001312490552663803   │\n",
       "│ Value/reward                  │ 2.035726547241211      │\n",
       "│ Time/Total                    │ 3239.46044921875       │\n",
       "│ Time/Rollout                  │ 12.046368598937988     │\n",
       "│ Time/Update                   │ 1.9534282684326172     │\n",
       "│ Time/Epoch                    │ 13.999850273132324     │\n",
       "│ Time/FPS                      │ 146.2872772216797      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.008872985839844     │\n",
       "│ Metrics/EpCost                │ 54.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 243.0                  │\n",
       "│ Train/Entropy                 │ 0.1626308411359787     │\n",
       "│ Train/KL                      │ 0.01624317280948162    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9982026815414429     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9982026815414429     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9982026815414429     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018170969560742378   │\n",
       "│ Train/LR                      │ 0.00015360000543296337 │\n",
       "│ Train/PolicyStd               │ 0.284776508808136      │\n",
       "│ TotalEnvSteps                 │ 499712.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016872618347406387  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0019121412187814713  │\n",
       "│ Value/Adv                     │ 0.20251810550689697    │\n",
       "│ Loss/Loss_reward_critic       │ 0.027375802397727966   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00847623124718666    │\n",
       "│ Value/reward                  │ 2.0175328254699707     │\n",
       "│ Time/Total                    │ 3253.088134765625      │\n",
       "│ Time/Rollout                  │ 11.690143585205078     │\n",
       "│ Time/Update                   │ 1.925408124923706      │\n",
       "│ Time/Epoch                    │ 13.615608215332031     │\n",
       "│ Time/FPS                      │ 150.41561889648438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.008872985839844     │\n",
       "│ Metrics/EpCost                │ 54.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 243.0                  │\n",
       "│ Train/Entropy                 │ 0.1626308411359787     │\n",
       "│ Train/KL                      │ 0.01624317280948162    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9982026815414429     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9982026815414429     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9982026815414429     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018170969560742378   │\n",
       "│ Train/LR                      │ 0.00015360000543296337 │\n",
       "│ Train/PolicyStd               │ 0.284776508808136      │\n",
       "│ TotalEnvSteps                 │ 499712.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016872618347406387  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0019121412187814713  │\n",
       "│ Value/Adv                     │ 0.20251810550689697    │\n",
       "│ Loss/Loss_reward_critic       │ 0.027375802397727966   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00847623124718666    │\n",
       "│ Value/reward                  │ 2.0175328254699707     │\n",
       "│ Time/Total                    │ 3253.088134765625      │\n",
       "│ Time/Rollout                  │ 11.690143585205078     │\n",
       "│ Time/Update                   │ 1.925408124923706      │\n",
       "│ Time/Epoch                    │ 13.615608215332031     │\n",
       "│ Time/FPS                      │ 150.41561889648438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.171218872070312     │\n",
       "│ Metrics/EpCost                │ 56.459999084472656     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 244.0                  │\n",
       "│ Train/Entropy                 │ 0.16121025383472443    │\n",
       "│ Train/KL                      │ 0.01564723625779152    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9973985552787781     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9973985552787781     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9973985552787781     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018444307148456573   │\n",
       "│ Train/LR                      │ 0.00015300000086426735 │\n",
       "│ Train/PolicyStd               │ 0.2843535840511322     │\n",
       "│ TotalEnvSteps                 │ 501760.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018668808043003082  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.001796189695596695  │\n",
       "│ Value/Adv                     │ -0.023889265954494476  │\n",
       "│ Loss/Loss_reward_critic       │ 0.014993628486990929   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.012382173910737038  │\n",
       "│ Value/reward                  │ 2.0256006717681885     │\n",
       "│ Time/Total                    │ 3266.70947265625       │\n",
       "│ Time/Rollout                  │ 11.668111801147461     │\n",
       "│ Time/Update                   │ 1.9393727779388428     │\n",
       "│ Time/Epoch                    │ 13.607540130615234     │\n",
       "│ Time/FPS                      │ 150.5048065185547      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.171218872070312     │\n",
       "│ Metrics/EpCost                │ 56.459999084472656     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 244.0                  │\n",
       "│ Train/Entropy                 │ 0.16121025383472443    │\n",
       "│ Train/KL                      │ 0.01564723625779152    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9973985552787781     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9973985552787781     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9973985552787781     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018444307148456573   │\n",
       "│ Train/LR                      │ 0.00015300000086426735 │\n",
       "│ Train/PolicyStd               │ 0.2843535840511322     │\n",
       "│ TotalEnvSteps                 │ 501760.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018668808043003082  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.001796189695596695  │\n",
       "│ Value/Adv                     │ -0.023889265954494476  │\n",
       "│ Loss/Loss_reward_critic       │ 0.014993628486990929   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.012382173910737038  │\n",
       "│ Value/reward                  │ 2.0256006717681885     │\n",
       "│ Time/Total                    │ 3266.70947265625       │\n",
       "│ Time/Rollout                  │ 11.668111801147461     │\n",
       "│ Time/Update                   │ 1.9393727779388428     │\n",
       "│ Time/Epoch                    │ 13.607540130615234     │\n",
       "│ Time/FPS                      │ 150.5048065185547      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.26462173461914      │\n",
       "│ Metrics/EpCost                │ 55.84000015258789      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 245.0                  │\n",
       "│ Train/Entropy                 │ 0.1611207127571106     │\n",
       "│ Train/KL                      │ 0.014456464909017086   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9961438179016113     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9961438179016113     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9961438179016113     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01945783570408821    │\n",
       "│ Train/LR                      │ 0.00015239999629557133 │\n",
       "│ Train/PolicyStd               │ 0.28433170914649963    │\n",
       "│ TotalEnvSteps                 │ 503808.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017236003652215004  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0014328043907880783  │\n",
       "│ Value/Adv                     │ -0.15443070232868195   │\n",
       "│ Loss/Loss_reward_critic       │ 0.021253827959299088   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006260199472308159   │\n",
       "│ Value/reward                  │ 2.080773115158081      │\n",
       "│ Time/Total                    │ 3280.474609375         │\n",
       "│ Time/Rollout                  │ 11.813361167907715     │\n",
       "│ Time/Update                   │ 1.938718318939209      │\n",
       "│ Time/Epoch                    │ 13.752124786376953     │\n",
       "│ Time/FPS                      │ 148.92245483398438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.26462173461914      │\n",
       "│ Metrics/EpCost                │ 55.84000015258789      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 245.0                  │\n",
       "│ Train/Entropy                 │ 0.1611207127571106     │\n",
       "│ Train/KL                      │ 0.014456464909017086   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9961438179016113     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9961438179016113     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9961438179016113     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01945783570408821    │\n",
       "│ Train/LR                      │ 0.00015239999629557133 │\n",
       "│ Train/PolicyStd               │ 0.28433170914649963    │\n",
       "│ TotalEnvSteps                 │ 503808.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017236003652215004  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0014328043907880783  │\n",
       "│ Value/Adv                     │ -0.15443070232868195   │\n",
       "│ Loss/Loss_reward_critic       │ 0.021253827959299088   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006260199472308159   │\n",
       "│ Value/reward                  │ 2.080773115158081      │\n",
       "│ Time/Total                    │ 3280.474609375         │\n",
       "│ Time/Rollout                  │ 11.813361167907715     │\n",
       "│ Time/Update                   │ 1.938718318939209      │\n",
       "│ Time/Epoch                    │ 13.752124786376953     │\n",
       "│ Time/FPS                      │ 148.92245483398438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.2612361907959       │\n",
       "│ Metrics/EpCost                │ 56.68000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 246.0                  │\n",
       "│ Train/Entropy                 │ 0.16001486778259277    │\n",
       "│ Train/KL                      │ 0.01632261462509632    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9976250529289246     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9976250529289246     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9976250529289246     │\n",
       "│ Train/PolicyRatio/Std         │ 0.021399151533842087   │\n",
       "│ Train/LR                      │ 0.00015180000627879053 │\n",
       "│ Train/PolicyStd               │ 0.28402408957481384    │\n",
       "│ TotalEnvSteps                 │ 505856.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01582896150648594   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.001407042145729065   │\n",
       "│ Value/Adv                     │ 0.1990731805562973     │\n",
       "│ Loss/Loss_reward_critic       │ 0.024858638644218445   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0036048106849193573  │\n",
       "│ Value/reward                  │ 2.007652997970581      │\n",
       "│ Time/Total                    │ 3294.05029296875       │\n",
       "│ Time/Rollout                  │ 11.656152725219727     │\n",
       "│ Time/Update                   │ 1.9053313732147217     │\n",
       "│ Time/Epoch                    │ 13.561527252197266     │\n",
       "│ Time/FPS                      │ 151.0154571533203      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.2612361907959       │\n",
       "│ Metrics/EpCost                │ 56.68000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 246.0                  │\n",
       "│ Train/Entropy                 │ 0.16001486778259277    │\n",
       "│ Train/KL                      │ 0.01632261462509632    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9976250529289246     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9976250529289246     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9976250529289246     │\n",
       "│ Train/PolicyRatio/Std         │ 0.021399151533842087   │\n",
       "│ Train/LR                      │ 0.00015180000627879053 │\n",
       "│ Train/PolicyStd               │ 0.28402408957481384    │\n",
       "│ TotalEnvSteps                 │ 505856.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01582896150648594   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.001407042145729065   │\n",
       "│ Value/Adv                     │ 0.1990731805562973     │\n",
       "│ Loss/Loss_reward_critic       │ 0.024858638644218445   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0036048106849193573  │\n",
       "│ Value/reward                  │ 2.007652997970581      │\n",
       "│ Time/Total                    │ 3294.05029296875       │\n",
       "│ Time/Rollout                  │ 11.656152725219727     │\n",
       "│ Time/Update                   │ 1.9053313732147217     │\n",
       "│ Time/Epoch                    │ 13.561527252197266     │\n",
       "│ Time/FPS                      │ 151.0154571533203      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.264280319213867     │\n",
       "│ Metrics/EpCost                │ 58.20000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 247.0                  │\n",
       "│ Train/Entropy                 │ 0.16103613376617432    │\n",
       "│ Train/KL                      │ 0.01631406508386135    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9991737604141235     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9991737604141235     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9991737604141235     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02018406242132187    │\n",
       "│ Train/LR                      │ 0.0001512000017100945  │\n",
       "│ Train/PolicyStd               │ 0.28430259227752686    │\n",
       "│ TotalEnvSteps                 │ 507904.0               │\n",
       "│ Loss/Loss_pi                  │ -0.0183012206107378    │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0024722591042518616 │\n",
       "│ Value/Adv                     │ -0.04179408401250839   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015185150317847729   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.009673488326370716  │\n",
       "│ Value/reward                  │ 1.9736626148223877     │\n",
       "│ Time/Total                    │ 3307.961669921875      │\n",
       "│ Time/Rollout                  │ 11.883896827697754     │\n",
       "│ Time/Update                   │ 2.0149972438812256     │\n",
       "│ Time/Epoch                    │ 13.898950576782227     │\n",
       "│ Time/FPS                      │ 147.34925842285156     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.264280319213867     │\n",
       "│ Metrics/EpCost                │ 58.20000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 247.0                  │\n",
       "│ Train/Entropy                 │ 0.16103613376617432    │\n",
       "│ Train/KL                      │ 0.01631406508386135    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9991737604141235     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9991737604141235     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9991737604141235     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02018406242132187    │\n",
       "│ Train/LR                      │ 0.0001512000017100945  │\n",
       "│ Train/PolicyStd               │ 0.28430259227752686    │\n",
       "│ TotalEnvSteps                 │ 507904.0               │\n",
       "│ Loss/Loss_pi                  │ -0.0183012206107378    │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0024722591042518616 │\n",
       "│ Value/Adv                     │ -0.04179408401250839   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015185150317847729   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.009673488326370716  │\n",
       "│ Value/reward                  │ 1.9736626148223877     │\n",
       "│ Time/Total                    │ 3307.961669921875      │\n",
       "│ Time/Rollout                  │ 11.883896827697754     │\n",
       "│ Time/Update                   │ 2.0149972438812256     │\n",
       "│ Time/Epoch                    │ 13.898950576782227     │\n",
       "│ Time/FPS                      │ 147.34925842285156     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.271120071411133     │\n",
       "│ Metrics/EpCost                │ 57.97999954223633      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 248.0                  │\n",
       "│ Train/Entropy                 │ 0.1575789898633957     │\n",
       "│ Train/KL                      │ 0.015814222395420074   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.995276153087616      │\n",
       "│ Train/PolicyRatio/Min         │ 0.995276153087616      │\n",
       "│ Train/PolicyRatio/Max         │ 0.995276153087616      │\n",
       "│ Train/PolicyRatio/Std         │ 0.01921479031443596    │\n",
       "│ Train/LR                      │ 0.0001505999971413985  │\n",
       "│ Train/PolicyStd               │ 0.28332647681236267    │\n",
       "│ TotalEnvSteps                 │ 509952.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018093790858983994  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00020742975175380707 │\n",
       "│ Value/Adv                     │ -0.07498415559530258   │\n",
       "│ Loss/Loss_reward_critic       │ 0.025035079568624496   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.009849929250776768   │\n",
       "│ Value/reward                  │ 1.9878826141357422     │\n",
       "│ Time/Total                    │ 3321.800537109375      │\n",
       "│ Time/Rollout                  │ 11.84042739868164      │\n",
       "│ Time/Update                   │ 1.984485149383545      │\n",
       "│ Time/Epoch                    │ 13.824960708618164     │\n",
       "│ Time/FPS                      │ 148.1378631591797      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.271120071411133     │\n",
       "│ Metrics/EpCost                │ 57.97999954223633      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 248.0                  │\n",
       "│ Train/Entropy                 │ 0.1575789898633957     │\n",
       "│ Train/KL                      │ 0.015814222395420074   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.995276153087616      │\n",
       "│ Train/PolicyRatio/Min         │ 0.995276153087616      │\n",
       "│ Train/PolicyRatio/Max         │ 0.995276153087616      │\n",
       "│ Train/PolicyRatio/Std         │ 0.01921479031443596    │\n",
       "│ Train/LR                      │ 0.0001505999971413985  │\n",
       "│ Train/PolicyStd               │ 0.28332647681236267    │\n",
       "│ TotalEnvSteps                 │ 509952.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018093790858983994  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00020742975175380707 │\n",
       "│ Value/Adv                     │ -0.07498415559530258   │\n",
       "│ Loss/Loss_reward_critic       │ 0.025035079568624496   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.009849929250776768   │\n",
       "│ Value/reward                  │ 1.9878826141357422     │\n",
       "│ Time/Total                    │ 3321.800537109375      │\n",
       "│ Time/Rollout                  │ 11.84042739868164      │\n",
       "│ Time/Update                   │ 1.984485149383545      │\n",
       "│ Time/Epoch                    │ 13.824960708618164     │\n",
       "│ Time/FPS                      │ 148.1378631591797      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.327123641967773    │\n",
       "│ Metrics/EpCost                │ 56.79999923706055     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 249.0                 │\n",
       "│ Train/Entropy                 │ 0.15636539459228516   │\n",
       "│ Train/KL                      │ 0.011632101610302925  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9956966638565063    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9956966638565063    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9956966638565063    │\n",
       "│ Train/PolicyRatio/Std         │ 0.018004683777689934  │\n",
       "│ Train/LR                      │ 0.0001500000071246177 │\n",
       "│ Train/PolicyStd               │ 0.28299424052238464   │\n",
       "│ TotalEnvSteps                 │ 512000.0              │\n",
       "│ Loss/Loss_pi                  │ -0.013119635172188282 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0049741556867957115 │\n",
       "│ Value/Adv                     │ 0.09198183566331863   │\n",
       "│ Loss/Loss_reward_critic       │ 0.026988890022039413  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.001953810453414917  │\n",
       "│ Value/reward                  │ 1.980126142501831     │\n",
       "│ Time/Total                    │ 3335.654296875        │\n",
       "│ Time/Rollout                  │ 11.77003002166748     │\n",
       "│ Time/Update                   │ 2.0704915523529053    │\n",
       "│ Time/Epoch                    │ 13.840568542480469    │\n",
       "│ Time/FPS                      │ 147.97080993652344    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.327123641967773    │\n",
       "│ Metrics/EpCost                │ 56.79999923706055     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 249.0                 │\n",
       "│ Train/Entropy                 │ 0.15636539459228516   │\n",
       "│ Train/KL                      │ 0.011632101610302925  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9956966638565063    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9956966638565063    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9956966638565063    │\n",
       "│ Train/PolicyRatio/Std         │ 0.018004683777689934  │\n",
       "│ Train/LR                      │ 0.0001500000071246177 │\n",
       "│ Train/PolicyStd               │ 0.28299424052238464   │\n",
       "│ TotalEnvSteps                 │ 512000.0              │\n",
       "│ Loss/Loss_pi                  │ -0.013119635172188282 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0049741556867957115 │\n",
       "│ Value/Adv                     │ 0.09198183566331863   │\n",
       "│ Loss/Loss_reward_critic       │ 0.026988890022039413  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.001953810453414917  │\n",
       "│ Value/reward                  │ 1.980126142501831     │\n",
       "│ Time/Total                    │ 3335.654296875        │\n",
       "│ Time/Rollout                  │ 11.77003002166748     │\n",
       "│ Time/Update                   │ 2.0704915523529053    │\n",
       "│ Time/Epoch                    │ 13.840568542480469    │\n",
       "│ Time/FPS                      │ 147.97080993652344    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.432641983032227     │\n",
       "│ Metrics/EpCost                │ 58.20000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 250.0                  │\n",
       "│ Train/Entropy                 │ 0.15649309754371643    │\n",
       "│ Train/KL                      │ 0.013988844119012356   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9987514615058899     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9987514615058899     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9987514615058899     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01842888444662094    │\n",
       "│ Train/LR                      │ 0.00014940000255592167 │\n",
       "│ Train/PolicyStd               │ 0.2830139696598053     │\n",
       "│ TotalEnvSteps                 │ 514048.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017747724428772926  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004628089256584644  │\n",
       "│ Value/Adv                     │ 0.20053353905677795    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02067035809159279    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.006318531930446625  │\n",
       "│ Value/reward                  │ 1.9954040050506592     │\n",
       "│ Time/Total                    │ 3349.4384765625        │\n",
       "│ Time/Rollout                  │ 11.817193984985352     │\n",
       "│ Time/Update                   │ 1.9518942832946777     │\n",
       "│ Time/Epoch                    │ 13.769132614135742     │\n",
       "│ Time/FPS                      │ 148.73849487304688     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.432641983032227     │\n",
       "│ Metrics/EpCost                │ 58.20000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 250.0                  │\n",
       "│ Train/Entropy                 │ 0.15649309754371643    │\n",
       "│ Train/KL                      │ 0.013988844119012356   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9987514615058899     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9987514615058899     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9987514615058899     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01842888444662094    │\n",
       "│ Train/LR                      │ 0.00014940000255592167 │\n",
       "│ Train/PolicyStd               │ 0.2830139696598053     │\n",
       "│ TotalEnvSteps                 │ 514048.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017747724428772926  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004628089256584644  │\n",
       "│ Value/Adv                     │ 0.20053353905677795    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02067035809159279    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.006318531930446625  │\n",
       "│ Value/reward                  │ 1.9954040050506592     │\n",
       "│ Time/Total                    │ 3349.4384765625        │\n",
       "│ Time/Rollout                  │ 11.817193984985352     │\n",
       "│ Time/Update                   │ 1.9518942832946777     │\n",
       "│ Time/Epoch                    │ 13.769132614135742     │\n",
       "│ Time/FPS                      │ 148.73849487304688     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.595741271972656     │\n",
       "│ Metrics/EpCost                │ 59.400001525878906     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 251.0                  │\n",
       "│ Train/Entropy                 │ 0.15527279675006866    │\n",
       "│ Train/KL                      │ 0.01535567082464695    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0014749765396118     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0014749765396118     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0014749765396118     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018720615655183792   │\n",
       "│ Train/LR                      │ 0.00014879999798722565 │\n",
       "│ Train/PolicyStd               │ 0.28264862298965454    │\n",
       "│ TotalEnvSteps                 │ 516096.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01699739880859852   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.000750325620174408   │\n",
       "│ Value/Adv                     │ 0.2557271420955658     │\n",
       "│ Loss/Loss_reward_critic       │ 0.021708156913518906   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.001037798821926117   │\n",
       "│ Value/reward                  │ 2.1103031635284424     │\n",
       "│ Time/Total                    │ 3363.45751953125       │\n",
       "│ Time/Rollout                  │ 11.948498725891113     │\n",
       "│ Time/Update                   │ 2.0593936443328857     │\n",
       "│ Time/Epoch                    │ 14.007935523986816     │\n",
       "│ Time/FPS                      │ 146.20285034179688     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.595741271972656     │\n",
       "│ Metrics/EpCost                │ 59.400001525878906     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 251.0                  │\n",
       "│ Train/Entropy                 │ 0.15527279675006866    │\n",
       "│ Train/KL                      │ 0.01535567082464695    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0014749765396118     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0014749765396118     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0014749765396118     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018720615655183792   │\n",
       "│ Train/LR                      │ 0.00014879999798722565 │\n",
       "│ Train/PolicyStd               │ 0.28264862298965454    │\n",
       "│ TotalEnvSteps                 │ 516096.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01699739880859852   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.000750325620174408   │\n",
       "│ Value/Adv                     │ 0.2557271420955658     │\n",
       "│ Loss/Loss_reward_critic       │ 0.021708156913518906   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.001037798821926117   │\n",
       "│ Value/reward                  │ 2.1103031635284424     │\n",
       "│ Time/Total                    │ 3363.45751953125       │\n",
       "│ Time/Rollout                  │ 11.948498725891113     │\n",
       "│ Time/Update                   │ 2.0593936443328857     │\n",
       "│ Time/Epoch                    │ 14.007935523986816     │\n",
       "│ Time/FPS                      │ 146.20285034179688     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.244081497192383     │\n",
       "│ Metrics/EpCost                │ 59.63999938964844      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 252.0                  │\n",
       "│ Train/Entropy                 │ 0.1533614844083786     │\n",
       "│ Train/KL                      │ 0.011424913071095943   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0068705081939697     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0068705081939697     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0068705081939697     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01821019873023033    │\n",
       "│ Train/LR                      │ 0.00014819999341852963 │\n",
       "│ Train/PolicyStd               │ 0.2821318507194519     │\n",
       "│ TotalEnvSteps                 │ 518144.0               │\n",
       "│ Loss/Loss_pi                  │ -0.008473601192235947  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.008523797616362572   │\n",
       "│ Value/Adv                     │ -0.21152688562870026   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01761362887918949    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.004094528034329414  │\n",
       "│ Value/reward                  │ 1.737111210823059      │\n",
       "│ Time/Total                    │ 3377.44873046875       │\n",
       "│ Time/Rollout                  │ 11.996548652648926     │\n",
       "│ Time/Update                   │ 1.981112003326416      │\n",
       "│ Time/Epoch                    │ 13.97770881652832      │\n",
       "│ Time/FPS                      │ 146.51902770996094     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.244081497192383     │\n",
       "│ Metrics/EpCost                │ 59.63999938964844      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 252.0                  │\n",
       "│ Train/Entropy                 │ 0.1533614844083786     │\n",
       "│ Train/KL                      │ 0.011424913071095943   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0068705081939697     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0068705081939697     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0068705081939697     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01821019873023033    │\n",
       "│ Train/LR                      │ 0.00014819999341852963 │\n",
       "│ Train/PolicyStd               │ 0.2821318507194519     │\n",
       "│ TotalEnvSteps                 │ 518144.0               │\n",
       "│ Loss/Loss_pi                  │ -0.008473601192235947  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.008523797616362572   │\n",
       "│ Value/Adv                     │ -0.21152688562870026   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01761362887918949    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.004094528034329414  │\n",
       "│ Value/reward                  │ 1.737111210823059      │\n",
       "│ Time/Total                    │ 3377.44873046875       │\n",
       "│ Time/Rollout                  │ 11.996548652648926     │\n",
       "│ Time/Update                   │ 1.981112003326416      │\n",
       "│ Time/Epoch                    │ 13.97770881652832      │\n",
       "│ Time/FPS                      │ 146.51902770996094     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.29804039001465      │\n",
       "│ Metrics/EpCost                │ 61.47999954223633      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 253.0                  │\n",
       "│ Train/Entropy                 │ 0.14708900451660156    │\n",
       "│ Train/KL                      │ 0.015296676196157932   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.001802682876587      │\n",
       "│ Train/PolicyRatio/Min         │ 1.001802682876587      │\n",
       "│ Train/PolicyRatio/Max         │ 1.001802682876587      │\n",
       "│ Train/PolicyRatio/Std         │ 0.019668621942400932   │\n",
       "│ Train/LR                      │ 0.00014760000340174884 │\n",
       "│ Train/PolicyStd               │ 0.28039079904556274    │\n",
       "│ TotalEnvSteps                 │ 520192.0               │\n",
       "│ Loss/Loss_pi                  │ -0.019502852112054825  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.011029250919818878  │\n",
       "│ Value/Adv                     │ -0.06827608495950699   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01726948842406273    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0003441404551267624 │\n",
       "│ Value/reward                  │ 2.0549821853637695     │\n",
       "│ Time/Total                    │ 3391.183837890625      │\n",
       "│ Time/Rollout                  │ 11.665081977844238     │\n",
       "│ Time/Update                   │ 2.05761456489563       │\n",
       "│ Time/Epoch                    │ 13.722762107849121     │\n",
       "│ Time/FPS                      │ 149.24111938476562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.29804039001465      │\n",
       "│ Metrics/EpCost                │ 61.47999954223633      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 253.0                  │\n",
       "│ Train/Entropy                 │ 0.14708900451660156    │\n",
       "│ Train/KL                      │ 0.015296676196157932   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.001802682876587      │\n",
       "│ Train/PolicyRatio/Min         │ 1.001802682876587      │\n",
       "│ Train/PolicyRatio/Max         │ 1.001802682876587      │\n",
       "│ Train/PolicyRatio/Std         │ 0.019668621942400932   │\n",
       "│ Train/LR                      │ 0.00014760000340174884 │\n",
       "│ Train/PolicyStd               │ 0.28039079904556274    │\n",
       "│ TotalEnvSteps                 │ 520192.0               │\n",
       "│ Loss/Loss_pi                  │ -0.019502852112054825  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.011029250919818878  │\n",
       "│ Value/Adv                     │ -0.06827608495950699   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01726948842406273    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0003441404551267624 │\n",
       "│ Value/reward                  │ 2.0549821853637695     │\n",
       "│ Time/Total                    │ 3391.183837890625      │\n",
       "│ Time/Rollout                  │ 11.665081977844238     │\n",
       "│ Time/Update                   │ 2.05761456489563       │\n",
       "│ Time/Epoch                    │ 13.722762107849121     │\n",
       "│ Time/FPS                      │ 149.24111938476562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.44449806213379      │\n",
       "│ Metrics/EpCost                │ 63.68000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 254.0                  │\n",
       "│ Train/Entropy                 │ 0.14091706275939941    │\n",
       "│ Train/KL                      │ 0.01604665070772171    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.000062346458435      │\n",
       "│ Train/PolicyRatio/Min         │ 1.000062346458435      │\n",
       "│ Train/PolicyRatio/Max         │ 1.000062346458435      │\n",
       "│ Train/PolicyRatio/Std         │ 0.017987947911024094   │\n",
       "│ Train/LR                      │ 0.00014699999883305281 │\n",
       "│ Train/PolicyStd               │ 0.2787020206451416     │\n",
       "│ TotalEnvSteps                 │ 522240.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018795780837535858  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0007070712745189667  │\n",
       "│ Value/Adv                     │ 0.07651615142822266    │\n",
       "│ Loss/Loss_reward_critic       │ 0.020993322134017944   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0037238337099552155  │\n",
       "│ Value/reward                  │ 2.084459066390991      │\n",
       "│ Time/Total                    │ 3404.806640625         │\n",
       "│ Time/Rollout                  │ 11.60053539276123      │\n",
       "│ Time/Update                   │ 2.007904529571533      │\n",
       "│ Time/Epoch                    │ 13.608484268188477     │\n",
       "│ Time/FPS                      │ 150.49435424804688     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.44449806213379      │\n",
       "│ Metrics/EpCost                │ 63.68000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 254.0                  │\n",
       "│ Train/Entropy                 │ 0.14091706275939941    │\n",
       "│ Train/KL                      │ 0.01604665070772171    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.000062346458435      │\n",
       "│ Train/PolicyRatio/Min         │ 1.000062346458435      │\n",
       "│ Train/PolicyRatio/Max         │ 1.000062346458435      │\n",
       "│ Train/PolicyRatio/Std         │ 0.017987947911024094   │\n",
       "│ Train/LR                      │ 0.00014699999883305281 │\n",
       "│ Train/PolicyStd               │ 0.2787020206451416     │\n",
       "│ TotalEnvSteps                 │ 522240.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018795780837535858  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0007070712745189667  │\n",
       "│ Value/Adv                     │ 0.07651615142822266    │\n",
       "│ Loss/Loss_reward_critic       │ 0.020993322134017944   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0037238337099552155  │\n",
       "│ Value/reward                  │ 2.084459066390991      │\n",
       "│ Time/Total                    │ 3404.806640625         │\n",
       "│ Time/Rollout                  │ 11.60053539276123      │\n",
       "│ Time/Update                   │ 2.007904529571533      │\n",
       "│ Time/Epoch                    │ 13.608484268188477     │\n",
       "│ Time/FPS                      │ 150.49435424804688     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m4\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.178159713745117    │\n",
       "│ Metrics/EpCost                │ 62.959999084472656    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 255.0                 │\n",
       "│ Train/Entropy                 │ 0.1396135687828064    │\n",
       "│ Train/KL                      │ 0.021272506564855576  │\n",
       "│ Train/StopIter                │ 4.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0039469003677368    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0039469003677368    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0039469003677368    │\n",
       "│ Train/PolicyRatio/Std         │ 0.021881073713302612  │\n",
       "│ Train/LR                      │ 0.0001463999942643568 │\n",
       "│ Train/PolicyStd               │ 0.2783770263195038    │\n",
       "│ TotalEnvSteps                 │ 524288.0              │\n",
       "│ Loss/Loss_pi                  │ -0.008601095527410507 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.010194685310125351  │\n",
       "│ Value/Adv                     │ -0.16860544681549072  │\n",
       "│ Loss/Loss_reward_critic       │ 0.02331845462322235   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0023251324892044067 │\n",
       "│ Value/reward                  │ 1.626102328300476     │\n",
       "│ Time/Total                    │ 3417.4150390625       │\n",
       "│ Time/Rollout                  │ 11.821724891662598    │\n",
       "│ Time/Update                   │ 0.7746129035949707    │\n",
       "│ Time/Epoch                    │ 12.596390724182129    │\n",
       "│ Time/FPS                      │ 162.58627319335938    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.178159713745117    │\n",
       "│ Metrics/EpCost                │ 62.959999084472656    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 255.0                 │\n",
       "│ Train/Entropy                 │ 0.1396135687828064    │\n",
       "│ Train/KL                      │ 0.021272506564855576  │\n",
       "│ Train/StopIter                │ 4.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0039469003677368    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0039469003677368    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0039469003677368    │\n",
       "│ Train/PolicyRatio/Std         │ 0.021881073713302612  │\n",
       "│ Train/LR                      │ 0.0001463999942643568 │\n",
       "│ Train/PolicyStd               │ 0.2783770263195038    │\n",
       "│ TotalEnvSteps                 │ 524288.0              │\n",
       "│ Loss/Loss_pi                  │ -0.008601095527410507 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.010194685310125351  │\n",
       "│ Value/Adv                     │ -0.16860544681549072  │\n",
       "│ Loss/Loss_reward_critic       │ 0.02331845462322235   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0023251324892044067 │\n",
       "│ Value/reward                  │ 1.626102328300476     │\n",
       "│ Time/Total                    │ 3417.4150390625       │\n",
       "│ Time/Rollout                  │ 11.821724891662598    │\n",
       "│ Time/Update                   │ 0.7746129035949707    │\n",
       "│ Time/Epoch                    │ 12.596390724182129    │\n",
       "│ Time/FPS                      │ 162.58627319335938    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.223302841186523    │\n",
       "│ Metrics/EpCost                │ 61.15999984741211     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 256.0                 │\n",
       "│ Train/Entropy                 │ 0.1397833526134491    │\n",
       "│ Train/KL                      │ 0.0168919637799263    │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9947622418403625    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9947622418403625    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9947622418403625    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01921401172876358   │\n",
       "│ Train/LR                      │ 0.000145800004247576  │\n",
       "│ Train/PolicyStd               │ 0.27842456102371216   │\n",
       "│ TotalEnvSteps                 │ 526336.0              │\n",
       "│ Loss/Loss_pi                  │ -0.018092414364218712 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.009491318836808205 │\n",
       "│ Value/Adv                     │ -0.0885692685842514   │\n",
       "│ Loss/Loss_reward_critic       │ 0.025118136778473854  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.001799682155251503  │\n",
       "│ Value/reward                  │ 1.994968056678772     │\n",
       "│ Time/Total                    │ 3430.945068359375     │\n",
       "│ Time/Rollout                  │ 11.58442211151123     │\n",
       "│ Time/Update                   │ 1.928572177886963     │\n",
       "│ Time/Epoch                    │ 13.51305866241455     │\n",
       "│ Time/FPS                      │ 151.55711364746094    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.223302841186523    │\n",
       "│ Metrics/EpCost                │ 61.15999984741211     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 256.0                 │\n",
       "│ Train/Entropy                 │ 0.1397833526134491    │\n",
       "│ Train/KL                      │ 0.0168919637799263    │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9947622418403625    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9947622418403625    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9947622418403625    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01921401172876358   │\n",
       "│ Train/LR                      │ 0.000145800004247576  │\n",
       "│ Train/PolicyStd               │ 0.27842456102371216   │\n",
       "│ TotalEnvSteps                 │ 526336.0              │\n",
       "│ Loss/Loss_pi                  │ -0.018092414364218712 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.009491318836808205 │\n",
       "│ Value/Adv                     │ -0.0885692685842514   │\n",
       "│ Loss/Loss_reward_critic       │ 0.025118136778473854  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.001799682155251503  │\n",
       "│ Value/reward                  │ 1.994968056678772     │\n",
       "│ Time/Total                    │ 3430.945068359375     │\n",
       "│ Time/Rollout                  │ 11.58442211151123     │\n",
       "│ Time/Update                   │ 1.928572177886963     │\n",
       "│ Time/Epoch                    │ 13.51305866241455     │\n",
       "│ Time/FPS                      │ 151.55711364746094    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.625377655029297     │\n",
       "│ Metrics/EpCost                │ 56.959999084472656     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 257.0                  │\n",
       "│ Train/Entropy                 │ 0.13806214928627014    │\n",
       "│ Train/KL                      │ 0.019449107348918915   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9975289106369019     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9975289106369019     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9975289106369019     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018954306840896606   │\n",
       "│ Train/LR                      │ 0.00014519999967887998 │\n",
       "│ Train/PolicyStd               │ 0.27801114320755005    │\n",
       "│ TotalEnvSteps                 │ 528384.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01787574216723442   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00021667219698429108 │\n",
       "│ Value/Adv                     │ -0.1072479709982872    │\n",
       "│ Loss/Loss_reward_critic       │ 0.021520007401704788   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.003598129376769066  │\n",
       "│ Value/reward                  │ 2.0983810424804688     │\n",
       "│ Time/Total                    │ 3444.705322265625      │\n",
       "│ Time/Rollout                  │ 11.724532127380371     │\n",
       "│ Time/Update                   │ 2.021210193634033      │\n",
       "│ Time/Epoch                    │ 13.745790481567383     │\n",
       "│ Time/FPS                      │ 148.99107360839844     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.625377655029297     │\n",
       "│ Metrics/EpCost                │ 56.959999084472656     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 257.0                  │\n",
       "│ Train/Entropy                 │ 0.13806214928627014    │\n",
       "│ Train/KL                      │ 0.019449107348918915   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9975289106369019     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9975289106369019     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9975289106369019     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018954306840896606   │\n",
       "│ Train/LR                      │ 0.00014519999967887998 │\n",
       "│ Train/PolicyStd               │ 0.27801114320755005    │\n",
       "│ TotalEnvSteps                 │ 528384.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01787574216723442   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00021667219698429108 │\n",
       "│ Value/Adv                     │ -0.1072479709982872    │\n",
       "│ Loss/Loss_reward_critic       │ 0.021520007401704788   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.003598129376769066  │\n",
       "│ Value/reward                  │ 2.0983810424804688     │\n",
       "│ Time/Total                    │ 3444.705322265625      │\n",
       "│ Time/Rollout                  │ 11.724532127380371     │\n",
       "│ Time/Update                   │ 2.021210193634033      │\n",
       "│ Time/Epoch                    │ 13.745790481567383     │\n",
       "│ Time/FPS                      │ 148.99107360839844     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.589815139770508     │\n",
       "│ Metrics/EpCost                │ 55.900001525878906     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 258.0                  │\n",
       "│ Train/Entropy                 │ 0.13722674548625946    │\n",
       "│ Train/KL                      │ 0.014892793260514736   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9985570907592773     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9985570907592773     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9985570907592773     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018130119889974594   │\n",
       "│ Train/LR                      │ 0.00014459999511018395 │\n",
       "│ Train/PolicyStd               │ 0.27784934639930725    │\n",
       "│ TotalEnvSteps                 │ 530432.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013496140018105507  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004379602149128914   │\n",
       "│ Value/Adv                     │ -0.22545647621154785   │\n",
       "│ Loss/Loss_reward_critic       │ 0.022389698773622513   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0008696913719177246  │\n",
       "│ Value/reward                  │ 2.1139299869537354     │\n",
       "│ Time/Total                    │ 3458.923828125         │\n",
       "│ Time/Rollout                  │ 12.205147743225098     │\n",
       "│ Time/Update                   │ 2.0002331733703613     │\n",
       "│ Time/Epoch                    │ 14.205451965332031     │\n",
       "│ Time/FPS                      │ 144.17001342773438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.589815139770508     │\n",
       "│ Metrics/EpCost                │ 55.900001525878906     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 258.0                  │\n",
       "│ Train/Entropy                 │ 0.13722674548625946    │\n",
       "│ Train/KL                      │ 0.014892793260514736   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9985570907592773     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9985570907592773     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9985570907592773     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018130119889974594   │\n",
       "│ Train/LR                      │ 0.00014459999511018395 │\n",
       "│ Train/PolicyStd               │ 0.27784934639930725    │\n",
       "│ TotalEnvSteps                 │ 530432.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013496140018105507  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004379602149128914   │\n",
       "│ Value/Adv                     │ -0.22545647621154785   │\n",
       "│ Loss/Loss_reward_critic       │ 0.022389698773622513   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0008696913719177246  │\n",
       "│ Value/reward                  │ 2.1139299869537354     │\n",
       "│ Time/Total                    │ 3458.923828125         │\n",
       "│ Time/Rollout                  │ 12.205147743225098     │\n",
       "│ Time/Update                   │ 2.0002331733703613     │\n",
       "│ Time/Epoch                    │ 14.205451965332031     │\n",
       "│ Time/FPS                      │ 144.17001342773438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.685867309570312     │\n",
       "│ Metrics/EpCost                │ 57.400001525878906     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 259.0                  │\n",
       "│ Train/Entropy                 │ 0.1357363760471344     │\n",
       "│ Train/KL                      │ 0.014149008318781853   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.992432713508606      │\n",
       "│ Train/PolicyRatio/Min         │ 0.992432713508606      │\n",
       "│ Train/PolicyRatio/Max         │ 0.992432713508606      │\n",
       "│ Train/PolicyRatio/Std         │ 0.0177021361887455     │\n",
       "│ Train/LR                      │ 0.00014400000509340316 │\n",
       "│ Train/PolicyStd               │ 0.2774132490158081     │\n",
       "│ TotalEnvSteps                 │ 532480.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018478697165846825  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004982557147741318  │\n",
       "│ Value/Adv                     │ -0.10052065551280975   │\n",
       "│ Loss/Loss_reward_critic       │ 0.021260013803839684   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0011296849697828293 │\n",
       "│ Value/reward                  │ 2.1516833305358887     │\n",
       "│ Time/Total                    │ 3472.652099609375      │\n",
       "│ Time/Rollout                  │ 11.774486541748047     │\n",
       "│ Time/Update                   │ 1.941983938217163      │\n",
       "│ Time/Epoch                    │ 13.716519355773926     │\n",
       "│ Time/FPS                      │ 149.30902099609375     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.685867309570312     │\n",
       "│ Metrics/EpCost                │ 57.400001525878906     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 259.0                  │\n",
       "│ Train/Entropy                 │ 0.1357363760471344     │\n",
       "│ Train/KL                      │ 0.014149008318781853   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.992432713508606      │\n",
       "│ Train/PolicyRatio/Min         │ 0.992432713508606      │\n",
       "│ Train/PolicyRatio/Max         │ 0.992432713508606      │\n",
       "│ Train/PolicyRatio/Std         │ 0.0177021361887455     │\n",
       "│ Train/LR                      │ 0.00014400000509340316 │\n",
       "│ Train/PolicyStd               │ 0.2774132490158081     │\n",
       "│ TotalEnvSteps                 │ 532480.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018478697165846825  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004982557147741318  │\n",
       "│ Value/Adv                     │ -0.10052065551280975   │\n",
       "│ Loss/Loss_reward_critic       │ 0.021260013803839684   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0011296849697828293 │\n",
       "│ Value/reward                  │ 2.1516833305358887     │\n",
       "│ Time/Total                    │ 3472.652099609375      │\n",
       "│ Time/Rollout                  │ 11.774486541748047     │\n",
       "│ Time/Update                   │ 1.941983938217163      │\n",
       "│ Time/Epoch                    │ 13.716519355773926     │\n",
       "│ Time/FPS                      │ 149.30902099609375     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.76165199279785      │\n",
       "│ Metrics/EpCost                │ 57.380001068115234     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 260.0                  │\n",
       "│ Train/Entropy                 │ 0.13546837866306305    │\n",
       "│ Train/KL                      │ 0.014725033193826675   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0001440048217773     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0001440048217773     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0001440048217773     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018914803862571716   │\n",
       "│ Train/LR                      │ 0.00014340000052470714 │\n",
       "│ Train/PolicyStd               │ 0.2773185968399048     │\n",
       "│ TotalEnvSteps                 │ 534528.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017495693638920784  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0009830035269260406  │\n",
       "│ Value/Adv                     │ -0.1521661877632141    │\n",
       "│ Loss/Loss_reward_critic       │ 0.016484733670949936   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.004775280132889748  │\n",
       "│ Value/reward                  │ 2.1785922050476074     │\n",
       "│ Time/Total                    │ 3486.340087890625      │\n",
       "│ Time/Rollout                  │ 11.751041412353516     │\n",
       "│ Time/Update                   │ 1.9230163097381592     │\n",
       "│ Time/Epoch                    │ 13.674125671386719     │\n",
       "│ Time/FPS                      │ 149.7719268798828      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.76165199279785      │\n",
       "│ Metrics/EpCost                │ 57.380001068115234     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 260.0                  │\n",
       "│ Train/Entropy                 │ 0.13546837866306305    │\n",
       "│ Train/KL                      │ 0.014725033193826675   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0001440048217773     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0001440048217773     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0001440048217773     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018914803862571716   │\n",
       "│ Train/LR                      │ 0.00014340000052470714 │\n",
       "│ Train/PolicyStd               │ 0.2773185968399048     │\n",
       "│ TotalEnvSteps                 │ 534528.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017495693638920784  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0009830035269260406  │\n",
       "│ Value/Adv                     │ -0.1521661877632141    │\n",
       "│ Loss/Loss_reward_critic       │ 0.016484733670949936   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.004775280132889748  │\n",
       "│ Value/reward                  │ 2.1785922050476074     │\n",
       "│ Time/Total                    │ 3486.340087890625      │\n",
       "│ Time/Rollout                  │ 11.751041412353516     │\n",
       "│ Time/Update                   │ 1.9230163097381592     │\n",
       "│ Time/Epoch                    │ 13.674125671386719     │\n",
       "│ Time/FPS                      │ 149.7719268798828      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.743366241455078     │\n",
       "│ Metrics/EpCost                │ 58.18000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 261.0                  │\n",
       "│ Train/Entropy                 │ 0.13074420392513275    │\n",
       "│ Train/KL                      │ 0.013913200236856937   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9992769956588745     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9992769956588745     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9992769956588745     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02388775907456875    │\n",
       "│ Train/LR                      │ 0.00014279999595601112 │\n",
       "│ Train/PolicyStd               │ 0.27601227164268494    │\n",
       "│ TotalEnvSteps                 │ 536576.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017345452681183815  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.000150240957736969   │\n",
       "│ Value/Adv                     │ -0.17154553532600403   │\n",
       "│ Loss/Loss_reward_critic       │ 0.013358796946704388   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0031259367242455482 │\n",
       "│ Value/reward                  │ 2.16302490234375       │\n",
       "│ Time/Total                    │ 3500.124267578125      │\n",
       "│ Time/Rollout                  │ 11.799355506896973     │\n",
       "│ Time/Update                   │ 1.9716663360595703     │\n",
       "│ Time/Epoch                    │ 13.771074295043945     │\n",
       "│ Time/FPS                      │ 148.717529296875       │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.743366241455078     │\n",
       "│ Metrics/EpCost                │ 58.18000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 261.0                  │\n",
       "│ Train/Entropy                 │ 0.13074420392513275    │\n",
       "│ Train/KL                      │ 0.013913200236856937   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9992769956588745     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9992769956588745     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9992769956588745     │\n",
       "│ Train/PolicyRatio/Std         │ 0.02388775907456875    │\n",
       "│ Train/LR                      │ 0.00014279999595601112 │\n",
       "│ Train/PolicyStd               │ 0.27601227164268494    │\n",
       "│ TotalEnvSteps                 │ 536576.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017345452681183815  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.000150240957736969   │\n",
       "│ Value/Adv                     │ -0.17154553532600403   │\n",
       "│ Loss/Loss_reward_critic       │ 0.013358796946704388   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0031259367242455482 │\n",
       "│ Value/reward                  │ 2.16302490234375       │\n",
       "│ Time/Total                    │ 3500.124267578125      │\n",
       "│ Time/Rollout                  │ 11.799355506896973     │\n",
       "│ Time/Update                   │ 1.9716663360595703     │\n",
       "│ Time/Epoch                    │ 13.771074295043945     │\n",
       "│ Time/FPS                      │ 148.717529296875       │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m9\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.8494873046875       │\n",
       "│ Metrics/EpCost                │ 58.58000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 262.0                  │\n",
       "│ Train/Entropy                 │ 0.12362391501665115    │\n",
       "│ Train/KL                      │ 0.020094778388738632   │\n",
       "│ Train/StopIter                │ 9.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9944930672645569     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9944930672645569     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9944930672645569     │\n",
       "│ Train/PolicyRatio/Std         │ 0.021100997924804688   │\n",
       "│ Train/LR                      │ 0.00014220000593923032 │\n",
       "│ Train/PolicyStd               │ 0.274059534072876      │\n",
       "│ TotalEnvSteps                 │ 538624.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017786584794521332  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0004411321133375168 │\n",
       "│ Value/Adv                     │ -0.1568305343389511    │\n",
       "│ Loss/Loss_reward_critic       │ 0.020524896681308746   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.007166099734604359   │\n",
       "│ Value/reward                  │ 2.180894374847412      │\n",
       "│ Time/Total                    │ 3514.052490234375      │\n",
       "│ Time/Rollout                  │ 12.108366012573242     │\n",
       "│ Time/Update                   │ 1.8069438934326172     │\n",
       "│ Time/Epoch                    │ 13.915353775024414     │\n",
       "│ Time/FPS                      │ 147.17556762695312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.8494873046875       │\n",
       "│ Metrics/EpCost                │ 58.58000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 262.0                  │\n",
       "│ Train/Entropy                 │ 0.12362391501665115    │\n",
       "│ Train/KL                      │ 0.020094778388738632   │\n",
       "│ Train/StopIter                │ 9.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9944930672645569     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9944930672645569     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9944930672645569     │\n",
       "│ Train/PolicyRatio/Std         │ 0.021100997924804688   │\n",
       "│ Train/LR                      │ 0.00014220000593923032 │\n",
       "│ Train/PolicyStd               │ 0.274059534072876      │\n",
       "│ TotalEnvSteps                 │ 538624.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017786584794521332  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0004411321133375168 │\n",
       "│ Value/Adv                     │ -0.1568305343389511    │\n",
       "│ Loss/Loss_reward_critic       │ 0.020524896681308746   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.007166099734604359   │\n",
       "│ Value/reward                  │ 2.180894374847412      │\n",
       "│ Time/Total                    │ 3514.052490234375      │\n",
       "│ Time/Rollout                  │ 12.108366012573242     │\n",
       "│ Time/Update                   │ 1.8069438934326172     │\n",
       "│ Time/Epoch                    │ 13.915353775024414     │\n",
       "│ Time/FPS                      │ 147.17556762695312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.988847732543945    │\n",
       "│ Metrics/EpCost                │ 60.18000030517578     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 263.0                 │\n",
       "│ Train/Entropy                 │ 0.11901520192623138   │\n",
       "│ Train/KL                      │ 0.014371243305504322  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.002841591835022     │\n",
       "│ Train/PolicyRatio/Min         │ 1.002841591835022     │\n",
       "│ Train/PolicyRatio/Max         │ 1.002841591835022     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017574574798345566  │\n",
       "│ Train/LR                      │ 0.0001416000013705343 │\n",
       "│ Train/PolicyStd               │ 0.27279776334762573   │\n",
       "│ TotalEnvSteps                 │ 540672.0              │\n",
       "│ Loss/Loss_pi                  │ -0.015621316619217396 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002165268175303936  │\n",
       "│ Value/Adv                     │ -0.03802880644798279  │\n",
       "│ Loss/Loss_reward_critic       │ 0.022403160110116005  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0018782634288072586 │\n",
       "│ Value/reward                  │ 2.1431705951690674    │\n",
       "│ Time/Total                    │ 3527.964599609375     │\n",
       "│ Time/Rollout                  │ 11.904356956481934    │\n",
       "│ Time/Update                   │ 1.9942502975463867    │\n",
       "│ Time/Epoch                    │ 13.898658752441406    │\n",
       "│ Time/FPS                      │ 147.35235595703125    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.988847732543945    │\n",
       "│ Metrics/EpCost                │ 60.18000030517578     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 263.0                 │\n",
       "│ Train/Entropy                 │ 0.11901520192623138   │\n",
       "│ Train/KL                      │ 0.014371243305504322  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.002841591835022     │\n",
       "│ Train/PolicyRatio/Min         │ 1.002841591835022     │\n",
       "│ Train/PolicyRatio/Max         │ 1.002841591835022     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017574574798345566  │\n",
       "│ Train/LR                      │ 0.0001416000013705343 │\n",
       "│ Train/PolicyStd               │ 0.27279776334762573   │\n",
       "│ TotalEnvSteps                 │ 540672.0              │\n",
       "│ Loss/Loss_pi                  │ -0.015621316619217396 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002165268175303936  │\n",
       "│ Value/Adv                     │ -0.03802880644798279  │\n",
       "│ Loss/Loss_reward_critic       │ 0.022403160110116005  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0018782634288072586 │\n",
       "│ Value/reward                  │ 2.1431705951690674    │\n",
       "│ Time/Total                    │ 3527.964599609375     │\n",
       "│ Time/Rollout                  │ 11.904356956481934    │\n",
       "│ Time/Update                   │ 1.9942502975463867    │\n",
       "│ Time/Epoch                    │ 13.898658752441406    │\n",
       "│ Time/FPS                      │ 147.35235595703125    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m7\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.632064819335938     │\n",
       "│ Metrics/EpCost                │ 59.060001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 264.0                  │\n",
       "│ Train/Entropy                 │ 0.11533980816602707    │\n",
       "│ Train/KL                      │ 0.028639407828450203   │\n",
       "│ Train/StopIter                │ 7.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9978411793708801     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9978411793708801     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9978411793708801     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020841069519519806   │\n",
       "│ Train/LR                      │ 0.00014099999680183828 │\n",
       "│ Train/PolicyStd               │ 0.2717544436454773     │\n",
       "│ TotalEnvSteps                 │ 542720.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011659136041998863  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0039621805772185326  │\n",
       "│ Value/Adv                     │ -0.04301930218935013   │\n",
       "│ Loss/Loss_reward_critic       │ 0.022467387840151787   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 6.422773003578186e-05  │\n",
       "│ Value/reward                  │ 1.6434576511383057     │\n",
       "│ Time/Total                    │ 3540.99462890625       │\n",
       "│ Time/Rollout                  │ 11.683330535888672     │\n",
       "│ Time/Update                   │ 1.3345072269439697     │\n",
       "│ Time/Epoch                    │ 13.017889022827148     │\n",
       "│ Time/FPS                      │ 157.3219757080078      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.632064819335938     │\n",
       "│ Metrics/EpCost                │ 59.060001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 264.0                  │\n",
       "│ Train/Entropy                 │ 0.11533980816602707    │\n",
       "│ Train/KL                      │ 0.028639407828450203   │\n",
       "│ Train/StopIter                │ 7.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9978411793708801     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9978411793708801     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9978411793708801     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020841069519519806   │\n",
       "│ Train/LR                      │ 0.00014099999680183828 │\n",
       "│ Train/PolicyStd               │ 0.2717544436454773     │\n",
       "│ TotalEnvSteps                 │ 542720.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011659136041998863  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0039621805772185326  │\n",
       "│ Value/Adv                     │ -0.04301930218935013   │\n",
       "│ Loss/Loss_reward_critic       │ 0.022467387840151787   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 6.422773003578186e-05  │\n",
       "│ Value/reward                  │ 1.6434576511383057     │\n",
       "│ Time/Total                    │ 3540.99462890625       │\n",
       "│ Time/Rollout                  │ 11.683330535888672     │\n",
       "│ Time/Update                   │ 1.3345072269439697     │\n",
       "│ Time/Epoch                    │ 13.017889022827148     │\n",
       "│ Time/FPS                      │ 157.3219757080078      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.674602508544922     │\n",
       "│ Metrics/EpCost                │ 60.560001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 265.0                  │\n",
       "│ Train/Entropy                 │ 0.11358010768890381    │\n",
       "│ Train/KL                      │ 0.016140403226017952   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.001407265663147      │\n",
       "│ Train/PolicyRatio/Min         │ 1.001407265663147      │\n",
       "│ Train/PolicyRatio/Max         │ 1.001407265663147      │\n",
       "│ Train/PolicyRatio/Std         │ 0.0180495698004961     │\n",
       "│ Train/LR                      │ 0.00014040000678505749 │\n",
       "│ Train/PolicyStd               │ 0.2712375521659851     │\n",
       "│ TotalEnvSteps                 │ 544768.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015906115993857384  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0042469799518585205 │\n",
       "│ Value/Adv                     │ 0.0333254300057888     │\n",
       "│ Loss/Loss_reward_critic       │ 0.019288834184408188   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.003178553655743599  │\n",
       "│ Value/reward                  │ 2.1304385662078857     │\n",
       "│ Time/Total                    │ 3554.76171875          │\n",
       "│ Time/Rollout                  │ 11.654207229614258     │\n",
       "│ Time/Update                   │ 2.0991365909576416     │\n",
       "│ Time/Epoch                    │ 13.75339126586914      │\n",
       "│ Time/FPS                      │ 148.9087371826172      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.674602508544922     │\n",
       "│ Metrics/EpCost                │ 60.560001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 265.0                  │\n",
       "│ Train/Entropy                 │ 0.11358010768890381    │\n",
       "│ Train/KL                      │ 0.016140403226017952   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.001407265663147      │\n",
       "│ Train/PolicyRatio/Min         │ 1.001407265663147      │\n",
       "│ Train/PolicyRatio/Max         │ 1.001407265663147      │\n",
       "│ Train/PolicyRatio/Std         │ 0.0180495698004961     │\n",
       "│ Train/LR                      │ 0.00014040000678505749 │\n",
       "│ Train/PolicyStd               │ 0.2712375521659851     │\n",
       "│ TotalEnvSteps                 │ 544768.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015906115993857384  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0042469799518585205 │\n",
       "│ Value/Adv                     │ 0.0333254300057888     │\n",
       "│ Loss/Loss_reward_critic       │ 0.019288834184408188   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.003178553655743599  │\n",
       "│ Value/reward                  │ 2.1304385662078857     │\n",
       "│ Time/Total                    │ 3554.76171875          │\n",
       "│ Time/Rollout                  │ 11.654207229614258     │\n",
       "│ Time/Update                   │ 2.0991365909576416     │\n",
       "│ Time/Epoch                    │ 13.75339126586914      │\n",
       "│ Time/FPS                      │ 148.9087371826172      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.647689819335938     │\n",
       "│ Metrics/EpCost                │ 60.20000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 266.0                  │\n",
       "│ Train/Entropy                 │ 0.11290185153484344    │\n",
       "│ Train/KL                      │ 0.015181325376033783   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9952804446220398     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9952804446220398     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9952804446220398     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01783881150186062    │\n",
       "│ Train/LR                      │ 0.00013980000221636146 │\n",
       "│ Train/PolicyStd               │ 0.27107200026512146    │\n",
       "│ TotalEnvSteps                 │ 546816.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015112052671611309  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0007940633222460747  │\n",
       "│ Value/Adv                     │ -0.023506665602326393  │\n",
       "│ Loss/Loss_reward_critic       │ 0.019176427274942398   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0001124069094657898 │\n",
       "│ Value/reward                  │ 2.163299083709717      │\n",
       "│ Time/Total                    │ 3568.44775390625       │\n",
       "│ Time/Rollout                  │ 11.750744819641113     │\n",
       "│ Time/Update                   │ 1.9226303100585938     │\n",
       "│ Time/Epoch                    │ 13.673420906066895     │\n",
       "│ Time/FPS                      │ 149.77964782714844     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.647689819335938     │\n",
       "│ Metrics/EpCost                │ 60.20000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 266.0                  │\n",
       "│ Train/Entropy                 │ 0.11290185153484344    │\n",
       "│ Train/KL                      │ 0.015181325376033783   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9952804446220398     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9952804446220398     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9952804446220398     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01783881150186062    │\n",
       "│ Train/LR                      │ 0.00013980000221636146 │\n",
       "│ Train/PolicyStd               │ 0.27107200026512146    │\n",
       "│ TotalEnvSteps                 │ 546816.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015112052671611309  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0007940633222460747  │\n",
       "│ Value/Adv                     │ -0.023506665602326393  │\n",
       "│ Loss/Loss_reward_critic       │ 0.019176427274942398   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0001124069094657898 │\n",
       "│ Value/reward                  │ 2.163299083709717      │\n",
       "│ Time/Total                    │ 3568.44775390625       │\n",
       "│ Time/Rollout                  │ 11.750744819641113     │\n",
       "│ Time/Update                   │ 1.9226303100585938     │\n",
       "│ Time/Epoch                    │ 13.673420906066895     │\n",
       "│ Time/FPS                      │ 149.77964782714844     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m9\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.63410186767578      │\n",
       "│ Metrics/EpCost                │ 58.060001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 267.0                  │\n",
       "│ Train/Entropy                 │ 0.10904672741889954    │\n",
       "│ Train/KL                      │ 0.0208366010338068     │\n",
       "│ Train/StopIter                │ 9.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0013517141342163     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0013517141342163     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0013517141342163     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01950075291097164    │\n",
       "│ Train/LR                      │ 0.00013919999764766544 │\n",
       "│ Train/PolicyStd               │ 0.27007198333740234    │\n",
       "│ TotalEnvSteps                 │ 548864.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017367176711559296  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0022551240399479866 │\n",
       "│ Value/Adv                     │ 0.02932038903236389    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02019784413278103    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0010214168578386307  │\n",
       "│ Value/reward                  │ 2.1474761962890625     │\n",
       "│ Time/Total                    │ 3582.077392578125      │\n",
       "│ Time/Rollout                  │ 11.775187492370605     │\n",
       "│ Time/Update                   │ 1.8419487476348877     │\n",
       "│ Time/Epoch                    │ 13.6171875             │\n",
       "│ Time/FPS                      │ 150.39817810058594     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.63410186767578      │\n",
       "│ Metrics/EpCost                │ 58.060001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 267.0                  │\n",
       "│ Train/Entropy                 │ 0.10904672741889954    │\n",
       "│ Train/KL                      │ 0.0208366010338068     │\n",
       "│ Train/StopIter                │ 9.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0013517141342163     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0013517141342163     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0013517141342163     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01950075291097164    │\n",
       "│ Train/LR                      │ 0.00013919999764766544 │\n",
       "│ Train/PolicyStd               │ 0.27007198333740234    │\n",
       "│ TotalEnvSteps                 │ 548864.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017367176711559296  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0022551240399479866 │\n",
       "│ Value/Adv                     │ 0.02932038903236389    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02019784413278103    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0010214168578386307  │\n",
       "│ Value/reward                  │ 2.1474761962890625     │\n",
       "│ Time/Total                    │ 3582.077392578125      │\n",
       "│ Time/Rollout                  │ 11.775187492370605     │\n",
       "│ Time/Update                   │ 1.8419487476348877     │\n",
       "│ Time/Epoch                    │ 13.6171875             │\n",
       "│ Time/FPS                      │ 150.39817810058594     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.665424346923828     │\n",
       "│ Metrics/EpCost                │ 57.279998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 268.0                  │\n",
       "│ Train/Entropy                 │ 0.10558785498142242    │\n",
       "│ Train/KL                      │ 0.017827101051807404   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9960509538650513     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9960509538650513     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9960509538650513     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01965622417628765    │\n",
       "│ Train/LR                      │ 0.00013859999307896942 │\n",
       "│ Train/PolicyStd               │ 0.2691596448421478     │\n",
       "│ TotalEnvSteps                 │ 550912.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018218589946627617  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0008514132350683212 │\n",
       "│ Value/Adv                     │ 0.31823277473449707    │\n",
       "│ Loss/Loss_reward_critic       │ 0.016243577003479004   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.003954267129302025  │\n",
       "│ Value/reward                  │ 2.1501636505126953     │\n",
       "│ Time/Total                    │ 3596.229736328125      │\n",
       "│ Time/Rollout                  │ 12.022276878356934     │\n",
       "│ Time/Update                   │ 2.117475986480713      │\n",
       "│ Time/Epoch                    │ 14.139793395996094     │\n",
       "│ Time/FPS                      │ 144.83946228027344     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.665424346923828     │\n",
       "│ Metrics/EpCost                │ 57.279998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 268.0                  │\n",
       "│ Train/Entropy                 │ 0.10558785498142242    │\n",
       "│ Train/KL                      │ 0.017827101051807404   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9960509538650513     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9960509538650513     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9960509538650513     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01965622417628765    │\n",
       "│ Train/LR                      │ 0.00013859999307896942 │\n",
       "│ Train/PolicyStd               │ 0.2691596448421478     │\n",
       "│ TotalEnvSteps                 │ 550912.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018218589946627617  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0008514132350683212 │\n",
       "│ Value/Adv                     │ 0.31823277473449707    │\n",
       "│ Loss/Loss_reward_critic       │ 0.016243577003479004   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.003954267129302025  │\n",
       "│ Value/reward                  │ 2.1501636505126953     │\n",
       "│ Time/Total                    │ 3596.229736328125      │\n",
       "│ Time/Rollout                  │ 12.022276878356934     │\n",
       "│ Time/Update                   │ 2.117475986480713      │\n",
       "│ Time/Epoch                    │ 14.139793395996094     │\n",
       "│ Time/FPS                      │ 144.83946228027344     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.578672409057617     │\n",
       "│ Metrics/EpCost                │ 56.400001525878906     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 269.0                  │\n",
       "│ Train/Entropy                 │ 0.10104861110448837    │\n",
       "│ Train/KL                      │ 0.015755193307995796   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0053027868270874     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0053027868270874     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0053027868270874     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01858142763376236    │\n",
       "│ Train/LR                      │ 0.00013800000306218863 │\n",
       "│ Train/PolicyStd               │ 0.26800817251205444    │\n",
       "│ TotalEnvSteps                 │ 552960.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013728847727179527  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00448974221944809    │\n",
       "│ Value/Adv                     │ -0.014732450246810913  │\n",
       "│ Loss/Loss_reward_critic       │ 0.018030475825071335   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.001786898821592331   │\n",
       "│ Value/reward                  │ 2.2131128311157227     │\n",
       "│ Time/Total                    │ 3609.86962890625       │\n",
       "│ Time/Rollout                  │ 11.64515495300293      │\n",
       "│ Time/Update                   │ 1.982832431793213      │\n",
       "│ Time/Epoch                    │ 13.628034591674805     │\n",
       "│ Time/FPS                      │ 150.27845764160156     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.578672409057617     │\n",
       "│ Metrics/EpCost                │ 56.400001525878906     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 269.0                  │\n",
       "│ Train/Entropy                 │ 0.10104861110448837    │\n",
       "│ Train/KL                      │ 0.015755193307995796   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0053027868270874     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0053027868270874     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0053027868270874     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01858142763376236    │\n",
       "│ Train/LR                      │ 0.00013800000306218863 │\n",
       "│ Train/PolicyStd               │ 0.26800817251205444    │\n",
       "│ TotalEnvSteps                 │ 552960.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013728847727179527  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00448974221944809    │\n",
       "│ Value/Adv                     │ -0.014732450246810913  │\n",
       "│ Loss/Loss_reward_critic       │ 0.018030475825071335   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.001786898821592331   │\n",
       "│ Value/reward                  │ 2.2131128311157227     │\n",
       "│ Time/Total                    │ 3609.86962890625       │\n",
       "│ Time/Rollout                  │ 11.64515495300293      │\n",
       "│ Time/Update                   │ 1.982832431793213      │\n",
       "│ Time/Epoch                    │ 13.628034591674805     │\n",
       "│ Time/FPS                      │ 150.27845764160156     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.325294494628906     │\n",
       "│ Metrics/EpCost                │ 62.619998931884766     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 270.0                  │\n",
       "│ Train/Entropy                 │ 0.09262276440858841    │\n",
       "│ Train/KL                      │ 0.008639853447675705   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0021865367889404     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0021865367889404     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0021865367889404     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019048437476158142   │\n",
       "│ Train/LR                      │ 0.0001373999984934926  │\n",
       "│ Train/PolicyStd               │ 0.2657848596572876     │\n",
       "│ TotalEnvSteps                 │ 555008.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011358675546944141  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002370172180235386   │\n",
       "│ Value/Adv                     │ 0.0810631662607193     │\n",
       "│ Loss/Loss_reward_critic       │ 0.016414735466241837   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0016157403588294983 │\n",
       "│ Value/reward                  │ 1.964552402496338      │\n",
       "│ Time/Total                    │ 3623.53369140625       │\n",
       "│ Time/Rollout                  │ 11.643850326538086     │\n",
       "│ Time/Update                   │ 2.0037825107574463     │\n",
       "│ Time/Epoch                    │ 13.647671699523926     │\n",
       "│ Time/FPS                      │ 150.06222534179688     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.325294494628906     │\n",
       "│ Metrics/EpCost                │ 62.619998931884766     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 270.0                  │\n",
       "│ Train/Entropy                 │ 0.09262276440858841    │\n",
       "│ Train/KL                      │ 0.008639853447675705   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0021865367889404     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0021865367889404     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0021865367889404     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019048437476158142   │\n",
       "│ Train/LR                      │ 0.0001373999984934926  │\n",
       "│ Train/PolicyStd               │ 0.2657848596572876     │\n",
       "│ TotalEnvSteps                 │ 555008.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011358675546944141  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002370172180235386   │\n",
       "│ Value/Adv                     │ 0.0810631662607193     │\n",
       "│ Loss/Loss_reward_critic       │ 0.016414735466241837   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0016157403588294983 │\n",
       "│ Value/reward                  │ 1.964552402496338      │\n",
       "│ Time/Total                    │ 3623.53369140625       │\n",
       "│ Time/Rollout                  │ 11.643850326538086     │\n",
       "│ Time/Update                   │ 2.0037825107574463     │\n",
       "│ Time/Epoch                    │ 13.647671699523926     │\n",
       "│ Time/FPS                      │ 150.06222534179688     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.30944061279297      │\n",
       "│ Metrics/EpCost                │ 63.13999938964844      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 271.0                  │\n",
       "│ Train/Entropy                 │ 0.08525359630584717    │\n",
       "│ Train/KL                      │ 0.018140219151973724   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9986592531204224     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9986592531204224     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9986592531204224     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01829761266708374    │\n",
       "│ Train/LR                      │ 0.00013679999392479658 │\n",
       "│ Train/PolicyStd               │ 0.2637854516506195     │\n",
       "│ TotalEnvSteps                 │ 557056.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018253084272146225  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.006894408725202084  │\n",
       "│ Value/Adv                     │ -0.22624120116233826   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01736481301486492    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.000950077548623085   │\n",
       "│ Value/reward                  │ 2.1579630374908447     │\n",
       "│ Time/Total                    │ 3637.403564453125      │\n",
       "│ Time/Rollout                  │ 11.721816062927246     │\n",
       "│ Time/Update                   │ 2.1355865001678467     │\n",
       "│ Time/Epoch                    │ 13.857458114624023     │\n",
       "│ Time/FPS                      │ 147.79046630859375     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.30944061279297      │\n",
       "│ Metrics/EpCost                │ 63.13999938964844      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 271.0                  │\n",
       "│ Train/Entropy                 │ 0.08525359630584717    │\n",
       "│ Train/KL                      │ 0.018140219151973724   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9986592531204224     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9986592531204224     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9986592531204224     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01829761266708374    │\n",
       "│ Train/LR                      │ 0.00013679999392479658 │\n",
       "│ Train/PolicyStd               │ 0.2637854516506195     │\n",
       "│ TotalEnvSteps                 │ 557056.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018253084272146225  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.006894408725202084  │\n",
       "│ Value/Adv                     │ -0.22624120116233826   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01736481301486492    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.000950077548623085   │\n",
       "│ Value/reward                  │ 2.1579630374908447     │\n",
       "│ Time/Total                    │ 3637.403564453125      │\n",
       "│ Time/Rollout                  │ 11.721816062927246     │\n",
       "│ Time/Update                   │ 2.1355865001678467     │\n",
       "│ Time/Epoch                    │ 13.857458114624023     │\n",
       "│ Time/FPS                      │ 147.79046630859375     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.904338836669922     │\n",
       "│ Metrics/EpCost                │ 60.599998474121094     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 272.0                  │\n",
       "│ Train/Entropy                 │ 0.07852031290531158    │\n",
       "│ Train/KL                      │ 0.015321778133511543   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0035948753356934     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0035948753356934     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0035948753356934     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01925830729305744    │\n",
       "│ Train/LR                      │ 0.0001362000039080158  │\n",
       "│ Train/PolicyStd               │ 0.2619916796684265     │\n",
       "│ TotalEnvSteps                 │ 559104.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015031044371426105  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0032220399007201195  │\n",
       "│ Value/Adv                     │ 0.041346609592437744   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014891398139297962   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0024734148755669594 │\n",
       "│ Value/reward                  │ 2.1046929359436035     │\n",
       "│ Time/Total                    │ 3651.39697265625       │\n",
       "│ Time/Rollout                  │ 11.960494041442871     │\n",
       "│ Time/Update                   │ 2.020611524581909      │\n",
       "│ Time/Epoch                    │ 13.981149673461914     │\n",
       "│ Time/FPS                      │ 146.4829559326172      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.904338836669922     │\n",
       "│ Metrics/EpCost                │ 60.599998474121094     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 272.0                  │\n",
       "│ Train/Entropy                 │ 0.07852031290531158    │\n",
       "│ Train/KL                      │ 0.015321778133511543   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0035948753356934     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0035948753356934     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0035948753356934     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01925830729305744    │\n",
       "│ Train/LR                      │ 0.0001362000039080158  │\n",
       "│ Train/PolicyStd               │ 0.2619916796684265     │\n",
       "│ TotalEnvSteps                 │ 559104.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015031044371426105  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0032220399007201195  │\n",
       "│ Value/Adv                     │ 0.041346609592437744   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014891398139297962   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0024734148755669594 │\n",
       "│ Value/reward                  │ 2.1046929359436035     │\n",
       "│ Time/Total                    │ 3651.39697265625       │\n",
       "│ Time/Rollout                  │ 11.960494041442871     │\n",
       "│ Time/Update                   │ 2.020611524581909      │\n",
       "│ Time/Epoch                    │ 13.981149673461914     │\n",
       "│ Time/FPS                      │ 146.4829559326172      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.885128021240234     │\n",
       "│ Metrics/EpCost                │ 60.400001525878906     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 273.0                  │\n",
       "│ Train/Entropy                 │ 0.07336248457431793    │\n",
       "│ Train/KL                      │ 0.015334350056946278   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9942282438278198     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9942282438278198     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9942282438278198     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019499188289046288   │\n",
       "│ Train/LR                      │ 0.00013559999933931977 │\n",
       "│ Train/PolicyStd               │ 0.2606326937675476     │\n",
       "│ TotalEnvSteps                 │ 561152.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016848640516400337  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0018175961449742317 │\n",
       "│ Value/Adv                     │ 0.0965418890118599     │\n",
       "│ Loss/Loss_reward_critic       │ 0.0189718808978796     │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004080482758581638   │\n",
       "│ Value/reward                  │ 2.026662588119507      │\n",
       "│ Time/Total                    │ 3665.233154296875      │\n",
       "│ Time/Rollout                  │ 11.819042205810547     │\n",
       "│ Time/Update                   │ 2.003497362136841      │\n",
       "│ Time/Epoch                    │ 13.822633743286133     │\n",
       "│ Time/FPS                      │ 148.16281127929688     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.885128021240234     │\n",
       "│ Metrics/EpCost                │ 60.400001525878906     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 273.0                  │\n",
       "│ Train/Entropy                 │ 0.07336248457431793    │\n",
       "│ Train/KL                      │ 0.015334350056946278   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9942282438278198     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9942282438278198     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9942282438278198     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019499188289046288   │\n",
       "│ Train/LR                      │ 0.00013559999933931977 │\n",
       "│ Train/PolicyStd               │ 0.2606326937675476     │\n",
       "│ TotalEnvSteps                 │ 561152.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016848640516400337  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0018175961449742317 │\n",
       "│ Value/Adv                     │ 0.0965418890118599     │\n",
       "│ Loss/Loss_reward_critic       │ 0.0189718808978796     │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004080482758581638   │\n",
       "│ Value/reward                  │ 2.026662588119507      │\n",
       "│ Time/Total                    │ 3665.233154296875      │\n",
       "│ Time/Rollout                  │ 11.819042205810547     │\n",
       "│ Time/Update                   │ 2.003497362136841      │\n",
       "│ Time/Epoch                    │ 13.822633743286133     │\n",
       "│ Time/FPS                      │ 148.16281127929688     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.058368682861328      │\n",
       "│ Metrics/EpCost                │ 61.040000915527344      │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 274.0                   │\n",
       "│ Train/Entropy                 │ 0.07335995137691498     │\n",
       "│ Train/KL                      │ 0.014843402430415154    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9909982681274414      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9909982681274414      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9909982681274414      │\n",
       "│ Train/PolicyRatio/Std         │ 0.019289644435048103    │\n",
       "│ Train/LR                      │ 0.00013499999477062374  │\n",
       "│ Train/PolicyStd               │ 0.26061493158340454     │\n",
       "│ TotalEnvSteps                 │ 563200.0                │\n",
       "│ Loss/Loss_pi                  │ -0.017298921942710876   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00045028142631053925 │\n",
       "│ Value/Adv                     │ -0.09491221606731415    │\n",
       "│ Loss/Loss_reward_critic       │ 0.022508442401885986    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.003536561504006386    │\n",
       "│ Value/reward                  │ 2.0713863372802734      │\n",
       "│ Time/Total                    │ 3678.9267578125         │\n",
       "│ Time/Rollout                  │ 11.73016357421875       │\n",
       "│ Time/Update                   │ 1.9507503509521484      │\n",
       "│ Time/Epoch                    │ 13.68095588684082       │\n",
       "│ Time/FPS                      │ 149.6971435546875       │\n",
       "└───────────────────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.058368682861328      │\n",
       "│ Metrics/EpCost                │ 61.040000915527344      │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 274.0                   │\n",
       "│ Train/Entropy                 │ 0.07335995137691498     │\n",
       "│ Train/KL                      │ 0.014843402430415154    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9909982681274414      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9909982681274414      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9909982681274414      │\n",
       "│ Train/PolicyRatio/Std         │ 0.019289644435048103    │\n",
       "│ Train/LR                      │ 0.00013499999477062374  │\n",
       "│ Train/PolicyStd               │ 0.26061493158340454     │\n",
       "│ TotalEnvSteps                 │ 563200.0                │\n",
       "│ Loss/Loss_pi                  │ -0.017298921942710876   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00045028142631053925 │\n",
       "│ Value/Adv                     │ -0.09491221606731415    │\n",
       "│ Loss/Loss_reward_critic       │ 0.022508442401885986    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.003536561504006386    │\n",
       "│ Value/reward                  │ 2.0713863372802734      │\n",
       "│ Time/Total                    │ 3678.9267578125         │\n",
       "│ Time/Rollout                  │ 11.73016357421875       │\n",
       "│ Time/Update                   │ 1.9507503509521484      │\n",
       "│ Time/Epoch                    │ 13.68095588684082       │\n",
       "│ Time/FPS                      │ 149.6971435546875       │\n",
       "└───────────────────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m10\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.873565673828125     │\n",
       "│ Metrics/EpCost                │ 60.279998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 275.0                  │\n",
       "│ Train/Entropy                 │ 0.07113548368215561    │\n",
       "│ Train/KL                      │ 0.021847346797585487   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9956537485122681     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9956537485122681     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9956537485122681     │\n",
       "│ Train/PolicyRatio/Std         │ 0.021268924698233604   │\n",
       "│ Train/LR                      │ 0.00013440000475384295 │\n",
       "│ Train/PolicyStd               │ 0.26002731919288635    │\n",
       "│ TotalEnvSteps                 │ 565248.0               │\n",
       "│ Loss/Loss_pi                  │ -0.019369080662727356  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0020701587200164795 │\n",
       "│ Value/Adv                     │ 0.011482195928692818   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015268032439053059   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.007240409962832928  │\n",
       "│ Value/reward                  │ 2.023653507232666      │\n",
       "│ Time/Total                    │ 3692.510009765625      │\n",
       "│ Time/Rollout                  │ 11.703332901000977     │\n",
       "│ Time/Update                   │ 1.8671765327453613     │\n",
       "│ Time/Epoch                    │ 13.570551872253418     │\n",
       "│ Time/FPS                      │ 150.91502380371094     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.873565673828125     │\n",
       "│ Metrics/EpCost                │ 60.279998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 275.0                  │\n",
       "│ Train/Entropy                 │ 0.07113548368215561    │\n",
       "│ Train/KL                      │ 0.021847346797585487   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9956537485122681     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9956537485122681     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9956537485122681     │\n",
       "│ Train/PolicyRatio/Std         │ 0.021268924698233604   │\n",
       "│ Train/LR                      │ 0.00013440000475384295 │\n",
       "│ Train/PolicyStd               │ 0.26002731919288635    │\n",
       "│ TotalEnvSteps                 │ 565248.0               │\n",
       "│ Loss/Loss_pi                  │ -0.019369080662727356  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0020701587200164795 │\n",
       "│ Value/Adv                     │ 0.011482195928692818   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015268032439053059   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.007240409962832928  │\n",
       "│ Value/reward                  │ 2.023653507232666      │\n",
       "│ Time/Total                    │ 3692.510009765625      │\n",
       "│ Time/Rollout                  │ 11.703332901000977     │\n",
       "│ Time/Update                   │ 1.8671765327453613     │\n",
       "│ Time/Epoch                    │ 13.570551872253418     │\n",
       "│ Time/FPS                      │ 150.91502380371094     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.8576717376709       │\n",
       "│ Metrics/EpCost                │ 59.18000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 276.0                  │\n",
       "│ Train/Entropy                 │ 0.06811311095952988    │\n",
       "│ Train/KL                      │ 0.015472618862986565   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0013456344604492     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0013456344604492     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0013456344604492     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019877608865499496   │\n",
       "│ Train/LR                      │ 0.00013380000018514693 │\n",
       "│ Train/PolicyStd               │ 0.25929591059684753    │\n",
       "│ TotalEnvSteps                 │ 567296.0               │\n",
       "│ Loss/Loss_pi                  │ -0.021192921325564384  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0018238406628370285 │\n",
       "│ Value/Adv                     │ -0.05835358798503876   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014652078039944172   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0006159543991088867 │\n",
       "│ Value/reward                  │ 2.014496326446533      │\n",
       "│ Time/Total                    │ 3706.08935546875       │\n",
       "│ Time/Rollout                  │ 11.600003242492676     │\n",
       "│ Time/Update                   │ 1.9672002792358398     │\n",
       "│ Time/Epoch                    │ 13.567245483398438     │\n",
       "│ Time/FPS                      │ 150.95179748535156     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.8576717376709       │\n",
       "│ Metrics/EpCost                │ 59.18000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 276.0                  │\n",
       "│ Train/Entropy                 │ 0.06811311095952988    │\n",
       "│ Train/KL                      │ 0.015472618862986565   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0013456344604492     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0013456344604492     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0013456344604492     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019877608865499496   │\n",
       "│ Train/LR                      │ 0.00013380000018514693 │\n",
       "│ Train/PolicyStd               │ 0.25929591059684753    │\n",
       "│ TotalEnvSteps                 │ 567296.0               │\n",
       "│ Loss/Loss_pi                  │ -0.021192921325564384  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0018238406628370285 │\n",
       "│ Value/Adv                     │ -0.05835358798503876   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014652078039944172   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0006159543991088867 │\n",
       "│ Value/reward                  │ 2.014496326446533      │\n",
       "│ Time/Total                    │ 3706.08935546875       │\n",
       "│ Time/Rollout                  │ 11.600003242492676     │\n",
       "│ Time/Update                   │ 1.9672002792358398     │\n",
       "│ Time/Epoch                    │ 13.567245483398438     │\n",
       "│ Time/FPS                      │ 150.95179748535156     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m8\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.199172973632812    │\n",
       "│ Metrics/EpCost                │ 58.540000915527344    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 277.0                 │\n",
       "│ Train/Entropy                 │ 0.06447006016969681   │\n",
       "│ Train/KL                      │ 0.02213609218597412   │\n",
       "│ Train/StopIter                │ 8.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9927968978881836    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9927968978881836    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9927968978881836    │\n",
       "│ Train/PolicyRatio/Std         │ 0.021176183596253395  │\n",
       "│ Train/LR                      │ 0.0001331999956164509 │\n",
       "│ Train/PolicyStd               │ 0.25842052698135376   │\n",
       "│ TotalEnvSteps                 │ 569344.0              │\n",
       "│ Loss/Loss_pi                  │ -0.017028123140335083 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0041647981852293015 │\n",
       "│ Value/Adv                     │ -0.05192745476961136  │\n",
       "│ Loss/Loss_reward_critic       │ 0.012122531421482563  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.002529546618461609 │\n",
       "│ Value/reward                  │ 2.0296359062194824    │\n",
       "│ Time/Total                    │ 3719.396728515625     │\n",
       "│ Time/Rollout                  │ 11.759529113769531    │\n",
       "│ Time/Update                   │ 1.5355205535888672    │\n",
       "│ Time/Epoch                    │ 13.295099258422852    │\n",
       "│ Time/FPS                      │ 154.04173278808594    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.199172973632812    │\n",
       "│ Metrics/EpCost                │ 58.540000915527344    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 277.0                 │\n",
       "│ Train/Entropy                 │ 0.06447006016969681   │\n",
       "│ Train/KL                      │ 0.02213609218597412   │\n",
       "│ Train/StopIter                │ 8.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9927968978881836    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9927968978881836    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9927968978881836    │\n",
       "│ Train/PolicyRatio/Std         │ 0.021176183596253395  │\n",
       "│ Train/LR                      │ 0.0001331999956164509 │\n",
       "│ Train/PolicyStd               │ 0.25842052698135376   │\n",
       "│ TotalEnvSteps                 │ 569344.0              │\n",
       "│ Loss/Loss_pi                  │ -0.017028123140335083 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0041647981852293015 │\n",
       "│ Value/Adv                     │ -0.05192745476961136  │\n",
       "│ Loss/Loss_reward_critic       │ 0.012122531421482563  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.002529546618461609 │\n",
       "│ Value/reward                  │ 2.0296359062194824    │\n",
       "│ Time/Total                    │ 3719.396728515625     │\n",
       "│ Time/Rollout                  │ 11.759529113769531    │\n",
       "│ Time/Update                   │ 1.5355205535888672    │\n",
       "│ Time/Epoch                    │ 13.295099258422852    │\n",
       "│ Time/FPS                      │ 154.04173278808594    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.197826385498047    │\n",
       "│ Metrics/EpCost                │ 56.08000183105469     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 278.0                 │\n",
       "│ Train/Entropy                 │ 0.0606350377202034    │\n",
       "│ Train/KL                      │ 0.01911514811217785   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9921118021011353    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9921118021011353    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9921118021011353    │\n",
       "│ Train/PolicyRatio/Std         │ 0.020020969212055206  │\n",
       "│ Train/LR                      │ 0.0001326000055996701 │\n",
       "│ Train/PolicyStd               │ 0.25742679834365845   │\n",
       "│ TotalEnvSteps                 │ 571392.0              │\n",
       "│ Loss/Loss_pi                  │ -0.016936376690864563 │\n",
       "│ Loss/Loss_pi/Delta            │ 9.174644947052002e-05 │\n",
       "│ Value/Adv                     │ -0.21669428050518036  │\n",
       "│ Loss/Loss_reward_critic       │ 0.014650153927505016  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0025276225060224533 │\n",
       "│ Value/reward                  │ 2.019425868988037     │\n",
       "│ Time/Total                    │ 3733.123291015625     │\n",
       "│ Time/Rollout                  │ 11.735361099243164    │\n",
       "│ Time/Update                   │ 1.9762077331542969    │\n",
       "│ Time/Epoch                    │ 13.711645126342773    │\n",
       "│ Time/FPS                      │ 149.3621063232422     │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.197826385498047    │\n",
       "│ Metrics/EpCost                │ 56.08000183105469     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 278.0                 │\n",
       "│ Train/Entropy                 │ 0.0606350377202034    │\n",
       "│ Train/KL                      │ 0.01911514811217785   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9921118021011353    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9921118021011353    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9921118021011353    │\n",
       "│ Train/PolicyRatio/Std         │ 0.020020969212055206  │\n",
       "│ Train/LR                      │ 0.0001326000055996701 │\n",
       "│ Train/PolicyStd               │ 0.25742679834365845   │\n",
       "│ TotalEnvSteps                 │ 571392.0              │\n",
       "│ Loss/Loss_pi                  │ -0.016936376690864563 │\n",
       "│ Loss/Loss_pi/Delta            │ 9.174644947052002e-05 │\n",
       "│ Value/Adv                     │ -0.21669428050518036  │\n",
       "│ Loss/Loss_reward_critic       │ 0.014650153927505016  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0025276225060224533 │\n",
       "│ Value/reward                  │ 2.019425868988037     │\n",
       "│ Time/Total                    │ 3733.123291015625     │\n",
       "│ Time/Rollout                  │ 11.735361099243164    │\n",
       "│ Time/Update                   │ 1.9762077331542969    │\n",
       "│ Time/Epoch                    │ 13.711645126342773    │\n",
       "│ Time/FPS                      │ 149.3621063232422     │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.885433197021484    │\n",
       "│ Metrics/EpCost                │ 53.65999984741211     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 279.0                 │\n",
       "│ Train/Entropy                 │ 0.06288938224315643   │\n",
       "│ Train/KL                      │ 0.010819110088050365  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.010133147239685     │\n",
       "│ Train/PolicyRatio/Min         │ 1.010133147239685     │\n",
       "│ Train/PolicyRatio/Max         │ 1.010133147239685     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019014282152056694  │\n",
       "│ Train/LR                      │ 0.0001320000010309741 │\n",
       "│ Train/PolicyStd               │ 0.25798746943473816   │\n",
       "│ TotalEnvSteps                 │ 573440.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01141534186899662  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005521034821867943  │\n",
       "│ Value/Adv                     │ 0.028182584792375565  │\n",
       "│ Loss/Loss_reward_critic       │ 0.015369998291134834  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.000719844363629818  │\n",
       "│ Value/reward                  │ 2.0316903591156006    │\n",
       "│ Time/Total                    │ 3746.721923828125     │\n",
       "│ Time/Rollout                  │ 11.875761032104492    │\n",
       "│ Time/Update                   │ 1.7095327377319336    │\n",
       "│ Time/Epoch                    │ 13.585339546203613    │\n",
       "│ Time/FPS                      │ 150.75074768066406    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.885433197021484    │\n",
       "│ Metrics/EpCost                │ 53.65999984741211     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 279.0                 │\n",
       "│ Train/Entropy                 │ 0.06288938224315643   │\n",
       "│ Train/KL                      │ 0.010819110088050365  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.010133147239685     │\n",
       "│ Train/PolicyRatio/Min         │ 1.010133147239685     │\n",
       "│ Train/PolicyRatio/Max         │ 1.010133147239685     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019014282152056694  │\n",
       "│ Train/LR                      │ 0.0001320000010309741 │\n",
       "│ Train/PolicyStd               │ 0.25798746943473816   │\n",
       "│ TotalEnvSteps                 │ 573440.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01141534186899662  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005521034821867943  │\n",
       "│ Value/Adv                     │ 0.028182584792375565  │\n",
       "│ Loss/Loss_reward_critic       │ 0.015369998291134834  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.000719844363629818  │\n",
       "│ Value/reward                  │ 2.0316903591156006    │\n",
       "│ Time/Total                    │ 3746.721923828125     │\n",
       "│ Time/Rollout                  │ 11.875761032104492    │\n",
       "│ Time/Update                   │ 1.7095327377319336    │\n",
       "│ Time/Epoch                    │ 13.585339546203613    │\n",
       "│ Time/FPS                      │ 150.75074768066406    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.17858123779297      │\n",
       "│ Metrics/EpCost                │ 54.20000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 280.0                  │\n",
       "│ Train/Entropy                 │ 0.06436260044574738    │\n",
       "│ Train/KL                      │ 0.017137866467237473   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9986433982849121     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9986433982849121     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9986433982849121     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01879066787660122    │\n",
       "│ Train/LR                      │ 0.00013139999646227807 │\n",
       "│ Train/PolicyStd               │ 0.25833019614219666    │\n",
       "│ TotalEnvSteps                 │ 575488.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017811160534620285  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.006395818665623665  │\n",
       "│ Value/Adv                     │ -0.17854321002960205   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014812188223004341   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0005578100681304932 │\n",
       "│ Value/reward                  │ 2.0610859394073486     │\n",
       "│ Time/Total                    │ 3759.30859375          │\n",
       "│ Time/Rollout                  │ 10.887778282165527     │\n",
       "│ Time/Update                   │ 1.6825733184814453     │\n",
       "│ Time/Epoch                    │ 12.570393562316895     │\n",
       "│ Time/FPS                      │ 162.92251586914062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.17858123779297      │\n",
       "│ Metrics/EpCost                │ 54.20000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 280.0                  │\n",
       "│ Train/Entropy                 │ 0.06436260044574738    │\n",
       "│ Train/KL                      │ 0.017137866467237473   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9986433982849121     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9986433982849121     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9986433982849121     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01879066787660122    │\n",
       "│ Train/LR                      │ 0.00013139999646227807 │\n",
       "│ Train/PolicyStd               │ 0.25833019614219666    │\n",
       "│ TotalEnvSteps                 │ 575488.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017811160534620285  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.006395818665623665  │\n",
       "│ Value/Adv                     │ -0.17854321002960205   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014812188223004341   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0005578100681304932 │\n",
       "│ Value/reward                  │ 2.0610859394073486     │\n",
       "│ Time/Total                    │ 3759.30859375          │\n",
       "│ Time/Rollout                  │ 10.887778282165527     │\n",
       "│ Time/Update                   │ 1.6825733184814453     │\n",
       "│ Time/Epoch                    │ 12.570393562316895     │\n",
       "│ Time/FPS                      │ 162.92251586914062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.257726669311523     │\n",
       "│ Metrics/EpCost                │ 53.279998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 281.0                  │\n",
       "│ Train/Entropy                 │ 0.06574652343988419    │\n",
       "│ Train/KL                      │ 0.01840350404381752    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9976975321769714     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9976975321769714     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9976975321769714     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020524175837635994   │\n",
       "│ Train/LR                      │ 0.00013080000644549727 │\n",
       "│ Train/PolicyStd               │ 0.2586379051208496     │\n",
       "│ TotalEnvSteps                 │ 577536.0               │\n",
       "│ Loss/Loss_pi                  │ -0.020912259817123413  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.003101099282503128  │\n",
       "│ Value/Adv                     │ -0.34898698329925537   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014824467711150646   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 1.2279488146305084e-05 │\n",
       "│ Value/reward                  │ 2.0950369834899902     │\n",
       "│ Time/Total                    │ 3771.880126953125      │\n",
       "│ Time/Rollout                  │ 10.870912551879883     │\n",
       "│ Time/Update                   │ 1.6889722347259521     │\n",
       "│ Time/Epoch                    │ 12.559928894042969     │\n",
       "│ Time/FPS                      │ 163.05824279785156     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.257726669311523     │\n",
       "│ Metrics/EpCost                │ 53.279998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 281.0                  │\n",
       "│ Train/Entropy                 │ 0.06574652343988419    │\n",
       "│ Train/KL                      │ 0.01840350404381752    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9976975321769714     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9976975321769714     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9976975321769714     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020524175837635994   │\n",
       "│ Train/LR                      │ 0.00013080000644549727 │\n",
       "│ Train/PolicyStd               │ 0.2586379051208496     │\n",
       "│ TotalEnvSteps                 │ 577536.0               │\n",
       "│ Loss/Loss_pi                  │ -0.020912259817123413  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.003101099282503128  │\n",
       "│ Value/Adv                     │ -0.34898698329925537   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014824467711150646   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 1.2279488146305084e-05 │\n",
       "│ Value/reward                  │ 2.0950369834899902     │\n",
       "│ Time/Total                    │ 3771.880126953125      │\n",
       "│ Time/Rollout                  │ 10.870912551879883     │\n",
       "│ Time/Update                   │ 1.6889722347259521     │\n",
       "│ Time/Epoch                    │ 12.559928894042969     │\n",
       "│ Time/FPS                      │ 163.05824279785156     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.250947952270508     │\n",
       "│ Metrics/EpCost                │ 52.08000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 282.0                  │\n",
       "│ Train/Entropy                 │ 0.06386594474315643    │\n",
       "│ Train/KL                      │ 0.015198063105344772   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9957990646362305     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9957990646362305     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9957990646362305     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018356122076511383   │\n",
       "│ Train/LR                      │ 0.00013020000187680125 │\n",
       "│ Train/PolicyStd               │ 0.2581130862236023     │\n",
       "│ TotalEnvSteps                 │ 579584.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01409878395497799   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.006813475862145424   │\n",
       "│ Value/Adv                     │ 0.08109752833843231    │\n",
       "│ Loss/Loss_reward_critic       │ 0.020324379205703735   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.005499911494553089   │\n",
       "│ Value/reward                  │ 2.0305497646331787     │\n",
       "│ Time/Total                    │ 3784.47412109375       │\n",
       "│ Time/Rollout                  │ 10.870390892028809     │\n",
       "│ Time/Update                   │ 1.7122516632080078     │\n",
       "│ Time/Epoch                    │ 12.582695007324219     │\n",
       "│ Time/FPS                      │ 162.7632293701172      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.250947952270508     │\n",
       "│ Metrics/EpCost                │ 52.08000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 282.0                  │\n",
       "│ Train/Entropy                 │ 0.06386594474315643    │\n",
       "│ Train/KL                      │ 0.015198063105344772   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9957990646362305     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9957990646362305     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9957990646362305     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018356122076511383   │\n",
       "│ Train/LR                      │ 0.00013020000187680125 │\n",
       "│ Train/PolicyStd               │ 0.2581130862236023     │\n",
       "│ TotalEnvSteps                 │ 579584.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01409878395497799   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.006813475862145424   │\n",
       "│ Value/Adv                     │ 0.08109752833843231    │\n",
       "│ Loss/Loss_reward_critic       │ 0.020324379205703735   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.005499911494553089   │\n",
       "│ Value/reward                  │ 2.0305497646331787     │\n",
       "│ Time/Total                    │ 3784.47412109375       │\n",
       "│ Time/Rollout                  │ 10.870390892028809     │\n",
       "│ Time/Update                   │ 1.7122516632080078     │\n",
       "│ Time/Epoch                    │ 12.582695007324219     │\n",
       "│ Time/FPS                      │ 162.7632293701172      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.138757705688477     │\n",
       "│ Metrics/EpCost                │ 52.65999984741211      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 283.0                  │\n",
       "│ Train/Entropy                 │ 0.06008969992399216    │\n",
       "│ Train/KL                      │ 0.013993807137012482   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9980720281600952     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9980720281600952     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9980720281600952     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01930188201367855    │\n",
       "│ Train/LR                      │ 0.00012959999730810523 │\n",
       "│ Train/PolicyStd               │ 0.2571069896221161     │\n",
       "│ TotalEnvSteps                 │ 581632.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01773734763264656   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0036385636776685715 │\n",
       "│ Value/Adv                     │ -0.17846786975860596   │\n",
       "│ Loss/Loss_reward_critic       │ 0.021181676536798477   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0008572973310947418  │\n",
       "│ Value/reward                  │ 2.055966854095459      │\n",
       "│ Time/Total                    │ 3796.985595703125      │\n",
       "│ Time/Rollout                  │ 10.804458618164062     │\n",
       "│ Time/Update                   │ 1.6954286098480225     │\n",
       "│ Time/Epoch                    │ 12.499930381774902     │\n",
       "│ Time/FPS                      │ 163.84092712402344     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.138757705688477     │\n",
       "│ Metrics/EpCost                │ 52.65999984741211      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 283.0                  │\n",
       "│ Train/Entropy                 │ 0.06008969992399216    │\n",
       "│ Train/KL                      │ 0.013993807137012482   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9980720281600952     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9980720281600952     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9980720281600952     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01930188201367855    │\n",
       "│ Train/LR                      │ 0.00012959999730810523 │\n",
       "│ Train/PolicyStd               │ 0.2571069896221161     │\n",
       "│ TotalEnvSteps                 │ 581632.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01773734763264656   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0036385636776685715 │\n",
       "│ Value/Adv                     │ -0.17846786975860596   │\n",
       "│ Loss/Loss_reward_critic       │ 0.021181676536798477   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0008572973310947418  │\n",
       "│ Value/reward                  │ 2.055966854095459      │\n",
       "│ Time/Total                    │ 3796.985595703125      │\n",
       "│ Time/Rollout                  │ 10.804458618164062     │\n",
       "│ Time/Update                   │ 1.6954286098480225     │\n",
       "│ Time/Epoch                    │ 12.499930381774902     │\n",
       "│ Time/FPS                      │ 163.84092712402344     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.059450149536133     │\n",
       "│ Metrics/EpCost                │ 53.2599983215332       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 284.0                  │\n",
       "│ Train/Entropy                 │ 0.05827261134982109    │\n",
       "│ Train/KL                      │ 0.015303508378565311   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9965446591377258     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9965446591377258     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9965446591377258     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019314110279083252   │\n",
       "│ Train/LR                      │ 0.0001289999927394092  │\n",
       "│ Train/PolicyStd               │ 0.25661295652389526    │\n",
       "│ TotalEnvSteps                 │ 583680.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01625220663845539   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0014851409941911697  │\n",
       "│ Value/Adv                     │ 0.12059818208217621    │\n",
       "│ Loss/Loss_reward_critic       │ 0.020392945036292076   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0007887315005064011 │\n",
       "│ Value/reward                  │ 2.0546493530273438     │\n",
       "│ Time/Total                    │ 3809.529541015625      │\n",
       "│ Time/Rollout                  │ 10.842878341674805     │\n",
       "│ Time/Update                   │ 1.6897063255310059     │\n",
       "│ Time/Epoch                    │ 12.532628059387207     │\n",
       "│ Time/FPS                      │ 163.41346740722656     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.059450149536133     │\n",
       "│ Metrics/EpCost                │ 53.2599983215332       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 284.0                  │\n",
       "│ Train/Entropy                 │ 0.05827261134982109    │\n",
       "│ Train/KL                      │ 0.015303508378565311   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9965446591377258     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9965446591377258     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9965446591377258     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019314110279083252   │\n",
       "│ Train/LR                      │ 0.0001289999927394092  │\n",
       "│ Train/PolicyStd               │ 0.25661295652389526    │\n",
       "│ TotalEnvSteps                 │ 583680.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01625220663845539   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0014851409941911697  │\n",
       "│ Value/Adv                     │ 0.12059818208217621    │\n",
       "│ Loss/Loss_reward_critic       │ 0.020392945036292076   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0007887315005064011 │\n",
       "│ Value/reward                  │ 2.0546493530273438     │\n",
       "│ Time/Total                    │ 3809.529541015625      │\n",
       "│ Time/Rollout                  │ 10.842878341674805     │\n",
       "│ Time/Update                   │ 1.6897063255310059     │\n",
       "│ Time/Epoch                    │ 12.532628059387207     │\n",
       "│ Time/FPS                      │ 163.41346740722656     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.944744110107422     │\n",
       "│ Metrics/EpCost                │ 52.959999084472656     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 285.0                  │\n",
       "│ Train/Entropy                 │ 0.05567460507154465    │\n",
       "│ Train/KL                      │ 0.01507516484707594    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9964555501937866     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9964555501937866     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9964555501937866     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020608969032764435   │\n",
       "│ Train/LR                      │ 0.00012840000272262841 │\n",
       "│ Train/PolicyStd               │ 0.25593382120132446    │\n",
       "│ TotalEnvSteps                 │ 585728.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017751285806298256  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.001499079167842865  │\n",
       "│ Value/Adv                     │ -0.11164261400699615   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02045646496117115    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 6.35199248790741e-05   │\n",
       "│ Value/reward                  │ 2.042189359664917      │\n",
       "│ Time/Total                    │ 3822.064697265625      │\n",
       "│ Time/Rollout                  │ 10.808710098266602     │\n",
       "│ Time/Update                   │ 1.7147350311279297     │\n",
       "│ Time/Epoch                    │ 12.523490905761719     │\n",
       "│ Time/FPS                      │ 163.53269958496094     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.944744110107422     │\n",
       "│ Metrics/EpCost                │ 52.959999084472656     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 285.0                  │\n",
       "│ Train/Entropy                 │ 0.05567460507154465    │\n",
       "│ Train/KL                      │ 0.01507516484707594    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9964555501937866     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9964555501937866     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9964555501937866     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020608969032764435   │\n",
       "│ Train/LR                      │ 0.00012840000272262841 │\n",
       "│ Train/PolicyStd               │ 0.25593382120132446    │\n",
       "│ TotalEnvSteps                 │ 585728.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017751285806298256  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.001499079167842865  │\n",
       "│ Value/Adv                     │ -0.11164261400699615   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02045646496117115    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 6.35199248790741e-05   │\n",
       "│ Value/reward                  │ 2.042189359664917      │\n",
       "│ Time/Total                    │ 3822.064697265625      │\n",
       "│ Time/Rollout                  │ 10.808710098266602     │\n",
       "│ Time/Update                   │ 1.7147350311279297     │\n",
       "│ Time/Epoch                    │ 12.523490905761719     │\n",
       "│ Time/FPS                      │ 163.53269958496094     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.061521530151367      │\n",
       "│ Metrics/EpCost                │ 50.65999984741211       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 286.0                   │\n",
       "│ Train/Entropy                 │ 0.04982132837176323     │\n",
       "│ Train/KL                      │ 0.015959233045578003    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9979006052017212      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9979006052017212      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9979006052017212      │\n",
       "│ Train/PolicyRatio/Std         │ 0.018474621698260307    │\n",
       "│ Train/LR                      │ 0.0001277999981539324   │\n",
       "│ Train/PolicyStd               │ 0.25442904233932495     │\n",
       "│ TotalEnvSteps                 │ 587776.0                │\n",
       "│ Loss/Loss_pi                  │ -0.016998576000332832   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0007527098059654236   │\n",
       "│ Value/Adv                     │ 0.022841736674308777    │\n",
       "│ Loss/Loss_reward_critic       │ 0.020286299288272858    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00017016567289829254 │\n",
       "│ Value/reward                  │ 2.130969524383545       │\n",
       "│ Time/Total                    │ 3834.614990234375       │\n",
       "│ Time/Rollout                  │ 10.847247123718262      │\n",
       "│ Time/Update                   │ 1.691133737564087       │\n",
       "│ Time/Epoch                    │ 12.538442611694336      │\n",
       "│ Time/FPS                      │ 163.3376922607422       │\n",
       "└───────────────────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.061521530151367      │\n",
       "│ Metrics/EpCost                │ 50.65999984741211       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 286.0                   │\n",
       "│ Train/Entropy                 │ 0.04982132837176323     │\n",
       "│ Train/KL                      │ 0.015959233045578003    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9979006052017212      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9979006052017212      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9979006052017212      │\n",
       "│ Train/PolicyRatio/Std         │ 0.018474621698260307    │\n",
       "│ Train/LR                      │ 0.0001277999981539324   │\n",
       "│ Train/PolicyStd               │ 0.25442904233932495     │\n",
       "│ TotalEnvSteps                 │ 587776.0                │\n",
       "│ Loss/Loss_pi                  │ -0.016998576000332832   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0007527098059654236   │\n",
       "│ Value/Adv                     │ 0.022841736674308777    │\n",
       "│ Loss/Loss_reward_critic       │ 0.020286299288272858    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00017016567289829254 │\n",
       "│ Value/reward                  │ 2.130969524383545       │\n",
       "│ Time/Total                    │ 3834.614990234375       │\n",
       "│ Time/Rollout                  │ 10.847247123718262      │\n",
       "│ Time/Update                   │ 1.691133737564087       │\n",
       "│ Time/Epoch                    │ 12.538442611694336      │\n",
       "│ Time/FPS                      │ 163.3376922607422       │\n",
       "└───────────────────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.659496307373047     │\n",
       "│ Metrics/EpCost                │ 49.900001525878906     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 287.0                  │\n",
       "│ Train/Entropy                 │ 0.042113371193408966   │\n",
       "│ Train/KL                      │ 0.011172914877533913   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.005035161972046      │\n",
       "│ Train/PolicyRatio/Min         │ 1.005035161972046      │\n",
       "│ Train/PolicyRatio/Max         │ 1.005035161972046      │\n",
       "│ Train/PolicyRatio/Std         │ 0.018426889553666115   │\n",
       "│ Train/LR                      │ 0.00012719999358523637 │\n",
       "│ Train/PolicyStd               │ 0.2524692118167877     │\n",
       "│ TotalEnvSteps                 │ 589824.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011721889488399029  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0052766865119338036  │\n",
       "│ Value/Adv                     │ -0.023657429963350296  │\n",
       "│ Loss/Loss_reward_critic       │ 0.013267705217003822   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.007018594071269035  │\n",
       "│ Value/reward                  │ 1.9505925178527832     │\n",
       "│ Time/Total                    │ 3847.173095703125      │\n",
       "│ Time/Rollout                  │ 10.849573135375977     │\n",
       "│ Time/Update                   │ 1.6886250972747803     │\n",
       "│ Time/Epoch                    │ 12.538239479064941     │\n",
       "│ Time/FPS                      │ 163.34033203125        │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.659496307373047     │\n",
       "│ Metrics/EpCost                │ 49.900001525878906     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 287.0                  │\n",
       "│ Train/Entropy                 │ 0.042113371193408966   │\n",
       "│ Train/KL                      │ 0.011172914877533913   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.005035161972046      │\n",
       "│ Train/PolicyRatio/Min         │ 1.005035161972046      │\n",
       "│ Train/PolicyRatio/Max         │ 1.005035161972046      │\n",
       "│ Train/PolicyRatio/Std         │ 0.018426889553666115   │\n",
       "│ Train/LR                      │ 0.00012719999358523637 │\n",
       "│ Train/PolicyStd               │ 0.2524692118167877     │\n",
       "│ TotalEnvSteps                 │ 589824.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011721889488399029  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0052766865119338036  │\n",
       "│ Value/Adv                     │ -0.023657429963350296  │\n",
       "│ Loss/Loss_reward_critic       │ 0.013267705217003822   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.007018594071269035  │\n",
       "│ Value/reward                  │ 1.9505925178527832     │\n",
       "│ Time/Total                    │ 3847.173095703125      │\n",
       "│ Time/Rollout                  │ 10.849573135375977     │\n",
       "│ Time/Update                   │ 1.6886250972747803     │\n",
       "│ Time/Epoch                    │ 12.538239479064941     │\n",
       "│ Time/FPS                      │ 163.34033203125        │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.614200592041016     │\n",
       "│ Metrics/EpCost                │ 48.619998931884766     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 288.0                  │\n",
       "│ Train/Entropy                 │ 0.03764045238494873    │\n",
       "│ Train/KL                      │ 0.014918147586286068   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.002284049987793      │\n",
       "│ Train/PolicyRatio/Min         │ 1.002284049987793      │\n",
       "│ Train/PolicyRatio/Max         │ 1.002284049987793      │\n",
       "│ Train/PolicyRatio/Std         │ 0.017874039709568024   │\n",
       "│ Train/LR                      │ 0.00012660000356845558 │\n",
       "│ Train/PolicyStd               │ 0.25136882066726685    │\n",
       "│ TotalEnvSteps                 │ 591872.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014530541375279427  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002808651886880398  │\n",
       "│ Value/Adv                     │ 0.03298399597406387    │\n",
       "│ Loss/Loss_reward_critic       │ 0.020101716741919518   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006834011524915695   │\n",
       "│ Value/reward                  │ 2.1492302417755127     │\n",
       "│ Time/Total                    │ 3859.698486328125      │\n",
       "│ Time/Rollout                  │ 10.826201438903809     │\n",
       "│ Time/Update                   │ 1.6873834133148193     │\n",
       "│ Time/Epoch                    │ 12.513632774353027     │\n",
       "│ Time/FPS                      │ 163.66151428222656     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.614200592041016     │\n",
       "│ Metrics/EpCost                │ 48.619998931884766     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 288.0                  │\n",
       "│ Train/Entropy                 │ 0.03764045238494873    │\n",
       "│ Train/KL                      │ 0.014918147586286068   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.002284049987793      │\n",
       "│ Train/PolicyRatio/Min         │ 1.002284049987793      │\n",
       "│ Train/PolicyRatio/Max         │ 1.002284049987793      │\n",
       "│ Train/PolicyRatio/Std         │ 0.017874039709568024   │\n",
       "│ Train/LR                      │ 0.00012660000356845558 │\n",
       "│ Train/PolicyStd               │ 0.25136882066726685    │\n",
       "│ TotalEnvSteps                 │ 591872.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014530541375279427  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002808651886880398  │\n",
       "│ Value/Adv                     │ 0.03298399597406387    │\n",
       "│ Loss/Loss_reward_critic       │ 0.020101716741919518   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006834011524915695   │\n",
       "│ Value/reward                  │ 2.1492302417755127     │\n",
       "│ Time/Total                    │ 3859.698486328125      │\n",
       "│ Time/Rollout                  │ 10.826201438903809     │\n",
       "│ Time/Update                   │ 1.6873834133148193     │\n",
       "│ Time/Epoch                    │ 12.513632774353027     │\n",
       "│ Time/FPS                      │ 163.66151428222656     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.02228355407715      │\n",
       "│ Metrics/EpCost                │ 48.79999923706055      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 289.0                  │\n",
       "│ Train/Entropy                 │ 0.0349680632352829     │\n",
       "│ Train/KL                      │ 0.01625671796500683    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9944267272949219     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9944267272949219     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9944267272949219     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01908157393336296    │\n",
       "│ Train/LR                      │ 0.00012599999899975955 │\n",
       "│ Train/PolicyStd               │ 0.2507276237010956     │\n",
       "│ TotalEnvSteps                 │ 593920.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01869305968284607   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004162518307566643  │\n",
       "│ Value/Adv                     │ 0.002023282926529646   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02166721224784851    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0015654955059289932  │\n",
       "│ Value/reward                  │ 2.2205867767333984     │\n",
       "│ Time/Total                    │ 3872.25048828125       │\n",
       "│ Time/Rollout                  │ 10.854452133178711     │\n",
       "│ Time/Update                   │ 1.6862893104553223     │\n",
       "│ Time/Epoch                    │ 12.54078197479248      │\n",
       "│ Time/FPS                      │ 163.3072052001953      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.02228355407715      │\n",
       "│ Metrics/EpCost                │ 48.79999923706055      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 289.0                  │\n",
       "│ Train/Entropy                 │ 0.0349680632352829     │\n",
       "│ Train/KL                      │ 0.01625671796500683    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9944267272949219     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9944267272949219     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9944267272949219     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01908157393336296    │\n",
       "│ Train/LR                      │ 0.00012599999899975955 │\n",
       "│ Train/PolicyStd               │ 0.2507276237010956     │\n",
       "│ TotalEnvSteps                 │ 593920.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01869305968284607   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004162518307566643  │\n",
       "│ Value/Adv                     │ 0.002023282926529646   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02166721224784851    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0015654955059289932  │\n",
       "│ Value/reward                  │ 2.2205867767333984     │\n",
       "│ Time/Total                    │ 3872.25048828125       │\n",
       "│ Time/Rollout                  │ 10.854452133178711     │\n",
       "│ Time/Update                   │ 1.6862893104553223     │\n",
       "│ Time/Epoch                    │ 12.54078197479248      │\n",
       "│ Time/FPS                      │ 163.3072052001953      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.94078826904297       │\n",
       "│ Metrics/EpCost                │ 48.439998626708984      │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 290.0                   │\n",
       "│ Train/Entropy                 │ 0.034460388123989105    │\n",
       "│ Train/KL                      │ 0.017308199778199196    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0024192333221436      │\n",
       "│ Train/PolicyRatio/Min         │ 1.0024192333221436      │\n",
       "│ Train/PolicyRatio/Max         │ 1.0024192333221436      │\n",
       "│ Train/PolicyRatio/Std         │ 0.022758953273296356    │\n",
       "│ Train/LR                      │ 0.00012539999443106353  │\n",
       "│ Train/PolicyStd               │ 0.2505986988544464      │\n",
       "│ TotalEnvSteps                 │ 595968.0                │\n",
       "│ Loss/Loss_pi                  │ -0.021006347611546516   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002313287928700447   │\n",
       "│ Value/Adv                     │ -0.12399080395698547    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02130443975329399     │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00036277249455451965 │\n",
       "│ Value/reward                  │ 2.103245735168457       │\n",
       "│ Time/Total                    │ 3884.787841796875       │\n",
       "│ Time/Rollout                  │ 10.824751853942871      │\n",
       "│ Time/Update                   │ 1.6995935440063477      │\n",
       "│ Time/Epoch                    │ 12.524385452270508      │\n",
       "│ Time/FPS                      │ 163.52099609375         │\n",
       "└───────────────────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.94078826904297       │\n",
       "│ Metrics/EpCost                │ 48.439998626708984      │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 290.0                   │\n",
       "│ Train/Entropy                 │ 0.034460388123989105    │\n",
       "│ Train/KL                      │ 0.017308199778199196    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0024192333221436      │\n",
       "│ Train/PolicyRatio/Min         │ 1.0024192333221436      │\n",
       "│ Train/PolicyRatio/Max         │ 1.0024192333221436      │\n",
       "│ Train/PolicyRatio/Std         │ 0.022758953273296356    │\n",
       "│ Train/LR                      │ 0.00012539999443106353  │\n",
       "│ Train/PolicyStd               │ 0.2505986988544464      │\n",
       "│ TotalEnvSteps                 │ 595968.0                │\n",
       "│ Loss/Loss_pi                  │ -0.021006347611546516   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002313287928700447   │\n",
       "│ Value/Adv                     │ -0.12399080395698547    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02130443975329399     │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00036277249455451965 │\n",
       "│ Value/reward                  │ 2.103245735168457       │\n",
       "│ Time/Total                    │ 3884.787841796875       │\n",
       "│ Time/Rollout                  │ 10.824751853942871      │\n",
       "│ Time/Update                   │ 1.6995935440063477      │\n",
       "│ Time/Epoch                    │ 12.524385452270508      │\n",
       "│ Time/FPS                      │ 163.52099609375         │\n",
       "└───────────────────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.013683319091797     │\n",
       "│ Metrics/EpCost                │ 50.65999984741211      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 291.0                  │\n",
       "│ Train/Entropy                 │ 0.03702068328857422    │\n",
       "│ Train/KL                      │ 0.013909313827753067   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.990822434425354      │\n",
       "│ Train/PolicyRatio/Min         │ 0.990822434425354      │\n",
       "│ Train/PolicyRatio/Max         │ 0.990822434425354      │\n",
       "│ Train/PolicyRatio/Std         │ 0.018661264330148697   │\n",
       "│ Train/LR                      │ 0.00012480000441428274 │\n",
       "│ Train/PolicyStd               │ 0.25124627351760864    │\n",
       "│ TotalEnvSteps                 │ 598016.0               │\n",
       "│ Loss/Loss_pi                  │ -0.020148569718003273  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0008577778935432434  │\n",
       "│ Value/Adv                     │ 0.2068416178226471     │\n",
       "│ Loss/Loss_reward_critic       │ 0.01869283989071846    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.002611599862575531  │\n",
       "│ Value/reward                  │ 2.079831838607788      │\n",
       "│ Time/Total                    │ 3897.34814453125       │\n",
       "│ Time/Rollout                  │ 10.853092193603516     │\n",
       "│ Time/Update                   │ 1.6957638263702393     │\n",
       "│ Time/Epoch                    │ 12.548898696899414     │\n",
       "│ Time/FPS                      │ 163.2015838623047      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.013683319091797     │\n",
       "│ Metrics/EpCost                │ 50.65999984741211      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 291.0                  │\n",
       "│ Train/Entropy                 │ 0.03702068328857422    │\n",
       "│ Train/KL                      │ 0.013909313827753067   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.990822434425354      │\n",
       "│ Train/PolicyRatio/Min         │ 0.990822434425354      │\n",
       "│ Train/PolicyRatio/Max         │ 0.990822434425354      │\n",
       "│ Train/PolicyRatio/Std         │ 0.018661264330148697   │\n",
       "│ Train/LR                      │ 0.00012480000441428274 │\n",
       "│ Train/PolicyStd               │ 0.25124627351760864    │\n",
       "│ TotalEnvSteps                 │ 598016.0               │\n",
       "│ Loss/Loss_pi                  │ -0.020148569718003273  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0008577778935432434  │\n",
       "│ Value/Adv                     │ 0.2068416178226471     │\n",
       "│ Loss/Loss_reward_critic       │ 0.01869283989071846    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.002611599862575531  │\n",
       "│ Value/reward                  │ 2.079831838607788      │\n",
       "│ Time/Total                    │ 3897.34814453125       │\n",
       "│ Time/Rollout                  │ 10.853092193603516     │\n",
       "│ Time/Update                   │ 1.6957638263702393     │\n",
       "│ Time/Epoch                    │ 12.548898696899414     │\n",
       "│ Time/FPS                      │ 163.2015838623047      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.037473678588867     │\n",
       "│ Metrics/EpCost                │ 50.2599983215332       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 292.0                  │\n",
       "│ Train/Entropy                 │ 0.034409742802381516   │\n",
       "│ Train/KL                      │ 0.014994355849921703   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.999862790107727      │\n",
       "│ Train/PolicyRatio/Min         │ 0.999862790107727      │\n",
       "│ Train/PolicyRatio/Max         │ 0.999862790107727      │\n",
       "│ Train/PolicyRatio/Std         │ 0.020383071154356003   │\n",
       "│ Train/LR                      │ 0.00012419999984558672 │\n",
       "│ Train/PolicyStd               │ 0.2505715489387512     │\n",
       "│ TotalEnvSteps                 │ 600064.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015581144019961357  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004567425698041916   │\n",
       "│ Value/Adv                     │ 0.28664630651474       │\n",
       "│ Loss/Loss_reward_critic       │ 0.019455967471003532   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0007631275802850723  │\n",
       "│ Value/reward                  │ 2.0987589359283447     │\n",
       "│ Time/Total                    │ 3909.932373046875      │\n",
       "│ Time/Rollout                  │ 10.866544723510742     │\n",
       "│ Time/Update                   │ 1.7059581279754639     │\n",
       "│ Time/Epoch                    │ 12.57255744934082      │\n",
       "│ Time/FPS                      │ 162.89447021484375     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.037473678588867     │\n",
       "│ Metrics/EpCost                │ 50.2599983215332       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 292.0                  │\n",
       "│ Train/Entropy                 │ 0.034409742802381516   │\n",
       "│ Train/KL                      │ 0.014994355849921703   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.999862790107727      │\n",
       "│ Train/PolicyRatio/Min         │ 0.999862790107727      │\n",
       "│ Train/PolicyRatio/Max         │ 0.999862790107727      │\n",
       "│ Train/PolicyRatio/Std         │ 0.020383071154356003   │\n",
       "│ Train/LR                      │ 0.00012419999984558672 │\n",
       "│ Train/PolicyStd               │ 0.2505715489387512     │\n",
       "│ TotalEnvSteps                 │ 600064.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015581144019961357  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004567425698041916   │\n",
       "│ Value/Adv                     │ 0.28664630651474       │\n",
       "│ Loss/Loss_reward_critic       │ 0.019455967471003532   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0007631275802850723  │\n",
       "│ Value/reward                  │ 2.0987589359283447     │\n",
       "│ Time/Total                    │ 3909.932373046875      │\n",
       "│ Time/Rollout                  │ 10.866544723510742     │\n",
       "│ Time/Update                   │ 1.7059581279754639     │\n",
       "│ Time/Epoch                    │ 12.57255744934082      │\n",
       "│ Time/FPS                      │ 162.89447021484375     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.966053009033203    │\n",
       "│ Metrics/EpCost                │ 54.459999084472656    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 293.0                 │\n",
       "│ Train/Entropy                 │ 0.02737254463136196   │\n",
       "│ Train/KL                      │ 0.01677028276026249   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0002739429473877    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0002739429473877    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0002739429473877    │\n",
       "│ Train/PolicyRatio/Std         │ 0.018789730966091156  │\n",
       "│ Train/LR                      │ 0.0001235999952768907 │\n",
       "│ Train/PolicyStd               │ 0.24878986179828644   │\n",
       "│ TotalEnvSteps                 │ 602112.0              │\n",
       "│ Loss/Loss_pi                  │ -0.019529078155755997 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00394793413579464  │\n",
       "│ Value/Adv                     │ -0.16780078411102295  │\n",
       "│ Loss/Loss_reward_critic       │ 0.01586673967540264   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.003589227795600891 │\n",
       "│ Value/reward                  │ 2.1446778774261475    │\n",
       "│ Time/Total                    │ 3922.455810546875     │\n",
       "│ Time/Rollout                  │ 10.81239128112793     │\n",
       "│ Time/Update                   │ 1.699507236480713     │\n",
       "│ Time/Epoch                    │ 12.511945724487305    │\n",
       "│ Time/FPS                      │ 163.68357849121094    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.966053009033203    │\n",
       "│ Metrics/EpCost                │ 54.459999084472656    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 293.0                 │\n",
       "│ Train/Entropy                 │ 0.02737254463136196   │\n",
       "│ Train/KL                      │ 0.01677028276026249   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0002739429473877    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0002739429473877    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0002739429473877    │\n",
       "│ Train/PolicyRatio/Std         │ 0.018789730966091156  │\n",
       "│ Train/LR                      │ 0.0001235999952768907 │\n",
       "│ Train/PolicyStd               │ 0.24878986179828644   │\n",
       "│ TotalEnvSteps                 │ 602112.0              │\n",
       "│ Loss/Loss_pi                  │ -0.019529078155755997 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00394793413579464  │\n",
       "│ Value/Adv                     │ -0.16780078411102295  │\n",
       "│ Loss/Loss_reward_critic       │ 0.01586673967540264   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.003589227795600891 │\n",
       "│ Value/reward                  │ 2.1446778774261475    │\n",
       "│ Time/Total                    │ 3922.455810546875     │\n",
       "│ Time/Rollout                  │ 10.81239128112793     │\n",
       "│ Time/Update                   │ 1.699507236480713     │\n",
       "│ Time/Epoch                    │ 12.511945724487305    │\n",
       "│ Time/FPS                      │ 163.68357849121094    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m7\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.189420700073242     │\n",
       "│ Metrics/EpCost                │ 56.58000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 294.0                  │\n",
       "│ Train/Entropy                 │ 0.024177957326173782   │\n",
       "│ Train/KL                      │ 0.021034391596913338   │\n",
       "│ Train/StopIter                │ 7.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9972193837165833     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9972193837165833     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9972193837165833     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018304575234651566   │\n",
       "│ Train/LR                      │ 0.0001230000052601099  │\n",
       "│ Train/PolicyStd               │ 0.24799518287181854    │\n",
       "│ TotalEnvSteps                 │ 604160.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015448326244950294  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004080751910805702   │\n",
       "│ Value/Adv                     │ -0.0006452202796936035 │\n",
       "│ Loss/Loss_reward_critic       │ 0.02073521353304386    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00486847385764122    │\n",
       "│ Value/reward                  │ 2.14565372467041       │\n",
       "│ Time/Total                    │ 3934.568115234375      │\n",
       "│ Time/Rollout                  │ 10.898962020874023     │\n",
       "│ Time/Update                   │ 1.201685905456543      │\n",
       "│ Time/Epoch                    │ 12.100726127624512     │\n",
       "│ Time/FPS                      │ 169.24606323242188     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.189420700073242     │\n",
       "│ Metrics/EpCost                │ 56.58000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 294.0                  │\n",
       "│ Train/Entropy                 │ 0.024177957326173782   │\n",
       "│ Train/KL                      │ 0.021034391596913338   │\n",
       "│ Train/StopIter                │ 7.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9972193837165833     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9972193837165833     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9972193837165833     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018304575234651566   │\n",
       "│ Train/LR                      │ 0.0001230000052601099  │\n",
       "│ Train/PolicyStd               │ 0.24799518287181854    │\n",
       "│ TotalEnvSteps                 │ 604160.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015448326244950294  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004080751910805702   │\n",
       "│ Value/Adv                     │ -0.0006452202796936035 │\n",
       "│ Loss/Loss_reward_critic       │ 0.02073521353304386    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00486847385764122    │\n",
       "│ Value/reward                  │ 2.14565372467041       │\n",
       "│ Time/Total                    │ 3934.568115234375      │\n",
       "│ Time/Rollout                  │ 10.898962020874023     │\n",
       "│ Time/Update                   │ 1.201685905456543      │\n",
       "│ Time/Epoch                    │ 12.100726127624512     │\n",
       "│ Time/FPS                      │ 169.24606323242188     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.46990203857422      │\n",
       "│ Metrics/EpCost                │ 49.599998474121094     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 295.0                  │\n",
       "│ Train/Entropy                 │ 0.02237246371805668    │\n",
       "│ Train/KL                      │ 0.015468573197722435   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0023390054702759     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0023390054702759     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0023390054702759     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018886195495724678   │\n",
       "│ Train/LR                      │ 0.00012240000069141388 │\n",
       "│ Train/PolicyStd               │ 0.24754926562309265    │\n",
       "│ TotalEnvSteps                 │ 606208.0               │\n",
       "│ Loss/Loss_pi                  │ -0.019308457151055336  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0038601309061050415 │\n",
       "│ Value/Adv                     │ -0.2240358144044876    │\n",
       "│ Loss/Loss_reward_critic       │ 0.023809589445590973   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0030743759125471115  │\n",
       "│ Value/reward                  │ 2.208246946334839      │\n",
       "│ Time/Total                    │ 3947.114501953125      │\n",
       "│ Time/Rollout                  │ 10.83398723602295      │\n",
       "│ Time/Update                   │ 1.6949429512023926     │\n",
       "│ Time/Epoch                    │ 12.528974533081055     │\n",
       "│ Time/FPS                      │ 163.4611053466797      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.46990203857422      │\n",
       "│ Metrics/EpCost                │ 49.599998474121094     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 295.0                  │\n",
       "│ Train/Entropy                 │ 0.02237246371805668    │\n",
       "│ Train/KL                      │ 0.015468573197722435   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0023390054702759     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0023390054702759     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0023390054702759     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018886195495724678   │\n",
       "│ Train/LR                      │ 0.00012240000069141388 │\n",
       "│ Train/PolicyStd               │ 0.24754926562309265    │\n",
       "│ TotalEnvSteps                 │ 606208.0               │\n",
       "│ Loss/Loss_pi                  │ -0.019308457151055336  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0038601309061050415 │\n",
       "│ Value/Adv                     │ -0.2240358144044876    │\n",
       "│ Loss/Loss_reward_critic       │ 0.023809589445590973   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0030743759125471115  │\n",
       "│ Value/reward                  │ 2.208246946334839      │\n",
       "│ Time/Total                    │ 3947.114501953125      │\n",
       "│ Time/Rollout                  │ 10.83398723602295      │\n",
       "│ Time/Update                   │ 1.6949429512023926     │\n",
       "│ Time/Epoch                    │ 12.528974533081055     │\n",
       "│ Time/FPS                      │ 163.4611053466797      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.487173080444336     │\n",
       "│ Metrics/EpCost                │ 48.880001068115234     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 296.0                  │\n",
       "│ Train/Entropy                 │ 0.019609570503234863   │\n",
       "│ Train/KL                      │ 0.013422203250229359   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0008848905563354     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0008848905563354     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0008848905563354     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01925705000758171    │\n",
       "│ Train/LR                      │ 0.00012180000339867547 │\n",
       "│ Train/PolicyStd               │ 0.24687454104423523    │\n",
       "│ TotalEnvSteps                 │ 608256.0               │\n",
       "│ Loss/Loss_pi                  │ -0.020760763436555862  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0014523062855005264 │\n",
       "│ Value/Adv                     │ 0.12789444625377655    │\n",
       "│ Loss/Loss_reward_critic       │ 0.013289198279380798   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.010520391166210175  │\n",
       "│ Value/reward                  │ 2.17244291305542       │\n",
       "│ Time/Total                    │ 3959.700439453125      │\n",
       "│ Time/Rollout                  │ 10.866539001464844     │\n",
       "│ Time/Update                   │ 1.7077887058258057     │\n",
       "│ Time/Epoch                    │ 12.574372291564941     │\n",
       "│ Time/FPS                      │ 162.87095642089844     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.487173080444336     │\n",
       "│ Metrics/EpCost                │ 48.880001068115234     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 296.0                  │\n",
       "│ Train/Entropy                 │ 0.019609570503234863   │\n",
       "│ Train/KL                      │ 0.013422203250229359   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0008848905563354     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0008848905563354     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0008848905563354     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01925705000758171    │\n",
       "│ Train/LR                      │ 0.00012180000339867547 │\n",
       "│ Train/PolicyStd               │ 0.24687454104423523    │\n",
       "│ TotalEnvSteps                 │ 608256.0               │\n",
       "│ Loss/Loss_pi                  │ -0.020760763436555862  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0014523062855005264 │\n",
       "│ Value/Adv                     │ 0.12789444625377655    │\n",
       "│ Loss/Loss_reward_critic       │ 0.013289198279380798   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.010520391166210175  │\n",
       "│ Value/reward                  │ 2.17244291305542       │\n",
       "│ Time/Total                    │ 3959.700439453125      │\n",
       "│ Time/Rollout                  │ 10.866539001464844     │\n",
       "│ Time/Update                   │ 1.7077887058258057     │\n",
       "│ Time/Epoch                    │ 12.574372291564941     │\n",
       "│ Time/FPS                      │ 162.87095642089844     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.45838165283203      │\n",
       "│ Metrics/EpCost                │ 48.2400016784668       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 297.0                  │\n",
       "│ Train/Entropy                 │ 0.014831556007266045   │\n",
       "│ Train/KL                      │ 0.009632180444896221   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0096542835235596     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0096542835235596     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0096542835235596     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019680650904774666   │\n",
       "│ Train/LR                      │ 0.00012119999882997945 │\n",
       "│ Train/PolicyStd               │ 0.24573171138763428    │\n",
       "│ TotalEnvSteps                 │ 610304.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012051102705299854  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.008709660731256008   │\n",
       "│ Value/Adv                     │ -0.10267478227615356   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014353632926940918   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0010644346475601196  │\n",
       "│ Value/reward                  │ 1.9464253187179565     │\n",
       "│ Time/Total                    │ 3972.2685546875        │\n",
       "│ Time/Rollout                  │ 10.8160400390625       │\n",
       "│ Time/Update                   │ 1.7402660846710205     │\n",
       "│ Time/Epoch                    │ 12.556352615356445     │\n",
       "│ Time/FPS                      │ 163.10470581054688     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.45838165283203      │\n",
       "│ Metrics/EpCost                │ 48.2400016784668       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 297.0                  │\n",
       "│ Train/Entropy                 │ 0.014831556007266045   │\n",
       "│ Train/KL                      │ 0.009632180444896221   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0096542835235596     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0096542835235596     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0096542835235596     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019680650904774666   │\n",
       "│ Train/LR                      │ 0.00012119999882997945 │\n",
       "│ Train/PolicyStd               │ 0.24573171138763428    │\n",
       "│ TotalEnvSteps                 │ 610304.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012051102705299854  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.008709660731256008   │\n",
       "│ Value/Adv                     │ -0.10267478227615356   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014353632926940918   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0010644346475601196  │\n",
       "│ Value/reward                  │ 1.9464253187179565     │\n",
       "│ Time/Total                    │ 3972.2685546875        │\n",
       "│ Time/Rollout                  │ 10.8160400390625       │\n",
       "│ Time/Update                   │ 1.7402660846710205     │\n",
       "│ Time/Epoch                    │ 12.556352615356445     │\n",
       "│ Time/FPS                      │ 163.10470581054688     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.496870040893555     │\n",
       "│ Metrics/EpCost                │ 49.459999084472656     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 298.0                  │\n",
       "│ Train/Entropy                 │ 0.014622698538005352   │\n",
       "│ Train/KL                      │ 0.016569189727306366   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9896029233932495     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9896029233932495     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9896029233932495     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01890103705227375    │\n",
       "│ Train/LR                      │ 0.00012060000153724104 │\n",
       "│ Train/PolicyStd               │ 0.24568219482898712    │\n",
       "│ TotalEnvSteps                 │ 612352.0               │\n",
       "│ Loss/Loss_pi                  │ -0.02107941173017025   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.009028309024870396  │\n",
       "│ Value/Adv                     │ 0.06635352969169617    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017940612509846687   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0035869795829057693  │\n",
       "│ Value/reward                  │ 2.0412280559539795     │\n",
       "│ Time/Total                    │ 3984.853271484375      │\n",
       "│ Time/Rollout                  │ 10.869950294494629     │\n",
       "│ Time/Update                   │ 1.703059434890747      │\n",
       "│ Time/Epoch                    │ 12.573068618774414     │\n",
       "│ Time/FPS                      │ 162.88784790039062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.496870040893555     │\n",
       "│ Metrics/EpCost                │ 49.459999084472656     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 298.0                  │\n",
       "│ Train/Entropy                 │ 0.014622698538005352   │\n",
       "│ Train/KL                      │ 0.016569189727306366   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9896029233932495     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9896029233932495     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9896029233932495     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01890103705227375    │\n",
       "│ Train/LR                      │ 0.00012060000153724104 │\n",
       "│ Train/PolicyStd               │ 0.24568219482898712    │\n",
       "│ TotalEnvSteps                 │ 612352.0               │\n",
       "│ Loss/Loss_pi                  │ -0.02107941173017025   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.009028309024870396  │\n",
       "│ Value/Adv                     │ 0.06635352969169617    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017940612509846687   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0035869795829057693  │\n",
       "│ Value/reward                  │ 2.0412280559539795     │\n",
       "│ Time/Total                    │ 3984.853271484375      │\n",
       "│ Time/Rollout                  │ 10.869950294494629     │\n",
       "│ Time/Update                   │ 1.703059434890747      │\n",
       "│ Time/Epoch                    │ 12.573068618774414     │\n",
       "│ Time/FPS                      │ 162.88784790039062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.447202682495117     │\n",
       "│ Metrics/EpCost                │ 48.70000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 299.0                  │\n",
       "│ Train/Entropy                 │ 0.014706796035170555   │\n",
       "│ Train/KL                      │ 0.011708183214068413   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9985392689704895     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9985392689704895     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9985392689704895     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01738942414522171    │\n",
       "│ Train/LR                      │ 0.00011999999696854502 │\n",
       "│ Train/PolicyStd               │ 0.24568481743335724    │\n",
       "│ TotalEnvSteps                 │ 614400.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017271611839532852  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0038077998906373978  │\n",
       "│ Value/Adv                     │ -0.00504701305180788   │\n",
       "│ Loss/Loss_reward_critic       │ 0.016808930784463882   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0011316817253828049 │\n",
       "│ Value/reward                  │ 2.206470489501953      │\n",
       "│ Time/Total                    │ 3997.43701171875       │\n",
       "│ Time/Rollout                  │ 10.84072494506836      │\n",
       "│ Time/Update                   │ 1.730607032775879      │\n",
       "│ Time/Epoch                    │ 12.57137680053711      │\n",
       "│ Time/FPS                      │ 162.90977478027344     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.447202682495117     │\n",
       "│ Metrics/EpCost                │ 48.70000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 299.0                  │\n",
       "│ Train/Entropy                 │ 0.014706796035170555   │\n",
       "│ Train/KL                      │ 0.011708183214068413   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9985392689704895     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9985392689704895     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9985392689704895     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01738942414522171    │\n",
       "│ Train/LR                      │ 0.00011999999696854502 │\n",
       "│ Train/PolicyStd               │ 0.24568481743335724    │\n",
       "│ TotalEnvSteps                 │ 614400.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017271611839532852  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0038077998906373978  │\n",
       "│ Value/Adv                     │ -0.00504701305180788   │\n",
       "│ Loss/Loss_reward_critic       │ 0.016808930784463882   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0011316817253828049 │\n",
       "│ Value/reward                  │ 2.206470489501953      │\n",
       "│ Time/Total                    │ 3997.43701171875       │\n",
       "│ Time/Rollout                  │ 10.84072494506836      │\n",
       "│ Time/Update                   │ 1.730607032775879      │\n",
       "│ Time/Epoch                    │ 12.57137680053711      │\n",
       "│ Time/FPS                      │ 162.90977478027344     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.578462600708008     │\n",
       "│ Metrics/EpCost                │ 49.18000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 300.0                  │\n",
       "│ Train/Entropy                 │ 0.014640070497989655   │\n",
       "│ Train/KL                      │ 0.015075376257300377   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0000557899475098     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0000557899475098     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0000557899475098     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020213447511196136   │\n",
       "│ Train/LR                      │ 0.00011939999967580661 │\n",
       "│ Train/PolicyStd               │ 0.24568001925945282    │\n",
       "│ TotalEnvSteps                 │ 616448.0               │\n",
       "│ Loss/Loss_pi                  │ -0.020263712853193283  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002992101013660431  │\n",
       "│ Value/Adv                     │ 0.2079707831144333     │\n",
       "│ Loss/Loss_reward_critic       │ 0.018415827304124832   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0016068965196609497  │\n",
       "│ Value/reward                  │ 2.1605618000030518     │\n",
       "│ Time/Total                    │ 4009.988525390625      │\n",
       "│ Time/Rollout                  │ 10.852356910705566     │\n",
       "│ Time/Update                   │ 1.6863062381744385     │\n",
       "│ Time/Epoch                    │ 12.538707733154297     │\n",
       "│ Time/FPS                      │ 163.334228515625       │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.578462600708008     │\n",
       "│ Metrics/EpCost                │ 49.18000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 300.0                  │\n",
       "│ Train/Entropy                 │ 0.014640070497989655   │\n",
       "│ Train/KL                      │ 0.015075376257300377   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0000557899475098     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0000557899475098     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0000557899475098     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020213447511196136   │\n",
       "│ Train/LR                      │ 0.00011939999967580661 │\n",
       "│ Train/PolicyStd               │ 0.24568001925945282    │\n",
       "│ TotalEnvSteps                 │ 616448.0               │\n",
       "│ Loss/Loss_pi                  │ -0.020263712853193283  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002992101013660431  │\n",
       "│ Value/Adv                     │ 0.2079707831144333     │\n",
       "│ Loss/Loss_reward_critic       │ 0.018415827304124832   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0016068965196609497  │\n",
       "│ Value/reward                  │ 2.1605618000030518     │\n",
       "│ Time/Total                    │ 4009.988525390625      │\n",
       "│ Time/Rollout                  │ 10.852356910705566     │\n",
       "│ Time/Update                   │ 1.6863062381744385     │\n",
       "│ Time/Epoch                    │ 12.538707733154297     │\n",
       "│ Time/FPS                      │ 163.334228515625       │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m4\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.153114318847656     │\n",
       "│ Metrics/EpCost                │ 48.29999923706055      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 301.0                  │\n",
       "│ Train/Entropy                 │ 0.014949051663279533   │\n",
       "│ Train/KL                      │ 0.025143569335341454   │\n",
       "│ Train/StopIter                │ 4.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0055444240570068     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0055444240570068     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0055444240570068     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018144909292459488   │\n",
       "│ Train/LR                      │ 0.0001188000023830682  │\n",
       "│ Train/PolicyStd               │ 0.24577200412750244    │\n",
       "│ TotalEnvSteps                 │ 618496.0               │\n",
       "│ Loss/Loss_pi                  │ -0.003899388713762164  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.01636432413943112    │\n",
       "│ Value/Adv                     │ 0.10626935213804245    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01338845957070589    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0050273677334189415 │\n",
       "│ Value/reward                  │ 2.2083747386932373     │\n",
       "│ Time/Total                    │ 4021.460693359375      │\n",
       "│ Time/Rollout                  │ 10.794898986816406     │\n",
       "│ Time/Update                   │ 0.6656069755554199     │\n",
       "│ Time/Epoch                    │ 11.460548400878906     │\n",
       "│ Time/FPS                      │ 178.70001220703125     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.153114318847656     │\n",
       "│ Metrics/EpCost                │ 48.29999923706055      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 301.0                  │\n",
       "│ Train/Entropy                 │ 0.014949051663279533   │\n",
       "│ Train/KL                      │ 0.025143569335341454   │\n",
       "│ Train/StopIter                │ 4.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0055444240570068     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0055444240570068     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0055444240570068     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018144909292459488   │\n",
       "│ Train/LR                      │ 0.0001188000023830682  │\n",
       "│ Train/PolicyStd               │ 0.24577200412750244    │\n",
       "│ TotalEnvSteps                 │ 618496.0               │\n",
       "│ Loss/Loss_pi                  │ -0.003899388713762164  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.01636432413943112    │\n",
       "│ Value/Adv                     │ 0.10626935213804245    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01338845957070589    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0050273677334189415 │\n",
       "│ Value/reward                  │ 2.2083747386932373     │\n",
       "│ Time/Total                    │ 4021.460693359375      │\n",
       "│ Time/Rollout                  │ 10.794898986816406     │\n",
       "│ Time/Update                   │ 0.6656069755554199     │\n",
       "│ Time/Epoch                    │ 11.460548400878906     │\n",
       "│ Time/FPS                      │ 178.70001220703125     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.04082679748535      │\n",
       "│ Metrics/EpCost                │ 50.02000045776367      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 302.0                  │\n",
       "│ Train/Entropy                 │ 0.008518212474882603   │\n",
       "│ Train/KL                      │ 0.013417997397482395   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0009410381317139     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0009410381317139     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0009410381317139     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018653504550457      │\n",
       "│ Train/LR                      │ 0.00011819999781437218 │\n",
       "│ Train/PolicyStd               │ 0.24420782923698425    │\n",
       "│ TotalEnvSteps                 │ 620544.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01587783731520176   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.011978448601439595  │\n",
       "│ Value/Adv                     │ 0.19564832746982574    │\n",
       "│ Loss/Loss_reward_critic       │ 0.014287421479821205   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0008989619091153145  │\n",
       "│ Value/reward                  │ 2.0153703689575195     │\n",
       "│ Time/Total                    │ 4033.938232421875      │\n",
       "│ Time/Rollout                  │ 10.783714294433594     │\n",
       "│ Time/Update                   │ 1.6821396350860596     │\n",
       "│ Time/Epoch                    │ 12.465896606445312     │\n",
       "│ Time/FPS                      │ 164.28823852539062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.04082679748535      │\n",
       "│ Metrics/EpCost                │ 50.02000045776367      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 302.0                  │\n",
       "│ Train/Entropy                 │ 0.008518212474882603   │\n",
       "│ Train/KL                      │ 0.013417997397482395   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0009410381317139     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0009410381317139     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0009410381317139     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018653504550457      │\n",
       "│ Train/LR                      │ 0.00011819999781437218 │\n",
       "│ Train/PolicyStd               │ 0.24420782923698425    │\n",
       "│ TotalEnvSteps                 │ 620544.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01587783731520176   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.011978448601439595  │\n",
       "│ Value/Adv                     │ 0.19564832746982574    │\n",
       "│ Loss/Loss_reward_critic       │ 0.014287421479821205   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0008989619091153145  │\n",
       "│ Value/reward                  │ 2.0153703689575195     │\n",
       "│ Time/Total                    │ 4033.938232421875      │\n",
       "│ Time/Rollout                  │ 10.783714294433594     │\n",
       "│ Time/Update                   │ 1.6821396350860596     │\n",
       "│ Time/Epoch                    │ 12.465896606445312     │\n",
       "│ Time/FPS                      │ 164.28823852539062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.955881118774414     │\n",
       "│ Metrics/EpCost                │ 50.5                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 303.0                  │\n",
       "│ Train/Entropy                 │ 0.001893024891614914   │\n",
       "│ Train/KL                      │ 0.015872778370976448   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0050268173217773     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0050268173217773     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0050268173217773     │\n",
       "│ Train/PolicyRatio/Std         │ 0.021525869145989418   │\n",
       "│ Train/LR                      │ 0.00011760000052163377 │\n",
       "│ Train/PolicyStd               │ 0.24257874488830566    │\n",
       "│ TotalEnvSteps                 │ 622592.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015612421557307243  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.000265415757894516   │\n",
       "│ Value/Adv                     │ -0.05396287143230438   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018202634528279305   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.003915213048458099   │\n",
       "│ Value/reward                  │ 2.0204200744628906     │\n",
       "│ Time/Total                    │ 4046.445556640625      │\n",
       "│ Time/Rollout                  │ 10.807056427001953     │\n",
       "│ Time/Update                   │ 1.6889126300811768     │\n",
       "│ Time/Epoch                    │ 12.496012687683105     │\n",
       "│ Time/FPS                      │ 163.8922882080078      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.955881118774414     │\n",
       "│ Metrics/EpCost                │ 50.5                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 303.0                  │\n",
       "│ Train/Entropy                 │ 0.001893024891614914   │\n",
       "│ Train/KL                      │ 0.015872778370976448   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0050268173217773     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0050268173217773     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0050268173217773     │\n",
       "│ Train/PolicyRatio/Std         │ 0.021525869145989418   │\n",
       "│ Train/LR                      │ 0.00011760000052163377 │\n",
       "│ Train/PolicyStd               │ 0.24257874488830566    │\n",
       "│ TotalEnvSteps                 │ 622592.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015612421557307243  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.000265415757894516   │\n",
       "│ Value/Adv                     │ -0.05396287143230438   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018202634528279305   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.003915213048458099   │\n",
       "│ Value/reward                  │ 2.0204200744628906     │\n",
       "│ Time/Total                    │ 4046.445556640625      │\n",
       "│ Time/Rollout                  │ 10.807056427001953     │\n",
       "│ Time/Update                   │ 1.6889126300811768     │\n",
       "│ Time/Epoch                    │ 12.496012687683105     │\n",
       "│ Time/FPS                      │ 163.8922882080078      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m5\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.01081085205078      │\n",
       "│ Metrics/EpCost                │ 52.939998626708984     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 304.0                  │\n",
       "│ Train/Entropy                 │ 0.002716217888519168   │\n",
       "│ Train/KL                      │ 0.021145302802324295   │\n",
       "│ Train/StopIter                │ 5.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0005934238433838     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0005934238433838     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0005934238433838     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01663380116224289    │\n",
       "│ Train/LR                      │ 0.00011700000322889537 │\n",
       "│ Train/PolicyStd               │ 0.2427656650543213     │\n",
       "│ TotalEnvSteps                 │ 624640.0               │\n",
       "│ Loss/Loss_pi                  │ -0.005793408490717411  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.009819013066589832   │\n",
       "│ Value/Adv                     │ 0.09551126509904861    │\n",
       "│ Loss/Loss_reward_critic       │ 0.023363731801509857   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.005161097273230553   │\n",
       "│ Value/reward                  │ 2.2286596298217773     │\n",
       "│ Time/Total                    │ 4058.095947265625      │\n",
       "│ Time/Rollout                  │ 10.799827575683594     │\n",
       "│ Time/Update                   │ 0.838850736618042      │\n",
       "│ Time/Epoch                    │ 11.638738632202148     │\n",
       "│ Time/FPS                      │ 175.96409606933594     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.01081085205078      │\n",
       "│ Metrics/EpCost                │ 52.939998626708984     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 304.0                  │\n",
       "│ Train/Entropy                 │ 0.002716217888519168   │\n",
       "│ Train/KL                      │ 0.021145302802324295   │\n",
       "│ Train/StopIter                │ 5.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0005934238433838     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0005934238433838     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0005934238433838     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01663380116224289    │\n",
       "│ Train/LR                      │ 0.00011700000322889537 │\n",
       "│ Train/PolicyStd               │ 0.2427656650543213     │\n",
       "│ TotalEnvSteps                 │ 624640.0               │\n",
       "│ Loss/Loss_pi                  │ -0.005793408490717411  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.009819013066589832   │\n",
       "│ Value/Adv                     │ 0.09551126509904861    │\n",
       "│ Loss/Loss_reward_critic       │ 0.023363731801509857   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.005161097273230553   │\n",
       "│ Value/reward                  │ 2.2286596298217773     │\n",
       "│ Time/Total                    │ 4058.095947265625      │\n",
       "│ Time/Rollout                  │ 10.799827575683594     │\n",
       "│ Time/Update                   │ 0.838850736618042      │\n",
       "│ Time/Epoch                    │ 11.638738632202148     │\n",
       "│ Time/FPS                      │ 175.96409606933594     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.959732055664062     │\n",
       "│ Metrics/EpCost                │ 54.119998931884766     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 305.0                  │\n",
       "│ Train/Entropy                 │ 0.002169935265555978   │\n",
       "│ Train/KL                      │ 0.01716342568397522    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9980775117874146     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9980775117874146     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9980775117874146     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020857416093349457   │\n",
       "│ Train/LR                      │ 0.00011639999866019934 │\n",
       "│ Train/PolicyStd               │ 0.24263222515583038    │\n",
       "│ TotalEnvSteps                 │ 626688.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01919708587229252   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.013403677381575108  │\n",
       "│ Value/Adv                     │ -0.07392920553684235   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01874556578695774    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.004618166014552116  │\n",
       "│ Value/reward                  │ 2.1277809143066406     │\n",
       "│ Time/Total                    │ 4070.71337890625       │\n",
       "│ Time/Rollout                  │ 10.825636863708496     │\n",
       "│ Time/Update                   │ 1.7755377292633057     │\n",
       "│ Time/Epoch                    │ 12.601232528686523     │\n",
       "│ Time/FPS                      │ 162.5238037109375      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.959732055664062     │\n",
       "│ Metrics/EpCost                │ 54.119998931884766     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 305.0                  │\n",
       "│ Train/Entropy                 │ 0.002169935265555978   │\n",
       "│ Train/KL                      │ 0.01716342568397522    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9980775117874146     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9980775117874146     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9980775117874146     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020857416093349457   │\n",
       "│ Train/LR                      │ 0.00011639999866019934 │\n",
       "│ Train/PolicyStd               │ 0.24263222515583038    │\n",
       "│ TotalEnvSteps                 │ 626688.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01919708587229252   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.013403677381575108  │\n",
       "│ Value/Adv                     │ -0.07392920553684235   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01874556578695774    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.004618166014552116  │\n",
       "│ Value/reward                  │ 2.1277809143066406     │\n",
       "│ Time/Total                    │ 4070.71337890625       │\n",
       "│ Time/Rollout                  │ 10.825636863708496     │\n",
       "│ Time/Update                   │ 1.7755377292633057     │\n",
       "│ Time/Epoch                    │ 12.601232528686523     │\n",
       "│ Time/FPS                      │ 162.5238037109375      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.9168758392334       │\n",
       "│ Metrics/EpCost                │ 54.84000015258789      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 306.0                  │\n",
       "│ Train/Entropy                 │ -0.00396152725443244   │\n",
       "│ Train/KL                      │ 0.014256002381443977   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9967538714408875     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9967538714408875     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9967538714408875     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018947362899780273   │\n",
       "│ Train/LR                      │ 0.00011580000136746094 │\n",
       "│ Train/PolicyStd               │ 0.2411407232284546     │\n",
       "│ TotalEnvSteps                 │ 628736.0               │\n",
       "│ Loss/Loss_pi                  │ -0.019981039687991142  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0007839538156986237 │\n",
       "│ Value/Adv                     │ -0.009873220697045326  │\n",
       "│ Loss/Loss_reward_critic       │ 0.015005925670266151   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0037396401166915894 │\n",
       "│ Value/reward                  │ 2.1094555854797363     │\n",
       "│ Time/Total                    │ 4083.272216796875      │\n",
       "│ Time/Rollout                  │ 10.842005729675293     │\n",
       "│ Time/Update                   │ 1.705256462097168      │\n",
       "│ Time/Epoch                    │ 12.547304153442383     │\n",
       "│ Time/FPS                      │ 163.22232055664062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.9168758392334       │\n",
       "│ Metrics/EpCost                │ 54.84000015258789      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 306.0                  │\n",
       "│ Train/Entropy                 │ -0.00396152725443244   │\n",
       "│ Train/KL                      │ 0.014256002381443977   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9967538714408875     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9967538714408875     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9967538714408875     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018947362899780273   │\n",
       "│ Train/LR                      │ 0.00011580000136746094 │\n",
       "│ Train/PolicyStd               │ 0.2411407232284546     │\n",
       "│ TotalEnvSteps                 │ 628736.0               │\n",
       "│ Loss/Loss_pi                  │ -0.019981039687991142  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0007839538156986237 │\n",
       "│ Value/Adv                     │ -0.009873220697045326  │\n",
       "│ Loss/Loss_reward_critic       │ 0.015005925670266151   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0037396401166915894 │\n",
       "│ Value/reward                  │ 2.1094555854797363     │\n",
       "│ Time/Total                    │ 4083.272216796875      │\n",
       "│ Time/Rollout                  │ 10.842005729675293     │\n",
       "│ Time/Update                   │ 1.705256462097168      │\n",
       "│ Time/Epoch                    │ 12.547304153442383     │\n",
       "│ Time/FPS                      │ 163.22232055664062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.78449249267578      │\n",
       "│ Metrics/EpCost                │ 57.70000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 307.0                  │\n",
       "│ Train/Entropy                 │ -0.00797665398567915   │\n",
       "│ Train/KL                      │ 0.014470507390797138   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0009520053863525     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0009520053863525     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0009520053863525     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019421251490712166   │\n",
       "│ Train/LR                      │ 0.00011519999679876491 │\n",
       "│ Train/PolicyStd               │ 0.24016018211841583    │\n",
       "│ TotalEnvSteps                 │ 630784.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015501134097576141  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004479905590415001   │\n",
       "│ Value/Adv                     │ -0.08673856407403946   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015059597790241241   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 5.367211997509003e-05  │\n",
       "│ Value/reward                  │ 2.037111282348633      │\n",
       "│ Time/Total                    │ 4095.9287109375        │\n",
       "│ Time/Rollout                  │ 10.937554359436035     │\n",
       "│ Time/Update                   │ 1.7070667743682861     │\n",
       "│ Time/Epoch                    │ 12.64466381072998      │\n",
       "│ Time/FPS                      │ 161.96556091308594     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.78449249267578      │\n",
       "│ Metrics/EpCost                │ 57.70000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 307.0                  │\n",
       "│ Train/Entropy                 │ -0.00797665398567915   │\n",
       "│ Train/KL                      │ 0.014470507390797138   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0009520053863525     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0009520053863525     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0009520053863525     │\n",
       "│ Train/PolicyRatio/Std         │ 0.019421251490712166   │\n",
       "│ Train/LR                      │ 0.00011519999679876491 │\n",
       "│ Train/PolicyStd               │ 0.24016018211841583    │\n",
       "│ TotalEnvSteps                 │ 630784.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015501134097576141  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004479905590415001   │\n",
       "│ Value/Adv                     │ -0.08673856407403946   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015059597790241241   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 5.367211997509003e-05  │\n",
       "│ Value/reward                  │ 2.037111282348633      │\n",
       "│ Time/Total                    │ 4095.9287109375        │\n",
       "│ Time/Rollout                  │ 10.937554359436035     │\n",
       "│ Time/Update                   │ 1.7070667743682861     │\n",
       "│ Time/Epoch                    │ 12.64466381072998      │\n",
       "│ Time/FPS                      │ 161.96556091308594     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.977094650268555     │\n",
       "│ Metrics/EpCost                │ 57.34000015258789      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 308.0                  │\n",
       "│ Train/Entropy                 │ -0.011964034289121628  │\n",
       "│ Train/KL                      │ 0.015375133603811264   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9948679208755493     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9948679208755493     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9948679208755493     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01729157380759716    │\n",
       "│ Train/LR                      │ 0.0001145999995060265  │\n",
       "│ Train/PolicyStd               │ 0.2391825169324875     │\n",
       "│ TotalEnvSteps                 │ 632832.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015561479143798351  │\n",
       "│ Loss/Loss_pi/Delta            │ -6.034504622220993e-05 │\n",
       "│ Value/Adv                     │ -0.18866021931171417   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02046952024102211    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0054099224507808685  │\n",
       "│ Value/reward                  │ 2.135082960128784      │\n",
       "│ Time/Total                    │ 4108.50830078125       │\n",
       "│ Time/Rollout                  │ 10.85975456237793      │\n",
       "│ Time/Update                   │ 1.7080531120300293     │\n",
       "│ Time/Epoch                    │ 12.567852020263672     │\n",
       "│ Time/FPS                      │ 162.95545959472656     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.977094650268555     │\n",
       "│ Metrics/EpCost                │ 57.34000015258789      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 308.0                  │\n",
       "│ Train/Entropy                 │ -0.011964034289121628  │\n",
       "│ Train/KL                      │ 0.015375133603811264   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9948679208755493     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9948679208755493     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9948679208755493     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01729157380759716    │\n",
       "│ Train/LR                      │ 0.0001145999995060265  │\n",
       "│ Train/PolicyStd               │ 0.2391825169324875     │\n",
       "│ TotalEnvSteps                 │ 632832.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015561479143798351  │\n",
       "│ Loss/Loss_pi/Delta            │ -6.034504622220993e-05 │\n",
       "│ Value/Adv                     │ -0.18866021931171417   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02046952024102211    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0054099224507808685  │\n",
       "│ Value/reward                  │ 2.135082960128784      │\n",
       "│ Time/Total                    │ 4108.50830078125       │\n",
       "│ Time/Rollout                  │ 10.85975456237793      │\n",
       "│ Time/Update                   │ 1.7080531120300293     │\n",
       "│ Time/Epoch                    │ 12.567852020263672     │\n",
       "│ Time/FPS                      │ 162.95545959472656     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.796842575073242      │\n",
       "│ Metrics/EpCost                │ 56.13999938964844       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 309.0                   │\n",
       "│ Train/Entropy                 │ -0.016725923866033554   │\n",
       "│ Train/KL                      │ 0.013818989507853985    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0019493103027344      │\n",
       "│ Train/PolicyRatio/Min         │ 1.0019493103027344      │\n",
       "│ Train/PolicyRatio/Max         │ 1.0019493103027344      │\n",
       "│ Train/PolicyRatio/Std         │ 0.018130837008357048    │\n",
       "│ Train/LR                      │ 0.0001140000022132881   │\n",
       "│ Train/PolicyStd               │ 0.2380315512418747      │\n",
       "│ TotalEnvSteps                 │ 634880.0                │\n",
       "│ Loss/Loss_pi                  │ -0.01576298102736473    │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00020150188356637955 │\n",
       "│ Value/Adv                     │ 0.15287750959396362     │\n",
       "│ Loss/Loss_reward_critic       │ 0.014348986558616161    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.006120533682405949   │\n",
       "│ Value/reward                  │ 2.0737459659576416      │\n",
       "│ Time/Total                    │ 4121.07080078125        │\n",
       "│ Time/Rollout                  │ 10.858628273010254      │\n",
       "│ Time/Update                   │ 1.6904053688049316      │\n",
       "│ Time/Epoch                    │ 12.549078941345215      │\n",
       "│ Time/FPS                      │ 163.19923400878906      │\n",
       "└───────────────────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.796842575073242      │\n",
       "│ Metrics/EpCost                │ 56.13999938964844       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 309.0                   │\n",
       "│ Train/Entropy                 │ -0.016725923866033554   │\n",
       "│ Train/KL                      │ 0.013818989507853985    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0019493103027344      │\n",
       "│ Train/PolicyRatio/Min         │ 1.0019493103027344      │\n",
       "│ Train/PolicyRatio/Max         │ 1.0019493103027344      │\n",
       "│ Train/PolicyRatio/Std         │ 0.018130837008357048    │\n",
       "│ Train/LR                      │ 0.0001140000022132881   │\n",
       "│ Train/PolicyStd               │ 0.2380315512418747      │\n",
       "│ TotalEnvSteps                 │ 634880.0                │\n",
       "│ Loss/Loss_pi                  │ -0.01576298102736473    │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00020150188356637955 │\n",
       "│ Value/Adv                     │ 0.15287750959396362     │\n",
       "│ Loss/Loss_reward_critic       │ 0.014348986558616161    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.006120533682405949   │\n",
       "│ Value/reward                  │ 2.0737459659576416      │\n",
       "│ Time/Total                    │ 4121.07080078125        │\n",
       "│ Time/Rollout                  │ 10.858628273010254      │\n",
       "│ Time/Update                   │ 1.6904053688049316      │\n",
       "│ Time/Epoch                    │ 12.549078941345215      │\n",
       "│ Time/FPS                      │ 163.19923400878906      │\n",
       "└───────────────────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.627342224121094     │\n",
       "│ Metrics/EpCost                │ 55.0                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 310.0                  │\n",
       "│ Train/Entropy                 │ -0.024621274322271347  │\n",
       "│ Train/KL                      │ 0.011213511228561401   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0034540891647339     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0034540891647339     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0034540891647339     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01783517561852932    │\n",
       "│ Train/LR                      │ 0.00011339999764459208 │\n",
       "│ Train/PolicyStd               │ 0.23615917563438416    │\n",
       "│ TotalEnvSteps                 │ 636928.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012066007591784     │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0036969734355807304  │\n",
       "│ Value/Adv                     │ -0.0050381869077682495 │\n",
       "│ Loss/Loss_reward_critic       │ 0.020300719887018204   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.005951733328402042   │\n",
       "│ Value/reward                  │ 2.0090160369873047     │\n",
       "│ Time/Total                    │ 4133.61181640625       │\n",
       "│ Time/Rollout                  │ 10.833498001098633     │\n",
       "│ Time/Update                   │ 1.6946041584014893     │\n",
       "│ Time/Epoch                    │ 12.528146743774414     │\n",
       "│ Time/FPS                      │ 163.471923828125       │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.627342224121094     │\n",
       "│ Metrics/EpCost                │ 55.0                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 310.0                  │\n",
       "│ Train/Entropy                 │ -0.024621274322271347  │\n",
       "│ Train/KL                      │ 0.011213511228561401   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0034540891647339     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0034540891647339     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0034540891647339     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01783517561852932    │\n",
       "│ Train/LR                      │ 0.00011339999764459208 │\n",
       "│ Train/PolicyStd               │ 0.23615917563438416    │\n",
       "│ TotalEnvSteps                 │ 636928.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012066007591784     │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0036969734355807304  │\n",
       "│ Value/Adv                     │ -0.0050381869077682495 │\n",
       "│ Loss/Loss_reward_critic       │ 0.020300719887018204   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.005951733328402042   │\n",
       "│ Value/reward                  │ 2.0090160369873047     │\n",
       "│ Time/Total                    │ 4133.61181640625       │\n",
       "│ Time/Rollout                  │ 10.833498001098633     │\n",
       "│ Time/Update                   │ 1.6946041584014893     │\n",
       "│ Time/Epoch                    │ 12.528146743774414     │\n",
       "│ Time/FPS                      │ 163.471923828125       │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.478267669677734     │\n",
       "│ Metrics/EpCost                │ 56.31999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 311.0                  │\n",
       "│ Train/Entropy                 │ -0.032952986657619476  │\n",
       "│ Train/KL                      │ 0.01137428730726242    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.003252387046814      │\n",
       "│ Train/PolicyRatio/Min         │ 1.003252387046814      │\n",
       "│ Train/PolicyRatio/Max         │ 1.003252387046814      │\n",
       "│ Train/PolicyRatio/Std         │ 0.016972148790955544   │\n",
       "│ Train/LR                      │ 0.00011280000035185367 │\n",
       "│ Train/PolicyStd               │ 0.23421624302864075    │\n",
       "│ TotalEnvSteps                 │ 638976.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014278067275881767  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002212059684097767  │\n",
       "│ Value/Adv                     │ 0.056114763021469116   │\n",
       "│ Loss/Loss_reward_critic       │ 0.016234954819083214   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00406576506793499   │\n",
       "│ Value/reward                  │ 1.9902544021606445     │\n",
       "│ Time/Total                    │ 4146.18310546875       │\n",
       "│ Time/Rollout                  │ 10.88131332397461      │\n",
       "│ Time/Update                   │ 1.6784899234771729     │\n",
       "│ Time/Epoch                    │ 12.559846878051758     │\n",
       "│ Time/FPS                      │ 163.059326171875       │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.478267669677734     │\n",
       "│ Metrics/EpCost                │ 56.31999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 311.0                  │\n",
       "│ Train/Entropy                 │ -0.032952986657619476  │\n",
       "│ Train/KL                      │ 0.01137428730726242    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.003252387046814      │\n",
       "│ Train/PolicyRatio/Min         │ 1.003252387046814      │\n",
       "│ Train/PolicyRatio/Max         │ 1.003252387046814      │\n",
       "│ Train/PolicyRatio/Std         │ 0.016972148790955544   │\n",
       "│ Train/LR                      │ 0.00011280000035185367 │\n",
       "│ Train/PolicyStd               │ 0.23421624302864075    │\n",
       "│ TotalEnvSteps                 │ 638976.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014278067275881767  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002212059684097767  │\n",
       "│ Value/Adv                     │ 0.056114763021469116   │\n",
       "│ Loss/Loss_reward_critic       │ 0.016234954819083214   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00406576506793499   │\n",
       "│ Value/reward                  │ 1.9902544021606445     │\n",
       "│ Time/Total                    │ 4146.18310546875       │\n",
       "│ Time/Rollout                  │ 10.88131332397461      │\n",
       "│ Time/Update                   │ 1.6784899234771729     │\n",
       "│ Time/Epoch                    │ 12.559846878051758     │\n",
       "│ Time/FPS                      │ 163.059326171875       │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.79918670654297      │\n",
       "│ Metrics/EpCost                │ 57.279998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 312.0                  │\n",
       "│ Train/Entropy                 │ -0.040055349469184875  │\n",
       "│ Train/KL                      │ 0.012222613207995892   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9993264079093933     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9993264079093933     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9993264079093933     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01587517186999321    │\n",
       "│ Train/LR                      │ 0.00011220000305911526 │\n",
       "│ Train/PolicyStd               │ 0.2325679063796997     │\n",
       "│ TotalEnvSteps                 │ 641024.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013987111859023571  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00029095541685819626 │\n",
       "│ Value/Adv                     │ 0.20803050696849823    │\n",
       "│ Loss/Loss_reward_critic       │ 0.019139455631375313   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002904500812292099   │\n",
       "│ Value/reward                  │ 2.1316447257995605     │\n",
       "│ Time/Total                    │ 4158.79638671875       │\n",
       "│ Time/Rollout                  │ 10.88879680633545      │\n",
       "│ Time/Update                   │ 1.7128210067749023     │\n",
       "│ Time/Epoch                    │ 12.601679801940918     │\n",
       "│ Time/FPS                      │ 162.51803588867188     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.79918670654297      │\n",
       "│ Metrics/EpCost                │ 57.279998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 312.0                  │\n",
       "│ Train/Entropy                 │ -0.040055349469184875  │\n",
       "│ Train/KL                      │ 0.012222613207995892   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9993264079093933     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9993264079093933     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9993264079093933     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01587517186999321    │\n",
       "│ Train/LR                      │ 0.00011220000305911526 │\n",
       "│ Train/PolicyStd               │ 0.2325679063796997     │\n",
       "│ TotalEnvSteps                 │ 641024.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013987111859023571  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00029095541685819626 │\n",
       "│ Value/Adv                     │ 0.20803050696849823    │\n",
       "│ Loss/Loss_reward_critic       │ 0.019139455631375313   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002904500812292099   │\n",
       "│ Value/reward                  │ 2.1316447257995605     │\n",
       "│ Time/Total                    │ 4158.79638671875       │\n",
       "│ Time/Rollout                  │ 10.88879680633545      │\n",
       "│ Time/Update                   │ 1.7128210067749023     │\n",
       "│ Time/Epoch                    │ 12.601679801940918     │\n",
       "│ Time/FPS                      │ 162.51803588867188     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.87114143371582      │\n",
       "│ Metrics/EpCost                │ 56.31999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 313.0                  │\n",
       "│ Train/Entropy                 │ -0.04196067899465561   │\n",
       "│ Train/KL                      │ 0.016865206882357597   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9972127676010132     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9972127676010132     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9972127676010132     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01852293685078621    │\n",
       "│ Train/LR                      │ 0.00011159999849041924 │\n",
       "│ Train/PolicyStd               │ 0.23210224509239197    │\n",
       "│ TotalEnvSteps                 │ 643072.0               │\n",
       "│ Loss/Loss_pi                  │ -0.0176901463419199    │\n",
       "│ Loss/Loss_pi/Delta            │ -0.003703034482896328  │\n",
       "│ Value/Adv                     │ 0.0066704172641038895  │\n",
       "│ Loss/Loss_reward_critic       │ 0.021809983998537064   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002670528367161751   │\n",
       "│ Value/reward                  │ 2.221076250076294      │\n",
       "│ Time/Total                    │ 4171.3671875           │\n",
       "│ Time/Rollout                  │ 10.862273216247559     │\n",
       "│ Time/Update                   │ 1.6970477104187012     │\n",
       "│ Time/Epoch                    │ 12.559367179870605     │\n",
       "│ Time/FPS                      │ 163.0655517578125      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.87114143371582      │\n",
       "│ Metrics/EpCost                │ 56.31999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 313.0                  │\n",
       "│ Train/Entropy                 │ -0.04196067899465561   │\n",
       "│ Train/KL                      │ 0.016865206882357597   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9972127676010132     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9972127676010132     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9972127676010132     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01852293685078621    │\n",
       "│ Train/LR                      │ 0.00011159999849041924 │\n",
       "│ Train/PolicyStd               │ 0.23210224509239197    │\n",
       "│ TotalEnvSteps                 │ 643072.0               │\n",
       "│ Loss/Loss_pi                  │ -0.0176901463419199    │\n",
       "│ Loss/Loss_pi/Delta            │ -0.003703034482896328  │\n",
       "│ Value/Adv                     │ 0.0066704172641038895  │\n",
       "│ Loss/Loss_reward_critic       │ 0.021809983998537064   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002670528367161751   │\n",
       "│ Value/reward                  │ 2.221076250076294      │\n",
       "│ Time/Total                    │ 4171.3671875           │\n",
       "│ Time/Rollout                  │ 10.862273216247559     │\n",
       "│ Time/Update                   │ 1.6970477104187012     │\n",
       "│ Time/Epoch                    │ 12.559367179870605     │\n",
       "│ Time/FPS                      │ 163.0655517578125      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.835195541381836     │\n",
       "│ Metrics/EpCost                │ 57.20000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 314.0                  │\n",
       "│ Train/Entropy                 │ -0.044134825468063354  │\n",
       "│ Train/KL                      │ 0.018266094848513603   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9958587884902954     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9958587884902954     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9958587884902954     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01872694119811058    │\n",
       "│ Train/LR                      │ 0.00011100000119768083 │\n",
       "│ Train/PolicyStd               │ 0.23160529136657715    │\n",
       "│ TotalEnvSteps                 │ 645120.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015424391254782677  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0022657550871372223  │\n",
       "│ Value/Adv                     │ -0.0454285591840744    │\n",
       "│ Loss/Loss_reward_critic       │ 0.022260939702391624   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00045095570385456085 │\n",
       "│ Value/reward                  │ 2.201336622238159      │\n",
       "│ Time/Total                    │ 4184.0302734375        │\n",
       "│ Time/Rollout                  │ 10.903204917907715     │\n",
       "│ Time/Update                   │ 1.7481155395507812     │\n",
       "│ Time/Epoch                    │ 12.6513671875          │\n",
       "│ Time/FPS                      │ 161.87974548339844     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.835195541381836     │\n",
       "│ Metrics/EpCost                │ 57.20000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 314.0                  │\n",
       "│ Train/Entropy                 │ -0.044134825468063354  │\n",
       "│ Train/KL                      │ 0.018266094848513603   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9958587884902954     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9958587884902954     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9958587884902954     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01872694119811058    │\n",
       "│ Train/LR                      │ 0.00011100000119768083 │\n",
       "│ Train/PolicyStd               │ 0.23160529136657715    │\n",
       "│ TotalEnvSteps                 │ 645120.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015424391254782677  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0022657550871372223  │\n",
       "│ Value/Adv                     │ -0.0454285591840744    │\n",
       "│ Loss/Loss_reward_critic       │ 0.022260939702391624   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00045095570385456085 │\n",
       "│ Value/reward                  │ 2.201336622238159      │\n",
       "│ Time/Total                    │ 4184.0302734375        │\n",
       "│ Time/Rollout                  │ 10.903204917907715     │\n",
       "│ Time/Update                   │ 1.7481155395507812     │\n",
       "│ Time/Epoch                    │ 12.6513671875          │\n",
       "│ Time/FPS                      │ 161.87974548339844     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.79473876953125      │\n",
       "│ Metrics/EpCost                │ 58.86000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 315.0                  │\n",
       "│ Train/Entropy                 │ -0.05013632774353027   │\n",
       "│ Train/KL                      │ 0.015802690759301186   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0004360675811768     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0004360675811768     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0004360675811768     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017617039382457733   │\n",
       "│ Train/LR                      │ 0.00011039999662898481 │\n",
       "│ Train/PolicyStd               │ 0.23024389147758484    │\n",
       "│ TotalEnvSteps                 │ 647168.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017432982102036476  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0020085908472537994 │\n",
       "│ Value/Adv                     │ -0.0010129697620868683 │\n",
       "│ Loss/Loss_reward_critic       │ 0.01837870106101036    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0038822386413812637 │\n",
       "│ Value/reward                  │ 2.1280927658081055     │\n",
       "│ Time/Total                    │ 4196.603515625         │\n",
       "│ Time/Rollout                  │ 10.842907905578613     │\n",
       "│ Time/Update                   │ 1.7185332775115967     │\n",
       "│ Time/Epoch                    │ 12.561487197875977     │\n",
       "│ Time/FPS                      │ 163.03802490234375     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.79473876953125      │\n",
       "│ Metrics/EpCost                │ 58.86000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 315.0                  │\n",
       "│ Train/Entropy                 │ -0.05013632774353027   │\n",
       "│ Train/KL                      │ 0.015802690759301186   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0004360675811768     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0004360675811768     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0004360675811768     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017617039382457733   │\n",
       "│ Train/LR                      │ 0.00011039999662898481 │\n",
       "│ Train/PolicyStd               │ 0.23024389147758484    │\n",
       "│ TotalEnvSteps                 │ 647168.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017432982102036476  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0020085908472537994 │\n",
       "│ Value/Adv                     │ -0.0010129697620868683 │\n",
       "│ Loss/Loss_reward_critic       │ 0.01837870106101036    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0038822386413812637 │\n",
       "│ Value/reward                  │ 2.1280927658081055     │\n",
       "│ Time/Total                    │ 4196.603515625         │\n",
       "│ Time/Rollout                  │ 10.842907905578613     │\n",
       "│ Time/Update                   │ 1.7185332775115967     │\n",
       "│ Time/Epoch                    │ 12.561487197875977     │\n",
       "│ Time/FPS                      │ 163.03802490234375     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.695951461791992    │\n",
       "│ Metrics/EpCost                │ 57.84000015258789     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 316.0                 │\n",
       "│ Train/Entropy                 │ -0.052822839468717575 │\n",
       "│ Train/KL                      │ 0.01370379701256752   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9984567761421204    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9984567761421204    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9984567761421204    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01822369173169136   │\n",
       "│ Train/LR                      │ 0.0001097999993362464 │\n",
       "│ Train/PolicyStd               │ 0.22962801158428192   │\n",
       "│ TotalEnvSteps                 │ 649216.0              │\n",
       "│ Loss/Loss_pi                  │ -0.013640901073813438 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0037920810282230377 │\n",
       "│ Value/Adv                     │ -0.015134043991565704 │\n",
       "│ Loss/Loss_reward_critic       │ 0.021132400259375572  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0027536991983652115 │\n",
       "│ Value/reward                  │ 2.116185188293457     │\n",
       "│ Time/Total                    │ 4209.20068359375      │\n",
       "│ Time/Rollout                  │ 10.897704124450684    │\n",
       "│ Time/Update                   │ 1.6877365112304688    │\n",
       "│ Time/Epoch                    │ 12.585488319396973    │\n",
       "│ Time/FPS                      │ 162.72711181640625    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.695951461791992    │\n",
       "│ Metrics/EpCost                │ 57.84000015258789     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 316.0                 │\n",
       "│ Train/Entropy                 │ -0.052822839468717575 │\n",
       "│ Train/KL                      │ 0.01370379701256752   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9984567761421204    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9984567761421204    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9984567761421204    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01822369173169136   │\n",
       "│ Train/LR                      │ 0.0001097999993362464 │\n",
       "│ Train/PolicyStd               │ 0.22962801158428192   │\n",
       "│ TotalEnvSteps                 │ 649216.0              │\n",
       "│ Loss/Loss_pi                  │ -0.013640901073813438 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0037920810282230377 │\n",
       "│ Value/Adv                     │ -0.015134043991565704 │\n",
       "│ Loss/Loss_reward_critic       │ 0.021132400259375572  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0027536991983652115 │\n",
       "│ Value/reward                  │ 2.116185188293457     │\n",
       "│ Time/Total                    │ 4209.20068359375      │\n",
       "│ Time/Rollout                  │ 10.897704124450684    │\n",
       "│ Time/Update                   │ 1.6877365112304688    │\n",
       "│ Time/Epoch                    │ 12.585488319396973    │\n",
       "│ Time/FPS                      │ 162.72711181640625    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.693532943725586     │\n",
       "│ Metrics/EpCost                │ 59.279998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 317.0                  │\n",
       "│ Train/Entropy                 │ -0.05694938451051712   │\n",
       "│ Train/KL                      │ 0.017816239967942238   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9942207336425781     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9942207336425781     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9942207336425781     │\n",
       "│ Train/PolicyRatio/Std         │ 0.022015459835529327   │\n",
       "│ Train/LR                      │ 0.00010920000204350799 │\n",
       "│ Train/PolicyStd               │ 0.22867245972156525    │\n",
       "│ TotalEnvSteps                 │ 651264.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01935272291302681   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.005711821839213371  │\n",
       "│ Value/Adv                     │ 0.03677251935005188    │\n",
       "│ Loss/Loss_reward_critic       │ 0.023874441161751747   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002742040902376175   │\n",
       "│ Value/reward                  │ 2.193974256515503      │\n",
       "│ Time/Total                    │ 4221.82958984375       │\n",
       "│ Time/Rollout                  │ 10.892281532287598     │\n",
       "│ Time/Update                   │ 1.7253353595733643     │\n",
       "│ Time/Epoch                    │ 12.61766242980957      │\n",
       "│ Time/FPS                      │ 162.31216430664062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.693532943725586     │\n",
       "│ Metrics/EpCost                │ 59.279998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 317.0                  │\n",
       "│ Train/Entropy                 │ -0.05694938451051712   │\n",
       "│ Train/KL                      │ 0.017816239967942238   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9942207336425781     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9942207336425781     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9942207336425781     │\n",
       "│ Train/PolicyRatio/Std         │ 0.022015459835529327   │\n",
       "│ Train/LR                      │ 0.00010920000204350799 │\n",
       "│ Train/PolicyStd               │ 0.22867245972156525    │\n",
       "│ TotalEnvSteps                 │ 651264.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01935272291302681   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.005711821839213371  │\n",
       "│ Value/Adv                     │ 0.03677251935005188    │\n",
       "│ Loss/Loss_reward_critic       │ 0.023874441161751747   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002742040902376175   │\n",
       "│ Value/reward                  │ 2.193974256515503      │\n",
       "│ Time/Total                    │ 4221.82958984375       │\n",
       "│ Time/Rollout                  │ 10.892281532287598     │\n",
       "│ Time/Update                   │ 1.7253353595733643     │\n",
       "│ Time/Epoch                    │ 12.61766242980957      │\n",
       "│ Time/FPS                      │ 162.31216430664062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.76583480834961      │\n",
       "│ Metrics/EpCost                │ 55.959999084472656     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 318.0                  │\n",
       "│ Train/Entropy                 │ -0.0621412992477417    │\n",
       "│ Train/KL                      │ 0.014078246429562569   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9981857538223267     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9981857538223267     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9981857538223267     │\n",
       "│ Train/PolicyRatio/Std         │ 0.0184247437864542     │\n",
       "│ Train/LR                      │ 0.00010859999747481197 │\n",
       "│ Train/PolicyStd               │ 0.22748783230781555    │\n",
       "│ TotalEnvSteps                 │ 653312.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018996791914105415  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00035593099892139435 │\n",
       "│ Value/Adv                     │ -0.04748861491680145   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01886528916656971    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005009151995182037  │\n",
       "│ Value/reward                  │ 2.248711585998535      │\n",
       "│ Time/Total                    │ 4234.3203125           │\n",
       "│ Time/Rollout                  │ 10.789921760559082     │\n",
       "│ Time/Update                   │ 1.688934326171875      │\n",
       "│ Time/Epoch                    │ 12.47890853881836      │\n",
       "│ Time/FPS                      │ 164.116943359375       │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.76583480834961      │\n",
       "│ Metrics/EpCost                │ 55.959999084472656     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 318.0                  │\n",
       "│ Train/Entropy                 │ -0.0621412992477417    │\n",
       "│ Train/KL                      │ 0.014078246429562569   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9981857538223267     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9981857538223267     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9981857538223267     │\n",
       "│ Train/PolicyRatio/Std         │ 0.0184247437864542     │\n",
       "│ Train/LR                      │ 0.00010859999747481197 │\n",
       "│ Train/PolicyStd               │ 0.22748783230781555    │\n",
       "│ TotalEnvSteps                 │ 653312.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018996791914105415  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00035593099892139435 │\n",
       "│ Value/Adv                     │ -0.04748861491680145   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01886528916656971    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005009151995182037  │\n",
       "│ Value/reward                  │ 2.248711585998535      │\n",
       "│ Time/Total                    │ 4234.3203125           │\n",
       "│ Time/Rollout                  │ 10.789921760559082     │\n",
       "│ Time/Update                   │ 1.688934326171875      │\n",
       "│ Time/Epoch                    │ 12.47890853881836      │\n",
       "│ Time/FPS                      │ 164.116943359375       │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.70649528503418      │\n",
       "│ Metrics/EpCost                │ 53.08000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 319.0                  │\n",
       "│ Train/Entropy                 │ -0.06625136733055115   │\n",
       "│ Train/KL                      │ 0.01615353301167488    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0041463375091553     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0041463375091553     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0041463375091553     │\n",
       "│ Train/PolicyRatio/Std         │ 0.021047724410891533   │\n",
       "│ Train/LR                      │ 0.00010800000018207356 │\n",
       "│ Train/PolicyStd               │ 0.2265397310256958     │\n",
       "│ TotalEnvSteps                 │ 655360.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018217291682958603  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0007795002311468124  │\n",
       "│ Value/Adv                     │ 0.008591016754508018   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02019343711435795    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0013281479477882385  │\n",
       "│ Value/reward                  │ 2.2458930015563965     │\n",
       "│ Time/Total                    │ 4246.875               │\n",
       "│ Time/Rollout                  │ 10.778973579406738     │\n",
       "│ Time/Update                   │ 1.7636590003967285     │\n",
       "│ Time/Epoch                    │ 12.542675018310547     │\n",
       "│ Time/FPS                      │ 163.28256225585938     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.70649528503418      │\n",
       "│ Metrics/EpCost                │ 53.08000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 319.0                  │\n",
       "│ Train/Entropy                 │ -0.06625136733055115   │\n",
       "│ Train/KL                      │ 0.01615353301167488    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0041463375091553     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0041463375091553     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0041463375091553     │\n",
       "│ Train/PolicyRatio/Std         │ 0.021047724410891533   │\n",
       "│ Train/LR                      │ 0.00010800000018207356 │\n",
       "│ Train/PolicyStd               │ 0.2265397310256958     │\n",
       "│ TotalEnvSteps                 │ 655360.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018217291682958603  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0007795002311468124  │\n",
       "│ Value/Adv                     │ 0.008591016754508018   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02019343711435795    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0013281479477882385  │\n",
       "│ Value/reward                  │ 2.2458930015563965     │\n",
       "│ Time/Total                    │ 4246.875               │\n",
       "│ Time/Rollout                  │ 10.778973579406738     │\n",
       "│ Time/Update                   │ 1.7636590003967285     │\n",
       "│ Time/Epoch                    │ 12.542675018310547     │\n",
       "│ Time/FPS                      │ 163.28256225585938     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.734533309936523      │\n",
       "│ Metrics/EpCost                │ 52.97999954223633       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 320.0                   │\n",
       "│ Train/Entropy                 │ -0.06816992908716202    │\n",
       "│ Train/KL                      │ 0.016905955970287323    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9985470771789551      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9985470771789551      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9985470771789551      │\n",
       "│ Train/PolicyRatio/Std         │ 0.020726561546325684    │\n",
       "│ Train/LR                      │ 0.00010740000288933516  │\n",
       "│ Train/PolicyStd               │ 0.2261015921831131      │\n",
       "│ TotalEnvSteps                 │ 657408.0                │\n",
       "│ Loss/Loss_pi                  │ -0.018452709540724754   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00023541785776615143 │\n",
       "│ Value/Adv                     │ -0.12656137347221375    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02471752092242241     │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004524083808064461    │\n",
       "│ Value/reward                  │ 2.2464325428009033      │\n",
       "│ Time/Total                    │ 4259.39111328125        │\n",
       "│ Time/Rollout                  │ 10.813302040100098      │\n",
       "│ Time/Update                   │ 1.6889760494232178      │\n",
       "│ Time/Epoch                    │ 12.502321243286133      │\n",
       "│ Time/FPS                      │ 163.80958557128906      │\n",
       "└───────────────────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.734533309936523      │\n",
       "│ Metrics/EpCost                │ 52.97999954223633       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 320.0                   │\n",
       "│ Train/Entropy                 │ -0.06816992908716202    │\n",
       "│ Train/KL                      │ 0.016905955970287323    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9985470771789551      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9985470771789551      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9985470771789551      │\n",
       "│ Train/PolicyRatio/Std         │ 0.020726561546325684    │\n",
       "│ Train/LR                      │ 0.00010740000288933516  │\n",
       "│ Train/PolicyStd               │ 0.2261015921831131      │\n",
       "│ TotalEnvSteps                 │ 657408.0                │\n",
       "│ Loss/Loss_pi                  │ -0.018452709540724754   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00023541785776615143 │\n",
       "│ Value/Adv                     │ -0.12656137347221375    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02471752092242241     │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004524083808064461    │\n",
       "│ Value/reward                  │ 2.2464325428009033      │\n",
       "│ Time/Total                    │ 4259.39111328125        │\n",
       "│ Time/Rollout                  │ 10.813302040100098      │\n",
       "│ Time/Update                   │ 1.6889760494232178      │\n",
       "│ Time/Epoch                    │ 12.502321243286133      │\n",
       "│ Time/FPS                      │ 163.80958557128906      │\n",
       "└───────────────────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.78191375732422      │\n",
       "│ Metrics/EpCost                │ 52.040000915527344     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 321.0                  │\n",
       "│ Train/Entropy                 │ -0.0695536807179451    │\n",
       "│ Train/KL                      │ 0.015059312805533409   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9997164607048035     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9997164607048035     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9997164607048035     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017099954187870026   │\n",
       "│ Train/LR                      │ 0.00010679999832063913 │\n",
       "│ Train/PolicyStd               │ 0.22580066323280334    │\n",
       "│ TotalEnvSteps                 │ 659456.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012811578810214996  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005641130730509758   │\n",
       "│ Value/Adv                     │ -0.022727586328983307  │\n",
       "│ Loss/Loss_reward_critic       │ 0.019476009532809258   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0052415113896131516 │\n",
       "│ Value/reward                  │ 2.221082925796509      │\n",
       "│ Time/Total                    │ 4271.91552734375       │\n",
       "│ Time/Rollout                  │ 10.82210922241211      │\n",
       "│ Time/Update                   │ 1.6910204887390137     │\n",
       "│ Time/Epoch                    │ 12.513174057006836     │\n",
       "│ Time/FPS                      │ 163.66751098632812     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 19.78191375732422      │\n",
       "│ Metrics/EpCost                │ 52.040000915527344     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 321.0                  │\n",
       "│ Train/Entropy                 │ -0.0695536807179451    │\n",
       "│ Train/KL                      │ 0.015059312805533409   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9997164607048035     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9997164607048035     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9997164607048035     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017099954187870026   │\n",
       "│ Train/LR                      │ 0.00010679999832063913 │\n",
       "│ Train/PolicyStd               │ 0.22580066323280334    │\n",
       "│ TotalEnvSteps                 │ 659456.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012811578810214996  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005641130730509758   │\n",
       "│ Value/Adv                     │ -0.022727586328983307  │\n",
       "│ Loss/Loss_reward_critic       │ 0.019476009532809258   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0052415113896131516 │\n",
       "│ Value/reward                  │ 2.221082925796509      │\n",
       "│ Time/Total                    │ 4271.91552734375       │\n",
       "│ Time/Rollout                  │ 10.82210922241211      │\n",
       "│ Time/Update                   │ 1.6910204887390137     │\n",
       "│ Time/Epoch                    │ 12.513174057006836     │\n",
       "│ Time/FPS                      │ 163.66751098632812     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.255109786987305     │\n",
       "│ Metrics/EpCost                │ 52.439998626708984     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 322.0                  │\n",
       "│ Train/Entropy                 │ -0.0718541368842125    │\n",
       "│ Train/KL                      │ 0.015603977255523205   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9997134208679199     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9997134208679199     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9997134208679199     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018525773659348488   │\n",
       "│ Train/LR                      │ 0.00010620000102790073 │\n",
       "│ Train/PolicyStd               │ 0.22529101371765137    │\n",
       "│ TotalEnvSteps                 │ 661504.0               │\n",
       "│ Loss/Loss_pi                  │ -0.019924983382225037  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00711340457201004   │\n",
       "│ Value/Adv                     │ -0.261318564414978     │\n",
       "│ Loss/Loss_reward_critic       │ 0.015906570479273796   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0035694390535354614 │\n",
       "│ Value/reward                  │ 2.3354077339172363     │\n",
       "│ Time/Total                    │ 4284.4296875           │\n",
       "│ Time/Rollout                  │ 10.816569328308105     │\n",
       "│ Time/Update                   │ 1.685990810394287      │\n",
       "│ Time/Epoch                    │ 12.502603530883789     │\n",
       "│ Time/FPS                      │ 163.80589294433594     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.255109786987305     │\n",
       "│ Metrics/EpCost                │ 52.439998626708984     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 322.0                  │\n",
       "│ Train/Entropy                 │ -0.0718541368842125    │\n",
       "│ Train/KL                      │ 0.015603977255523205   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9997134208679199     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9997134208679199     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9997134208679199     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018525773659348488   │\n",
       "│ Train/LR                      │ 0.00010620000102790073 │\n",
       "│ Train/PolicyStd               │ 0.22529101371765137    │\n",
       "│ TotalEnvSteps                 │ 661504.0               │\n",
       "│ Loss/Loss_pi                  │ -0.019924983382225037  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00711340457201004   │\n",
       "│ Value/Adv                     │ -0.261318564414978     │\n",
       "│ Loss/Loss_reward_critic       │ 0.015906570479273796   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0035694390535354614 │\n",
       "│ Value/reward                  │ 2.3354077339172363     │\n",
       "│ Time/Total                    │ 4284.4296875           │\n",
       "│ Time/Rollout                  │ 10.816569328308105     │\n",
       "│ Time/Update                   │ 1.685990810394287      │\n",
       "│ Time/Epoch                    │ 12.502603530883789     │\n",
       "│ Time/FPS                      │ 163.80589294433594     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m10\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.226354598999023    │\n",
       "│ Metrics/EpCost                │ 53.15999984741211     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 323.0                 │\n",
       "│ Train/Entropy                 │ -0.07668955624103546  │\n",
       "│ Train/KL                      │ 0.020412197336554527  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9960392117500305    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9960392117500305    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9960392117500305    │\n",
       "│ Train/PolicyRatio/Std         │ 0.02058115415275097   │\n",
       "│ Train/LR                      │ 0.0001055999964592047 │\n",
       "│ Train/PolicyStd               │ 0.22420358657836914   │\n",
       "│ TotalEnvSteps                 │ 663552.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01805119775235653  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0018737856298685074 │\n",
       "│ Value/Adv                     │ 0.05440074950456619   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01797686703503132   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0020702965557575226 │\n",
       "│ Value/reward                  │ 2.2951879501342773    │\n",
       "│ Time/Total                    │ 4297.056640625        │\n",
       "│ Time/Rollout                  │ 10.900404930114746    │\n",
       "│ Time/Update                   │ 1.714787483215332     │\n",
       "│ Time/Epoch                    │ 12.615235328674316    │\n",
       "│ Time/FPS                      │ 162.34339904785156    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.226354598999023    │\n",
       "│ Metrics/EpCost                │ 53.15999984741211     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 323.0                 │\n",
       "│ Train/Entropy                 │ -0.07668955624103546  │\n",
       "│ Train/KL                      │ 0.020412197336554527  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9960392117500305    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9960392117500305    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9960392117500305    │\n",
       "│ Train/PolicyRatio/Std         │ 0.02058115415275097   │\n",
       "│ Train/LR                      │ 0.0001055999964592047 │\n",
       "│ Train/PolicyStd               │ 0.22420358657836914   │\n",
       "│ TotalEnvSteps                 │ 663552.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01805119775235653  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0018737856298685074 │\n",
       "│ Value/Adv                     │ 0.05440074950456619   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01797686703503132   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0020702965557575226 │\n",
       "│ Value/reward                  │ 2.2951879501342773    │\n",
       "│ Time/Total                    │ 4297.056640625        │\n",
       "│ Time/Rollout                  │ 10.900404930114746    │\n",
       "│ Time/Update                   │ 1.714787483215332     │\n",
       "│ Time/Epoch                    │ 12.615235328674316    │\n",
       "│ Time/FPS                      │ 162.34339904785156    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.188488006591797    │\n",
       "│ Metrics/EpCost                │ 53.97999954223633     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 324.0                 │\n",
       "│ Train/Entropy                 │ -0.08249306678771973  │\n",
       "│ Train/KL                      │ 0.015721939504146576  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9952337145805359    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9952337145805359    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9952337145805359    │\n",
       "│ Train/PolicyRatio/Std         │ 0.02020876295864582   │\n",
       "│ Train/LR                      │ 0.0001049999991664663 │\n",
       "│ Train/PolicyStd               │ 0.22291460633277893   │\n",
       "│ TotalEnvSteps                 │ 665600.0              │\n",
       "│ Loss/Loss_pi                  │ -0.015624386258423328 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002426811493933201  │\n",
       "│ Value/Adv                     │ -0.2200213074684143   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01839585043489933   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0004189833998680115 │\n",
       "│ Value/reward                  │ 2.176025867462158     │\n",
       "│ Time/Total                    │ 4309.55517578125      │\n",
       "│ Time/Rollout                  │ 10.799898147583008    │\n",
       "│ Time/Update                   │ 1.6869850158691406    │\n",
       "│ Time/Epoch                    │ 12.48692798614502     │\n",
       "│ Time/FPS                      │ 164.0115203857422     │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.188488006591797    │\n",
       "│ Metrics/EpCost                │ 53.97999954223633     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 324.0                 │\n",
       "│ Train/Entropy                 │ -0.08249306678771973  │\n",
       "│ Train/KL                      │ 0.015721939504146576  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9952337145805359    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9952337145805359    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9952337145805359    │\n",
       "│ Train/PolicyRatio/Std         │ 0.02020876295864582   │\n",
       "│ Train/LR                      │ 0.0001049999991664663 │\n",
       "│ Train/PolicyStd               │ 0.22291460633277893   │\n",
       "│ TotalEnvSteps                 │ 665600.0              │\n",
       "│ Loss/Loss_pi                  │ -0.015624386258423328 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002426811493933201  │\n",
       "│ Value/Adv                     │ -0.2200213074684143   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01839585043489933   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0004189833998680115 │\n",
       "│ Value/reward                  │ 2.176025867462158     │\n",
       "│ Time/Total                    │ 4309.55517578125      │\n",
       "│ Time/Rollout                  │ 10.799898147583008    │\n",
       "│ Time/Update                   │ 1.6869850158691406    │\n",
       "│ Time/Epoch                    │ 12.48692798614502     │\n",
       "│ Time/FPS                      │ 164.0115203857422     │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.20071792602539      │\n",
       "│ Metrics/EpCost                │ 53.47999954223633      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 325.0                  │\n",
       "│ Train/Entropy                 │ -0.0846305713057518    │\n",
       "│ Train/KL                      │ 0.018693823367357254   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9904265403747559     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9904265403747559     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9904265403747559     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01935541443526745    │\n",
       "│ Train/LR                      │ 0.00010440000187372789 │\n",
       "│ Train/PolicyStd               │ 0.2224484384059906     │\n",
       "│ TotalEnvSteps                 │ 667648.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01464774738997221   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0009766388684511185  │\n",
       "│ Value/Adv                     │ 0.2132297307252884     │\n",
       "│ Loss/Loss_reward_critic       │ 0.013799396343529224   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.004596454091370106  │\n",
       "│ Value/reward                  │ 2.261695384979248      │\n",
       "│ Time/Total                    │ 4322.04638671875       │\n",
       "│ Time/Rollout                  │ 10.794487953186035     │\n",
       "│ Time/Update                   │ 1.6842989921569824     │\n",
       "│ Time/Epoch                    │ 12.47883129119873      │\n",
       "│ Time/FPS                      │ 164.11795043945312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.20071792602539      │\n",
       "│ Metrics/EpCost                │ 53.47999954223633      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 325.0                  │\n",
       "│ Train/Entropy                 │ -0.0846305713057518    │\n",
       "│ Train/KL                      │ 0.018693823367357254   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9904265403747559     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9904265403747559     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9904265403747559     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01935541443526745    │\n",
       "│ Train/LR                      │ 0.00010440000187372789 │\n",
       "│ Train/PolicyStd               │ 0.2224484384059906     │\n",
       "│ TotalEnvSteps                 │ 667648.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01464774738997221   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0009766388684511185  │\n",
       "│ Value/Adv                     │ 0.2132297307252884     │\n",
       "│ Loss/Loss_reward_critic       │ 0.013799396343529224   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.004596454091370106  │\n",
       "│ Value/reward                  │ 2.261695384979248      │\n",
       "│ Time/Total                    │ 4322.04638671875       │\n",
       "│ Time/Rollout                  │ 10.794487953186035     │\n",
       "│ Time/Update                   │ 1.6842989921569824     │\n",
       "│ Time/Epoch                    │ 12.47883129119873      │\n",
       "│ Time/FPS                      │ 164.11795043945312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m9\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.65630340576172      │\n",
       "│ Metrics/EpCost                │ 54.7599983215332       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 326.0                  │\n",
       "│ Train/Entropy                 │ -0.08776196837425232   │\n",
       "│ Train/KL                      │ 0.020185859873890877   │\n",
       "│ Train/StopIter                │ 9.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9959723353385925     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9959723353385925     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9959723353385925     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020445987582206726   │\n",
       "│ Train/LR                      │ 0.00010379999730503187 │\n",
       "│ Train/PolicyStd               │ 0.22175878286361694    │\n",
       "│ TotalEnvSteps                 │ 669696.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017585985362529755  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0029382379725575447 │\n",
       "│ Value/Adv                     │ 0.10793248564004898    │\n",
       "│ Loss/Loss_reward_critic       │ 0.015779534354805946   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.001980138011276722   │\n",
       "│ Value/reward                  │ 2.2673161029815674     │\n",
       "│ Time/Total                    │ 4334.419921875         │\n",
       "│ Time/Rollout                  │ 10.826009750366211     │\n",
       "│ Time/Update                   │ 1.5357985496520996     │\n",
       "│ Time/Epoch                    │ 12.361854553222656     │\n",
       "│ Time/FPS                      │ 165.6709442138672      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.65630340576172      │\n",
       "│ Metrics/EpCost                │ 54.7599983215332       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 326.0                  │\n",
       "│ Train/Entropy                 │ -0.08776196837425232   │\n",
       "│ Train/KL                      │ 0.020185859873890877   │\n",
       "│ Train/StopIter                │ 9.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9959723353385925     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9959723353385925     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9959723353385925     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020445987582206726   │\n",
       "│ Train/LR                      │ 0.00010379999730503187 │\n",
       "│ Train/PolicyStd               │ 0.22175878286361694    │\n",
       "│ TotalEnvSteps                 │ 669696.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017585985362529755  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0029382379725575447 │\n",
       "│ Value/Adv                     │ 0.10793248564004898    │\n",
       "│ Loss/Loss_reward_critic       │ 0.015779534354805946   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.001980138011276722   │\n",
       "│ Value/reward                  │ 2.2673161029815674     │\n",
       "│ Time/Total                    │ 4334.419921875         │\n",
       "│ Time/Rollout                  │ 10.826009750366211     │\n",
       "│ Time/Update                   │ 1.5357985496520996     │\n",
       "│ Time/Epoch                    │ 12.361854553222656     │\n",
       "│ Time/FPS                      │ 165.6709442138672      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.782543182373047     │\n",
       "│ Metrics/EpCost                │ 54.58000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 327.0                  │\n",
       "│ Train/Entropy                 │ -0.09075827151536942   │\n",
       "│ Train/KL                      │ 0.01590024121105671    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9994408488273621     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9994408488273621     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9994408488273621     │\n",
       "│ Train/PolicyRatio/Std         │ 0.0191997941583395     │\n",
       "│ Train/LR                      │ 0.00010320000001229346 │\n",
       "│ Train/PolicyStd               │ 0.2210879623889923     │\n",
       "│ TotalEnvSteps                 │ 671744.0               │\n",
       "│ Loss/Loss_pi                  │ -0.021225551143288612  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0036395657807588577 │\n",
       "│ Value/Adv                     │ 0.03561318665742874    │\n",
       "│ Loss/Loss_reward_critic       │ 0.009120987728238106   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.006658546626567841  │\n",
       "│ Value/reward                  │ 2.2105953693389893     │\n",
       "│ Time/Total                    │ 4346.92138671875       │\n",
       "│ Time/Rollout                  │ 10.79907512664795      │\n",
       "│ Time/Update                   │ 1.6909940242767334     │\n",
       "│ Time/Epoch                    │ 12.490116119384766     │\n",
       "│ Time/FPS                      │ 163.96966552734375     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.782543182373047     │\n",
       "│ Metrics/EpCost                │ 54.58000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 327.0                  │\n",
       "│ Train/Entropy                 │ -0.09075827151536942   │\n",
       "│ Train/KL                      │ 0.01590024121105671    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9994408488273621     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9994408488273621     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9994408488273621     │\n",
       "│ Train/PolicyRatio/Std         │ 0.0191997941583395     │\n",
       "│ Train/LR                      │ 0.00010320000001229346 │\n",
       "│ Train/PolicyStd               │ 0.2210879623889923     │\n",
       "│ TotalEnvSteps                 │ 671744.0               │\n",
       "│ Loss/Loss_pi                  │ -0.021225551143288612  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0036395657807588577 │\n",
       "│ Value/Adv                     │ 0.03561318665742874    │\n",
       "│ Loss/Loss_reward_critic       │ 0.009120987728238106   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.006658546626567841  │\n",
       "│ Value/reward                  │ 2.2105953693389893     │\n",
       "│ Time/Total                    │ 4346.92138671875       │\n",
       "│ Time/Rollout                  │ 10.79907512664795      │\n",
       "│ Time/Update                   │ 1.6909940242767334     │\n",
       "│ Time/Epoch                    │ 12.490116119384766     │\n",
       "│ Time/FPS                      │ 163.96966552734375     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.960124969482422     │\n",
       "│ Metrics/EpCost                │ 55.08000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 328.0                  │\n",
       "│ Train/Entropy                 │ -0.09286759793758392   │\n",
       "│ Train/KL                      │ 0.016667652875185013   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9901607632637024     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9901607632637024     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9901607632637024     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016178328543901443   │\n",
       "│ Train/LR                      │ 0.00010260000271955505 │\n",
       "│ Train/PolicyStd               │ 0.22062170505523682    │\n",
       "│ TotalEnvSteps                 │ 673792.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01617627963423729   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005049271509051323   │\n",
       "│ Value/Adv                     │ 0.0920957401394844     │\n",
       "│ Loss/Loss_reward_critic       │ 0.017280109226703644   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.008159121498465538   │\n",
       "│ Value/reward                  │ 2.24035906791687       │\n",
       "│ Time/Total                    │ 4359.50390625          │\n",
       "│ Time/Rollout                  │ 10.868494033813477     │\n",
       "│ Time/Update                   │ 1.7022664546966553     │\n",
       "│ Time/Epoch                    │ 12.570804595947266     │\n",
       "│ Time/FPS                      │ 162.9171905517578      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.960124969482422     │\n",
       "│ Metrics/EpCost                │ 55.08000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 328.0                  │\n",
       "│ Train/Entropy                 │ -0.09286759793758392   │\n",
       "│ Train/KL                      │ 0.016667652875185013   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9901607632637024     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9901607632637024     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9901607632637024     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016178328543901443   │\n",
       "│ Train/LR                      │ 0.00010260000271955505 │\n",
       "│ Train/PolicyStd               │ 0.22062170505523682    │\n",
       "│ TotalEnvSteps                 │ 673792.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01617627963423729   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005049271509051323   │\n",
       "│ Value/Adv                     │ 0.0920957401394844     │\n",
       "│ Loss/Loss_reward_critic       │ 0.017280109226703644   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.008159121498465538   │\n",
       "│ Value/reward                  │ 2.24035906791687       │\n",
       "│ Time/Total                    │ 4359.50390625          │\n",
       "│ Time/Rollout                  │ 10.868494033813477     │\n",
       "│ Time/Update                   │ 1.7022664546966553     │\n",
       "│ Time/Epoch                    │ 12.570804595947266     │\n",
       "│ Time/FPS                      │ 162.9171905517578      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.745197296142578     │\n",
       "│ Metrics/EpCost                │ 70.0199966430664       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 329.0                  │\n",
       "│ Train/Entropy                 │ -0.09524676203727722   │\n",
       "│ Train/KL                      │ 0.014145120978355408   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0108602046966553     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0108602046966553     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0108602046966553     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018187763169407845   │\n",
       "│ Train/LR                      │ 0.00010199999815085903 │\n",
       "│ Train/PolicyStd               │ 0.22007544338703156    │\n",
       "│ TotalEnvSteps                 │ 675840.0               │\n",
       "│ Loss/Loss_pi                  │ -0.00809120386838913   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00808507576584816    │\n",
       "│ Value/Adv                     │ -0.07548060268163681   │\n",
       "│ Loss/Loss_reward_critic       │ 0.017947979271411896   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.000667870044708252   │\n",
       "│ Value/reward                  │ 2.0746984481811523     │\n",
       "│ Time/Total                    │ 4372.05224609375       │\n",
       "│ Time/Rollout                  │ 10.847640991210938     │\n",
       "│ Time/Update                   │ 1.6895771026611328     │\n",
       "│ Time/Epoch                    │ 12.537261009216309     │\n",
       "│ Time/FPS                      │ 163.3530731201172      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.745197296142578     │\n",
       "│ Metrics/EpCost                │ 70.0199966430664       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 329.0                  │\n",
       "│ Train/Entropy                 │ -0.09524676203727722   │\n",
       "│ Train/KL                      │ 0.014145120978355408   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0108602046966553     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0108602046966553     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0108602046966553     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018187763169407845   │\n",
       "│ Train/LR                      │ 0.00010199999815085903 │\n",
       "│ Train/PolicyStd               │ 0.22007544338703156    │\n",
       "│ TotalEnvSteps                 │ 675840.0               │\n",
       "│ Loss/Loss_pi                  │ -0.00809120386838913   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00808507576584816    │\n",
       "│ Value/Adv                     │ -0.07548060268163681   │\n",
       "│ Loss/Loss_reward_critic       │ 0.017947979271411896   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.000667870044708252   │\n",
       "│ Value/reward                  │ 2.0746984481811523     │\n",
       "│ Time/Total                    │ 4372.05224609375       │\n",
       "│ Time/Rollout                  │ 10.847640991210938     │\n",
       "│ Time/Update                   │ 1.6895771026611328     │\n",
       "│ Time/Epoch                    │ 12.537261009216309     │\n",
       "│ Time/FPS                      │ 163.3530731201172      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.774452209472656     │\n",
       "│ Metrics/EpCost                │ 70.08000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 330.0                  │\n",
       "│ Train/Entropy                 │ -0.09647791087627411   │\n",
       "│ Train/KL                      │ 0.015931332483887672   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0002912282943726     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0002912282943726     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0002912282943726     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01924615167081356    │\n",
       "│ Train/LR                      │ 0.00010140000085812062 │\n",
       "│ Train/PolicyStd               │ 0.21978497505187988    │\n",
       "│ TotalEnvSteps                 │ 677888.0               │\n",
       "│ Loss/Loss_pi                  │ -0.0158679261803627    │\n",
       "│ Loss/Loss_pi/Delta            │ -0.007776722311973572  │\n",
       "│ Value/Adv                     │ -0.06610865890979767   │\n",
       "│ Loss/Loss_reward_critic       │ 0.026553992182016373   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.008606012910604477   │\n",
       "│ Value/reward                  │ 2.161890983581543      │\n",
       "│ Time/Total                    │ 4384.61572265625       │\n",
       "│ Time/Rollout                  │ 10.839223861694336     │\n",
       "│ Time/Update                   │ 1.7105035781860352     │\n",
       "│ Time/Epoch                    │ 12.549772262573242     │\n",
       "│ Time/FPS                      │ 163.19021606445312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.774452209472656     │\n",
       "│ Metrics/EpCost                │ 70.08000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 330.0                  │\n",
       "│ Train/Entropy                 │ -0.09647791087627411   │\n",
       "│ Train/KL                      │ 0.015931332483887672   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0002912282943726     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0002912282943726     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0002912282943726     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01924615167081356    │\n",
       "│ Train/LR                      │ 0.00010140000085812062 │\n",
       "│ Train/PolicyStd               │ 0.21978497505187988    │\n",
       "│ TotalEnvSteps                 │ 677888.0               │\n",
       "│ Loss/Loss_pi                  │ -0.0158679261803627    │\n",
       "│ Loss/Loss_pi/Delta            │ -0.007776722311973572  │\n",
       "│ Value/Adv                     │ -0.06610865890979767   │\n",
       "│ Loss/Loss_reward_critic       │ 0.026553992182016373   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.008606012910604477   │\n",
       "│ Value/reward                  │ 2.161890983581543      │\n",
       "│ Time/Total                    │ 4384.61572265625       │\n",
       "│ Time/Rollout                  │ 10.839223861694336     │\n",
       "│ Time/Update                   │ 1.7105035781860352     │\n",
       "│ Time/Epoch                    │ 12.549772262573242     │\n",
       "│ Time/FPS                      │ 163.19021606445312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.892473220825195     │\n",
       "│ Metrics/EpCost                │ 69.44000244140625      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 331.0                  │\n",
       "│ Train/Entropy                 │ -0.09664081782102585   │\n",
       "│ Train/KL                      │ 0.014229307882487774   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9989005327224731     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9989005327224731     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9989005327224731     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020397033542394638   │\n",
       "│ Train/LR                      │ 0.00010080000356538221 │\n",
       "│ Train/PolicyStd               │ 0.2197590321302414     │\n",
       "│ TotalEnvSteps                 │ 679936.0               │\n",
       "│ Loss/Loss_pi                  │ -0.019231054931879044  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.003363128751516342  │\n",
       "│ Value/Adv                     │ 0.27287957072257996    │\n",
       "│ Loss/Loss_reward_critic       │ 0.028713714331388474   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002159722149372101   │\n",
       "│ Value/reward                  │ 2.1978440284729004     │\n",
       "│ Time/Total                    │ 4397.09716796875       │\n",
       "│ Time/Rollout                  │ 10.786308288574219     │\n",
       "│ Time/Update                   │ 1.68326997756958       │\n",
       "│ Time/Epoch                    │ 12.469622611999512     │\n",
       "│ Time/FPS                      │ 164.2391357421875      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.892473220825195     │\n",
       "│ Metrics/EpCost                │ 69.44000244140625      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 331.0                  │\n",
       "│ Train/Entropy                 │ -0.09664081782102585   │\n",
       "│ Train/KL                      │ 0.014229307882487774   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9989005327224731     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9989005327224731     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9989005327224731     │\n",
       "│ Train/PolicyRatio/Std         │ 0.020397033542394638   │\n",
       "│ Train/LR                      │ 0.00010080000356538221 │\n",
       "│ Train/PolicyStd               │ 0.2197590321302414     │\n",
       "│ TotalEnvSteps                 │ 679936.0               │\n",
       "│ Loss/Loss_pi                  │ -0.019231054931879044  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.003363128751516342  │\n",
       "│ Value/Adv                     │ 0.27287957072257996    │\n",
       "│ Loss/Loss_reward_critic       │ 0.028713714331388474   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002159722149372101   │\n",
       "│ Value/reward                  │ 2.1978440284729004     │\n",
       "│ Time/Total                    │ 4397.09716796875       │\n",
       "│ Time/Rollout                  │ 10.786308288574219     │\n",
       "│ Time/Update                   │ 1.68326997756958       │\n",
       "│ Time/Epoch                    │ 12.469622611999512     │\n",
       "│ Time/FPS                      │ 164.2391357421875      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.671092987060547     │\n",
       "│ Metrics/EpCost                │ 67.63999938964844      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 332.0                  │\n",
       "│ Train/Entropy                 │ -0.09836353361606598   │\n",
       "│ Train/KL                      │ 0.014531291089951992   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9981052279472351     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9981052279472351     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9981052279472351     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01968729868531227    │\n",
       "│ Train/LR                      │ 0.00010019999899668619 │\n",
       "│ Train/PolicyStd               │ 0.2194167673587799     │\n",
       "│ TotalEnvSteps                 │ 681984.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014715328812599182  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0045157261192798615  │\n",
       "│ Value/Adv                     │ -0.16914165019989014   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01587310992181301    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.012840604409575462  │\n",
       "│ Value/reward                  │ 2.0716288089752197     │\n",
       "│ Time/Total                    │ 4409.7275390625        │\n",
       "│ Time/Rollout                  │ 10.926790237426758     │\n",
       "│ Time/Update                   │ 1.6922907829284668     │\n",
       "│ Time/Epoch                    │ 12.619128227233887     │\n",
       "│ Time/FPS                      │ 162.29330444335938     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.671092987060547     │\n",
       "│ Metrics/EpCost                │ 67.63999938964844      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 332.0                  │\n",
       "│ Train/Entropy                 │ -0.09836353361606598   │\n",
       "│ Train/KL                      │ 0.014531291089951992   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9981052279472351     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9981052279472351     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9981052279472351     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01968729868531227    │\n",
       "│ Train/LR                      │ 0.00010019999899668619 │\n",
       "│ Train/PolicyStd               │ 0.2194167673587799     │\n",
       "│ TotalEnvSteps                 │ 681984.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014715328812599182  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0045157261192798615  │\n",
       "│ Value/Adv                     │ -0.16914165019989014   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01587310992181301    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.012840604409575462  │\n",
       "│ Value/reward                  │ 2.0716288089752197     │\n",
       "│ Time/Total                    │ 4409.7275390625        │\n",
       "│ Time/Rollout                  │ 10.926790237426758     │\n",
       "│ Time/Update                   │ 1.6922907829284668     │\n",
       "│ Time/Epoch                    │ 12.619128227233887     │\n",
       "│ Time/FPS                      │ 162.29330444335938     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.659006118774414    │\n",
       "│ Metrics/EpCost                │ 67.72000122070312     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 333.0                 │\n",
       "│ Train/Entropy                 │ -0.100105881690979    │\n",
       "│ Train/KL                      │ 0.017739931121468544  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9988005757331848    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9988005757331848    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9988005757331848    │\n",
       "│ Train/PolicyRatio/Std         │ 0.020229363813996315  │\n",
       "│ Train/LR                      │ 9.960000170394778e-05 │\n",
       "│ Train/PolicyStd               │ 0.2190515547990799    │\n",
       "│ TotalEnvSteps                 │ 684032.0              │\n",
       "│ Loss/Loss_pi                  │ -0.022063903510570526 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.007348574697971344 │\n",
       "│ Value/Adv                     │ -0.1250729262828827   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01927115209400654   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0033980421721935272 │\n",
       "│ Value/reward                  │ 2.21807861328125      │\n",
       "│ Time/Total                    │ 4422.29736328125      │\n",
       "│ Time/Rollout                  │ 10.840938568115234    │\n",
       "│ Time/Update                   │ 1.717374563217163     │\n",
       "│ Time/Epoch                    │ 12.558355331420898    │\n",
       "│ Time/FPS                      │ 163.0786895751953     │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.659006118774414    │\n",
       "│ Metrics/EpCost                │ 67.72000122070312     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 333.0                 │\n",
       "│ Train/Entropy                 │ -0.100105881690979    │\n",
       "│ Train/KL                      │ 0.017739931121468544  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9988005757331848    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9988005757331848    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9988005757331848    │\n",
       "│ Train/PolicyRatio/Std         │ 0.020229363813996315  │\n",
       "│ Train/LR                      │ 9.960000170394778e-05 │\n",
       "│ Train/PolicyStd               │ 0.2190515547990799    │\n",
       "│ TotalEnvSteps                 │ 684032.0              │\n",
       "│ Loss/Loss_pi                  │ -0.022063903510570526 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.007348574697971344 │\n",
       "│ Value/Adv                     │ -0.1250729262828827   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01927115209400654   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0033980421721935272 │\n",
       "│ Value/reward                  │ 2.21807861328125      │\n",
       "│ Time/Total                    │ 4422.29736328125      │\n",
       "│ Time/Rollout                  │ 10.840938568115234    │\n",
       "│ Time/Update                   │ 1.717374563217163     │\n",
       "│ Time/Epoch                    │ 12.558355331420898    │\n",
       "│ Time/FPS                      │ 163.0786895751953     │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.81338119506836      │\n",
       "│ Metrics/EpCost                │ 66.94000244140625      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 334.0                  │\n",
       "│ Train/Entropy                 │ -0.10311919450759888   │\n",
       "│ Train/KL                      │ 0.018311072140932083   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0002591609954834     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0002591609954834     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0002591609954834     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017535343766212463   │\n",
       "│ Train/LR                      │ 9.899999713525176e-05  │\n",
       "│ Train/PolicyStd               │ 0.21839773654937744    │\n",
       "│ TotalEnvSteps                 │ 686080.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018802454695105553  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0032614488154649734  │\n",
       "│ Value/Adv                     │ -0.20418260991573334   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018885711207985878   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0003854408860206604 │\n",
       "│ Value/reward                  │ 2.1795852184295654     │\n",
       "│ Time/Total                    │ 4434.888671875         │\n",
       "│ Time/Rollout                  │ 10.842301368713379     │\n",
       "│ Time/Update                   │ 1.737518310546875      │\n",
       "│ Time/Epoch                    │ 12.579866409301758     │\n",
       "│ Time/FPS                      │ 162.79983520507812     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.81338119506836      │\n",
       "│ Metrics/EpCost                │ 66.94000244140625      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 334.0                  │\n",
       "│ Train/Entropy                 │ -0.10311919450759888   │\n",
       "│ Train/KL                      │ 0.018311072140932083   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0002591609954834     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0002591609954834     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0002591609954834     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017535343766212463   │\n",
       "│ Train/LR                      │ 9.899999713525176e-05  │\n",
       "│ Train/PolicyStd               │ 0.21839773654937744    │\n",
       "│ TotalEnvSteps                 │ 686080.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018802454695105553  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0032614488154649734  │\n",
       "│ Value/Adv                     │ -0.20418260991573334   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018885711207985878   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0003854408860206604 │\n",
       "│ Value/reward                  │ 2.1795852184295654     │\n",
       "│ Time/Total                    │ 4434.888671875         │\n",
       "│ Time/Rollout                  │ 10.842301368713379     │\n",
       "│ Time/Update                   │ 1.737518310546875      │\n",
       "│ Time/Epoch                    │ 12.579866409301758     │\n",
       "│ Time/FPS                      │ 162.79983520507812     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.0316104888916      │\n",
       "│ Metrics/EpCost                │ 66.81999969482422     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 335.0                 │\n",
       "│ Train/Entropy                 │ -0.10854265838861465  │\n",
       "│ Train/KL                      │ 0.014698582701385021  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9998599886894226    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9998599886894226    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9998599886894226    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01812106929719448   │\n",
       "│ Train/LR                      │ 9.839999984251335e-05 │\n",
       "│ Train/PolicyStd               │ 0.2172357738018036    │\n",
       "│ TotalEnvSteps                 │ 688128.0              │\n",
       "│ Loss/Loss_pi                  │ -0.016844196245074272 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0019582584500312805 │\n",
       "│ Value/Adv                     │ -0.11356368660926819  │\n",
       "│ Loss/Loss_reward_critic       │ 0.019192975014448166  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0003072638064622879 │\n",
       "│ Value/reward                  │ 2.1649169921875       │\n",
       "│ Time/Total                    │ 4447.3828125          │\n",
       "│ Time/Rollout                  │ 10.792691230773926    │\n",
       "│ Time/Update                   │ 1.6901226043701172    │\n",
       "│ Time/Epoch                    │ 12.482855796813965    │\n",
       "│ Time/FPS                      │ 164.06503295898438    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.0316104888916      │\n",
       "│ Metrics/EpCost                │ 66.81999969482422     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 335.0                 │\n",
       "│ Train/Entropy                 │ -0.10854265838861465  │\n",
       "│ Train/KL                      │ 0.014698582701385021  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9998599886894226    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9998599886894226    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9998599886894226    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01812106929719448   │\n",
       "│ Train/LR                      │ 9.839999984251335e-05 │\n",
       "│ Train/PolicyStd               │ 0.2172357738018036    │\n",
       "│ TotalEnvSteps                 │ 688128.0              │\n",
       "│ Loss/Loss_pi                  │ -0.016844196245074272 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0019582584500312805 │\n",
       "│ Value/Adv                     │ -0.11356368660926819  │\n",
       "│ Loss/Loss_reward_critic       │ 0.019192975014448166  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0003072638064622879 │\n",
       "│ Value/reward                  │ 2.1649169921875       │\n",
       "│ Time/Total                    │ 4447.3828125          │\n",
       "│ Time/Rollout                  │ 10.792691230773926    │\n",
       "│ Time/Update                   │ 1.6901226043701172    │\n",
       "│ Time/Epoch                    │ 12.482855796813965    │\n",
       "│ Time/FPS                      │ 164.06503295898438    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.10870361328125      │\n",
       "│ Metrics/EpCost                │ 65.95999908447266      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 336.0                  │\n",
       "│ Train/Entropy                 │ -0.1148139014840126    │\n",
       "│ Train/KL                      │ 0.01580996811389923    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9972521066665649     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9972521066665649     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9972521066665649     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01876658946275711    │\n",
       "│ Train/LR                      │ 9.780000254977494e-05  │\n",
       "│ Train/PolicyStd               │ 0.2159062623977661     │\n",
       "│ TotalEnvSteps                 │ 690176.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016348645091056824  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0004955511540174484  │\n",
       "│ Value/Adv                     │ -0.146398663520813     │\n",
       "│ Loss/Loss_reward_critic       │ 0.015550522133708      │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0036424528807401657 │\n",
       "│ Value/reward                  │ 2.1984734535217285     │\n",
       "│ Time/Total                    │ 4459.876953125         │\n",
       "│ Time/Rollout                  │ 10.793561935424805     │\n",
       "│ Time/Update                   │ 1.6889874935150146     │\n",
       "│ Time/Epoch                    │ 12.482592582702637     │\n",
       "│ Time/FPS                      │ 164.06849670410156     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.10870361328125      │\n",
       "│ Metrics/EpCost                │ 65.95999908447266      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 336.0                  │\n",
       "│ Train/Entropy                 │ -0.1148139014840126    │\n",
       "│ Train/KL                      │ 0.01580996811389923    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9972521066665649     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9972521066665649     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9972521066665649     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01876658946275711    │\n",
       "│ Train/LR                      │ 9.780000254977494e-05  │\n",
       "│ Train/PolicyStd               │ 0.2159062623977661     │\n",
       "│ TotalEnvSteps                 │ 690176.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016348645091056824  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0004955511540174484  │\n",
       "│ Value/Adv                     │ -0.146398663520813     │\n",
       "│ Loss/Loss_reward_critic       │ 0.015550522133708      │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0036424528807401657 │\n",
       "│ Value/reward                  │ 2.1984734535217285     │\n",
       "│ Time/Total                    │ 4459.876953125         │\n",
       "│ Time/Rollout                  │ 10.793561935424805     │\n",
       "│ Time/Update                   │ 1.6889874935150146     │\n",
       "│ Time/Epoch                    │ 12.482592582702637     │\n",
       "│ Time/FPS                      │ 164.06849670410156     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.754762649536133    │\n",
       "│ Metrics/EpCost                │ 67.04000091552734     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 337.0                 │\n",
       "│ Train/Entropy                 │ -0.11818595230579376  │\n",
       "│ Train/KL                      │ 0.015678588300943375  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0103933811187744    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0103933811187744    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0103933811187744    │\n",
       "│ Train/PolicyRatio/Std         │ 0.018234746530652046  │\n",
       "│ Train/LR                      │ 9.719999798107892e-05 │\n",
       "│ Train/PolicyStd               │ 0.21520671248435974   │\n",
       "│ TotalEnvSteps                 │ 692224.0              │\n",
       "│ Loss/Loss_pi                  │ -0.012467965483665466 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0038806796073913574 │\n",
       "│ Value/Adv                     │ -0.0856546014547348   │\n",
       "│ Loss/Loss_reward_critic       │ 0.011689266189932823  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.003861255943775177 │\n",
       "│ Value/reward                  │ 1.877734661102295     │\n",
       "│ Time/Total                    │ 4472.4248046875       │\n",
       "│ Time/Rollout                  │ 10.845319747924805    │\n",
       "│ Time/Update                   │ 1.690627098083496     │\n",
       "│ Time/Epoch                    │ 12.535987854003906    │\n",
       "│ Time/FPS                      │ 163.36965942382812    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.754762649536133    │\n",
       "│ Metrics/EpCost                │ 67.04000091552734     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 337.0                 │\n",
       "│ Train/Entropy                 │ -0.11818595230579376  │\n",
       "│ Train/KL                      │ 0.015678588300943375  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0103933811187744    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0103933811187744    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0103933811187744    │\n",
       "│ Train/PolicyRatio/Std         │ 0.018234746530652046  │\n",
       "│ Train/LR                      │ 9.719999798107892e-05 │\n",
       "│ Train/PolicyStd               │ 0.21520671248435974   │\n",
       "│ TotalEnvSteps                 │ 692224.0              │\n",
       "│ Loss/Loss_pi                  │ -0.012467965483665466 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0038806796073913574 │\n",
       "│ Value/Adv                     │ -0.0856546014547348   │\n",
       "│ Loss/Loss_reward_critic       │ 0.011689266189932823  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.003861255943775177 │\n",
       "│ Value/reward                  │ 1.877734661102295     │\n",
       "│ Time/Total                    │ 4472.4248046875       │\n",
       "│ Time/Rollout                  │ 10.845319747924805    │\n",
       "│ Time/Update                   │ 1.690627098083496     │\n",
       "│ Time/Epoch                    │ 12.535987854003906    │\n",
       "│ Time/FPS                      │ 163.36965942382812    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.655427932739258    │\n",
       "│ Metrics/EpCost                │ 67.9000015258789      │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 338.0                 │\n",
       "│ Train/Entropy                 │ -0.11767666041851044  │\n",
       "│ Train/KL                      │ 0.012414108030498028  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0001561641693115    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0001561641693115    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0001561641693115    │\n",
       "│ Train/PolicyRatio/Std         │ 0.018582426011562347  │\n",
       "│ Train/LR                      │ 9.660000068834051e-05 │\n",
       "│ Train/PolicyStd               │ 0.2153237760066986    │\n",
       "│ TotalEnvSteps                 │ 694272.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01773999258875847  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.005272027105093002 │\n",
       "│ Value/Adv                     │ 0.25984570384025574   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01640365459024906   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004714388400316238  │\n",
       "│ Value/reward                  │ 2.2042603492736816    │\n",
       "│ Time/Total                    │ 4485.015625           │\n",
       "│ Time/Rollout                  │ 10.890336990356445    │\n",
       "│ Time/Update                   │ 1.6889805793762207    │\n",
       "│ Time/Epoch                    │ 12.57935905456543     │\n",
       "│ Time/FPS                      │ 162.806396484375      │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.655427932739258    │\n",
       "│ Metrics/EpCost                │ 67.9000015258789      │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 338.0                 │\n",
       "│ Train/Entropy                 │ -0.11767666041851044  │\n",
       "│ Train/KL                      │ 0.012414108030498028  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0001561641693115    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0001561641693115    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0001561641693115    │\n",
       "│ Train/PolicyRatio/Std         │ 0.018582426011562347  │\n",
       "│ Train/LR                      │ 9.660000068834051e-05 │\n",
       "│ Train/PolicyStd               │ 0.2153237760066986    │\n",
       "│ TotalEnvSteps                 │ 694272.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01773999258875847  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.005272027105093002 │\n",
       "│ Value/Adv                     │ 0.25984570384025574   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01640365459024906   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004714388400316238  │\n",
       "│ Value/reward                  │ 2.2042603492736816    │\n",
       "│ Time/Total                    │ 4485.015625           │\n",
       "│ Time/Rollout                  │ 10.890336990356445    │\n",
       "│ Time/Update                   │ 1.6889805793762207    │\n",
       "│ Time/Epoch                    │ 12.57935905456543     │\n",
       "│ Time/FPS                      │ 162.806396484375      │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.763662338256836     │\n",
       "│ Metrics/EpCost                │ 67.0                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 339.0                  │\n",
       "│ Train/Entropy                 │ -0.11897891759872437   │\n",
       "│ Train/KL                      │ 0.01576624996960163    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9944106936454773     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9944106936454773     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9944106936454773     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01890323869884014    │\n",
       "│ Train/LR                      │ 9.600000339560211e-05  │\n",
       "│ Train/PolicyStd               │ 0.21505551040172577    │\n",
       "│ TotalEnvSteps                 │ 696320.0               │\n",
       "│ Loss/Loss_pi                  │ -0.0172535739839077    │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00048641860485076904 │\n",
       "│ Value/Adv                     │ -0.013872968032956123  │\n",
       "│ Loss/Loss_reward_critic       │ 0.021128546446561813   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004724891856312752   │\n",
       "│ Value/reward                  │ 2.238999605178833      │\n",
       "│ Time/Total                    │ 4497.55517578125       │\n",
       "│ Time/Rollout                  │ 10.821014404296875     │\n",
       "│ Time/Update                   │ 1.7065906524658203     │\n",
       "│ Time/Epoch                    │ 12.527647972106934     │\n",
       "│ Time/FPS                      │ 163.47842407226562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.763662338256836     │\n",
       "│ Metrics/EpCost                │ 67.0                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 339.0                  │\n",
       "│ Train/Entropy                 │ -0.11897891759872437   │\n",
       "│ Train/KL                      │ 0.01576624996960163    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9944106936454773     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9944106936454773     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9944106936454773     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01890323869884014    │\n",
       "│ Train/LR                      │ 9.600000339560211e-05  │\n",
       "│ Train/PolicyStd               │ 0.21505551040172577    │\n",
       "│ TotalEnvSteps                 │ 696320.0               │\n",
       "│ Loss/Loss_pi                  │ -0.0172535739839077    │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00048641860485076904 │\n",
       "│ Value/Adv                     │ -0.013872968032956123  │\n",
       "│ Loss/Loss_reward_critic       │ 0.021128546446561813   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004724891856312752   │\n",
       "│ Value/reward                  │ 2.238999605178833      │\n",
       "│ Time/Total                    │ 4497.55517578125       │\n",
       "│ Time/Rollout                  │ 10.821014404296875     │\n",
       "│ Time/Update                   │ 1.7065906524658203     │\n",
       "│ Time/Epoch                    │ 12.527647972106934     │\n",
       "│ Time/FPS                      │ 163.47842407226562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m6\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.841978073120117    │\n",
       "│ Metrics/EpCost                │ 64.19999694824219     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 340.0                 │\n",
       "│ Train/Entropy                 │ -0.12192687392234802  │\n",
       "│ Train/KL                      │ 0.0201101154088974    │\n",
       "│ Train/StopIter                │ 6.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.995450496673584     │\n",
       "│ Train/PolicyRatio/Min         │ 0.995450496673584     │\n",
       "│ Train/PolicyRatio/Max         │ 0.995450496673584     │\n",
       "│ Train/PolicyRatio/Std         │ 0.0195988230407238    │\n",
       "│ Train/LR                      │ 9.539999882690609e-05 │\n",
       "│ Train/PolicyStd               │ 0.21442437171936035   │\n",
       "│ TotalEnvSteps                 │ 698368.0              │\n",
       "│ Loss/Loss_pi                  │ -0.016360558569431305 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0008930154144763947 │\n",
       "│ Value/Adv                     │ 0.17869144678115845   │\n",
       "│ Loss/Loss_reward_critic       │ 0.022084912285208702  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0009563658386468887 │\n",
       "│ Value/reward                  │ 2.079040765762329     │\n",
       "│ Time/Total                    │ 4509.4716796875       │\n",
       "│ Time/Rollout                  │ 10.920160293579102    │\n",
       "│ Time/Update                   │ 0.9824333190917969    │\n",
       "│ Time/Epoch                    │ 11.902639389038086    │\n",
       "│ Time/FPS                      │ 172.0626983642578     │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.841978073120117    │\n",
       "│ Metrics/EpCost                │ 64.19999694824219     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 340.0                 │\n",
       "│ Train/Entropy                 │ -0.12192687392234802  │\n",
       "│ Train/KL                      │ 0.0201101154088974    │\n",
       "│ Train/StopIter                │ 6.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.995450496673584     │\n",
       "│ Train/PolicyRatio/Min         │ 0.995450496673584     │\n",
       "│ Train/PolicyRatio/Max         │ 0.995450496673584     │\n",
       "│ Train/PolicyRatio/Std         │ 0.0195988230407238    │\n",
       "│ Train/LR                      │ 9.539999882690609e-05 │\n",
       "│ Train/PolicyStd               │ 0.21442437171936035   │\n",
       "│ TotalEnvSteps                 │ 698368.0              │\n",
       "│ Loss/Loss_pi                  │ -0.016360558569431305 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0008930154144763947 │\n",
       "│ Value/Adv                     │ 0.17869144678115845   │\n",
       "│ Loss/Loss_reward_critic       │ 0.022084912285208702  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0009563658386468887 │\n",
       "│ Value/reward                  │ 2.079040765762329     │\n",
       "│ Time/Total                    │ 4509.4716796875       │\n",
       "│ Time/Rollout                  │ 10.920160293579102    │\n",
       "│ Time/Update                   │ 0.9824333190917969    │\n",
       "│ Time/Epoch                    │ 11.902639389038086    │\n",
       "│ Time/FPS                      │ 172.0626983642578     │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.90732192993164      │\n",
       "│ Metrics/EpCost                │ 65.5                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 341.0                  │\n",
       "│ Train/Entropy                 │ -0.12410595268011093   │\n",
       "│ Train/KL                      │ 0.013183815404772758   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.991925835609436      │\n",
       "│ Train/PolicyRatio/Min         │ 0.991925835609436      │\n",
       "│ Train/PolicyRatio/Max         │ 0.991925835609436      │\n",
       "│ Train/PolicyRatio/Std         │ 0.01812382973730564    │\n",
       "│ Train/LR                      │ 9.480000153416768e-05  │\n",
       "│ Train/PolicyStd               │ 0.2139567881822586     │\n",
       "│ TotalEnvSteps                 │ 700416.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01754635199904442   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0011857934296131134 │\n",
       "│ Value/Adv                     │ -0.1465526521205902    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01650175452232361    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005583157762885094  │\n",
       "│ Value/reward                  │ 2.1647727489471436     │\n",
       "│ Time/Total                    │ 4522.00732421875       │\n",
       "│ Time/Rollout                  │ 10.833806037902832     │\n",
       "│ Time/Update                   │ 1.690110445022583      │\n",
       "│ Time/Epoch                    │ 12.523958206176758     │\n",
       "│ Time/FPS                      │ 163.52658081054688     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.90732192993164      │\n",
       "│ Metrics/EpCost                │ 65.5                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 341.0                  │\n",
       "│ Train/Entropy                 │ -0.12410595268011093   │\n",
       "│ Train/KL                      │ 0.013183815404772758   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.991925835609436      │\n",
       "│ Train/PolicyRatio/Min         │ 0.991925835609436      │\n",
       "│ Train/PolicyRatio/Max         │ 0.991925835609436      │\n",
       "│ Train/PolicyRatio/Std         │ 0.01812382973730564    │\n",
       "│ Train/LR                      │ 9.480000153416768e-05  │\n",
       "│ Train/PolicyStd               │ 0.2139567881822586     │\n",
       "│ TotalEnvSteps                 │ 700416.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01754635199904442   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0011857934296131134 │\n",
       "│ Value/Adv                     │ -0.1465526521205902    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01650175452232361    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005583157762885094  │\n",
       "│ Value/reward                  │ 2.1647727489471436     │\n",
       "│ Time/Total                    │ 4522.00732421875       │\n",
       "│ Time/Rollout                  │ 10.833806037902832     │\n",
       "│ Time/Update                   │ 1.690110445022583      │\n",
       "│ Time/Epoch                    │ 12.523958206176758     │\n",
       "│ Time/FPS                      │ 163.52658081054688     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.9517822265625      │\n",
       "│ Metrics/EpCost                │ 65.19999694824219     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 342.0                 │\n",
       "│ Train/Entropy                 │ -0.1281098574399948   │\n",
       "│ Train/KL                      │ 0.01725039631128311   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9928137063980103    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9928137063980103    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9928137063980103    │\n",
       "│ Train/PolicyRatio/Std         │ 0.018435582518577576  │\n",
       "│ Train/LR                      │ 9.419999696547166e-05 │\n",
       "│ Train/PolicyStd               │ 0.21311266720294952   │\n",
       "│ TotalEnvSteps                 │ 702464.0              │\n",
       "│ Loss/Loss_pi                  │ -0.015721261501312256 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0018250904977321625 │\n",
       "│ Value/Adv                     │ 0.03399193286895752   │\n",
       "│ Loss/Loss_reward_critic       │ 0.023687709122896194  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.007185954600572586  │\n",
       "│ Value/reward                  │ 2.174980640411377     │\n",
       "│ Time/Total                    │ 4534.46533203125      │\n",
       "│ Time/Rollout                  │ 10.762188911437988    │\n",
       "│ Time/Update                   │ 1.6843245029449463    │\n",
       "│ Time/Epoch                    │ 12.446556091308594    │\n",
       "│ Time/FPS                      │ 164.54351806640625    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.9517822265625      │\n",
       "│ Metrics/EpCost                │ 65.19999694824219     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 342.0                 │\n",
       "│ Train/Entropy                 │ -0.1281098574399948   │\n",
       "│ Train/KL                      │ 0.01725039631128311   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9928137063980103    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9928137063980103    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9928137063980103    │\n",
       "│ Train/PolicyRatio/Std         │ 0.018435582518577576  │\n",
       "│ Train/LR                      │ 9.419999696547166e-05 │\n",
       "│ Train/PolicyStd               │ 0.21311266720294952   │\n",
       "│ TotalEnvSteps                 │ 702464.0              │\n",
       "│ Loss/Loss_pi                  │ -0.015721261501312256 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0018250904977321625 │\n",
       "│ Value/Adv                     │ 0.03399193286895752   │\n",
       "│ Loss/Loss_reward_critic       │ 0.023687709122896194  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.007185954600572586  │\n",
       "│ Value/reward                  │ 2.174980640411377     │\n",
       "│ Time/Total                    │ 4534.46533203125      │\n",
       "│ Time/Rollout                  │ 10.762188911437988    │\n",
       "│ Time/Update                   │ 1.6843245029449463    │\n",
       "│ Time/Epoch                    │ 12.446556091308594    │\n",
       "│ Time/FPS                      │ 164.54351806640625    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.886920928955078    │\n",
       "│ Metrics/EpCost                │ 64.72000122070312     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 343.0                 │\n",
       "│ Train/Entropy                 │ -0.13045267760753632  │\n",
       "│ Train/KL                      │ 0.016745509579777718  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9936658143997192    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9936658143997192    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9936658143997192    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01955857127904892   │\n",
       "│ Train/LR                      │ 9.359999967273325e-05 │\n",
       "│ Train/PolicyStd               │ 0.21260233223438263   │\n",
       "│ TotalEnvSteps                 │ 704512.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01878175511956215  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.003060493618249893 │\n",
       "│ Value/Adv                     │ 0.04535697400569916   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014773920178413391  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.008913788944482803 │\n",
       "│ Value/reward                  │ 2.1246581077575684    │\n",
       "│ Time/Total                    │ 4546.99365234375      │\n",
       "│ Time/Rollout                  │ 10.779138565063477    │\n",
       "│ Time/Update                   │ 1.7370038032531738    │\n",
       "│ Time/Epoch                    │ 12.516189575195312    │\n",
       "│ Time/FPS                      │ 163.62808227539062    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.886920928955078    │\n",
       "│ Metrics/EpCost                │ 64.72000122070312     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 343.0                 │\n",
       "│ Train/Entropy                 │ -0.13045267760753632  │\n",
       "│ Train/KL                      │ 0.016745509579777718  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9936658143997192    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9936658143997192    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9936658143997192    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01955857127904892   │\n",
       "│ Train/LR                      │ 9.359999967273325e-05 │\n",
       "│ Train/PolicyStd               │ 0.21260233223438263   │\n",
       "│ TotalEnvSteps                 │ 704512.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01878175511956215  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.003060493618249893 │\n",
       "│ Value/Adv                     │ 0.04535697400569916   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014773920178413391  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.008913788944482803 │\n",
       "│ Value/reward                  │ 2.1246581077575684    │\n",
       "│ Time/Total                    │ 4546.99365234375      │\n",
       "│ Time/Rollout                  │ 10.779138565063477    │\n",
       "│ Time/Update                   │ 1.7370038032531738    │\n",
       "│ Time/Epoch                    │ 12.516189575195312    │\n",
       "│ Time/FPS                      │ 163.62808227539062    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.922447204589844     │\n",
       "│ Metrics/EpCost                │ 66.9800033569336       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 344.0                  │\n",
       "│ Train/Entropy                 │ -0.13231167197227478   │\n",
       "│ Train/KL                      │ 0.0171185415238142     │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9923403859138489     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9923403859138489     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9923403859138489     │\n",
       "│ Train/PolicyRatio/Std         │ 0.0204895231872797     │\n",
       "│ Train/LR                      │ 9.300000237999484e-05  │\n",
       "│ Train/PolicyStd               │ 0.2121860533952713     │\n",
       "│ TotalEnvSteps                 │ 706560.0               │\n",
       "│ Loss/Loss_pi                  │ -0.022172313183546066  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0033905580639839172 │\n",
       "│ Value/Adv                     │ 0.00034076347947120667 │\n",
       "│ Loss/Loss_reward_critic       │ 0.01798110082745552    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0032071806490421295  │\n",
       "│ Value/reward                  │ 2.173243522644043      │\n",
       "│ Time/Total                    │ 4559.58349609375       │\n",
       "│ Time/Rollout                  │ 10.848132133483887     │\n",
       "│ Time/Update                   │ 1.7292780876159668     │\n",
       "│ Time/Epoch                    │ 12.577463150024414     │\n",
       "│ Time/FPS                      │ 162.83094787597656     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.922447204589844     │\n",
       "│ Metrics/EpCost                │ 66.9800033569336       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 344.0                  │\n",
       "│ Train/Entropy                 │ -0.13231167197227478   │\n",
       "│ Train/KL                      │ 0.0171185415238142     │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9923403859138489     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9923403859138489     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9923403859138489     │\n",
       "│ Train/PolicyRatio/Std         │ 0.0204895231872797     │\n",
       "│ Train/LR                      │ 9.300000237999484e-05  │\n",
       "│ Train/PolicyStd               │ 0.2121860533952713     │\n",
       "│ TotalEnvSteps                 │ 706560.0               │\n",
       "│ Loss/Loss_pi                  │ -0.022172313183546066  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0033905580639839172 │\n",
       "│ Value/Adv                     │ 0.00034076347947120667 │\n",
       "│ Loss/Loss_reward_critic       │ 0.01798110082745552    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0032071806490421295  │\n",
       "│ Value/reward                  │ 2.173243522644043      │\n",
       "│ Time/Total                    │ 4559.58349609375       │\n",
       "│ Time/Rollout                  │ 10.848132133483887     │\n",
       "│ Time/Update                   │ 1.7292780876159668     │\n",
       "│ Time/Epoch                    │ 12.577463150024414     │\n",
       "│ Time/FPS                      │ 162.83094787597656     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.84234619140625      │\n",
       "│ Metrics/EpCost                │ 68.0999984741211       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 345.0                  │\n",
       "│ Train/Entropy                 │ -0.1342388093471527    │\n",
       "│ Train/KL                      │ 0.01336020976305008    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9951163530349731     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9951163530349731     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9951163530349731     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01871994510293007    │\n",
       "│ Train/LR                      │ 9.239999781129882e-05  │\n",
       "│ Train/PolicyStd               │ 0.2117597609758377     │\n",
       "│ TotalEnvSteps                 │ 708608.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01740243472158909   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004769878461956978   │\n",
       "│ Value/Adv                     │ -0.05352172628045082   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015054131858050823   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0029269689694046974 │\n",
       "│ Value/reward                  │ 2.161505937576294      │\n",
       "│ Time/Total                    │ 4572.21630859375       │\n",
       "│ Time/Rollout                  │ 10.908639907836914     │\n",
       "│ Time/Update                   │ 1.7091975212097168     │\n",
       "│ Time/Epoch                    │ 12.617880821228027     │\n",
       "│ Time/FPS                      │ 162.30935668945312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.84234619140625      │\n",
       "│ Metrics/EpCost                │ 68.0999984741211       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 345.0                  │\n",
       "│ Train/Entropy                 │ -0.1342388093471527    │\n",
       "│ Train/KL                      │ 0.01336020976305008    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9951163530349731     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9951163530349731     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9951163530349731     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01871994510293007    │\n",
       "│ Train/LR                      │ 9.239999781129882e-05  │\n",
       "│ Train/PolicyStd               │ 0.2117597609758377     │\n",
       "│ TotalEnvSteps                 │ 708608.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01740243472158909   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004769878461956978   │\n",
       "│ Value/Adv                     │ -0.05352172628045082   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015054131858050823   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0029269689694046974 │\n",
       "│ Value/reward                  │ 2.161505937576294      │\n",
       "│ Time/Total                    │ 4572.21630859375       │\n",
       "│ Time/Rollout                  │ 10.908639907836914     │\n",
       "│ Time/Update                   │ 1.7091975212097168     │\n",
       "│ Time/Epoch                    │ 12.617880821228027     │\n",
       "│ Time/FPS                      │ 162.30935668945312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.728784561157227     │\n",
       "│ Metrics/EpCost                │ 68.9000015258789       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 346.0                  │\n",
       "│ Train/Entropy                 │ -0.1382419615983963    │\n",
       "│ Train/KL                      │ 0.013400809839367867   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.996893048286438      │\n",
       "│ Train/PolicyRatio/Min         │ 0.996893048286438      │\n",
       "│ Train/PolicyRatio/Max         │ 0.996893048286438      │\n",
       "│ Train/PolicyRatio/Std         │ 0.018505381420254707   │\n",
       "│ Train/LR                      │ 9.180000051856041e-05  │\n",
       "│ Train/PolicyStd               │ 0.21090707182884216    │\n",
       "│ TotalEnvSteps                 │ 710656.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017949772998690605  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0005473382771015167 │\n",
       "│ Value/Adv                     │ 0.08973760157823563    │\n",
       "│ Loss/Loss_reward_critic       │ 0.016307765617966652   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0012536337599158287  │\n",
       "│ Value/reward                  │ 2.12261962890625       │\n",
       "│ Time/Total                    │ 4584.8876953125        │\n",
       "│ Time/Rollout                  │ 10.894430160522461     │\n",
       "│ Time/Update                   │ 1.7653064727783203     │\n",
       "│ Time/Epoch                    │ 12.659780502319336     │\n",
       "│ Time/FPS                      │ 161.77215576171875     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.728784561157227     │\n",
       "│ Metrics/EpCost                │ 68.9000015258789       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 346.0                  │\n",
       "│ Train/Entropy                 │ -0.1382419615983963    │\n",
       "│ Train/KL                      │ 0.013400809839367867   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.996893048286438      │\n",
       "│ Train/PolicyRatio/Min         │ 0.996893048286438      │\n",
       "│ Train/PolicyRatio/Max         │ 0.996893048286438      │\n",
       "│ Train/PolicyRatio/Std         │ 0.018505381420254707   │\n",
       "│ Train/LR                      │ 9.180000051856041e-05  │\n",
       "│ Train/PolicyStd               │ 0.21090707182884216    │\n",
       "│ TotalEnvSteps                 │ 710656.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017949772998690605  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0005473382771015167 │\n",
       "│ Value/Adv                     │ 0.08973760157823563    │\n",
       "│ Loss/Loss_reward_critic       │ 0.016307765617966652   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0012536337599158287  │\n",
       "│ Value/reward                  │ 2.12261962890625       │\n",
       "│ Time/Total                    │ 4584.8876953125        │\n",
       "│ Time/Rollout                  │ 10.894430160522461     │\n",
       "│ Time/Update                   │ 1.7653064727783203     │\n",
       "│ Time/Epoch                    │ 12.659780502319336     │\n",
       "│ Time/FPS                      │ 161.77215576171875     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.685405731201172    │\n",
       "│ Metrics/EpCost                │ 69.4000015258789      │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 347.0                 │\n",
       "│ Train/Entropy                 │ -0.1395227611064911   │\n",
       "│ Train/KL                      │ 0.01679675467312336   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9967507123947144    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9967507123947144    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9967507123947144    │\n",
       "│ Train/PolicyRatio/Std         │ 0.020646492019295692  │\n",
       "│ Train/LR                      │ 9.1200003225822e-05   │\n",
       "│ Train/PolicyStd               │ 0.21064169704914093   │\n",
       "│ TotalEnvSteps                 │ 712704.0              │\n",
       "│ Loss/Loss_pi                  │ -0.017392389476299286 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0005573835223913193 │\n",
       "│ Value/Adv                     │ -0.24477404356002808  │\n",
       "│ Loss/Loss_reward_critic       │ 0.014505748637020588  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.001802016980946064 │\n",
       "│ Value/reward                  │ 2.0407612323760986    │\n",
       "│ Time/Total                    │ 4597.49560546875      │\n",
       "│ Time/Rollout                  │ 10.862119674682617    │\n",
       "│ Time/Update                   │ 1.7337157726287842    │\n",
       "│ Time/Epoch                    │ 12.59587574005127     │\n",
       "│ Time/FPS                      │ 162.59291076660156    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.685405731201172    │\n",
       "│ Metrics/EpCost                │ 69.4000015258789      │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 347.0                 │\n",
       "│ Train/Entropy                 │ -0.1395227611064911   │\n",
       "│ Train/KL                      │ 0.01679675467312336   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9967507123947144    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9967507123947144    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9967507123947144    │\n",
       "│ Train/PolicyRatio/Std         │ 0.020646492019295692  │\n",
       "│ Train/LR                      │ 9.1200003225822e-05   │\n",
       "│ Train/PolicyStd               │ 0.21064169704914093   │\n",
       "│ TotalEnvSteps                 │ 712704.0              │\n",
       "│ Loss/Loss_pi                  │ -0.017392389476299286 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0005573835223913193 │\n",
       "│ Value/Adv                     │ -0.24477404356002808  │\n",
       "│ Loss/Loss_reward_critic       │ 0.014505748637020588  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.001802016980946064 │\n",
       "│ Value/reward                  │ 2.0407612323760986    │\n",
       "│ Time/Total                    │ 4597.49560546875      │\n",
       "│ Time/Rollout                  │ 10.862119674682617    │\n",
       "│ Time/Update                   │ 1.7337157726287842    │\n",
       "│ Time/Epoch                    │ 12.59587574005127     │\n",
       "│ Time/FPS                      │ 162.59291076660156    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m1\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.711828231811523     │\n",
       "│ Metrics/EpCost                │ 68.0                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 348.0                  │\n",
       "│ Train/Entropy                 │ -0.13900072872638702   │\n",
       "│ Train/KL                      │ 0.024233274161815643   │\n",
       "│ Train/StopIter                │ 1.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9957972168922424     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9957972168922424     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9957972168922424     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01416764222085476    │\n",
       "│ Train/LR                      │ 9.059999865712598e-05  │\n",
       "│ Train/PolicyStd               │ 0.21075963973999023    │\n",
       "│ TotalEnvSteps                 │ 714752.0               │\n",
       "│ Loss/Loss_pi                  │ -0.0014361236244440079 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.015956265851855278   │\n",
       "│ Value/Adv                     │ 0.1196572333574295     │\n",
       "│ Loss/Loss_reward_critic       │ 0.025143153965473175   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.010637405328452587   │\n",
       "│ Value/reward                  │ 2.1734766960144043     │\n",
       "│ Time/Total                    │ 4608.58056640625       │\n",
       "│ Time/Rollout                  │ 10.895307540893555     │\n",
       "│ Time/Update                   │ 0.17818665504455566    │\n",
       "│ Time/Epoch                    │ 11.073538780212402     │\n",
       "│ Time/FPS                      │ 184.94540405273438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.711828231811523     │\n",
       "│ Metrics/EpCost                │ 68.0                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 348.0                  │\n",
       "│ Train/Entropy                 │ -0.13900072872638702   │\n",
       "│ Train/KL                      │ 0.024233274161815643   │\n",
       "│ Train/StopIter                │ 1.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9957972168922424     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9957972168922424     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9957972168922424     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01416764222085476    │\n",
       "│ Train/LR                      │ 9.059999865712598e-05  │\n",
       "│ Train/PolicyStd               │ 0.21075963973999023    │\n",
       "│ TotalEnvSteps                 │ 714752.0               │\n",
       "│ Loss/Loss_pi                  │ -0.0014361236244440079 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.015956265851855278   │\n",
       "│ Value/Adv                     │ 0.1196572333574295     │\n",
       "│ Loss/Loss_reward_critic       │ 0.025143153965473175   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.010637405328452587   │\n",
       "│ Value/reward                  │ 2.1734766960144043     │\n",
       "│ Time/Total                    │ 4608.58056640625       │\n",
       "│ Time/Rollout                  │ 10.895307540893555     │\n",
       "│ Time/Update                   │ 0.17818665504455566    │\n",
       "│ Time/Epoch                    │ 11.073538780212402     │\n",
       "│ Time/FPS                      │ 184.94540405273438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.725513458251953     │\n",
       "│ Metrics/EpCost                │ 67.05999755859375      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 349.0                  │\n",
       "│ Train/Entropy                 │ -0.14215537905693054   │\n",
       "│ Train/KL                      │ 0.016135992482304573   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9996317028999329     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9996317028999329     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9996317028999329     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01808972842991352    │\n",
       "│ Train/LR                      │ 9.000000136438757e-05  │\n",
       "│ Train/PolicyStd               │ 0.21008184552192688    │\n",
       "│ TotalEnvSteps                 │ 716800.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01653878763318062   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.01510266400873661   │\n",
       "│ Value/Adv                     │ 0.10167787969112396    │\n",
       "│ Loss/Loss_reward_critic       │ 0.021344518288969994   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0037986356765031815 │\n",
       "│ Value/reward                  │ 2.197885036468506      │\n",
       "│ Time/Total                    │ 4621.22216796875       │\n",
       "│ Time/Rollout                  │ 10.904532432556152     │\n",
       "│ Time/Update                   │ 1.7256314754486084     │\n",
       "│ Time/Epoch                    │ 12.630207061767578     │\n",
       "│ Time/FPS                      │ 162.1509552001953      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.725513458251953     │\n",
       "│ Metrics/EpCost                │ 67.05999755859375      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 349.0                  │\n",
       "│ Train/Entropy                 │ -0.14215537905693054   │\n",
       "│ Train/KL                      │ 0.016135992482304573   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9996317028999329     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9996317028999329     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9996317028999329     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01808972842991352    │\n",
       "│ Train/LR                      │ 9.000000136438757e-05  │\n",
       "│ Train/PolicyStd               │ 0.21008184552192688    │\n",
       "│ TotalEnvSteps                 │ 716800.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01653878763318062   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.01510266400873661   │\n",
       "│ Value/Adv                     │ 0.10167787969112396    │\n",
       "│ Loss/Loss_reward_critic       │ 0.021344518288969994   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0037986356765031815 │\n",
       "│ Value/reward                  │ 2.197885036468506      │\n",
       "│ Time/Total                    │ 4621.22216796875       │\n",
       "│ Time/Rollout                  │ 10.904532432556152     │\n",
       "│ Time/Update                   │ 1.7256314754486084     │\n",
       "│ Time/Epoch                    │ 12.630207061767578     │\n",
       "│ Time/FPS                      │ 162.1509552001953      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.505226135253906    │\n",
       "│ Metrics/EpCost                │ 65.62000274658203     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 350.0                 │\n",
       "│ Train/Entropy                 │ -0.14847922325134277  │\n",
       "│ Train/KL                      │ 0.016979873180389404  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.999396800994873     │\n",
       "│ Train/PolicyRatio/Min         │ 0.999396800994873     │\n",
       "│ Train/PolicyRatio/Max         │ 0.999396800994873     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01992294378578663   │\n",
       "│ Train/LR                      │ 8.939999679569155e-05 │\n",
       "│ Train/PolicyStd               │ 0.20875351130962372   │\n",
       "│ TotalEnvSteps                 │ 718848.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01810545101761818  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.001566663384437561 │\n",
       "│ Value/Adv                     │ 0.25412997603416443   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015708262100815773  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005636256188154221 │\n",
       "│ Value/reward                  │ 1.9116159677505493    │\n",
       "│ Time/Total                    │ 4633.77734375         │\n",
       "│ Time/Rollout                  │ 10.821605682373047    │\n",
       "│ Time/Update                   │ 1.7205381393432617    │\n",
       "│ Time/Epoch                    │ 12.54218864440918     │\n",
       "│ Time/FPS                      │ 163.2888946533203     │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.505226135253906    │\n",
       "│ Metrics/EpCost                │ 65.62000274658203     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 350.0                 │\n",
       "│ Train/Entropy                 │ -0.14847922325134277  │\n",
       "│ Train/KL                      │ 0.016979873180389404  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.999396800994873     │\n",
       "│ Train/PolicyRatio/Min         │ 0.999396800994873     │\n",
       "│ Train/PolicyRatio/Max         │ 0.999396800994873     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01992294378578663   │\n",
       "│ Train/LR                      │ 8.939999679569155e-05 │\n",
       "│ Train/PolicyStd               │ 0.20875351130962372   │\n",
       "│ TotalEnvSteps                 │ 718848.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01810545101761818  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.001566663384437561 │\n",
       "│ Value/Adv                     │ 0.25412997603416443   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015708262100815773  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005636256188154221 │\n",
       "│ Value/reward                  │ 1.9116159677505493    │\n",
       "│ Time/Total                    │ 4633.77734375         │\n",
       "│ Time/Rollout                  │ 10.821605682373047    │\n",
       "│ Time/Update                   │ 1.7205381393432617    │\n",
       "│ Time/Epoch                    │ 12.54218864440918     │\n",
       "│ Time/FPS                      │ 163.2888946533203     │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.48065185546875     │\n",
       "│ Metrics/EpCost                │ 64.5                  │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 351.0                 │\n",
       "│ Train/Entropy                 │ -0.15486690402030945  │\n",
       "│ Train/KL                      │ 0.015750132501125336  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9959746599197388    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9959746599197388    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9959746599197388    │\n",
       "│ Train/PolicyRatio/Std         │ 0.019631246104836464  │\n",
       "│ Train/LR                      │ 8.879999950295314e-05 │\n",
       "│ Train/PolicyStd               │ 0.20745500922203064   │\n",
       "│ TotalEnvSteps                 │ 720896.0              │\n",
       "│ Loss/Loss_pi                  │ -0.016669588163495064 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0014358628541231155 │\n",
       "│ Value/Adv                     │ 0.031049635261297226  │\n",
       "│ Loss/Loss_reward_critic       │ 0.01664704456925392   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0009387824684381485 │\n",
       "│ Value/reward                  │ 2.0745110511779785    │\n",
       "│ Time/Total                    │ 4646.4501953125       │\n",
       "│ Time/Rollout                  │ 10.873703956604004    │\n",
       "│ Time/Update                   │ 1.7878775596618652    │\n",
       "│ Time/Epoch                    │ 12.66163158416748     │\n",
       "│ Time/FPS                      │ 161.74850463867188    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.48065185546875     │\n",
       "│ Metrics/EpCost                │ 64.5                  │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 351.0                 │\n",
       "│ Train/Entropy                 │ -0.15486690402030945  │\n",
       "│ Train/KL                      │ 0.015750132501125336  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9959746599197388    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9959746599197388    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9959746599197388    │\n",
       "│ Train/PolicyRatio/Std         │ 0.019631246104836464  │\n",
       "│ Train/LR                      │ 8.879999950295314e-05 │\n",
       "│ Train/PolicyStd               │ 0.20745500922203064   │\n",
       "│ TotalEnvSteps                 │ 720896.0              │\n",
       "│ Loss/Loss_pi                  │ -0.016669588163495064 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0014358628541231155 │\n",
       "│ Value/Adv                     │ 0.031049635261297226  │\n",
       "│ Loss/Loss_reward_critic       │ 0.01664704456925392   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0009387824684381485 │\n",
       "│ Value/reward                  │ 2.0745110511779785    │\n",
       "│ Time/Total                    │ 4646.4501953125       │\n",
       "│ Time/Rollout                  │ 10.873703956604004    │\n",
       "│ Time/Update                   │ 1.7878775596618652    │\n",
       "│ Time/Epoch                    │ 12.66163158416748     │\n",
       "│ Time/FPS                      │ 161.74850463867188    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.601247787475586     │\n",
       "│ Metrics/EpCost                │ 64.5                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 352.0                  │\n",
       "│ Train/Entropy                 │ -0.15755510330200195   │\n",
       "│ Train/KL                      │ 0.013474099338054657   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9993239641189575     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9993239641189575     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9993239641189575     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018627990037202835   │\n",
       "│ Train/LR                      │ 8.820000221021473e-05  │\n",
       "│ Train/PolicyStd               │ 0.20691780745983124    │\n",
       "│ TotalEnvSteps                 │ 722944.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017358049750328064  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0006884615868330002 │\n",
       "│ Value/Adv                     │ -0.14213065803050995   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014672746881842613   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0019742976874113083 │\n",
       "│ Value/reward                  │ 2.1139612197875977     │\n",
       "│ Time/Total                    │ 4658.9765625           │\n",
       "│ Time/Rollout                  │ 10.809885025024414     │\n",
       "│ Time/Update                   │ 1.703108310699463      │\n",
       "│ Time/Epoch                    │ 12.513036727905273     │\n",
       "│ Time/FPS                      │ 163.6693115234375      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.601247787475586     │\n",
       "│ Metrics/EpCost                │ 64.5                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 352.0                  │\n",
       "│ Train/Entropy                 │ -0.15755510330200195   │\n",
       "│ Train/KL                      │ 0.013474099338054657   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9993239641189575     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9993239641189575     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9993239641189575     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018627990037202835   │\n",
       "│ Train/LR                      │ 8.820000221021473e-05  │\n",
       "│ Train/PolicyStd               │ 0.20691780745983124    │\n",
       "│ TotalEnvSteps                 │ 722944.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017358049750328064  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0006884615868330002 │\n",
       "│ Value/Adv                     │ -0.14213065803050995   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014672746881842613   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0019742976874113083 │\n",
       "│ Value/reward                  │ 2.1139612197875977     │\n",
       "│ Time/Total                    │ 4658.9765625           │\n",
       "│ Time/Rollout                  │ 10.809885025024414     │\n",
       "│ Time/Update                   │ 1.703108310699463      │\n",
       "│ Time/Epoch                    │ 12.513036727905273     │\n",
       "│ Time/FPS                      │ 163.6693115234375      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.54825210571289      │\n",
       "│ Metrics/EpCost                │ 63.63999938964844      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 353.0                  │\n",
       "│ Train/Entropy                 │ -0.15909931063652039   │\n",
       "│ Train/KL                      │ 0.017169099301099777   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9980896711349487     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9980896711349487     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9980896711349487     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01813940890133381    │\n",
       "│ Train/LR                      │ 8.759999764151871e-05  │\n",
       "│ Train/PolicyStd               │ 0.20659847557544708    │\n",
       "│ TotalEnvSteps                 │ 724992.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016831135377287865  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0005269143730401993  │\n",
       "│ Value/Adv                     │ -0.004053419455885887  │\n",
       "│ Loss/Loss_reward_critic       │ 0.01324885617941618    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0014238907024264336 │\n",
       "│ Value/reward                  │ 2.1862902641296387     │\n",
       "│ Time/Total                    │ 4671.546875            │\n",
       "│ Time/Rollout                  │ 10.812393188476562     │\n",
       "│ Time/Update                   │ 1.743753433227539      │\n",
       "│ Time/Epoch                    │ 12.55618953704834      │\n",
       "│ Time/FPS                      │ 163.1068115234375      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.54825210571289      │\n",
       "│ Metrics/EpCost                │ 63.63999938964844      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 353.0                  │\n",
       "│ Train/Entropy                 │ -0.15909931063652039   │\n",
       "│ Train/KL                      │ 0.017169099301099777   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9980896711349487     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9980896711349487     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9980896711349487     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01813940890133381    │\n",
       "│ Train/LR                      │ 8.759999764151871e-05  │\n",
       "│ Train/PolicyStd               │ 0.20659847557544708    │\n",
       "│ TotalEnvSteps                 │ 724992.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016831135377287865  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0005269143730401993  │\n",
       "│ Value/Adv                     │ -0.004053419455885887  │\n",
       "│ Loss/Loss_reward_critic       │ 0.01324885617941618    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0014238907024264336 │\n",
       "│ Value/reward                  │ 2.1862902641296387     │\n",
       "│ Time/Total                    │ 4671.546875            │\n",
       "│ Time/Rollout                  │ 10.812393188476562     │\n",
       "│ Time/Update                   │ 1.743753433227539      │\n",
       "│ Time/Epoch                    │ 12.55618953704834      │\n",
       "│ Time/FPS                      │ 163.1068115234375      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Early stopping at iter </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"color: #008000; text-decoration-color: #008000\"> due to reaching max kl</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mEarly stopping at iter \u001b[0m\u001b[1;36m10\u001b[0m\u001b[32m due to reaching max kl\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.8347110748291       │\n",
       "│ Metrics/EpCost                │ 46.86000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 354.0                  │\n",
       "│ Train/Entropy                 │ -0.1617998331785202    │\n",
       "│ Train/KL                      │ 0.020849039778113365   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.992053210735321      │\n",
       "│ Train/PolicyRatio/Min         │ 0.992053210735321      │\n",
       "│ Train/PolicyRatio/Max         │ 0.992053210735321      │\n",
       "│ Train/PolicyRatio/Std         │ 0.01918913796544075    │\n",
       "│ Train/LR                      │ 8.70000003487803e-05   │\n",
       "│ Train/PolicyStd               │ 0.20602747797966003    │\n",
       "│ TotalEnvSteps                 │ 727040.0               │\n",
       "│ Loss/Loss_pi                  │ -0.021893324330449104  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00506218895316124   │\n",
       "│ Value/Adv                     │ 0.03994527459144592    │\n",
       "│ Loss/Loss_reward_critic       │ 0.012536128051578999   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0007127281278371811 │\n",
       "│ Value/reward                  │ 2.001225233078003      │\n",
       "│ Time/Total                    │ 4684.07275390625       │\n",
       "│ Time/Rollout                  │ 10.813340187072754     │\n",
       "│ Time/Update                   │ 1.6991338729858398     │\n",
       "│ Time/Epoch                    │ 12.512516021728516     │\n",
       "│ Time/FPS                      │ 163.67611694335938     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.8347110748291       │\n",
       "│ Metrics/EpCost                │ 46.86000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 354.0                  │\n",
       "│ Train/Entropy                 │ -0.1617998331785202    │\n",
       "│ Train/KL                      │ 0.020849039778113365   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.992053210735321      │\n",
       "│ Train/PolicyRatio/Min         │ 0.992053210735321      │\n",
       "│ Train/PolicyRatio/Max         │ 0.992053210735321      │\n",
       "│ Train/PolicyRatio/Std         │ 0.01918913796544075    │\n",
       "│ Train/LR                      │ 8.70000003487803e-05   │\n",
       "│ Train/PolicyStd               │ 0.20602747797966003    │\n",
       "│ TotalEnvSteps                 │ 727040.0               │\n",
       "│ Loss/Loss_pi                  │ -0.021893324330449104  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00506218895316124   │\n",
       "│ Value/Adv                     │ 0.03994527459144592    │\n",
       "│ Loss/Loss_reward_critic       │ 0.012536128051578999   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0007127281278371811 │\n",
       "│ Value/reward                  │ 2.001225233078003      │\n",
       "│ Time/Total                    │ 4684.07275390625       │\n",
       "│ Time/Rollout                  │ 10.813340187072754     │\n",
       "│ Time/Update                   │ 1.6991338729858398     │\n",
       "│ Time/Epoch                    │ 12.512516021728516     │\n",
       "│ Time/FPS                      │ 163.67611694335938     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.812314987182617    │\n",
       "│ Metrics/EpCost                │ 45.70000076293945     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 355.0                 │\n",
       "│ Train/Entropy                 │ -0.1626335084438324   │\n",
       "│ Train/KL                      │ 0.015899434685707092  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9980983734130859    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9980983734130859    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9980983734130859    │\n",
       "│ Train/PolicyRatio/Std         │ 0.020117441192269325  │\n",
       "│ Train/LR                      │ 8.64000030560419e-05  │\n",
       "│ Train/PolicyStd               │ 0.20583248138427734   │\n",
       "│ TotalEnvSteps                 │ 729088.0              │\n",
       "│ Loss/Loss_pi                  │ -0.018871018663048744 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00302230566740036   │\n",
       "│ Value/Adv                     │ -0.11471833288669586  │\n",
       "│ Loss/Loss_reward_critic       │ 0.01587172970175743   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0033356016501784325 │\n",
       "│ Value/reward                  │ 2.1475911140441895    │\n",
       "│ Time/Total                    │ 4696.62841796875      │\n",
       "│ Time/Rollout                  │ 10.842750549316406    │\n",
       "│ Time/Update                   │ 1.7009773254394531    │\n",
       "│ Time/Epoch                    │ 12.543797492980957    │\n",
       "│ Time/FPS                      │ 163.26795959472656    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.812314987182617    │\n",
       "│ Metrics/EpCost                │ 45.70000076293945     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 355.0                 │\n",
       "│ Train/Entropy                 │ -0.1626335084438324   │\n",
       "│ Train/KL                      │ 0.015899434685707092  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9980983734130859    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9980983734130859    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9980983734130859    │\n",
       "│ Train/PolicyRatio/Std         │ 0.020117441192269325  │\n",
       "│ Train/LR                      │ 8.64000030560419e-05  │\n",
       "│ Train/PolicyStd               │ 0.20583248138427734   │\n",
       "│ TotalEnvSteps                 │ 729088.0              │\n",
       "│ Loss/Loss_pi                  │ -0.018871018663048744 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00302230566740036   │\n",
       "│ Value/Adv                     │ -0.11471833288669586  │\n",
       "│ Loss/Loss_reward_critic       │ 0.01587172970175743   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0033356016501784325 │\n",
       "│ Value/reward                  │ 2.1475911140441895    │\n",
       "│ Time/Total                    │ 4696.62841796875      │\n",
       "│ Time/Rollout                  │ 10.842750549316406    │\n",
       "│ Time/Update                   │ 1.7009773254394531    │\n",
       "│ Time/Epoch                    │ 12.543797492980957    │\n",
       "│ Time/FPS                      │ 163.26795959472656    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.70852279663086     │\n",
       "│ Metrics/EpCost                │ 48.5                  │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 356.0                 │\n",
       "│ Train/Entropy                 │ -0.16175398230552673  │\n",
       "│ Train/KL                      │ 0.01567566953599453   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9987517595291138    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9987517595291138    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9987517595291138    │\n",
       "│ Train/PolicyRatio/Std         │ 0.021131426095962524  │\n",
       "│ Train/LR                      │ 8.579999848734587e-05 │\n",
       "│ Train/PolicyStd               │ 0.2060147225856781    │\n",
       "│ TotalEnvSteps                 │ 731136.0              │\n",
       "│ Loss/Loss_pi                  │ -0.021127304062247276 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002256285399198532 │\n",
       "│ Value/Adv                     │ -0.1289450079202652   │\n",
       "│ Loss/Loss_reward_critic       │ 0.020344983786344528  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004473254084587097  │\n",
       "│ Value/reward                  │ 2.101320505142212     │\n",
       "│ Time/Total                    │ 4709.2490234375       │\n",
       "│ Time/Rollout                  │ 10.837739944458008    │\n",
       "│ Time/Update                   │ 1.7711641788482666    │\n",
       "│ Time/Epoch                    │ 12.608945846557617    │\n",
       "│ Time/FPS                      │ 162.4243621826172     │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.70852279663086     │\n",
       "│ Metrics/EpCost                │ 48.5                  │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 356.0                 │\n",
       "│ Train/Entropy                 │ -0.16175398230552673  │\n",
       "│ Train/KL                      │ 0.01567566953599453   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9987517595291138    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9987517595291138    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9987517595291138    │\n",
       "│ Train/PolicyRatio/Std         │ 0.021131426095962524  │\n",
       "│ Train/LR                      │ 8.579999848734587e-05 │\n",
       "│ Train/PolicyStd               │ 0.2060147225856781    │\n",
       "│ TotalEnvSteps                 │ 731136.0              │\n",
       "│ Loss/Loss_pi                  │ -0.021127304062247276 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002256285399198532 │\n",
       "│ Value/Adv                     │ -0.1289450079202652   │\n",
       "│ Loss/Loss_reward_critic       │ 0.020344983786344528  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004473254084587097  │\n",
       "│ Value/reward                  │ 2.101320505142212     │\n",
       "│ Time/Total                    │ 4709.2490234375       │\n",
       "│ Time/Rollout                  │ 10.837739944458008    │\n",
       "│ Time/Update                   │ 1.7711641788482666    │\n",
       "│ Time/Epoch                    │ 12.608945846557617    │\n",
       "│ Time/FPS                      │ 162.4243621826172     │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.019851684570312    │\n",
       "│ Metrics/EpCost                │ 47.65999984741211     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 357.0                 │\n",
       "│ Train/Entropy                 │ -0.1611045002937317   │\n",
       "│ Train/KL                      │ 0.016041168943047523  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9894202947616577    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9894202947616577    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9894202947616577    │\n",
       "│ Train/PolicyRatio/Std         │ 0.016259875148534775  │\n",
       "│ Train/LR                      │ 8.520000119460747e-05 │\n",
       "│ Train/PolicyStd               │ 0.2061431109905243    │\n",
       "│ TotalEnvSteps                 │ 733184.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01870613917708397  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002421164885163307  │\n",
       "│ Value/Adv                     │ 0.20753179490566254   │\n",
       "│ Loss/Loss_reward_critic       │ 0.021068494766950607  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0007235109806060791 │\n",
       "│ Value/reward                  │ 2.122659683227539     │\n",
       "│ Time/Total                    │ 4721.7900390625       │\n",
       "│ Time/Rollout                  │ 10.825972557067871    │\n",
       "│ Time/Update                   │ 1.7037386894226074    │\n",
       "│ Time/Epoch                    │ 12.529755592346191    │\n",
       "│ Time/FPS                      │ 163.45091247558594    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.019851684570312    │\n",
       "│ Metrics/EpCost                │ 47.65999984741211     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 357.0                 │\n",
       "│ Train/Entropy                 │ -0.1611045002937317   │\n",
       "│ Train/KL                      │ 0.016041168943047523  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9894202947616577    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9894202947616577    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9894202947616577    │\n",
       "│ Train/PolicyRatio/Std         │ 0.016259875148534775  │\n",
       "│ Train/LR                      │ 8.520000119460747e-05 │\n",
       "│ Train/PolicyStd               │ 0.2061431109905243    │\n",
       "│ TotalEnvSteps                 │ 733184.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01870613917708397  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002421164885163307  │\n",
       "│ Value/Adv                     │ 0.20753179490566254   │\n",
       "│ Loss/Loss_reward_critic       │ 0.021068494766950607  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0007235109806060791 │\n",
       "│ Value/reward                  │ 2.122659683227539     │\n",
       "│ Time/Total                    │ 4721.7900390625       │\n",
       "│ Time/Rollout                  │ 10.825972557067871    │\n",
       "│ Time/Update                   │ 1.7037386894226074    │\n",
       "│ Time/Epoch                    │ 12.529755592346191    │\n",
       "│ Time/FPS                      │ 163.45091247558594    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.59442710876465     │\n",
       "│ Metrics/EpCost                │ 46.08000183105469     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 358.0                 │\n",
       "│ Train/Entropy                 │ -0.1607351154088974   │\n",
       "│ Train/KL                      │ 0.012304103001952171  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.007165551185608     │\n",
       "│ Train/PolicyRatio/Min         │ 1.007165551185608     │\n",
       "│ Train/PolicyRatio/Max         │ 1.007165551185608     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017925260588526726  │\n",
       "│ Train/LR                      │ 8.459999662591144e-05 │\n",
       "│ Train/PolicyStd               │ 0.20618338882923126   │\n",
       "│ TotalEnvSteps                 │ 735232.0              │\n",
       "│ Loss/Loss_pi                  │ -0.012871472164988518 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005834667012095451  │\n",
       "│ Value/Adv                     │ -0.06291978061199188  │\n",
       "│ Loss/Loss_reward_critic       │ 0.011476108804345131  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.009592385962605476 │\n",
       "│ Value/reward                  │ 1.9351410865783691    │\n",
       "│ Time/Total                    │ 4734.34521484375      │\n",
       "│ Time/Rollout                  │ 10.860430717468262    │\n",
       "│ Time/Update                   │ 1.6828854084014893    │\n",
       "│ Time/Epoch                    │ 12.543375015258789    │\n",
       "│ Time/FPS                      │ 163.27345275878906    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.59442710876465     │\n",
       "│ Metrics/EpCost                │ 46.08000183105469     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 358.0                 │\n",
       "│ Train/Entropy                 │ -0.1607351154088974   │\n",
       "│ Train/KL                      │ 0.012304103001952171  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.007165551185608     │\n",
       "│ Train/PolicyRatio/Min         │ 1.007165551185608     │\n",
       "│ Train/PolicyRatio/Max         │ 1.007165551185608     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017925260588526726  │\n",
       "│ Train/LR                      │ 8.459999662591144e-05 │\n",
       "│ Train/PolicyStd               │ 0.20618338882923126   │\n",
       "│ TotalEnvSteps                 │ 735232.0              │\n",
       "│ Loss/Loss_pi                  │ -0.012871472164988518 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005834667012095451  │\n",
       "│ Value/Adv                     │ -0.06291978061199188  │\n",
       "│ Loss/Loss_reward_critic       │ 0.011476108804345131  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.009592385962605476 │\n",
       "│ Value/reward                  │ 1.9351410865783691    │\n",
       "│ Time/Total                    │ 4734.34521484375      │\n",
       "│ Time/Rollout                  │ 10.860430717468262    │\n",
       "│ Time/Update                   │ 1.6828854084014893    │\n",
       "│ Time/Epoch                    │ 12.543375015258789    │\n",
       "│ Time/FPS                      │ 163.27345275878906    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.40399932861328     │\n",
       "│ Metrics/EpCost                │ 46.29999923706055     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 359.0                 │\n",
       "│ Train/Entropy                 │ -0.1637604534626007   │\n",
       "│ Train/KL                      │ 0.008808206766843796  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0054614543914795    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0054614543914795    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0054614543914795    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01541447639465332   │\n",
       "│ Train/LR                      │ 8.399999933317304e-05 │\n",
       "│ Train/PolicyStd               │ 0.20553259551525116   │\n",
       "│ TotalEnvSteps                 │ 737280.0              │\n",
       "│ Loss/Loss_pi                  │ -0.011157740838825703 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.001713731326162815  │\n",
       "│ Value/Adv                     │ -0.21671338379383087  │\n",
       "│ Loss/Loss_reward_critic       │ 0.028433725237846375  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.016957616433501244  │\n",
       "│ Value/reward                  │ 1.8736637830734253    │\n",
       "│ Time/Total                    │ 4746.91796875         │\n",
       "│ Time/Rollout                  │ 10.851119041442871    │\n",
       "│ Time/Update                   │ 1.7099990844726562    │\n",
       "│ Time/Epoch                    │ 12.561163902282715    │\n",
       "│ Time/FPS                      │ 163.042236328125      │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.40399932861328     │\n",
       "│ Metrics/EpCost                │ 46.29999923706055     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 359.0                 │\n",
       "│ Train/Entropy                 │ -0.1637604534626007   │\n",
       "│ Train/KL                      │ 0.008808206766843796  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0054614543914795    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0054614543914795    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0054614543914795    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01541447639465332   │\n",
       "│ Train/LR                      │ 8.399999933317304e-05 │\n",
       "│ Train/PolicyStd               │ 0.20553259551525116   │\n",
       "│ TotalEnvSteps                 │ 737280.0              │\n",
       "│ Loss/Loss_pi                  │ -0.011157740838825703 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.001713731326162815  │\n",
       "│ Value/Adv                     │ -0.21671338379383087  │\n",
       "│ Loss/Loss_reward_critic       │ 0.028433725237846375  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.016957616433501244  │\n",
       "│ Value/reward                  │ 1.8736637830734253    │\n",
       "│ Time/Total                    │ 4746.91796875         │\n",
       "│ Time/Rollout                  │ 10.851119041442871    │\n",
       "│ Time/Update                   │ 1.7099990844726562    │\n",
       "│ Time/Epoch                    │ 12.561163902282715    │\n",
       "│ Time/FPS                      │ 163.042236328125      │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.429115295410156    │\n",
       "│ Metrics/EpCost                │ 47.599998474121094    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 360.0                 │\n",
       "│ Train/Entropy                 │ -0.16724397242069244  │\n",
       "│ Train/KL                      │ 0.0138345742598176    │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.999856173992157     │\n",
       "│ Train/PolicyRatio/Min         │ 0.999856173992157     │\n",
       "│ Train/PolicyRatio/Max         │ 0.999856173992157     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017786884680390358  │\n",
       "│ Train/LR                      │ 8.340000204043463e-05 │\n",
       "│ Train/PolicyStd               │ 0.20482341945171356   │\n",
       "│ TotalEnvSteps                 │ 739328.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01630270481109619  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.005144963972270489 │\n",
       "│ Value/Adv                     │ -0.07295135408639908  │\n",
       "│ Loss/Loss_reward_critic       │ 0.02299235388636589   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005441371351480484 │\n",
       "│ Value/reward                  │ 2.0706892013549805    │\n",
       "│ Time/Total                    │ 4759.42333984375      │\n",
       "│ Time/Rollout                  │ 10.812782287597656    │\n",
       "│ Time/Update                   │ 1.6771717071533203    │\n",
       "│ Time/Epoch                    │ 12.489996910095215    │\n",
       "│ Time/FPS                      │ 163.97122192382812    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.429115295410156    │\n",
       "│ Metrics/EpCost                │ 47.599998474121094    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 360.0                 │\n",
       "│ Train/Entropy                 │ -0.16724397242069244  │\n",
       "│ Train/KL                      │ 0.0138345742598176    │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.999856173992157     │\n",
       "│ Train/PolicyRatio/Min         │ 0.999856173992157     │\n",
       "│ Train/PolicyRatio/Max         │ 0.999856173992157     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017786884680390358  │\n",
       "│ Train/LR                      │ 8.340000204043463e-05 │\n",
       "│ Train/PolicyStd               │ 0.20482341945171356   │\n",
       "│ TotalEnvSteps                 │ 739328.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01630270481109619  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.005144963972270489 │\n",
       "│ Value/Adv                     │ -0.07295135408639908  │\n",
       "│ Loss/Loss_reward_critic       │ 0.02299235388636589   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005441371351480484 │\n",
       "│ Value/reward                  │ 2.0706892013549805    │\n",
       "│ Time/Total                    │ 4759.42333984375      │\n",
       "│ Time/Rollout                  │ 10.812782287597656    │\n",
       "│ Time/Update                   │ 1.6771717071533203    │\n",
       "│ Time/Epoch                    │ 12.489996910095215    │\n",
       "│ Time/FPS                      │ 163.97122192382812    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.436988830566406    │\n",
       "│ Metrics/EpCost                │ 48.65999984741211     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 361.0                 │\n",
       "│ Train/Entropy                 │ -0.1704370230436325   │\n",
       "│ Train/KL                      │ 0.01585213653743267   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0018993616104126    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0018993616104126    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0018993616104126    │\n",
       "│ Train/PolicyRatio/Std         │ 0.018056288361549377  │\n",
       "│ Train/LR                      │ 8.27999974717386e-05  │\n",
       "│ Train/PolicyStd               │ 0.20417830348014832   │\n",
       "│ TotalEnvSteps                 │ 741376.0              │\n",
       "│ Loss/Loss_pi                  │ -0.023137683048844337 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.006834978237748146 │\n",
       "│ Value/Adv                     │ -0.09630557894706726  │\n",
       "│ Loss/Loss_reward_critic       │ 0.018809642642736435  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.004182711243629456 │\n",
       "│ Value/reward                  │ 2.153188943862915     │\n",
       "│ Time/Total                    │ 4772.03662109375      │\n",
       "│ Time/Rollout                  │ 10.831196784973145    │\n",
       "│ Time/Update                   │ 1.7706286907196045    │\n",
       "│ Time/Epoch                    │ 12.601873397827148    │\n",
       "│ Time/FPS                      │ 162.51551818847656    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.436988830566406    │\n",
       "│ Metrics/EpCost                │ 48.65999984741211     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 361.0                 │\n",
       "│ Train/Entropy                 │ -0.1704370230436325   │\n",
       "│ Train/KL                      │ 0.01585213653743267   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0018993616104126    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0018993616104126    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0018993616104126    │\n",
       "│ Train/PolicyRatio/Std         │ 0.018056288361549377  │\n",
       "│ Train/LR                      │ 8.27999974717386e-05  │\n",
       "│ Train/PolicyStd               │ 0.20417830348014832   │\n",
       "│ TotalEnvSteps                 │ 741376.0              │\n",
       "│ Loss/Loss_pi                  │ -0.023137683048844337 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.006834978237748146 │\n",
       "│ Value/Adv                     │ -0.09630557894706726  │\n",
       "│ Loss/Loss_reward_critic       │ 0.018809642642736435  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.004182711243629456 │\n",
       "│ Value/reward                  │ 2.153188943862915     │\n",
       "│ Time/Total                    │ 4772.03662109375      │\n",
       "│ Time/Rollout                  │ 10.831196784973145    │\n",
       "│ Time/Update                   │ 1.7706286907196045    │\n",
       "│ Time/Epoch                    │ 12.601873397827148    │\n",
       "│ Time/FPS                      │ 162.51551818847656    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.512001037597656    │\n",
       "│ Metrics/EpCost                │ 48.040000915527344    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 362.0                 │\n",
       "│ Train/Entropy                 │ -0.1711745262145996   │\n",
       "│ Train/KL                      │ 0.010823904536664486  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0075271129608154    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0075271129608154    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0075271129608154    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01558756921440363   │\n",
       "│ Train/LR                      │ 8.22000001790002e-05  │\n",
       "│ Train/PolicyStd               │ 0.20401176810264587   │\n",
       "│ TotalEnvSteps                 │ 743424.0              │\n",
       "│ Loss/Loss_pi                  │ -0.00869295559823513  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.014444727450609207  │\n",
       "│ Value/Adv                     │ -0.09582746028900146  │\n",
       "│ Loss/Loss_reward_critic       │ 0.01586684212088585   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.002942800521850586 │\n",
       "│ Value/reward                  │ 2.0231688022613525    │\n",
       "│ Time/Total                    │ 4784.6875             │\n",
       "│ Time/Rollout                  │ 10.906514167785645    │\n",
       "│ Time/Update                   │ 1.7325153350830078    │\n",
       "│ Time/Epoch                    │ 12.639069557189941    │\n",
       "│ Time/FPS                      │ 162.03724670410156    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.512001037597656    │\n",
       "│ Metrics/EpCost                │ 48.040000915527344    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 362.0                 │\n",
       "│ Train/Entropy                 │ -0.1711745262145996   │\n",
       "│ Train/KL                      │ 0.010823904536664486  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0075271129608154    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0075271129608154    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0075271129608154    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01558756921440363   │\n",
       "│ Train/LR                      │ 8.22000001790002e-05  │\n",
       "│ Train/PolicyStd               │ 0.20401176810264587   │\n",
       "│ TotalEnvSteps                 │ 743424.0              │\n",
       "│ Loss/Loss_pi                  │ -0.00869295559823513  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.014444727450609207  │\n",
       "│ Value/Adv                     │ -0.09582746028900146  │\n",
       "│ Loss/Loss_reward_critic       │ 0.01586684212088585   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.002942800521850586 │\n",
       "│ Value/reward                  │ 2.0231688022613525    │\n",
       "│ Time/Total                    │ 4784.6875             │\n",
       "│ Time/Rollout                  │ 10.906514167785645    │\n",
       "│ Time/Update                   │ 1.7325153350830078    │\n",
       "│ Time/Epoch                    │ 12.639069557189941    │\n",
       "│ Time/FPS                      │ 162.03724670410156    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.577808380126953    │\n",
       "│ Metrics/EpCost                │ 49.2400016784668      │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 363.0                 │\n",
       "│ Train/Entropy                 │ -0.1727527379989624   │\n",
       "│ Train/KL                      │ 0.015684686601161957  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.998853325843811     │\n",
       "│ Train/PolicyRatio/Min         │ 0.998853325843811     │\n",
       "│ Train/PolicyRatio/Max         │ 0.998853325843811     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017977822571992874  │\n",
       "│ Train/LR                      │ 8.160000288626179e-05 │\n",
       "│ Train/PolicyStd               │ 0.20367614924907684   │\n",
       "│ TotalEnvSteps                 │ 745472.0              │\n",
       "│ Loss/Loss_pi                  │ -0.018011117354035378 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.009318161755800247 │\n",
       "│ Value/Adv                     │ -0.1923469603061676   │\n",
       "│ Loss/Loss_reward_critic       │ 0.016910944133996964  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0010441020131111145 │\n",
       "│ Value/reward                  │ 2.192643880844116     │\n",
       "│ Time/Total                    │ 4797.28857421875      │\n",
       "│ Time/Rollout                  │ 10.842669486999512    │\n",
       "│ Time/Update                   │ 1.744013786315918     │\n",
       "│ Time/Epoch                    │ 12.586729049682617    │\n",
       "│ Time/FPS                      │ 162.71107482910156    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.577808380126953    │\n",
       "│ Metrics/EpCost                │ 49.2400016784668      │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 363.0                 │\n",
       "│ Train/Entropy                 │ -0.1727527379989624   │\n",
       "│ Train/KL                      │ 0.015684686601161957  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.998853325843811     │\n",
       "│ Train/PolicyRatio/Min         │ 0.998853325843811     │\n",
       "│ Train/PolicyRatio/Max         │ 0.998853325843811     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017977822571992874  │\n",
       "│ Train/LR                      │ 8.160000288626179e-05 │\n",
       "│ Train/PolicyStd               │ 0.20367614924907684   │\n",
       "│ TotalEnvSteps                 │ 745472.0              │\n",
       "│ Loss/Loss_pi                  │ -0.018011117354035378 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.009318161755800247 │\n",
       "│ Value/Adv                     │ -0.1923469603061676   │\n",
       "│ Loss/Loss_reward_critic       │ 0.016910944133996964  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0010441020131111145 │\n",
       "│ Value/reward                  │ 2.192643880844116     │\n",
       "│ Time/Total                    │ 4797.28857421875      │\n",
       "│ Time/Rollout                  │ 10.842669486999512    │\n",
       "│ Time/Update                   │ 1.744013786315918     │\n",
       "│ Time/Epoch                    │ 12.586729049682617    │\n",
       "│ Time/FPS                      │ 162.71107482910156    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.472103118896484     │\n",
       "│ Metrics/EpCost                │ 49.02000045776367      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 364.0                  │\n",
       "│ Train/Entropy                 │ -0.17494402825832367   │\n",
       "│ Train/KL                      │ 0.01593082584440708    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0026851892471313     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0026851892471313     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0026851892471313     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01797575131058693    │\n",
       "│ Train/LR                      │ 8.099999831756577e-05  │\n",
       "│ Train/PolicyStd               │ 0.20322541892528534    │\n",
       "│ TotalEnvSteps                 │ 747520.0               │\n",
       "│ Loss/Loss_pi                  │ -0.02253669872879982   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0045255813747644424 │\n",
       "│ Value/Adv                     │ -0.19519555568695068   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015588367357850075   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0013225767761468887 │\n",
       "│ Value/reward                  │ 2.127645254135132      │\n",
       "│ Time/Total                    │ 4809.87548828125       │\n",
       "│ Time/Rollout                  │ 10.844524383544922     │\n",
       "│ Time/Update                   │ 1.7308306694030762     │\n",
       "│ Time/Epoch                    │ 12.575399398803711     │\n",
       "│ Time/FPS                      │ 162.85765075683594     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.472103118896484     │\n",
       "│ Metrics/EpCost                │ 49.02000045776367      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 364.0                  │\n",
       "│ Train/Entropy                 │ -0.17494402825832367   │\n",
       "│ Train/KL                      │ 0.01593082584440708    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0026851892471313     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0026851892471313     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0026851892471313     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01797575131058693    │\n",
       "│ Train/LR                      │ 8.099999831756577e-05  │\n",
       "│ Train/PolicyStd               │ 0.20322541892528534    │\n",
       "│ TotalEnvSteps                 │ 747520.0               │\n",
       "│ Loss/Loss_pi                  │ -0.02253669872879982   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0045255813747644424 │\n",
       "│ Value/Adv                     │ -0.19519555568695068   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015588367357850075   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0013225767761468887 │\n",
       "│ Value/reward                  │ 2.127645254135132      │\n",
       "│ Time/Total                    │ 4809.87548828125       │\n",
       "│ Time/Rollout                  │ 10.844524383544922     │\n",
       "│ Time/Update                   │ 1.7308306694030762     │\n",
       "│ Time/Epoch                    │ 12.575399398803711     │\n",
       "│ Time/FPS                      │ 162.85765075683594     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.534893035888672    │\n",
       "│ Metrics/EpCost                │ 49.619998931884766    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 365.0                 │\n",
       "│ Train/Entropy                 │ -0.17662787437438965  │\n",
       "│ Train/KL                      │ 0.01165403425693512   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9998372197151184    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9998372197151184    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9998372197151184    │\n",
       "│ Train/PolicyRatio/Std         │ 0.016262074932456017  │\n",
       "│ Train/LR                      │ 8.040000102482736e-05 │\n",
       "│ Train/PolicyStd               │ 0.20288912951946259   │\n",
       "│ TotalEnvSteps                 │ 749568.0              │\n",
       "│ Loss/Loss_pi                  │ -0.015473239123821259 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.007063459604978561  │\n",
       "│ Value/Adv                     │ 0.07756415009498596   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02425689622759819   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.008668528869748116  │\n",
       "│ Value/reward                  │ 2.1763200759887695    │\n",
       "│ Time/Total                    │ 4822.39599609375      │\n",
       "│ Time/Rollout                  │ 10.824888229370117    │\n",
       "│ Time/Update                   │ 1.6839714050292969    │\n",
       "│ Time/Epoch                    │ 12.508901596069336    │\n",
       "│ Time/FPS                      │ 163.72340393066406    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.534893035888672    │\n",
       "│ Metrics/EpCost                │ 49.619998931884766    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 365.0                 │\n",
       "│ Train/Entropy                 │ -0.17662787437438965  │\n",
       "│ Train/KL                      │ 0.01165403425693512   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9998372197151184    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9998372197151184    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9998372197151184    │\n",
       "│ Train/PolicyRatio/Std         │ 0.016262074932456017  │\n",
       "│ Train/LR                      │ 8.040000102482736e-05 │\n",
       "│ Train/PolicyStd               │ 0.20288912951946259   │\n",
       "│ TotalEnvSteps                 │ 749568.0              │\n",
       "│ Loss/Loss_pi                  │ -0.015473239123821259 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.007063459604978561  │\n",
       "│ Value/Adv                     │ 0.07756415009498596   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02425689622759819   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.008668528869748116  │\n",
       "│ Value/reward                  │ 2.1763200759887695    │\n",
       "│ Time/Total                    │ 4822.39599609375      │\n",
       "│ Time/Rollout                  │ 10.824888229370117    │\n",
       "│ Time/Update                   │ 1.6839714050292969    │\n",
       "│ Time/Epoch                    │ 12.508901596069336    │\n",
       "│ Time/FPS                      │ 163.72340393066406    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.51852798461914     │\n",
       "│ Metrics/EpCost                │ 50.68000030517578     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 366.0                 │\n",
       "│ Train/Entropy                 │ -0.17899326980113983  │\n",
       "│ Train/KL                      │ 0.017393210902810097  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9985885620117188    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9985885620117188    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9985885620117188    │\n",
       "│ Train/PolicyRatio/Std         │ 0.020420536398887634  │\n",
       "│ Train/LR                      │ 7.979999645613134e-05 │\n",
       "│ Train/PolicyStd               │ 0.2024221420288086    │\n",
       "│ TotalEnvSteps                 │ 751616.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01954897865653038  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004075739532709122 │\n",
       "│ Value/Adv                     │ -0.013099923729896545 │\n",
       "│ Loss/Loss_reward_critic       │ 0.01500450074672699   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0092523954808712   │\n",
       "│ Value/reward                  │ 2.114509344100952     │\n",
       "│ Time/Total                    │ 4834.974609375        │\n",
       "│ Time/Rollout                  │ 10.884897232055664    │\n",
       "│ Time/Update                   │ 1.682088851928711     │\n",
       "│ Time/Epoch                    │ 12.56702995300293     │\n",
       "│ Time/FPS                      │ 162.96612548828125    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.51852798461914     │\n",
       "│ Metrics/EpCost                │ 50.68000030517578     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 366.0                 │\n",
       "│ Train/Entropy                 │ -0.17899326980113983  │\n",
       "│ Train/KL                      │ 0.017393210902810097  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9985885620117188    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9985885620117188    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9985885620117188    │\n",
       "│ Train/PolicyRatio/Std         │ 0.020420536398887634  │\n",
       "│ Train/LR                      │ 7.979999645613134e-05 │\n",
       "│ Train/PolicyStd               │ 0.2024221420288086    │\n",
       "│ TotalEnvSteps                 │ 751616.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01954897865653038  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004075739532709122 │\n",
       "│ Value/Adv                     │ -0.013099923729896545 │\n",
       "│ Loss/Loss_reward_critic       │ 0.01500450074672699   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0092523954808712   │\n",
       "│ Value/reward                  │ 2.114509344100952     │\n",
       "│ Time/Total                    │ 4834.974609375        │\n",
       "│ Time/Rollout                  │ 10.884897232055664    │\n",
       "│ Time/Update                   │ 1.682088851928711     │\n",
       "│ Time/Epoch                    │ 12.56702995300293     │\n",
       "│ Time/FPS                      │ 162.96612548828125    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.412097930908203    │\n",
       "│ Metrics/EpCost                │ 51.099998474121094    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 367.0                 │\n",
       "│ Train/Entropy                 │ -0.18098746240139008  │\n",
       "│ Train/KL                      │ 0.01503919716924429   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9973065257072449    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9973065257072449    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9973065257072449    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01700553111732006   │\n",
       "│ Train/LR                      │ 7.919999916339293e-05 │\n",
       "│ Train/PolicyStd               │ 0.20200295746326447   │\n",
       "│ TotalEnvSteps                 │ 753664.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01740378886461258  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002145189791917801  │\n",
       "│ Value/Adv                     │ 0.2695373594760895    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01055559515953064   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00444890558719635  │\n",
       "│ Value/reward                  │ 2.0802736282348633    │\n",
       "│ Time/Total                    │ 4847.53173828125      │\n",
       "│ Time/Rollout                  │ 10.85828685760498     │\n",
       "│ Time/Update                   │ 1.687427282333374     │\n",
       "│ Time/Epoch                    │ 12.545758247375488    │\n",
       "│ Time/FPS                      │ 163.242431640625      │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.412097930908203    │\n",
       "│ Metrics/EpCost                │ 51.099998474121094    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 367.0                 │\n",
       "│ Train/Entropy                 │ -0.18098746240139008  │\n",
       "│ Train/KL                      │ 0.01503919716924429   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9973065257072449    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9973065257072449    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9973065257072449    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01700553111732006   │\n",
       "│ Train/LR                      │ 7.919999916339293e-05 │\n",
       "│ Train/PolicyStd               │ 0.20200295746326447   │\n",
       "│ TotalEnvSteps                 │ 753664.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01740378886461258  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002145189791917801  │\n",
       "│ Value/Adv                     │ 0.2695373594760895    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01055559515953064   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00444890558719635  │\n",
       "│ Value/reward                  │ 2.0802736282348633    │\n",
       "│ Time/Total                    │ 4847.53173828125      │\n",
       "│ Time/Rollout                  │ 10.85828685760498     │\n",
       "│ Time/Update                   │ 1.687427282333374     │\n",
       "│ Time/Epoch                    │ 12.545758247375488    │\n",
       "│ Time/FPS                      │ 163.242431640625      │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.419219970703125     │\n",
       "│ Metrics/EpCost                │ 51.560001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 368.0                  │\n",
       "│ Train/Entropy                 │ -0.18190190196037292   │\n",
       "│ Train/KL                      │ 0.016949063166975975   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9906862378120422     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9906862378120422     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9906862378120422     │\n",
       "│ Train/PolicyRatio/Std         │ 0.021021321415901184   │\n",
       "│ Train/LR                      │ 7.860000187065452e-05  │\n",
       "│ Train/PolicyStd               │ 0.20181019604206085    │\n",
       "│ TotalEnvSteps                 │ 755712.0               │\n",
       "│ Loss/Loss_pi                  │ -0.02078884281218052   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0033850539475679398 │\n",
       "│ Value/Adv                     │ -0.057581886649131775  │\n",
       "│ Loss/Loss_reward_critic       │ 0.014608124271035194   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004052529111504555   │\n",
       "│ Value/reward                  │ 2.0896759033203125     │\n",
       "│ Time/Total                    │ 4860.10595703125       │\n",
       "│ Time/Rollout                  │ 10.845318794250488     │\n",
       "│ Time/Update                   │ 1.7178270816802979     │\n",
       "│ Time/Epoch                    │ 12.563209533691406     │\n",
       "│ Time/FPS                      │ 163.01568603515625     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.419219970703125     │\n",
       "│ Metrics/EpCost                │ 51.560001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 368.0                  │\n",
       "│ Train/Entropy                 │ -0.18190190196037292   │\n",
       "│ Train/KL                      │ 0.016949063166975975   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9906862378120422     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9906862378120422     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9906862378120422     │\n",
       "│ Train/PolicyRatio/Std         │ 0.021021321415901184   │\n",
       "│ Train/LR                      │ 7.860000187065452e-05  │\n",
       "│ Train/PolicyStd               │ 0.20181019604206085    │\n",
       "│ TotalEnvSteps                 │ 755712.0               │\n",
       "│ Loss/Loss_pi                  │ -0.02078884281218052   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0033850539475679398 │\n",
       "│ Value/Adv                     │ -0.057581886649131775  │\n",
       "│ Loss/Loss_reward_critic       │ 0.014608124271035194   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004052529111504555   │\n",
       "│ Value/reward                  │ 2.0896759033203125     │\n",
       "│ Time/Total                    │ 4860.10595703125       │\n",
       "│ Time/Rollout                  │ 10.845318794250488     │\n",
       "│ Time/Update                   │ 1.7178270816802979     │\n",
       "│ Time/Epoch                    │ 12.563209533691406     │\n",
       "│ Time/FPS                      │ 163.01568603515625     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.367887496948242    │\n",
       "│ Metrics/EpCost                │ 52.099998474121094    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 369.0                 │\n",
       "│ Train/Entropy                 │ -0.18364217877388     │\n",
       "│ Train/KL                      │ 0.014013906009495258  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9988188743591309    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9988188743591309    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9988188743591309    │\n",
       "│ Train/PolicyRatio/Std         │ 0.016543442383408546  │\n",
       "│ Train/LR                      │ 7.79999973019585e-05  │\n",
       "│ Train/PolicyStd               │ 0.2014731466770172    │\n",
       "│ TotalEnvSteps                 │ 757760.0              │\n",
       "│ Loss/Loss_pi                  │ -0.017525451257824898 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0032633915543556213 │\n",
       "│ Value/Adv                     │ 0.06838038563728333   │\n",
       "│ Loss/Loss_reward_critic       │ 0.011922081001102924  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00268604326993227  │\n",
       "│ Value/reward                  │ 2.168498992919922     │\n",
       "│ Time/Total                    │ 4872.6748046875       │\n",
       "│ Time/Rollout                  │ 10.86985969543457     │\n",
       "│ Time/Update                   │ 1.6872332096099854    │\n",
       "│ Time/Epoch                    │ 12.55713939666748     │\n",
       "│ Time/FPS                      │ 163.094482421875      │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.367887496948242    │\n",
       "│ Metrics/EpCost                │ 52.099998474121094    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 369.0                 │\n",
       "│ Train/Entropy                 │ -0.18364217877388     │\n",
       "│ Train/KL                      │ 0.014013906009495258  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9988188743591309    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9988188743591309    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9988188743591309    │\n",
       "│ Train/PolicyRatio/Std         │ 0.016543442383408546  │\n",
       "│ Train/LR                      │ 7.79999973019585e-05  │\n",
       "│ Train/PolicyStd               │ 0.2014731466770172    │\n",
       "│ TotalEnvSteps                 │ 757760.0              │\n",
       "│ Loss/Loss_pi                  │ -0.017525451257824898 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0032633915543556213 │\n",
       "│ Value/Adv                     │ 0.06838038563728333   │\n",
       "│ Loss/Loss_reward_critic       │ 0.011922081001102924  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00268604326993227  │\n",
       "│ Value/reward                  │ 2.168498992919922     │\n",
       "│ Time/Total                    │ 4872.6748046875       │\n",
       "│ Time/Rollout                  │ 10.86985969543457     │\n",
       "│ Time/Update                   │ 1.6872332096099854    │\n",
       "│ Time/Epoch                    │ 12.55713939666748     │\n",
       "│ Time/FPS                      │ 163.094482421875      │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.3703556060791      │\n",
       "│ Metrics/EpCost                │ 51.2599983215332      │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 370.0                 │\n",
       "│ Train/Entropy                 │ -0.18658608198165894  │\n",
       "│ Train/KL                      │ 0.01278857421129942   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9988623857498169    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9988623857498169    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9988623857498169    │\n",
       "│ Train/PolicyRatio/Std         │ 0.0206639114767313    │\n",
       "│ Train/LR                      │ 7.74000000092201e-05  │\n",
       "│ Train/PolicyStd               │ 0.20089617371559143   │\n",
       "│ TotalEnvSteps                 │ 759808.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01612776890397072  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0013976823538541794 │\n",
       "│ Value/Adv                     │ 0.06351551413536072   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01486972440034151   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0029476433992385864 │\n",
       "│ Value/reward                  │ 2.1191394329071045    │\n",
       "│ Time/Total                    │ 4885.2119140625       │\n",
       "│ Time/Rollout                  │ 10.82462215423584     │\n",
       "│ Time/Update                   │ 1.6987700462341309    │\n",
       "│ Time/Epoch                    │ 12.523433685302734    │\n",
       "│ Time/FPS                      │ 163.53343200683594    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.3703556060791      │\n",
       "│ Metrics/EpCost                │ 51.2599983215332      │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 370.0                 │\n",
       "│ Train/Entropy                 │ -0.18658608198165894  │\n",
       "│ Train/KL                      │ 0.01278857421129942   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9988623857498169    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9988623857498169    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9988623857498169    │\n",
       "│ Train/PolicyRatio/Std         │ 0.0206639114767313    │\n",
       "│ Train/LR                      │ 7.74000000092201e-05  │\n",
       "│ Train/PolicyStd               │ 0.20089617371559143   │\n",
       "│ TotalEnvSteps                 │ 759808.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01612776890397072  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0013976823538541794 │\n",
       "│ Value/Adv                     │ 0.06351551413536072   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01486972440034151   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0029476433992385864 │\n",
       "│ Value/reward                  │ 2.1191394329071045    │\n",
       "│ Time/Total                    │ 4885.2119140625       │\n",
       "│ Time/Rollout                  │ 10.82462215423584     │\n",
       "│ Time/Update                   │ 1.6987700462341309    │\n",
       "│ Time/Epoch                    │ 12.523433685302734    │\n",
       "│ Time/FPS                      │ 163.53343200683594    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.521814346313477     │\n",
       "│ Metrics/EpCost                │ 50.47999954223633      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 371.0                  │\n",
       "│ Train/Entropy                 │ -0.1909211128950119    │\n",
       "│ Train/KL                      │ 0.01276836171746254    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9987486004829407     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9987486004829407     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9987486004829407     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01755264587700367    │\n",
       "│ Train/LR                      │ 7.680000271648169e-05  │\n",
       "│ Train/PolicyStd               │ 0.20004291832447052    │\n",
       "│ TotalEnvSteps                 │ 761856.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018188418820500374  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0020606499165296555 │\n",
       "│ Value/Adv                     │ 0.2889469861984253     │\n",
       "│ Loss/Loss_reward_critic       │ 0.01860886439681053    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.003739139996469021   │\n",
       "│ Value/reward                  │ 2.198554754257202      │\n",
       "│ Time/Total                    │ 4897.80322265625       │\n",
       "│ Time/Rollout                  │ 10.8719482421875       │\n",
       "│ Time/Update                   │ 1.7054078578948975     │\n",
       "│ Time/Epoch                    │ 12.577401161193848     │\n",
       "│ Time/FPS                      │ 162.8317413330078      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.521814346313477     │\n",
       "│ Metrics/EpCost                │ 50.47999954223633      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 371.0                  │\n",
       "│ Train/Entropy                 │ -0.1909211128950119    │\n",
       "│ Train/KL                      │ 0.01276836171746254    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9987486004829407     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9987486004829407     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9987486004829407     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01755264587700367    │\n",
       "│ Train/LR                      │ 7.680000271648169e-05  │\n",
       "│ Train/PolicyStd               │ 0.20004291832447052    │\n",
       "│ TotalEnvSteps                 │ 761856.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018188418820500374  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0020606499165296555 │\n",
       "│ Value/Adv                     │ 0.2889469861984253     │\n",
       "│ Loss/Loss_reward_critic       │ 0.01860886439681053    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.003739139996469021   │\n",
       "│ Value/reward                  │ 2.198554754257202      │\n",
       "│ Time/Total                    │ 4897.80322265625       │\n",
       "│ Time/Rollout                  │ 10.8719482421875       │\n",
       "│ Time/Update                   │ 1.7054078578948975     │\n",
       "│ Time/Epoch                    │ 12.577401161193848     │\n",
       "│ Time/FPS                      │ 162.8317413330078      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.5916748046875       │\n",
       "│ Metrics/EpCost                │ 52.20000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 372.0                  │\n",
       "│ Train/Entropy                 │ -0.1937503069639206    │\n",
       "│ Train/KL                      │ 0.01489785686135292    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9944798350334167     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9944798350334167     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9944798350334167     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01775444485247135    │\n",
       "│ Train/LR                      │ 7.619999814778566e-05  │\n",
       "│ Train/PolicyStd               │ 0.19947801530361176    │\n",
       "│ TotalEnvSteps                 │ 763904.0               │\n",
       "│ Loss/Loss_pi                  │ -0.02062162570655346   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0024332068860530853 │\n",
       "│ Value/Adv                     │ 0.08848915994167328    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017145927995443344   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0014629364013671875 │\n",
       "│ Value/reward                  │ 2.1210222244262695     │\n",
       "│ Time/Total                    │ 4910.36572265625       │\n",
       "│ Time/Rollout                  │ 10.863065719604492     │\n",
       "│ Time/Update                   │ 1.6878643035888672     │\n",
       "│ Time/Epoch                    │ 12.550973892211914     │\n",
       "│ Time/FPS                      │ 163.17459106445312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.5916748046875       │\n",
       "│ Metrics/EpCost                │ 52.20000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 372.0                  │\n",
       "│ Train/Entropy                 │ -0.1937503069639206    │\n",
       "│ Train/KL                      │ 0.01489785686135292    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9944798350334167     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9944798350334167     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9944798350334167     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01775444485247135    │\n",
       "│ Train/LR                      │ 7.619999814778566e-05  │\n",
       "│ Train/PolicyStd               │ 0.19947801530361176    │\n",
       "│ TotalEnvSteps                 │ 763904.0               │\n",
       "│ Loss/Loss_pi                  │ -0.02062162570655346   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0024332068860530853 │\n",
       "│ Value/Adv                     │ 0.08848915994167328    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017145927995443344   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0014629364013671875 │\n",
       "│ Value/reward                  │ 2.1210222244262695     │\n",
       "│ Time/Total                    │ 4910.36572265625       │\n",
       "│ Time/Rollout                  │ 10.863065719604492     │\n",
       "│ Time/Update                   │ 1.6878643035888672     │\n",
       "│ Time/Epoch                    │ 12.550973892211914     │\n",
       "│ Time/FPS                      │ 163.17459106445312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.610361099243164     │\n",
       "│ Metrics/EpCost                │ 51.18000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 373.0                  │\n",
       "│ Train/Entropy                 │ -0.1936957985162735    │\n",
       "│ Train/KL                      │ 0.014629561454057693   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9982526898384094     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9982526898384094     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9982526898384094     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018171407282352448   │\n",
       "│ Train/LR                      │ 7.560000085504726e-05  │\n",
       "│ Train/PolicyStd               │ 0.19948618113994598    │\n",
       "│ TotalEnvSteps                 │ 765952.0               │\n",
       "│ Loss/Loss_pi                  │ -0.020981423556804657  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0003597978502511978 │\n",
       "│ Value/Adv                     │ -0.11446873843669891   │\n",
       "│ Loss/Loss_reward_critic       │ 0.024302227422595024   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00715629942715168    │\n",
       "│ Value/reward                  │ 2.183867931365967      │\n",
       "│ Time/Total                    │ 4922.94091796875       │\n",
       "│ Time/Rollout                  │ 10.835481643676758     │\n",
       "│ Time/Update                   │ 1.7276942729949951     │\n",
       "│ Time/Epoch                    │ 12.563222885131836     │\n",
       "│ Time/FPS                      │ 163.0155029296875      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.610361099243164     │\n",
       "│ Metrics/EpCost                │ 51.18000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 373.0                  │\n",
       "│ Train/Entropy                 │ -0.1936957985162735    │\n",
       "│ Train/KL                      │ 0.014629561454057693   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9982526898384094     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9982526898384094     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9982526898384094     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018171407282352448   │\n",
       "│ Train/LR                      │ 7.560000085504726e-05  │\n",
       "│ Train/PolicyStd               │ 0.19948618113994598    │\n",
       "│ TotalEnvSteps                 │ 765952.0               │\n",
       "│ Loss/Loss_pi                  │ -0.020981423556804657  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0003597978502511978 │\n",
       "│ Value/Adv                     │ -0.11446873843669891   │\n",
       "│ Loss/Loss_reward_critic       │ 0.024302227422595024   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00715629942715168    │\n",
       "│ Value/reward                  │ 2.183867931365967      │\n",
       "│ Time/Total                    │ 4922.94091796875       │\n",
       "│ Time/Rollout                  │ 10.835481643676758     │\n",
       "│ Time/Update                   │ 1.7276942729949951     │\n",
       "│ Time/Epoch                    │ 12.563222885131836     │\n",
       "│ Time/FPS                      │ 163.0155029296875      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.583032608032227    │\n",
       "│ Metrics/EpCost                │ 51.36000061035156     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 374.0                 │\n",
       "│ Train/Entropy                 │ -0.19393697381019592  │\n",
       "│ Train/KL                      │ 0.013029251247644424  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9942175149917603    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9942175149917603    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9942175149917603    │\n",
       "│ Train/PolicyRatio/Std         │ 0.017548339441418648  │\n",
       "│ Train/LR                      │ 7.500000356230885e-05 │\n",
       "│ Train/PolicyStd               │ 0.1994142085313797    │\n",
       "│ TotalEnvSteps                 │ 768000.0              │\n",
       "│ Loss/Loss_pi                  │ -0.015650201588869095 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005331221967935562  │\n",
       "│ Value/Adv                     │ -0.14231663942337036  │\n",
       "│ Loss/Loss_reward_critic       │ 0.013155022636055946  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.011147204786539078 │\n",
       "│ Value/reward                  │ 2.1654903888702393    │\n",
       "│ Time/Total                    │ 4935.4736328125       │\n",
       "│ Time/Rollout                  │ 10.822784423828125    │\n",
       "│ Time/Update                   │ 1.6983046531677246    │\n",
       "│ Time/Epoch                    │ 12.521132469177246    │\n",
       "│ Time/FPS                      │ 163.56349182128906    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.583032608032227    │\n",
       "│ Metrics/EpCost                │ 51.36000061035156     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 374.0                 │\n",
       "│ Train/Entropy                 │ -0.19393697381019592  │\n",
       "│ Train/KL                      │ 0.013029251247644424  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9942175149917603    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9942175149917603    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9942175149917603    │\n",
       "│ Train/PolicyRatio/Std         │ 0.017548339441418648  │\n",
       "│ Train/LR                      │ 7.500000356230885e-05 │\n",
       "│ Train/PolicyStd               │ 0.1994142085313797    │\n",
       "│ TotalEnvSteps                 │ 768000.0              │\n",
       "│ Loss/Loss_pi                  │ -0.015650201588869095 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005331221967935562  │\n",
       "│ Value/Adv                     │ -0.14231663942337036  │\n",
       "│ Loss/Loss_reward_critic       │ 0.013155022636055946  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.011147204786539078 │\n",
       "│ Value/reward                  │ 2.1654903888702393    │\n",
       "│ Time/Total                    │ 4935.4736328125       │\n",
       "│ Time/Rollout                  │ 10.822784423828125    │\n",
       "│ Time/Update                   │ 1.6983046531677246    │\n",
       "│ Time/Epoch                    │ 12.521132469177246    │\n",
       "│ Time/FPS                      │ 163.56349182128906    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.85759735107422     │\n",
       "│ Metrics/EpCost                │ 51.36000061035156     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 375.0                 │\n",
       "│ Train/Entropy                 │ -0.19723723828792572  │\n",
       "│ Train/KL                      │ 0.012661036103963852  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9950577020645142    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9950577020645142    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9950577020645142    │\n",
       "│ Train/PolicyRatio/Std         │ 0.017152413725852966  │\n",
       "│ Train/LR                      │ 7.439999899361283e-05 │\n",
       "│ Train/PolicyStd               │ 0.19873762130737305   │\n",
       "│ TotalEnvSteps                 │ 770048.0              │\n",
       "│ Loss/Loss_pi                  │ -0.015363721176981926 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0002864804118871689 │\n",
       "│ Value/Adv                     │ 0.04528859630227089   │\n",
       "│ Loss/Loss_reward_critic       │ 0.016907919198274612  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.003752896562218666  │\n",
       "│ Value/reward                  │ 2.208104133605957     │\n",
       "│ Time/Total                    │ 4948.015625           │\n",
       "│ Time/Rollout                  │ 10.835489273071289    │\n",
       "│ Time/Update                   │ 1.6949851512908936    │\n",
       "│ Time/Epoch                    │ 12.530526161193848    │\n",
       "│ Time/FPS                      │ 163.4408721923828     │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.85759735107422     │\n",
       "│ Metrics/EpCost                │ 51.36000061035156     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 375.0                 │\n",
       "│ Train/Entropy                 │ -0.19723723828792572  │\n",
       "│ Train/KL                      │ 0.012661036103963852  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9950577020645142    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9950577020645142    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9950577020645142    │\n",
       "│ Train/PolicyRatio/Std         │ 0.017152413725852966  │\n",
       "│ Train/LR                      │ 7.439999899361283e-05 │\n",
       "│ Train/PolicyStd               │ 0.19873762130737305   │\n",
       "│ TotalEnvSteps                 │ 770048.0              │\n",
       "│ Loss/Loss_pi                  │ -0.015363721176981926 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0002864804118871689 │\n",
       "│ Value/Adv                     │ 0.04528859630227089   │\n",
       "│ Loss/Loss_reward_critic       │ 0.016907919198274612  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.003752896562218666  │\n",
       "│ Value/reward                  │ 2.208104133605957     │\n",
       "│ Time/Total                    │ 4948.015625           │\n",
       "│ Time/Rollout                  │ 10.835489273071289    │\n",
       "│ Time/Update                   │ 1.6949851512908936    │\n",
       "│ Time/Epoch                    │ 12.530526161193848    │\n",
       "│ Time/FPS                      │ 163.4408721923828     │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.88739585876465     │\n",
       "│ Metrics/EpCost                │ 53.099998474121094    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 376.0                 │\n",
       "│ Train/Entropy                 │ -0.20043298602104187  │\n",
       "│ Train/KL                      │ 0.014387265779078007  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0006418228149414    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0006418228149414    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0006418228149414    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01865927129983902   │\n",
       "│ Train/LR                      │ 7.380000170087442e-05 │\n",
       "│ Train/PolicyStd               │ 0.1981048583984375    │\n",
       "│ TotalEnvSteps                 │ 772096.0              │\n",
       "│ Loss/Loss_pi                  │ -0.019533485174179077 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004169763997197151 │\n",
       "│ Value/Adv                     │ 0.08547607064247131   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018092896789312363  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0011849775910377502 │\n",
       "│ Value/reward                  │ 2.195037364959717     │\n",
       "│ Time/Total                    │ 4960.568359375        │\n",
       "│ Time/Rollout                  │ 10.793063163757324    │\n",
       "│ Time/Update                   │ 1.7479026317596436    │\n",
       "│ Time/Epoch                    │ 12.541013717651367    │\n",
       "│ Time/FPS                      │ 163.30419921875       │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.88739585876465     │\n",
       "│ Metrics/EpCost                │ 53.099998474121094    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 376.0                 │\n",
       "│ Train/Entropy                 │ -0.20043298602104187  │\n",
       "│ Train/KL                      │ 0.014387265779078007  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0006418228149414    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0006418228149414    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0006418228149414    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01865927129983902   │\n",
       "│ Train/LR                      │ 7.380000170087442e-05 │\n",
       "│ Train/PolicyStd               │ 0.1981048583984375    │\n",
       "│ TotalEnvSteps                 │ 772096.0              │\n",
       "│ Loss/Loss_pi                  │ -0.019533485174179077 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004169763997197151 │\n",
       "│ Value/Adv                     │ 0.08547607064247131   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018092896789312363  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0011849775910377502 │\n",
       "│ Value/reward                  │ 2.195037364959717     │\n",
       "│ Time/Total                    │ 4960.568359375        │\n",
       "│ Time/Rollout                  │ 10.793063163757324    │\n",
       "│ Time/Update                   │ 1.7479026317596436    │\n",
       "│ Time/Epoch                    │ 12.541013717651367    │\n",
       "│ Time/FPS                      │ 163.30419921875       │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.424482345581055    │\n",
       "│ Metrics/EpCost                │ 53.060001373291016    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 377.0                 │\n",
       "│ Train/Entropy                 │ -0.20373642444610596  │\n",
       "│ Train/KL                      │ 0.010661698877811432  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0111675262451172    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0111675262451172    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0111675262451172    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01677723601460457   │\n",
       "│ Train/LR                      │ 7.31999971321784e-05  │\n",
       "│ Train/PolicyStd               │ 0.19745293259620667   │\n",
       "│ TotalEnvSteps                 │ 774144.0              │\n",
       "│ Loss/Loss_pi                  │ -0.013151201419532299 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.006382283754646778  │\n",
       "│ Value/Adv                     │ -0.04578206315636635  │\n",
       "│ Loss/Loss_reward_critic       │ 0.013091394677758217  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005001502111554146 │\n",
       "│ Value/reward                  │ 2.0527610778808594    │\n",
       "│ Time/Total                    │ 4973.25048828125      │\n",
       "│ Time/Rollout                  │ 10.94565486907959     │\n",
       "│ Time/Update                   │ 1.7227613925933838    │\n",
       "│ Time/Epoch                    │ 12.668469429016113    │\n",
       "│ Time/FPS                      │ 161.6612091064453     │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.424482345581055    │\n",
       "│ Metrics/EpCost                │ 53.060001373291016    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 377.0                 │\n",
       "│ Train/Entropy                 │ -0.20373642444610596  │\n",
       "│ Train/KL                      │ 0.010661698877811432  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0111675262451172    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0111675262451172    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0111675262451172    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01677723601460457   │\n",
       "│ Train/LR                      │ 7.31999971321784e-05  │\n",
       "│ Train/PolicyStd               │ 0.19745293259620667   │\n",
       "│ TotalEnvSteps                 │ 774144.0              │\n",
       "│ Loss/Loss_pi                  │ -0.013151201419532299 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.006382283754646778  │\n",
       "│ Value/Adv                     │ -0.04578206315636635  │\n",
       "│ Loss/Loss_reward_critic       │ 0.013091394677758217  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005001502111554146 │\n",
       "│ Value/reward                  │ 2.0527610778808594    │\n",
       "│ Time/Total                    │ 4973.25048828125      │\n",
       "│ Time/Rollout                  │ 10.94565486907959     │\n",
       "│ Time/Update                   │ 1.7227613925933838    │\n",
       "│ Time/Epoch                    │ 12.668469429016113    │\n",
       "│ Time/FPS                      │ 161.6612091064453     │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.220138549804688     │\n",
       "│ Metrics/EpCost                │ 52.13999938964844      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 378.0                  │\n",
       "│ Train/Entropy                 │ -0.20898032188415527   │\n",
       "│ Train/KL                      │ 0.01169716939330101    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9984842538833618     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9984842538833618     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9984842538833618     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01817704364657402    │\n",
       "│ Train/LR                      │ 7.259999983943999e-05  │\n",
       "│ Train/PolicyStd               │ 0.19641539454460144    │\n",
       "│ TotalEnvSteps                 │ 776192.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015642335638403893  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0024911342188715935 │\n",
       "│ Value/Adv                     │ -0.04575366899371147   │\n",
       "│ Loss/Loss_reward_critic       │ 0.013949774205684662   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.000858379527926445   │\n",
       "│ Value/reward                  │ 2.049783945083618      │\n",
       "│ Time/Total                    │ 4985.76416015625       │\n",
       "│ Time/Rollout                  │ 10.806522369384766     │\n",
       "│ Time/Update                   │ 1.6953978538513184     │\n",
       "│ Time/Epoch                    │ 12.501971244812012     │\n",
       "│ Time/FPS                      │ 163.81417846679688     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.220138549804688     │\n",
       "│ Metrics/EpCost                │ 52.13999938964844      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 378.0                  │\n",
       "│ Train/Entropy                 │ -0.20898032188415527   │\n",
       "│ Train/KL                      │ 0.01169716939330101    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9984842538833618     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9984842538833618     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9984842538833618     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01817704364657402    │\n",
       "│ Train/LR                      │ 7.259999983943999e-05  │\n",
       "│ Train/PolicyStd               │ 0.19641539454460144    │\n",
       "│ TotalEnvSteps                 │ 776192.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015642335638403893  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0024911342188715935 │\n",
       "│ Value/Adv                     │ -0.04575366899371147   │\n",
       "│ Loss/Loss_reward_critic       │ 0.013949774205684662   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.000858379527926445   │\n",
       "│ Value/reward                  │ 2.049783945083618      │\n",
       "│ Time/Total                    │ 4985.76416015625       │\n",
       "│ Time/Rollout                  │ 10.806522369384766     │\n",
       "│ Time/Update                   │ 1.6953978538513184     │\n",
       "│ Time/Epoch                    │ 12.501971244812012     │\n",
       "│ Time/FPS                      │ 163.81417846679688     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.34441566467285     │\n",
       "│ Metrics/EpCost                │ 53.099998474121094    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 379.0                 │\n",
       "│ Train/Entropy                 │ -0.21326419711112976  │\n",
       "│ Train/KL                      │ 0.01351154688745737   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.99773770570755      │\n",
       "│ Train/PolicyRatio/Min         │ 0.99773770570755      │\n",
       "│ Train/PolicyRatio/Max         │ 0.99773770570755      │\n",
       "│ Train/PolicyRatio/Std         │ 0.018713418394327164  │\n",
       "│ Train/LR                      │ 7.200000254670158e-05 │\n",
       "│ Train/PolicyStd               │ 0.19557076692581177   │\n",
       "│ TotalEnvSteps                 │ 778240.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01991148665547371  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004269151017069817 │\n",
       "│ Value/Adv                     │ -0.09230209141969681  │\n",
       "│ Loss/Loss_reward_critic       │ 0.015529850497841835  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0015800762921571732 │\n",
       "│ Value/reward                  │ 2.1713106632232666    │\n",
       "│ Time/Total                    │ 4998.46826171875      │\n",
       "│ Time/Rollout                  │ 10.967816352844238    │\n",
       "│ Time/Update                   │ 1.7244634628295898    │\n",
       "│ Time/Epoch                    │ 12.692329406738281    │\n",
       "│ Time/FPS                      │ 161.35731506347656    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.34441566467285     │\n",
       "│ Metrics/EpCost                │ 53.099998474121094    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 379.0                 │\n",
       "│ Train/Entropy                 │ -0.21326419711112976  │\n",
       "│ Train/KL                      │ 0.01351154688745737   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.99773770570755      │\n",
       "│ Train/PolicyRatio/Min         │ 0.99773770570755      │\n",
       "│ Train/PolicyRatio/Max         │ 0.99773770570755      │\n",
       "│ Train/PolicyRatio/Std         │ 0.018713418394327164  │\n",
       "│ Train/LR                      │ 7.200000254670158e-05 │\n",
       "│ Train/PolicyStd               │ 0.19557076692581177   │\n",
       "│ TotalEnvSteps                 │ 778240.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01991148665547371  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004269151017069817 │\n",
       "│ Value/Adv                     │ -0.09230209141969681  │\n",
       "│ Loss/Loss_reward_critic       │ 0.015529850497841835  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0015800762921571732 │\n",
       "│ Value/reward                  │ 2.1713106632232666    │\n",
       "│ Time/Total                    │ 4998.46826171875      │\n",
       "│ Time/Rollout                  │ 10.967816352844238    │\n",
       "│ Time/Update                   │ 1.7244634628295898    │\n",
       "│ Time/Epoch                    │ 12.692329406738281    │\n",
       "│ Time/FPS                      │ 161.35731506347656    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.462360382080078    │\n",
       "│ Metrics/EpCost                │ 53.2599983215332      │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 380.0                 │\n",
       "│ Train/Entropy                 │ -0.21490851044654846  │\n",
       "│ Train/KL                      │ 0.013787982054054737  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9918309450149536    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9918309450149536    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9918309450149536    │\n",
       "│ Train/PolicyRatio/Std         │ 0.018753143027424812  │\n",
       "│ Train/LR                      │ 7.139999797800556e-05 │\n",
       "│ Train/PolicyStd               │ 0.19524434208869934   │\n",
       "│ TotalEnvSteps                 │ 780288.0              │\n",
       "│ Loss/Loss_pi                  │ -0.018629463389515877 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0012820232659578323 │\n",
       "│ Value/Adv                     │ -0.08208564668893814  │\n",
       "│ Loss/Loss_reward_critic       │ 0.021862976253032684  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006333125755190849  │\n",
       "│ Value/reward                  │ 2.1636688709259033    │\n",
       "│ Time/Total                    │ 5011.04638671875      │\n",
       "│ Time/Rollout                  │ 10.855525016784668    │\n",
       "│ Time/Update                   │ 1.707521677017212     │\n",
       "│ Time/Epoch                    │ 12.563100814819336    │\n",
       "│ Time/FPS                      │ 163.01708984375       │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.462360382080078    │\n",
       "│ Metrics/EpCost                │ 53.2599983215332      │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 380.0                 │\n",
       "│ Train/Entropy                 │ -0.21490851044654846  │\n",
       "│ Train/KL                      │ 0.013787982054054737  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9918309450149536    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9918309450149536    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9918309450149536    │\n",
       "│ Train/PolicyRatio/Std         │ 0.018753143027424812  │\n",
       "│ Train/LR                      │ 7.139999797800556e-05 │\n",
       "│ Train/PolicyStd               │ 0.19524434208869934   │\n",
       "│ TotalEnvSteps                 │ 780288.0              │\n",
       "│ Loss/Loss_pi                  │ -0.018629463389515877 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0012820232659578323 │\n",
       "│ Value/Adv                     │ -0.08208564668893814  │\n",
       "│ Loss/Loss_reward_critic       │ 0.021862976253032684  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006333125755190849  │\n",
       "│ Value/reward                  │ 2.1636688709259033    │\n",
       "│ Time/Total                    │ 5011.04638671875      │\n",
       "│ Time/Rollout                  │ 10.855525016784668    │\n",
       "│ Time/Update                   │ 1.707521677017212     │\n",
       "│ Time/Epoch                    │ 12.563100814819336    │\n",
       "│ Time/FPS                      │ 163.01708984375       │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.482057571411133     │\n",
       "│ Metrics/EpCost                │ 49.560001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 381.0                  │\n",
       "│ Train/Entropy                 │ -0.21402280032634735   │\n",
       "│ Train/KL                      │ 0.015176048502326012   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9970780611038208     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9970780611038208     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9970780611038208     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018820004537701607   │\n",
       "│ Train/LR                      │ 7.080000068526715e-05  │\n",
       "│ Train/PolicyStd               │ 0.1954149752855301     │\n",
       "│ TotalEnvSteps                 │ 782336.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016805555671453476  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0018239077180624008  │\n",
       "│ Value/Adv                     │ -0.2613164484500885    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017337055876851082   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0045259203761816025 │\n",
       "│ Value/reward                  │ 2.205655336380005      │\n",
       "│ Time/Total                    │ 5023.65771484375       │\n",
       "│ Time/Rollout                  │ 10.905675888061523     │\n",
       "│ Time/Update                   │ 1.6940112113952637     │\n",
       "│ Time/Epoch                    │ 12.599733352661133     │\n",
       "│ Time/FPS                      │ 162.54312133789062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.482057571411133     │\n",
       "│ Metrics/EpCost                │ 49.560001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 381.0                  │\n",
       "│ Train/Entropy                 │ -0.21402280032634735   │\n",
       "│ Train/KL                      │ 0.015176048502326012   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9970780611038208     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9970780611038208     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9970780611038208     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018820004537701607   │\n",
       "│ Train/LR                      │ 7.080000068526715e-05  │\n",
       "│ Train/PolicyStd               │ 0.1954149752855301     │\n",
       "│ TotalEnvSteps                 │ 782336.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016805555671453476  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0018239077180624008  │\n",
       "│ Value/Adv                     │ -0.2613164484500885    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017337055876851082   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0045259203761816025 │\n",
       "│ Value/reward                  │ 2.205655336380005      │\n",
       "│ Time/Total                    │ 5023.65771484375       │\n",
       "│ Time/Rollout                  │ 10.905675888061523     │\n",
       "│ Time/Update                   │ 1.6940112113952637     │\n",
       "│ Time/Epoch                    │ 12.599733352661133     │\n",
       "│ Time/FPS                      │ 162.54312133789062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.516948699951172     │\n",
       "│ Metrics/EpCost                │ 50.560001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 382.0                  │\n",
       "│ Train/Entropy                 │ -0.2150835245847702    │\n",
       "│ Train/KL                      │ 0.012608282268047333   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0003408193588257     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0003408193588257     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0003408193588257     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016123849898576736   │\n",
       "│ Train/LR                      │ 7.020000339252874e-05  │\n",
       "│ Train/PolicyStd               │ 0.19521090388298035    │\n",
       "│ TotalEnvSteps                 │ 784384.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017095014452934265  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0002894587814807892 │\n",
       "│ Value/Adv                     │ 0.22446845471858978    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01939183846116066    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002054782584309578   │\n",
       "│ Value/reward                  │ 2.148332118988037      │\n",
       "│ Time/Total                    │ 5036.2724609375        │\n",
       "│ Time/Rollout                  │ 10.88573932647705      │\n",
       "│ Time/Update                   │ 1.7171566486358643     │\n",
       "│ Time/Epoch                    │ 12.602949142456055     │\n",
       "│ Time/FPS                      │ 162.5016632080078      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.516948699951172     │\n",
       "│ Metrics/EpCost                │ 50.560001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 382.0                  │\n",
       "│ Train/Entropy                 │ -0.2150835245847702    │\n",
       "│ Train/KL                      │ 0.012608282268047333   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0003408193588257     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0003408193588257     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0003408193588257     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016123849898576736   │\n",
       "│ Train/LR                      │ 7.020000339252874e-05  │\n",
       "│ Train/PolicyStd               │ 0.19521090388298035    │\n",
       "│ TotalEnvSteps                 │ 784384.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017095014452934265  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0002894587814807892 │\n",
       "│ Value/Adv                     │ 0.22446845471858978    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01939183846116066    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002054782584309578   │\n",
       "│ Value/reward                  │ 2.148332118988037      │\n",
       "│ Time/Total                    │ 5036.2724609375        │\n",
       "│ Time/Rollout                  │ 10.88573932647705      │\n",
       "│ Time/Update                   │ 1.7171566486358643     │\n",
       "│ Time/Epoch                    │ 12.602949142456055     │\n",
       "│ Time/FPS                      │ 162.5016632080078      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.47994041442871     │\n",
       "│ Metrics/EpCost                │ 53.060001373291016    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 383.0                 │\n",
       "│ Train/Entropy                 │ -0.22123941779136658  │\n",
       "│ Train/KL                      │ 0.008854050189256668  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0100204944610596    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0100204944610596    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0100204944610596    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01698228344321251   │\n",
       "│ Train/LR                      │ 6.959999882383272e-05 │\n",
       "│ Train/PolicyStd               │ 0.19400343298912048   │\n",
       "│ TotalEnvSteps                 │ 786432.0              │\n",
       "│ Loss/Loss_pi                  │ -0.013054597191512585 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0040404172614216805 │\n",
       "│ Value/Adv                     │ -0.0139442328363657   │\n",
       "│ Loss/Loss_reward_critic       │ 0.023588702082633972  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004196863621473312  │\n",
       "│ Value/reward                  │ 1.983975887298584     │\n",
       "│ Time/Total                    │ 5048.845703125        │\n",
       "│ Time/Rollout                  │ 10.857186317443848    │\n",
       "│ Time/Update                   │ 1.704653024673462     │\n",
       "│ Time/Epoch                    │ 12.561882019042969    │\n",
       "│ Time/FPS                      │ 163.0329132080078     │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.47994041442871     │\n",
       "│ Metrics/EpCost                │ 53.060001373291016    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 383.0                 │\n",
       "│ Train/Entropy                 │ -0.22123941779136658  │\n",
       "│ Train/KL                      │ 0.008854050189256668  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0100204944610596    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0100204944610596    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0100204944610596    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01698228344321251   │\n",
       "│ Train/LR                      │ 6.959999882383272e-05 │\n",
       "│ Train/PolicyStd               │ 0.19400343298912048   │\n",
       "│ TotalEnvSteps                 │ 786432.0              │\n",
       "│ Loss/Loss_pi                  │ -0.013054597191512585 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0040404172614216805 │\n",
       "│ Value/Adv                     │ -0.0139442328363657   │\n",
       "│ Loss/Loss_reward_critic       │ 0.023588702082633972  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004196863621473312  │\n",
       "│ Value/reward                  │ 1.983975887298584     │\n",
       "│ Time/Total                    │ 5048.845703125        │\n",
       "│ Time/Rollout                  │ 10.857186317443848    │\n",
       "│ Time/Update                   │ 1.704653024673462     │\n",
       "│ Time/Epoch                    │ 12.561882019042969    │\n",
       "│ Time/FPS                      │ 163.0329132080078     │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.719266891479492    │\n",
       "│ Metrics/EpCost                │ 53.2599983215332      │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 384.0                 │\n",
       "│ Train/Entropy                 │ -0.225684255361557    │\n",
       "│ Train/KL                      │ 0.012064950540661812  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9986197352409363    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9986197352409363    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9986197352409363    │\n",
       "│ Train/PolicyRatio/Std         │ 0.016937803477048874  │\n",
       "│ Train/LR                      │ 6.900000153109431e-05 │\n",
       "│ Train/PolicyStd               │ 0.19312798976898193   │\n",
       "│ TotalEnvSteps                 │ 788480.0              │\n",
       "│ Loss/Loss_pi                  │ -0.016756437718868256 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.003701840527355671 │\n",
       "│ Value/Adv                     │ -0.060144949704408646 │\n",
       "│ Loss/Loss_reward_critic       │ 0.013364104554057121  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.010224597528576851 │\n",
       "│ Value/reward                  │ 2.125338554382324     │\n",
       "│ Time/Total                    │ 5061.43212890625      │\n",
       "│ Time/Rollout                  │ 10.872440338134766    │\n",
       "│ Time/Update                   │ 1.7022500038146973    │\n",
       "│ Time/Epoch                    │ 12.574736595153809    │\n",
       "│ Time/FPS                      │ 162.86624145507812    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.719266891479492    │\n",
       "│ Metrics/EpCost                │ 53.2599983215332      │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 384.0                 │\n",
       "│ Train/Entropy                 │ -0.225684255361557    │\n",
       "│ Train/KL                      │ 0.012064950540661812  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9986197352409363    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9986197352409363    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9986197352409363    │\n",
       "│ Train/PolicyRatio/Std         │ 0.016937803477048874  │\n",
       "│ Train/LR                      │ 6.900000153109431e-05 │\n",
       "│ Train/PolicyStd               │ 0.19312798976898193   │\n",
       "│ TotalEnvSteps                 │ 788480.0              │\n",
       "│ Loss/Loss_pi                  │ -0.016756437718868256 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.003701840527355671 │\n",
       "│ Value/Adv                     │ -0.060144949704408646 │\n",
       "│ Loss/Loss_reward_critic       │ 0.013364104554057121  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.010224597528576851 │\n",
       "│ Value/reward                  │ 2.125338554382324     │\n",
       "│ Time/Total                    │ 5061.43212890625      │\n",
       "│ Time/Rollout                  │ 10.872440338134766    │\n",
       "│ Time/Update                   │ 1.7022500038146973    │\n",
       "│ Time/Epoch                    │ 12.574736595153809    │\n",
       "│ Time/FPS                      │ 162.86624145507812    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.674219131469727     │\n",
       "│ Metrics/EpCost                │ 52.720001220703125     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 385.0                  │\n",
       "│ Train/Entropy                 │ -0.2266780138015747    │\n",
       "│ Train/KL                      │ 0.011687816120684147   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9990531802177429     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9990531802177429     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9990531802177429     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017875127494335175   │\n",
       "│ Train/LR                      │ 6.839999696239829e-05  │\n",
       "│ Train/PolicyStd               │ 0.19293256103992462    │\n",
       "│ TotalEnvSteps                 │ 790528.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016841309145092964  │\n",
       "│ Loss/Loss_pi/Delta            │ -8.487142622470856e-05 │\n",
       "│ Value/Adv                     │ -0.09274766594171524   │\n",
       "│ Loss/Loss_reward_critic       │ 0.013956844806671143   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0005927402526140213  │\n",
       "│ Value/reward                  │ 2.1768109798431396     │\n",
       "│ Time/Total                    │ 5073.9375              │\n",
       "│ Time/Rollout                  │ 10.810701370239258     │\n",
       "│ Time/Update                   │ 1.682934045791626      │\n",
       "│ Time/Epoch                    │ 12.49367904663086      │\n",
       "│ Time/FPS                      │ 163.9228973388672      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.674219131469727     │\n",
       "│ Metrics/EpCost                │ 52.720001220703125     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 385.0                  │\n",
       "│ Train/Entropy                 │ -0.2266780138015747    │\n",
       "│ Train/KL                      │ 0.011687816120684147   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9990531802177429     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9990531802177429     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9990531802177429     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017875127494335175   │\n",
       "│ Train/LR                      │ 6.839999696239829e-05  │\n",
       "│ Train/PolicyStd               │ 0.19293256103992462    │\n",
       "│ TotalEnvSteps                 │ 790528.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016841309145092964  │\n",
       "│ Loss/Loss_pi/Delta            │ -8.487142622470856e-05 │\n",
       "│ Value/Adv                     │ -0.09274766594171524   │\n",
       "│ Loss/Loss_reward_critic       │ 0.013956844806671143   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0005927402526140213  │\n",
       "│ Value/reward                  │ 2.1768109798431396     │\n",
       "│ Time/Total                    │ 5073.9375              │\n",
       "│ Time/Rollout                  │ 10.810701370239258     │\n",
       "│ Time/Update                   │ 1.682934045791626      │\n",
       "│ Time/Epoch                    │ 12.49367904663086      │\n",
       "│ Time/FPS                      │ 163.9228973388672      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.76280975341797      │\n",
       "│ Metrics/EpCost                │ 52.400001525878906     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 386.0                  │\n",
       "│ Train/Entropy                 │ -0.22970464825630188   │\n",
       "│ Train/KL                      │ 0.013922041282057762   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9955922961235046     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9955922961235046     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9955922961235046     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016587942838668823   │\n",
       "│ Train/LR                      │ 6.779999966965988e-05  │\n",
       "│ Train/PolicyStd               │ 0.19234660267829895    │\n",
       "│ TotalEnvSteps                 │ 792576.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016847005113959312  │\n",
       "│ Loss/Loss_pi/Delta            │ -5.695968866348267e-06 │\n",
       "│ Value/Adv                     │ -0.01614101603627205   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01686960831284523    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0029127635061740875  │\n",
       "│ Value/reward                  │ 2.1648144721984863     │\n",
       "│ Time/Total                    │ 5086.5908203125        │\n",
       "│ Time/Rollout                  │ 10.895195007324219     │\n",
       "│ Time/Update                   │ 1.7466952800750732     │\n",
       "│ Time/Epoch                    │ 12.64193344116211      │\n",
       "│ Time/FPS                      │ 162.0005340576172      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.76280975341797      │\n",
       "│ Metrics/EpCost                │ 52.400001525878906     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 386.0                  │\n",
       "│ Train/Entropy                 │ -0.22970464825630188   │\n",
       "│ Train/KL                      │ 0.013922041282057762   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9955922961235046     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9955922961235046     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9955922961235046     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016587942838668823   │\n",
       "│ Train/LR                      │ 6.779999966965988e-05  │\n",
       "│ Train/PolicyStd               │ 0.19234660267829895    │\n",
       "│ TotalEnvSteps                 │ 792576.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016847005113959312  │\n",
       "│ Loss/Loss_pi/Delta            │ -5.695968866348267e-06 │\n",
       "│ Value/Adv                     │ -0.01614101603627205   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01686960831284523    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0029127635061740875  │\n",
       "│ Value/reward                  │ 2.1648144721984863     │\n",
       "│ Time/Total                    │ 5086.5908203125        │\n",
       "│ Time/Rollout                  │ 10.895195007324219     │\n",
       "│ Time/Update                   │ 1.7466952800750732     │\n",
       "│ Time/Epoch                    │ 12.64193344116211      │\n",
       "│ Time/FPS                      │ 162.0005340576172      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.103322982788086    │\n",
       "│ Metrics/EpCost                │ 50.880001068115234    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 387.0                 │\n",
       "│ Train/Entropy                 │ -0.2300000637769699   │\n",
       "│ Train/KL                      │ 0.010687345638871193  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9971765279769897    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9971765279769897    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9971765279769897    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01701231859624386   │\n",
       "│ Train/LR                      │ 6.720000237692147e-05 │\n",
       "│ Train/PolicyStd               │ 0.1922868937253952    │\n",
       "│ TotalEnvSteps                 │ 794624.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01516453642398119  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0016824686899781227 │\n",
       "│ Value/Adv                     │ -0.08973820507526398  │\n",
       "│ Loss/Loss_reward_critic       │ 0.021376673132181168  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0045070648193359375 │\n",
       "│ Value/reward                  │ 2.2184677124023438    │\n",
       "│ Time/Total                    │ 5099.09326171875      │\n",
       "│ Time/Rollout                  │ 10.804280281066895    │\n",
       "│ Time/Update                   │ 1.6861975193023682    │\n",
       "│ Time/Epoch                    │ 12.49052906036377     │\n",
       "│ Time/FPS                      │ 163.96424865722656    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.103322982788086    │\n",
       "│ Metrics/EpCost                │ 50.880001068115234    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 387.0                 │\n",
       "│ Train/Entropy                 │ -0.2300000637769699   │\n",
       "│ Train/KL                      │ 0.010687345638871193  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9971765279769897    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9971765279769897    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9971765279769897    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01701231859624386   │\n",
       "│ Train/LR                      │ 6.720000237692147e-05 │\n",
       "│ Train/PolicyStd               │ 0.1922868937253952    │\n",
       "│ TotalEnvSteps                 │ 794624.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01516453642398119  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0016824686899781227 │\n",
       "│ Value/Adv                     │ -0.08973820507526398  │\n",
       "│ Loss/Loss_reward_critic       │ 0.021376673132181168  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0045070648193359375 │\n",
       "│ Value/reward                  │ 2.2184677124023438    │\n",
       "│ Time/Total                    │ 5099.09326171875      │\n",
       "│ Time/Rollout                  │ 10.804280281066895    │\n",
       "│ Time/Update                   │ 1.6861975193023682    │\n",
       "│ Time/Epoch                    │ 12.49052906036377     │\n",
       "│ Time/FPS                      │ 163.96424865722656    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.141742706298828    │\n",
       "│ Metrics/EpCost                │ 52.02000045776367     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 388.0                 │\n",
       "│ Train/Entropy                 │ -0.2284887582063675   │\n",
       "│ Train/KL                      │ 0.015073963440954685  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9999977350234985    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9999977350234985    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9999977350234985    │\n",
       "│ Train/PolicyRatio/Std         │ 0.02038249559700489   │\n",
       "│ Train/LR                      │ 6.659999780822545e-05 │\n",
       "│ Train/PolicyStd               │ 0.19257852435112      │\n",
       "│ TotalEnvSteps                 │ 796672.0              │\n",
       "│ Loss/Loss_pi                  │ -0.018924202769994736 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.003759666346013546 │\n",
       "│ Value/Adv                     │ -0.05005021393299103  │\n",
       "│ Loss/Loss_reward_critic       │ 0.015543326735496521  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005833346396684647 │\n",
       "│ Value/reward                  │ 2.170804738998413     │\n",
       "│ Time/Total                    │ 5111.58154296875      │\n",
       "│ Time/Rollout                  │ 10.782720565795898    │\n",
       "│ Time/Update                   │ 1.6941993236541748    │\n",
       "│ Time/Epoch                    │ 12.476964950561523    │\n",
       "│ Time/FPS                      │ 164.14248657226562    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.141742706298828    │\n",
       "│ Metrics/EpCost                │ 52.02000045776367     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 388.0                 │\n",
       "│ Train/Entropy                 │ -0.2284887582063675   │\n",
       "│ Train/KL                      │ 0.015073963440954685  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9999977350234985    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9999977350234985    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9999977350234985    │\n",
       "│ Train/PolicyRatio/Std         │ 0.02038249559700489   │\n",
       "│ Train/LR                      │ 6.659999780822545e-05 │\n",
       "│ Train/PolicyStd               │ 0.19257852435112      │\n",
       "│ TotalEnvSteps                 │ 796672.0              │\n",
       "│ Loss/Loss_pi                  │ -0.018924202769994736 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.003759666346013546 │\n",
       "│ Value/Adv                     │ -0.05005021393299103  │\n",
       "│ Loss/Loss_reward_critic       │ 0.015543326735496521  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005833346396684647 │\n",
       "│ Value/reward                  │ 2.170804738998413     │\n",
       "│ Time/Total                    │ 5111.58154296875      │\n",
       "│ Time/Rollout                  │ 10.782720565795898    │\n",
       "│ Time/Update                   │ 1.6941993236541748    │\n",
       "│ Time/Epoch                    │ 12.476964950561523    │\n",
       "│ Time/FPS                      │ 164.14248657226562    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.202497482299805    │\n",
       "│ Metrics/EpCost                │ 52.619998931884766    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 389.0                 │\n",
       "│ Train/Entropy                 │ -0.23067355155944824  │\n",
       "│ Train/KL                      │ 0.012601770460605621  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9958440065383911    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9958440065383911    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9958440065383911    │\n",
       "│ Train/PolicyRatio/Std         │ 0.018913375213742256  │\n",
       "│ Train/LR                      │ 6.600000051548705e-05 │\n",
       "│ Train/PolicyStd               │ 0.19215735793113708   │\n",
       "│ TotalEnvSteps                 │ 798720.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01865510269999504  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0002691000699996948 │\n",
       "│ Value/Adv                     │ -0.06339056044816971  │\n",
       "│ Loss/Loss_reward_critic       │ 0.02051243931055069   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004969112575054169  │\n",
       "│ Value/reward                  │ 2.262234687805176     │\n",
       "│ Time/Total                    │ 5124.21044921875      │\n",
       "│ Time/Rollout                  │ 10.906169891357422    │\n",
       "│ Time/Update                   │ 1.7091569900512695    │\n",
       "│ Time/Epoch                    │ 12.615373611450195    │\n",
       "│ Time/FPS                      │ 162.34161376953125    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.202497482299805    │\n",
       "│ Metrics/EpCost                │ 52.619998931884766    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 389.0                 │\n",
       "│ Train/Entropy                 │ -0.23067355155944824  │\n",
       "│ Train/KL                      │ 0.012601770460605621  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9958440065383911    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9958440065383911    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9958440065383911    │\n",
       "│ Train/PolicyRatio/Std         │ 0.018913375213742256  │\n",
       "│ Train/LR                      │ 6.600000051548705e-05 │\n",
       "│ Train/PolicyStd               │ 0.19215735793113708   │\n",
       "│ TotalEnvSteps                 │ 798720.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01865510269999504  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0002691000699996948 │\n",
       "│ Value/Adv                     │ -0.06339056044816971  │\n",
       "│ Loss/Loss_reward_critic       │ 0.02051243931055069   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004969112575054169  │\n",
       "│ Value/reward                  │ 2.262234687805176     │\n",
       "│ Time/Total                    │ 5124.21044921875      │\n",
       "│ Time/Rollout                  │ 10.906169891357422    │\n",
       "│ Time/Update                   │ 1.7091569900512695    │\n",
       "│ Time/Epoch                    │ 12.615373611450195    │\n",
       "│ Time/FPS                      │ 162.34161376953125    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.192974090576172    │\n",
       "│ Metrics/EpCost                │ 54.400001525878906    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 390.0                 │\n",
       "│ Train/Entropy                 │ -0.2320663034915924   │\n",
       "│ Train/KL                      │ 0.01105906255543232   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0001310110092163    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0001310110092163    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0001310110092163    │\n",
       "│ Train/PolicyRatio/Std         │ 0.017000393941998482  │\n",
       "│ Train/LR                      │ 6.540000322274864e-05 │\n",
       "│ Train/PolicyStd               │ 0.19188974797725677   │\n",
       "│ TotalEnvSteps                 │ 800768.0              │\n",
       "│ Loss/Loss_pi                  │ -0.015138784423470497 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0035163182765245438 │\n",
       "│ Value/Adv                     │ 0.07393752038478851   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015091258101165295  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005421181209385395 │\n",
       "│ Value/reward                  │ 2.1919848918914795    │\n",
       "│ Time/Total                    │ 5136.73095703125      │\n",
       "│ Time/Rollout                  │ 10.802111625671387    │\n",
       "│ Time/Update                   │ 1.7053160667419434    │\n",
       "│ Time/Epoch                    │ 12.507469177246094    │\n",
       "│ Time/FPS                      │ 163.74217224121094    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.192974090576172    │\n",
       "│ Metrics/EpCost                │ 54.400001525878906    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 390.0                 │\n",
       "│ Train/Entropy                 │ -0.2320663034915924   │\n",
       "│ Train/KL                      │ 0.01105906255543232   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0001310110092163    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0001310110092163    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0001310110092163    │\n",
       "│ Train/PolicyRatio/Std         │ 0.017000393941998482  │\n",
       "│ Train/LR                      │ 6.540000322274864e-05 │\n",
       "│ Train/PolicyStd               │ 0.19188974797725677   │\n",
       "│ TotalEnvSteps                 │ 800768.0              │\n",
       "│ Loss/Loss_pi                  │ -0.015138784423470497 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0035163182765245438 │\n",
       "│ Value/Adv                     │ 0.07393752038478851   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015091258101165295  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005421181209385395 │\n",
       "│ Value/reward                  │ 2.1919848918914795    │\n",
       "│ Time/Total                    │ 5136.73095703125      │\n",
       "│ Time/Rollout                  │ 10.802111625671387    │\n",
       "│ Time/Update                   │ 1.7053160667419434    │\n",
       "│ Time/Epoch                    │ 12.507469177246094    │\n",
       "│ Time/FPS                      │ 163.74217224121094    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.066743850708008     │\n",
       "│ Metrics/EpCost                │ 52.099998474121094     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 391.0                  │\n",
       "│ Train/Entropy                 │ -0.2341182976961136    │\n",
       "│ Train/KL                      │ 0.01202500332146883    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0020557641983032     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0020557641983032     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0020557641983032     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01663403958082199    │\n",
       "│ Train/LR                      │ 6.479999865405262e-05  │\n",
       "│ Train/PolicyStd               │ 0.191499263048172      │\n",
       "│ TotalEnvSteps                 │ 802816.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01297903060913086   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0021597538143396378  │\n",
       "│ Value/Adv                     │ -0.19989128410816193   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014697532169520855   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0003937259316444397 │\n",
       "│ Value/reward                  │ 2.1787052154541016     │\n",
       "│ Time/Total                    │ 5149.3486328125        │\n",
       "│ Time/Rollout                  │ 10.882471084594727     │\n",
       "│ Time/Update                   │ 1.723222017288208      │\n",
       "│ Time/Epoch                    │ 12.60573673248291      │\n",
       "│ Time/FPS                      │ 162.46572875976562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.066743850708008     │\n",
       "│ Metrics/EpCost                │ 52.099998474121094     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 391.0                  │\n",
       "│ Train/Entropy                 │ -0.2341182976961136    │\n",
       "│ Train/KL                      │ 0.01202500332146883    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0020557641983032     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0020557641983032     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0020557641983032     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01663403958082199    │\n",
       "│ Train/LR                      │ 6.479999865405262e-05  │\n",
       "│ Train/PolicyStd               │ 0.191499263048172      │\n",
       "│ TotalEnvSteps                 │ 802816.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01297903060913086   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0021597538143396378  │\n",
       "│ Value/Adv                     │ -0.19989128410816193   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014697532169520855   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0003937259316444397 │\n",
       "│ Value/reward                  │ 2.1787052154541016     │\n",
       "│ Time/Total                    │ 5149.3486328125        │\n",
       "│ Time/Rollout                  │ 10.882471084594727     │\n",
       "│ Time/Update                   │ 1.723222017288208      │\n",
       "│ Time/Epoch                    │ 12.60573673248291      │\n",
       "│ Time/FPS                      │ 162.46572875976562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.13129425048828     │\n",
       "│ Metrics/EpCost                │ 53.08000183105469     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 392.0                 │\n",
       "│ Train/Entropy                 │ -0.23898108303546906  │\n",
       "│ Train/KL                      │ 0.014426833018660545  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.993974506855011     │\n",
       "│ Train/PolicyRatio/Min         │ 0.993974506855011     │\n",
       "│ Train/PolicyRatio/Max         │ 0.993974506855011     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01822504773736      │\n",
       "│ Train/LR                      │ 6.420000136131421e-05 │\n",
       "│ Train/PolicyStd               │ 0.190568208694458     │\n",
       "│ TotalEnvSteps                 │ 804864.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01697554811835289  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.003996517509222031 │\n",
       "│ Value/Adv                     │ -0.0743325874209404   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015884047374129295  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0011865152046084404 │\n",
       "│ Value/reward                  │ 2.2092034816741943    │\n",
       "│ Time/Total                    │ 5161.97802734375      │\n",
       "│ Time/Rollout                  │ 10.888510704040527    │\n",
       "│ Time/Update                   │ 1.729262113571167     │\n",
       "│ Time/Epoch                    │ 12.617820739746094    │\n",
       "│ Time/FPS                      │ 162.3101348876953     │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.13129425048828     │\n",
       "│ Metrics/EpCost                │ 53.08000183105469     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 392.0                 │\n",
       "│ Train/Entropy                 │ -0.23898108303546906  │\n",
       "│ Train/KL                      │ 0.014426833018660545  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.993974506855011     │\n",
       "│ Train/PolicyRatio/Min         │ 0.993974506855011     │\n",
       "│ Train/PolicyRatio/Max         │ 0.993974506855011     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01822504773736      │\n",
       "│ Train/LR                      │ 6.420000136131421e-05 │\n",
       "│ Train/PolicyStd               │ 0.190568208694458     │\n",
       "│ TotalEnvSteps                 │ 804864.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01697554811835289  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.003996517509222031 │\n",
       "│ Value/Adv                     │ -0.0743325874209404   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015884047374129295  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0011865152046084404 │\n",
       "│ Value/reward                  │ 2.2092034816741943    │\n",
       "│ Time/Total                    │ 5161.97802734375      │\n",
       "│ Time/Rollout                  │ 10.888510704040527    │\n",
       "│ Time/Update                   │ 1.729262113571167     │\n",
       "│ Time/Epoch                    │ 12.617820739746094    │\n",
       "│ Time/FPS                      │ 162.3101348876953     │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.191030502319336     │\n",
       "│ Metrics/EpCost                │ 53.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 393.0                  │\n",
       "│ Train/Entropy                 │ -0.24224801361560822   │\n",
       "│ Train/KL                      │ 0.012770568020641804   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.998286247253418      │\n",
       "│ Train/PolicyRatio/Min         │ 0.998286247253418      │\n",
       "│ Train/PolicyRatio/Max         │ 0.998286247253418      │\n",
       "│ Train/PolicyRatio/Std         │ 0.015570750460028648   │\n",
       "│ Train/LR                      │ 6.359999679261819e-05  │\n",
       "│ Train/PolicyStd               │ 0.18994802236557007    │\n",
       "│ TotalEnvSteps                 │ 806912.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01795526221394539   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0009797140955924988 │\n",
       "│ Value/Adv                     │ 0.006293082609772682   │\n",
       "│ Loss/Loss_reward_critic       │ 0.019889941439032555   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004005894064903259   │\n",
       "│ Value/reward                  │ 2.1402902603149414     │\n",
       "│ Time/Total                    │ 5174.5390625           │\n",
       "│ Time/Rollout                  │ 10.85942268371582      │\n",
       "│ Time/Update                   │ 1.690011739730835      │\n",
       "│ Time/Epoch                    │ 12.549483299255371     │\n",
       "│ Time/FPS                      │ 163.19398498535156     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.191030502319336     │\n",
       "│ Metrics/EpCost                │ 53.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 393.0                  │\n",
       "│ Train/Entropy                 │ -0.24224801361560822   │\n",
       "│ Train/KL                      │ 0.012770568020641804   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.998286247253418      │\n",
       "│ Train/PolicyRatio/Min         │ 0.998286247253418      │\n",
       "│ Train/PolicyRatio/Max         │ 0.998286247253418      │\n",
       "│ Train/PolicyRatio/Std         │ 0.015570750460028648   │\n",
       "│ Train/LR                      │ 6.359999679261819e-05  │\n",
       "│ Train/PolicyStd               │ 0.18994802236557007    │\n",
       "│ TotalEnvSteps                 │ 806912.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01795526221394539   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0009797140955924988 │\n",
       "│ Value/Adv                     │ 0.006293082609772682   │\n",
       "│ Loss/Loss_reward_critic       │ 0.019889941439032555   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004005894064903259   │\n",
       "│ Value/reward                  │ 2.1402902603149414     │\n",
       "│ Time/Total                    │ 5174.5390625           │\n",
       "│ Time/Rollout                  │ 10.85942268371582      │\n",
       "│ Time/Update                   │ 1.690011739730835      │\n",
       "│ Time/Epoch                    │ 12.549483299255371     │\n",
       "│ Time/FPS                      │ 163.19398498535156     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.25916290283203      │\n",
       "│ Metrics/EpCost                │ 52.7400016784668       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 394.0                  │\n",
       "│ Train/Entropy                 │ -0.24435177445411682   │\n",
       "│ Train/KL                      │ 0.010513236746191978   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.999652087688446      │\n",
       "│ Train/PolicyRatio/Min         │ 0.999652087688446      │\n",
       "│ Train/PolicyRatio/Max         │ 0.999652087688446      │\n",
       "│ Train/PolicyRatio/Std         │ 0.016596464440226555   │\n",
       "│ Train/LR                      │ 6.299999949987978e-05  │\n",
       "│ Train/PolicyStd               │ 0.1895565390586853     │\n",
       "│ TotalEnvSteps                 │ 808960.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015053573064506054  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002901689149439335   │\n",
       "│ Value/Adv                     │ 0.0782637819647789     │\n",
       "│ Loss/Loss_reward_critic       │ 0.01610833778977394    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0037816036492586136 │\n",
       "│ Value/reward                  │ 2.250913143157959      │\n",
       "│ Time/Total                    │ 5187.119140625         │\n",
       "│ Time/Rollout                  │ 10.834687232971191     │\n",
       "│ Time/Update                   │ 1.7332561016082764     │\n",
       "│ Time/Epoch                    │ 12.567987442016602     │\n",
       "│ Time/FPS                      │ 162.95370483398438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.25916290283203      │\n",
       "│ Metrics/EpCost                │ 52.7400016784668       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 394.0                  │\n",
       "│ Train/Entropy                 │ -0.24435177445411682   │\n",
       "│ Train/KL                      │ 0.010513236746191978   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.999652087688446      │\n",
       "│ Train/PolicyRatio/Min         │ 0.999652087688446      │\n",
       "│ Train/PolicyRatio/Max         │ 0.999652087688446      │\n",
       "│ Train/PolicyRatio/Std         │ 0.016596464440226555   │\n",
       "│ Train/LR                      │ 6.299999949987978e-05  │\n",
       "│ Train/PolicyStd               │ 0.1895565390586853     │\n",
       "│ TotalEnvSteps                 │ 808960.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015053573064506054  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002901689149439335   │\n",
       "│ Value/Adv                     │ 0.0782637819647789     │\n",
       "│ Loss/Loss_reward_critic       │ 0.01610833778977394    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0037816036492586136 │\n",
       "│ Value/reward                  │ 2.250913143157959      │\n",
       "│ Time/Total                    │ 5187.119140625         │\n",
       "│ Time/Rollout                  │ 10.834687232971191     │\n",
       "│ Time/Update                   │ 1.7332561016082764     │\n",
       "│ Time/Epoch                    │ 12.567987442016602     │\n",
       "│ Time/FPS                      │ 162.95370483398438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.26744842529297     │\n",
       "│ Metrics/EpCost                │ 53.58000183105469     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 395.0                 │\n",
       "│ Train/Entropy                 │ -0.24838896095752716  │\n",
       "│ Train/KL                      │ 0.012259891256690025  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.990237832069397     │\n",
       "│ Train/PolicyRatio/Min         │ 0.990237832069397     │\n",
       "│ Train/PolicyRatio/Max         │ 0.990237832069397     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017544234171509743  │\n",
       "│ Train/LR                      │ 6.240000220714137e-05 │\n",
       "│ Train/PolicyStd               │ 0.18879832327365875   │\n",
       "│ TotalEnvSteps                 │ 811008.0              │\n",
       "│ Loss/Loss_pi                  │ -0.020980071276426315 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.005926498211920261 │\n",
       "│ Value/Adv                     │ 0.056681737303733826  │\n",
       "│ Loss/Loss_reward_critic       │ 0.013301631435751915  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.002806706354022026 │\n",
       "│ Value/reward                  │ 2.1239004135131836    │\n",
       "│ Time/Total                    │ 5199.6953125          │\n",
       "│ Time/Rollout                  │ 10.868391990661621    │\n",
       "│ Time/Update                   │ 1.6958906650543213    │\n",
       "│ Time/Epoch                    │ 12.564338684082031    │\n",
       "│ Time/FPS                      │ 163.00103759765625    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.26744842529297     │\n",
       "│ Metrics/EpCost                │ 53.58000183105469     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 395.0                 │\n",
       "│ Train/Entropy                 │ -0.24838896095752716  │\n",
       "│ Train/KL                      │ 0.012259891256690025  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.990237832069397     │\n",
       "│ Train/PolicyRatio/Min         │ 0.990237832069397     │\n",
       "│ Train/PolicyRatio/Max         │ 0.990237832069397     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017544234171509743  │\n",
       "│ Train/LR                      │ 6.240000220714137e-05 │\n",
       "│ Train/PolicyStd               │ 0.18879832327365875   │\n",
       "│ TotalEnvSteps                 │ 811008.0              │\n",
       "│ Loss/Loss_pi                  │ -0.020980071276426315 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.005926498211920261 │\n",
       "│ Value/Adv                     │ 0.056681737303733826  │\n",
       "│ Loss/Loss_reward_critic       │ 0.013301631435751915  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.002806706354022026 │\n",
       "│ Value/reward                  │ 2.1239004135131836    │\n",
       "│ Time/Total                    │ 5199.6953125          │\n",
       "│ Time/Rollout                  │ 10.868391990661621    │\n",
       "│ Time/Update                   │ 1.6958906650543213    │\n",
       "│ Time/Epoch                    │ 12.564338684082031    │\n",
       "│ Time/FPS                      │ 163.00103759765625    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.38787269592285     │\n",
       "│ Metrics/EpCost                │ 52.97999954223633     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 396.0                 │\n",
       "│ Train/Entropy                 │ -0.253070205450058    │\n",
       "│ Train/KL                      │ 0.0078040421940386295 │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.01460599899292      │\n",
       "│ Train/PolicyRatio/Min         │ 1.01460599899292      │\n",
       "│ Train/PolicyRatio/Max         │ 1.01460599899292      │\n",
       "│ Train/PolicyRatio/Std         │ 0.018125900998711586  │\n",
       "│ Train/LR                      │ 6.179999763844535e-05 │\n",
       "│ Train/PolicyStd               │ 0.18791037797927856   │\n",
       "│ TotalEnvSteps                 │ 813056.0              │\n",
       "│ Loss/Loss_pi                  │ -0.012601964175701141 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.008378107100725174  │\n",
       "│ Value/Adv                     │ -0.014393851161003113 │\n",
       "│ Loss/Loss_reward_critic       │ 0.021903488785028458  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.008601857349276543  │\n",
       "│ Value/reward                  │ 1.9764493703842163    │\n",
       "│ Time/Total                    │ 5212.2216796875       │\n",
       "│ Time/Rollout                  │ 10.814619064331055    │\n",
       "│ Time/Update                   │ 1.6997950077056885    │\n",
       "│ Time/Epoch                    │ 12.514456748962402    │\n",
       "│ Time/FPS                      │ 163.65074157714844    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.38787269592285     │\n",
       "│ Metrics/EpCost                │ 52.97999954223633     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 396.0                 │\n",
       "│ Train/Entropy                 │ -0.253070205450058    │\n",
       "│ Train/KL                      │ 0.0078040421940386295 │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.01460599899292      │\n",
       "│ Train/PolicyRatio/Min         │ 1.01460599899292      │\n",
       "│ Train/PolicyRatio/Max         │ 1.01460599899292      │\n",
       "│ Train/PolicyRatio/Std         │ 0.018125900998711586  │\n",
       "│ Train/LR                      │ 6.179999763844535e-05 │\n",
       "│ Train/PolicyStd               │ 0.18791037797927856   │\n",
       "│ TotalEnvSteps                 │ 813056.0              │\n",
       "│ Loss/Loss_pi                  │ -0.012601964175701141 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.008378107100725174  │\n",
       "│ Value/Adv                     │ -0.014393851161003113 │\n",
       "│ Loss/Loss_reward_critic       │ 0.021903488785028458  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.008601857349276543  │\n",
       "│ Value/reward                  │ 1.9764493703842163    │\n",
       "│ Time/Total                    │ 5212.2216796875       │\n",
       "│ Time/Rollout                  │ 10.814619064331055    │\n",
       "│ Time/Update                   │ 1.6997950077056885    │\n",
       "│ Time/Epoch                    │ 12.514456748962402    │\n",
       "│ Time/FPS                      │ 163.65074157714844    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.391799926757812     │\n",
       "│ Metrics/EpCost                │ 52.040000915527344     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 397.0                  │\n",
       "│ Train/Entropy                 │ -0.25838330388069153   │\n",
       "│ Train/KL                      │ 0.012146808207035065   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9988530278205872     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9988530278205872     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9988530278205872     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01645883172750473    │\n",
       "│ Train/LR                      │ 6.120000034570694e-05  │\n",
       "│ Train/PolicyStd               │ 0.18690387904644012    │\n",
       "│ TotalEnvSteps                 │ 815104.0               │\n",
       "│ Loss/Loss_pi                  │ -0.02020292356610298   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00760095939040184   │\n",
       "│ Value/Adv                     │ -0.13493400812149048   │\n",
       "│ Loss/Loss_reward_critic       │ 0.019816875457763672   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0020866133272647858 │\n",
       "│ Value/reward                  │ 2.1681838035583496     │\n",
       "│ Time/Total                    │ 5224.80029296875       │\n",
       "│ Time/Rollout                  │ 10.879408836364746     │\n",
       "│ Time/Update                   │ 1.6873371601104736     │\n",
       "│ Time/Epoch                    │ 12.566793441772461     │\n",
       "│ Time/FPS                      │ 162.9691925048828      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.391799926757812     │\n",
       "│ Metrics/EpCost                │ 52.040000915527344     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 397.0                  │\n",
       "│ Train/Entropy                 │ -0.25838330388069153   │\n",
       "│ Train/KL                      │ 0.012146808207035065   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9988530278205872     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9988530278205872     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9988530278205872     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01645883172750473    │\n",
       "│ Train/LR                      │ 6.120000034570694e-05  │\n",
       "│ Train/PolicyStd               │ 0.18690387904644012    │\n",
       "│ TotalEnvSteps                 │ 815104.0               │\n",
       "│ Loss/Loss_pi                  │ -0.02020292356610298   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00760095939040184   │\n",
       "│ Value/Adv                     │ -0.13493400812149048   │\n",
       "│ Loss/Loss_reward_critic       │ 0.019816875457763672   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0020866133272647858 │\n",
       "│ Value/reward                  │ 2.1681838035583496     │\n",
       "│ Time/Total                    │ 5224.80029296875       │\n",
       "│ Time/Rollout                  │ 10.879408836364746     │\n",
       "│ Time/Update                   │ 1.6873371601104736     │\n",
       "│ Time/Epoch                    │ 12.566793441772461     │\n",
       "│ Time/FPS                      │ 162.9691925048828      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.460952758789062     │\n",
       "│ Metrics/EpCost                │ 53.540000915527344     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 398.0                  │\n",
       "│ Train/Entropy                 │ -0.2626272737979889    │\n",
       "│ Train/KL                      │ 0.013739941641688347   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9988198280334473     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9988198280334473     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9988198280334473     │\n",
       "│ Train/PolicyRatio/Std         │ 0.015174509026110172   │\n",
       "│ Train/LR                      │ 6.0599999414989725e-05 │\n",
       "│ Train/PolicyStd               │ 0.18611308932304382    │\n",
       "│ TotalEnvSteps                 │ 817152.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015201659873127937  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005001263692975044   │\n",
       "│ Value/Adv                     │ -0.07204214483499527   │\n",
       "│ Loss/Loss_reward_critic       │ 0.026220247149467468   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006403371691703796   │\n",
       "│ Value/reward                  │ 2.1159820556640625     │\n",
       "│ Time/Total                    │ 5237.32666015625       │\n",
       "│ Time/Rollout                  │ 10.827584266662598     │\n",
       "│ Time/Update                   │ 1.6872484683990479     │\n",
       "│ Time/Epoch                    │ 12.51487922668457      │\n",
       "│ Time/FPS                      │ 163.6452178955078      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.460952758789062     │\n",
       "│ Metrics/EpCost                │ 53.540000915527344     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 398.0                  │\n",
       "│ Train/Entropy                 │ -0.2626272737979889    │\n",
       "│ Train/KL                      │ 0.013739941641688347   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9988198280334473     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9988198280334473     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9988198280334473     │\n",
       "│ Train/PolicyRatio/Std         │ 0.015174509026110172   │\n",
       "│ Train/LR                      │ 6.0599999414989725e-05 │\n",
       "│ Train/PolicyStd               │ 0.18611308932304382    │\n",
       "│ TotalEnvSteps                 │ 817152.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015201659873127937  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005001263692975044   │\n",
       "│ Value/Adv                     │ -0.07204214483499527   │\n",
       "│ Loss/Loss_reward_critic       │ 0.026220247149467468   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006403371691703796   │\n",
       "│ Value/reward                  │ 2.1159820556640625     │\n",
       "│ Time/Total                    │ 5237.32666015625       │\n",
       "│ Time/Rollout                  │ 10.827584266662598     │\n",
       "│ Time/Update                   │ 1.6872484683990479     │\n",
       "│ Time/Epoch                    │ 12.51487922668457      │\n",
       "│ Time/FPS                      │ 163.6452178955078      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.574478149414062    │\n",
       "│ Metrics/EpCost                │ 54.65999984741211     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 399.0                 │\n",
       "│ Train/Entropy                 │ -0.2646905779838562   │\n",
       "│ Train/KL                      │ 0.011358566582202911  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9955536723136902    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9955536723136902    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9955536723136902    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01563105545938015   │\n",
       "│ Train/LR                      │ 5.999999848427251e-05 │\n",
       "│ Train/PolicyStd               │ 0.18573106825351715   │\n",
       "│ TotalEnvSteps                 │ 819200.0              │\n",
       "│ Loss/Loss_pi                  │ -0.013979418203234673 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0012222416698932648 │\n",
       "│ Value/Adv                     │ -0.11226733028888702  │\n",
       "│ Loss/Loss_reward_critic       │ 0.02058018371462822   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005640063434839249 │\n",
       "│ Value/reward                  │ 2.1525449752807617    │\n",
       "│ Time/Total                    │ 5249.9296875          │\n",
       "│ Time/Rollout                  │ 10.889408111572266    │\n",
       "│ Time/Update                   │ 1.7021563053131104    │\n",
       "│ Time/Epoch                    │ 12.591606140136719    │\n",
       "│ Time/FPS                      │ 162.64804077148438    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.574478149414062    │\n",
       "│ Metrics/EpCost                │ 54.65999984741211     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 399.0                 │\n",
       "│ Train/Entropy                 │ -0.2646905779838562   │\n",
       "│ Train/KL                      │ 0.011358566582202911  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9955536723136902    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9955536723136902    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9955536723136902    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01563105545938015   │\n",
       "│ Train/LR                      │ 5.999999848427251e-05 │\n",
       "│ Train/PolicyStd               │ 0.18573106825351715   │\n",
       "│ TotalEnvSteps                 │ 819200.0              │\n",
       "│ Loss/Loss_pi                  │ -0.013979418203234673 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0012222416698932648 │\n",
       "│ Value/Adv                     │ -0.11226733028888702  │\n",
       "│ Loss/Loss_reward_critic       │ 0.02058018371462822   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005640063434839249 │\n",
       "│ Value/reward                  │ 2.1525449752807617    │\n",
       "│ Time/Total                    │ 5249.9296875          │\n",
       "│ Time/Rollout                  │ 10.889408111572266    │\n",
       "│ Time/Update                   │ 1.7021563053131104    │\n",
       "│ Time/Epoch                    │ 12.591606140136719    │\n",
       "│ Time/FPS                      │ 162.64804077148438    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.563074111938477     │\n",
       "│ Metrics/EpCost                │ 55.81999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 400.0                  │\n",
       "│ Train/Entropy                 │ -0.2663194537162781    │\n",
       "│ Train/KL                      │ 0.013142767362296581   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9918238520622253     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9918238520622253     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9918238520622253     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017639538273215294   │\n",
       "│ Train/LR                      │ 5.94000011915341e-05   │\n",
       "│ Train/PolicyStd               │ 0.18543216586112976    │\n",
       "│ TotalEnvSteps                 │ 821248.0               │\n",
       "│ Loss/Loss_pi                  │ -0.019499411806464195  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.005519993603229523  │\n",
       "│ Value/Adv                     │ 0.08884266018867493    │\n",
       "│ Loss/Loss_reward_critic       │ 0.019147275015711784   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0014329086989164352 │\n",
       "│ Value/reward                  │ 2.1757891178131104     │\n",
       "│ Time/Total                    │ 5262.43896484375       │\n",
       "│ Time/Rollout                  │ 10.811990737915039     │\n",
       "│ Time/Update                   │ 1.682464599609375      │\n",
       "│ Time/Epoch                    │ 12.494499206542969     │\n",
       "│ Time/FPS                      │ 163.91213989257812     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.563074111938477     │\n",
       "│ Metrics/EpCost                │ 55.81999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 400.0                  │\n",
       "│ Train/Entropy                 │ -0.2663194537162781    │\n",
       "│ Train/KL                      │ 0.013142767362296581   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9918238520622253     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9918238520622253     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9918238520622253     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017639538273215294   │\n",
       "│ Train/LR                      │ 5.94000011915341e-05   │\n",
       "│ Train/PolicyStd               │ 0.18543216586112976    │\n",
       "│ TotalEnvSteps                 │ 821248.0               │\n",
       "│ Loss/Loss_pi                  │ -0.019499411806464195  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.005519993603229523  │\n",
       "│ Value/Adv                     │ 0.08884266018867493    │\n",
       "│ Loss/Loss_reward_critic       │ 0.019147275015711784   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0014329086989164352 │\n",
       "│ Value/reward                  │ 2.1757891178131104     │\n",
       "│ Time/Total                    │ 5262.43896484375       │\n",
       "│ Time/Rollout                  │ 10.811990737915039     │\n",
       "│ Time/Update                   │ 1.682464599609375      │\n",
       "│ Time/Epoch                    │ 12.494499206542969     │\n",
       "│ Time/FPS                      │ 163.91213989257812     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.4628849029541      │\n",
       "│ Metrics/EpCost                │ 54.380001068115234    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 401.0                 │\n",
       "│ Train/Entropy                 │ -0.26687711477279663  │\n",
       "│ Train/KL                      │ 0.013303034007549286  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9961373209953308    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9961373209953308    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9961373209953308    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01630505360662937   │\n",
       "│ Train/LR                      │ 5.880000026081689e-05 │\n",
       "│ Train/PolicyStd               │ 0.18532654643058777   │\n",
       "│ TotalEnvSteps                 │ 823296.0              │\n",
       "│ Loss/Loss_pi                  │ -0.014962109737098217 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004537302069365978  │\n",
       "│ Value/Adv                     │ -0.007002882659435272 │\n",
       "│ Loss/Loss_reward_critic       │ 0.017309945076704025  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.001837329939007759 │\n",
       "│ Value/reward                  │ 2.0911366939544678    │\n",
       "│ Time/Total                    │ 5275.07470703125      │\n",
       "│ Time/Rollout                  │ 10.895224571228027    │\n",
       "│ Time/Update                   │ 1.7290022373199463    │\n",
       "│ Time/Epoch                    │ 12.624269485473633    │\n",
       "│ Time/FPS                      │ 162.2272186279297     │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.4628849029541      │\n",
       "│ Metrics/EpCost                │ 54.380001068115234    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 401.0                 │\n",
       "│ Train/Entropy                 │ -0.26687711477279663  │\n",
       "│ Train/KL                      │ 0.013303034007549286  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9961373209953308    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9961373209953308    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9961373209953308    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01630505360662937   │\n",
       "│ Train/LR                      │ 5.880000026081689e-05 │\n",
       "│ Train/PolicyStd               │ 0.18532654643058777   │\n",
       "│ TotalEnvSteps                 │ 823296.0              │\n",
       "│ Loss/Loss_pi                  │ -0.014962109737098217 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004537302069365978  │\n",
       "│ Value/Adv                     │ -0.007002882659435272 │\n",
       "│ Loss/Loss_reward_critic       │ 0.017309945076704025  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.001837329939007759 │\n",
       "│ Value/reward                  │ 2.0911366939544678    │\n",
       "│ Time/Total                    │ 5275.07470703125      │\n",
       "│ Time/Rollout                  │ 10.895224571228027    │\n",
       "│ Time/Update                   │ 1.7290022373199463    │\n",
       "│ Time/Epoch                    │ 12.624269485473633    │\n",
       "│ Time/FPS                      │ 162.2272186279297     │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.9595947265625       │\n",
       "│ Metrics/EpCost                │ 56.31999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 402.0                  │\n",
       "│ Train/Entropy                 │ -0.2683863639831543    │\n",
       "│ Train/KL                      │ 0.010885398834943771   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9980748295783997     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9980748295783997     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9980748295783997     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016161669045686722   │\n",
       "│ Train/LR                      │ 5.819999933009967e-05  │\n",
       "│ Train/PolicyStd               │ 0.18505126237869263    │\n",
       "│ TotalEnvSteps                 │ 825344.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01610415056347847   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0011420408263802528 │\n",
       "│ Value/Adv                     │ 0.1159801185131073     │\n",
       "│ Loss/Loss_reward_critic       │ 0.018865447491407394   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0015555024147033691  │\n",
       "│ Value/reward                  │ 2.196397066116333      │\n",
       "│ Time/Total                    │ 5287.6484375           │\n",
       "│ Time/Rollout                  │ 10.8622407913208       │\n",
       "│ Time/Update                   │ 1.7001144886016846     │\n",
       "│ Time/Epoch                    │ 12.562408447265625     │\n",
       "│ Time/FPS                      │ 163.02606201171875     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.9595947265625       │\n",
       "│ Metrics/EpCost                │ 56.31999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 402.0                  │\n",
       "│ Train/Entropy                 │ -0.2683863639831543    │\n",
       "│ Train/KL                      │ 0.010885398834943771   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9980748295783997     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9980748295783997     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9980748295783997     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016161669045686722   │\n",
       "│ Train/LR                      │ 5.819999933009967e-05  │\n",
       "│ Train/PolicyStd               │ 0.18505126237869263    │\n",
       "│ TotalEnvSteps                 │ 825344.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01610415056347847   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0011420408263802528 │\n",
       "│ Value/Adv                     │ 0.1159801185131073     │\n",
       "│ Loss/Loss_reward_critic       │ 0.018865447491407394   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0015555024147033691  │\n",
       "│ Value/reward                  │ 2.196397066116333      │\n",
       "│ Time/Total                    │ 5287.6484375           │\n",
       "│ Time/Rollout                  │ 10.8622407913208       │\n",
       "│ Time/Update                   │ 1.7001144886016846     │\n",
       "│ Time/Epoch                    │ 12.562408447265625     │\n",
       "│ Time/FPS                      │ 163.02606201171875     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.955093383789062     │\n",
       "│ Metrics/EpCost                │ 57.58000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 403.0                  │\n",
       "│ Train/Entropy                 │ -0.2698538899421692    │\n",
       "│ Train/KL                      │ 0.010103409178555012   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0022106170654297     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0022106170654297     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0022106170654297     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017822805792093277   │\n",
       "│ Train/LR                      │ 5.759999839938246e-05  │\n",
       "│ Train/PolicyStd               │ 0.18478643894195557    │\n",
       "│ TotalEnvSteps                 │ 827392.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017175445333123207  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0010712947696447372 │\n",
       "│ Value/Adv                     │ 0.12219834327697754    │\n",
       "│ Loss/Loss_reward_critic       │ 0.024151017889380455   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.005285570397973061   │\n",
       "│ Value/reward                  │ 2.1016790866851807     │\n",
       "│ Time/Total                    │ 5300.29931640625       │\n",
       "│ Time/Rollout                  │ 10.924363136291504     │\n",
       "│ Time/Update                   │ 1.7146258354187012     │\n",
       "│ Time/Epoch                    │ 12.63903522491455      │\n",
       "│ Time/FPS                      │ 162.03768920898438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.955093383789062     │\n",
       "│ Metrics/EpCost                │ 57.58000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 403.0                  │\n",
       "│ Train/Entropy                 │ -0.2698538899421692    │\n",
       "│ Train/KL                      │ 0.010103409178555012   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0022106170654297     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0022106170654297     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0022106170654297     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017822805792093277   │\n",
       "│ Train/LR                      │ 5.759999839938246e-05  │\n",
       "│ Train/PolicyStd               │ 0.18478643894195557    │\n",
       "│ TotalEnvSteps                 │ 827392.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017175445333123207  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0010712947696447372 │\n",
       "│ Value/Adv                     │ 0.12219834327697754    │\n",
       "│ Loss/Loss_reward_critic       │ 0.024151017889380455   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.005285570397973061   │\n",
       "│ Value/reward                  │ 2.1016790866851807     │\n",
       "│ Time/Total                    │ 5300.29931640625       │\n",
       "│ Time/Rollout                  │ 10.924363136291504     │\n",
       "│ Time/Update                   │ 1.7146258354187012     │\n",
       "│ Time/Epoch                    │ 12.63903522491455      │\n",
       "│ Time/FPS                      │ 162.03768920898438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.929248809814453    │\n",
       "│ Metrics/EpCost                │ 57.900001525878906    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 404.0                 │\n",
       "│ Train/Entropy                 │ -0.26929575204849243  │\n",
       "│ Train/KL                      │ 0.0144409891217947    │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.997979998588562     │\n",
       "│ Train/PolicyRatio/Min         │ 0.997979998588562     │\n",
       "│ Train/PolicyRatio/Max         │ 0.997979998588562     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017438367009162903  │\n",
       "│ Train/LR                      │ 5.700000110664405e-05 │\n",
       "│ Train/PolicyStd               │ 0.18488630652427673   │\n",
       "│ TotalEnvSteps                 │ 829440.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01871776022017002  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.001542314887046814 │\n",
       "│ Value/Adv                     │ 0.05962799862027168   │\n",
       "│ Loss/Loss_reward_critic       │ 0.017146699130535126  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.007004318758845329 │\n",
       "│ Value/reward                  │ 2.099026679992676     │\n",
       "│ Time/Total                    │ 5312.845703125        │\n",
       "│ Time/Rollout                  │ 10.826339721679688    │\n",
       "│ Time/Update                   │ 1.7086772918701172    │\n",
       "│ Time/Epoch                    │ 12.535062789916992    │\n",
       "│ Time/FPS                      │ 163.38172912597656    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.929248809814453    │\n",
       "│ Metrics/EpCost                │ 57.900001525878906    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 404.0                 │\n",
       "│ Train/Entropy                 │ -0.26929575204849243  │\n",
       "│ Train/KL                      │ 0.0144409891217947    │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.997979998588562     │\n",
       "│ Train/PolicyRatio/Min         │ 0.997979998588562     │\n",
       "│ Train/PolicyRatio/Max         │ 0.997979998588562     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017438367009162903  │\n",
       "│ Train/LR                      │ 5.700000110664405e-05 │\n",
       "│ Train/PolicyStd               │ 0.18488630652427673   │\n",
       "│ TotalEnvSteps                 │ 829440.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01871776022017002  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.001542314887046814 │\n",
       "│ Value/Adv                     │ 0.05962799862027168   │\n",
       "│ Loss/Loss_reward_critic       │ 0.017146699130535126  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.007004318758845329 │\n",
       "│ Value/reward                  │ 2.099026679992676     │\n",
       "│ Time/Total                    │ 5312.845703125        │\n",
       "│ Time/Rollout                  │ 10.826339721679688    │\n",
       "│ Time/Update                   │ 1.7086772918701172    │\n",
       "│ Time/Epoch                    │ 12.535062789916992    │\n",
       "│ Time/FPS                      │ 163.38172912597656    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.909221649169922     │\n",
       "│ Metrics/EpCost                │ 57.560001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 405.0                  │\n",
       "│ Train/Entropy                 │ -0.2690422832965851    │\n",
       "│ Train/KL                      │ 0.012502807192504406   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.000450849533081      │\n",
       "│ Train/PolicyRatio/Min         │ 1.000450849533081      │\n",
       "│ Train/PolicyRatio/Max         │ 1.000450849533081      │\n",
       "│ Train/PolicyRatio/Std         │ 0.01625549979507923    │\n",
       "│ Train/LR                      │ 5.6400000175926834e-05 │\n",
       "│ Train/PolicyStd               │ 0.1849319189786911     │\n",
       "│ TotalEnvSteps                 │ 831488.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01986914686858654   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0011513866484165192 │\n",
       "│ Value/Adv                     │ 0.06397048383951187    │\n",
       "│ Loss/Loss_reward_critic       │ 0.019851481541991234   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002704782411456108   │\n",
       "│ Value/reward                  │ 2.2117724418640137     │\n",
       "│ Time/Total                    │ 5325.38671875          │\n",
       "│ Time/Rollout                  │ 10.846059799194336     │\n",
       "│ Time/Update                   │ 1.6833109855651855     │\n",
       "│ Time/Epoch                    │ 12.529411315917969     │\n",
       "│ Time/FPS                      │ 163.45541381835938     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.909221649169922     │\n",
       "│ Metrics/EpCost                │ 57.560001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 405.0                  │\n",
       "│ Train/Entropy                 │ -0.2690422832965851    │\n",
       "│ Train/KL                      │ 0.012502807192504406   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.000450849533081      │\n",
       "│ Train/PolicyRatio/Min         │ 1.000450849533081      │\n",
       "│ Train/PolicyRatio/Max         │ 1.000450849533081      │\n",
       "│ Train/PolicyRatio/Std         │ 0.01625549979507923    │\n",
       "│ Train/LR                      │ 5.6400000175926834e-05 │\n",
       "│ Train/PolicyStd               │ 0.1849319189786911     │\n",
       "│ TotalEnvSteps                 │ 831488.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01986914686858654   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0011513866484165192 │\n",
       "│ Value/Adv                     │ 0.06397048383951187    │\n",
       "│ Loss/Loss_reward_critic       │ 0.019851481541991234   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002704782411456108   │\n",
       "│ Value/reward                  │ 2.2117724418640137     │\n",
       "│ Time/Total                    │ 5325.38671875          │\n",
       "│ Time/Rollout                  │ 10.846059799194336     │\n",
       "│ Time/Update                   │ 1.6833109855651855     │\n",
       "│ Time/Epoch                    │ 12.529411315917969     │\n",
       "│ Time/FPS                      │ 163.45541381835938     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.95366668701172     │\n",
       "│ Metrics/EpCost                │ 60.060001373291016    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 406.0                 │\n",
       "│ Train/Entropy                 │ -0.2704095244407654   │\n",
       "│ Train/KL                      │ 0.009549057111144066  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0051662921905518    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0051662921905518    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0051662921905518    │\n",
       "│ Train/PolicyRatio/Std         │ 0.015170169062912464  │\n",
       "│ Train/LR                      │ 5.579999924520962e-05 │\n",
       "│ Train/PolicyStd               │ 0.18468305468559265   │\n",
       "│ TotalEnvSteps                 │ 833536.0              │\n",
       "│ Loss/Loss_pi                  │ -0.014882311224937439 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004986835643649101  │\n",
       "│ Value/Adv                     │ -0.15453305840492249  │\n",
       "│ Loss/Loss_reward_critic       │ 0.020862702280282974  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0010112207382917404 │\n",
       "│ Value/reward                  │ 2.0566394329071045    │\n",
       "│ Time/Total                    │ 5337.990234375        │\n",
       "│ Time/Rollout                  │ 10.877199172973633    │\n",
       "│ Time/Update                   │ 1.7146902084350586    │\n",
       "│ Time/Epoch                    │ 12.591931343078613    │\n",
       "│ Time/FPS                      │ 162.6438446044922     │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.95366668701172     │\n",
       "│ Metrics/EpCost                │ 60.060001373291016    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 406.0                 │\n",
       "│ Train/Entropy                 │ -0.2704095244407654   │\n",
       "│ Train/KL                      │ 0.009549057111144066  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0051662921905518    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0051662921905518    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0051662921905518    │\n",
       "│ Train/PolicyRatio/Std         │ 0.015170169062912464  │\n",
       "│ Train/LR                      │ 5.579999924520962e-05 │\n",
       "│ Train/PolicyStd               │ 0.18468305468559265   │\n",
       "│ TotalEnvSteps                 │ 833536.0              │\n",
       "│ Loss/Loss_pi                  │ -0.014882311224937439 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004986835643649101  │\n",
       "│ Value/Adv                     │ -0.15453305840492249  │\n",
       "│ Loss/Loss_reward_critic       │ 0.020862702280282974  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0010112207382917404 │\n",
       "│ Value/reward                  │ 2.0566394329071045    │\n",
       "│ Time/Total                    │ 5337.990234375        │\n",
       "│ Time/Rollout                  │ 10.877199172973633    │\n",
       "│ Time/Update                   │ 1.7146902084350586    │\n",
       "│ Time/Epoch                    │ 12.591931343078613    │\n",
       "│ Time/FPS                      │ 162.6438446044922     │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.691679000854492     │\n",
       "│ Metrics/EpCost                │ 59.400001525878906     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 407.0                  │\n",
       "│ Train/Entropy                 │ -0.27202439308166504   │\n",
       "│ Train/KL                      │ 0.01152760349214077    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.007202386856079      │\n",
       "│ Train/PolicyRatio/Min         │ 1.007202386856079      │\n",
       "│ Train/PolicyRatio/Max         │ 1.007202386856079      │\n",
       "│ Train/PolicyRatio/Std         │ 0.016084834933280945   │\n",
       "│ Train/LR                      │ 5.5199998314492404e-05 │\n",
       "│ Train/PolicyStd               │ 0.18439041078090668    │\n",
       "│ TotalEnvSteps                 │ 835584.0               │\n",
       "│ Loss/Loss_pi                  │ -0.0178076159209013    │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0029253046959638596 │\n",
       "│ Value/Adv                     │ -0.09329290688037872   │\n",
       "│ Loss/Loss_reward_critic       │ 0.013465074822306633   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.007397627457976341  │\n",
       "│ Value/reward                  │ 1.9412288665771484     │\n",
       "│ Time/Total                    │ 5350.548828125         │\n",
       "│ Time/Rollout                  │ 10.847297668457031     │\n",
       "│ Time/Update                   │ 1.6996495723724365     │\n",
       "│ Time/Epoch                    │ 12.546990394592285     │\n",
       "│ Time/FPS                      │ 163.22640991210938     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.691679000854492     │\n",
       "│ Metrics/EpCost                │ 59.400001525878906     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 407.0                  │\n",
       "│ Train/Entropy                 │ -0.27202439308166504   │\n",
       "│ Train/KL                      │ 0.01152760349214077    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.007202386856079      │\n",
       "│ Train/PolicyRatio/Min         │ 1.007202386856079      │\n",
       "│ Train/PolicyRatio/Max         │ 1.007202386856079      │\n",
       "│ Train/PolicyRatio/Std         │ 0.016084834933280945   │\n",
       "│ Train/LR                      │ 5.5199998314492404e-05 │\n",
       "│ Train/PolicyStd               │ 0.18439041078090668    │\n",
       "│ TotalEnvSteps                 │ 835584.0               │\n",
       "│ Loss/Loss_pi                  │ -0.0178076159209013    │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0029253046959638596 │\n",
       "│ Value/Adv                     │ -0.09329290688037872   │\n",
       "│ Loss/Loss_reward_critic       │ 0.013465074822306633   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.007397627457976341  │\n",
       "│ Value/reward                  │ 1.9412288665771484     │\n",
       "│ Time/Total                    │ 5350.548828125         │\n",
       "│ Time/Rollout                  │ 10.847297668457031     │\n",
       "│ Time/Update                   │ 1.6996495723724365     │\n",
       "│ Time/Epoch                    │ 12.546990394592285     │\n",
       "│ Time/FPS                      │ 163.22640991210938     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.167959213256836     │\n",
       "│ Metrics/EpCost                │ 59.0                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 408.0                  │\n",
       "│ Train/Entropy                 │ -0.27384132146835327   │\n",
       "│ Train/KL                      │ 0.011567476205527782   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9908550977706909     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9908550977706909     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9908550977706909     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01712784916162491    │\n",
       "│ Train/LR                      │ 5.4600001021753997e-05 │\n",
       "│ Train/PolicyStd               │ 0.18405315279960632    │\n",
       "│ TotalEnvSteps                 │ 837632.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016376176849007607  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.001431439071893692   │\n",
       "│ Value/Adv                     │ -0.16897448897361755   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02101353369653225    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0075484588742256165  │\n",
       "│ Value/reward                  │ 2.0501999855041504     │\n",
       "│ Time/Total                    │ 5363.14599609375       │\n",
       "│ Time/Rollout                  │ 10.884130477905273     │\n",
       "│ Time/Update                   │ 1.701470136642456      │\n",
       "│ Time/Epoch                    │ 12.585651397705078     │\n",
       "│ Time/FPS                      │ 162.72499084472656     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.167959213256836     │\n",
       "│ Metrics/EpCost                │ 59.0                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 408.0                  │\n",
       "│ Train/Entropy                 │ -0.27384132146835327   │\n",
       "│ Train/KL                      │ 0.011567476205527782   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9908550977706909     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9908550977706909     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9908550977706909     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01712784916162491    │\n",
       "│ Train/LR                      │ 5.4600001021753997e-05 │\n",
       "│ Train/PolicyStd               │ 0.18405315279960632    │\n",
       "│ TotalEnvSteps                 │ 837632.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016376176849007607  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.001431439071893692   │\n",
       "│ Value/Adv                     │ -0.16897448897361755   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02101353369653225    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0075484588742256165  │\n",
       "│ Value/reward                  │ 2.0501999855041504     │\n",
       "│ Time/Total                    │ 5363.14599609375       │\n",
       "│ Time/Rollout                  │ 10.884130477905273     │\n",
       "│ Time/Update                   │ 1.701470136642456      │\n",
       "│ Time/Epoch                    │ 12.585651397705078     │\n",
       "│ Time/FPS                      │ 162.72499084472656     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.04474449157715      │\n",
       "│ Metrics/EpCost                │ 60.599998474121094     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 409.0                  │\n",
       "│ Train/Entropy                 │ -0.27430063486099243   │\n",
       "│ Train/KL                      │ 0.01049584150314331    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0025094747543335     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0025094747543335     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0025094747543335     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017601914703845978   │\n",
       "│ Train/LR                      │ 5.400000009103678e-05  │\n",
       "│ Train/PolicyStd               │ 0.1839613914489746     │\n",
       "│ TotalEnvSteps                 │ 839680.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014180980622768402  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0021951962262392044  │\n",
       "│ Value/Adv                     │ 0.03252265974879265    │\n",
       "│ Loss/Loss_reward_critic       │ 0.020085744559764862   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0009277891367673874 │\n",
       "│ Value/reward                  │ 2.0095930099487305     │\n",
       "│ Time/Total                    │ 5375.79345703125       │\n",
       "│ Time/Rollout                  │ 10.902478218078613     │\n",
       "│ Time/Update                   │ 1.7334303855895996     │\n",
       "│ Time/Epoch                    │ 12.635953903198242     │\n",
       "│ Time/FPS                      │ 162.07720947265625     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.04474449157715      │\n",
       "│ Metrics/EpCost                │ 60.599998474121094     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 409.0                  │\n",
       "│ Train/Entropy                 │ -0.27430063486099243   │\n",
       "│ Train/KL                      │ 0.01049584150314331    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0025094747543335     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0025094747543335     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0025094747543335     │\n",
       "│ Train/PolicyRatio/Std         │ 0.017601914703845978   │\n",
       "│ Train/LR                      │ 5.400000009103678e-05  │\n",
       "│ Train/PolicyStd               │ 0.1839613914489746     │\n",
       "│ TotalEnvSteps                 │ 839680.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014180980622768402  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0021951962262392044  │\n",
       "│ Value/Adv                     │ 0.03252265974879265    │\n",
       "│ Loss/Loss_reward_critic       │ 0.020085744559764862   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0009277891367673874 │\n",
       "│ Value/reward                  │ 2.0095930099487305     │\n",
       "│ Time/Total                    │ 5375.79345703125       │\n",
       "│ Time/Rollout                  │ 10.902478218078613     │\n",
       "│ Time/Update                   │ 1.7334303855895996     │\n",
       "│ Time/Epoch                    │ 12.635953903198242     │\n",
       "│ Time/FPS                      │ 162.07720947265625     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.071664810180664     │\n",
       "│ Metrics/EpCost                │ 61.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 410.0                  │\n",
       "│ Train/Entropy                 │ -0.27587276697158813   │\n",
       "│ Train/KL                      │ 0.011915931478142738   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9959732890129089     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9959732890129089     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9959732890129089     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01635771617293358    │\n",
       "│ Train/LR                      │ 5.339999916031957e-05  │\n",
       "│ Train/PolicyStd               │ 0.1836685836315155     │\n",
       "│ TotalEnvSteps                 │ 841728.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017467448487877846  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0032864678651094437 │\n",
       "│ Value/Adv                     │ 0.008836623281240463   │\n",
       "│ Loss/Loss_reward_critic       │ 0.016684677451848984   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0034010671079158783 │\n",
       "│ Value/reward                  │ 2.1765944957733154     │\n",
       "│ Time/Total                    │ 5388.36572265625       │\n",
       "│ Time/Rollout                  │ 10.857458114624023     │\n",
       "│ Time/Update                   │ 1.7012224197387695     │\n",
       "│ Time/Epoch                    │ 12.558721542358398     │\n",
       "│ Time/FPS                      │ 163.0739288330078      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.071664810180664     │\n",
       "│ Metrics/EpCost                │ 61.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 410.0                  │\n",
       "│ Train/Entropy                 │ -0.27587276697158813   │\n",
       "│ Train/KL                      │ 0.011915931478142738   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9959732890129089     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9959732890129089     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9959732890129089     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01635771617293358    │\n",
       "│ Train/LR                      │ 5.339999916031957e-05  │\n",
       "│ Train/PolicyStd               │ 0.1836685836315155     │\n",
       "│ TotalEnvSteps                 │ 841728.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017467448487877846  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0032864678651094437 │\n",
       "│ Value/Adv                     │ 0.008836623281240463   │\n",
       "│ Loss/Loss_reward_critic       │ 0.016684677451848984   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0034010671079158783 │\n",
       "│ Value/reward                  │ 2.1765944957733154     │\n",
       "│ Time/Total                    │ 5388.36572265625       │\n",
       "│ Time/Rollout                  │ 10.857458114624023     │\n",
       "│ Time/Update                   │ 1.7012224197387695     │\n",
       "│ Time/Epoch                    │ 12.558721542358398     │\n",
       "│ Time/FPS                      │ 163.0739288330078      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.939594268798828     │\n",
       "│ Metrics/EpCost                │ 62.02000045776367      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 411.0                  │\n",
       "│ Train/Entropy                 │ -0.276066392660141     │\n",
       "│ Train/KL                      │ 0.013689989224076271   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0005807876586914     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0005807876586914     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0005807876586914     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01756923831999302    │\n",
       "│ Train/LR                      │ 5.279999822960235e-05  │\n",
       "│ Train/PolicyStd               │ 0.1836394965648651     │\n",
       "│ TotalEnvSteps                 │ 843776.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017252054065465927  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00021539442241191864 │\n",
       "│ Value/Adv                     │ -0.03815542161464691   │\n",
       "│ Loss/Loss_reward_critic       │ 0.010651848278939724   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00603282917290926   │\n",
       "│ Value/reward                  │ 2.051548957824707      │\n",
       "│ Time/Total                    │ 5400.99755859375       │\n",
       "│ Time/Rollout                  │ 10.899986267089844     │\n",
       "│ Time/Update                   │ 1.7201523780822754     │\n",
       "│ Time/Epoch                    │ 12.620184898376465     │\n",
       "│ Time/FPS                      │ 162.27972412109375     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.939594268798828     │\n",
       "│ Metrics/EpCost                │ 62.02000045776367      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 411.0                  │\n",
       "│ Train/Entropy                 │ -0.276066392660141     │\n",
       "│ Train/KL                      │ 0.013689989224076271   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0005807876586914     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0005807876586914     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0005807876586914     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01756923831999302    │\n",
       "│ Train/LR                      │ 5.279999822960235e-05  │\n",
       "│ Train/PolicyStd               │ 0.1836394965648651     │\n",
       "│ TotalEnvSteps                 │ 843776.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017252054065465927  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00021539442241191864 │\n",
       "│ Value/Adv                     │ -0.03815542161464691   │\n",
       "│ Loss/Loss_reward_critic       │ 0.010651848278939724   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00603282917290926   │\n",
       "│ Value/reward                  │ 2.051548957824707      │\n",
       "│ Time/Total                    │ 5400.99755859375       │\n",
       "│ Time/Rollout                  │ 10.899986267089844     │\n",
       "│ Time/Update                   │ 1.7201523780822754     │\n",
       "│ Time/Epoch                    │ 12.620184898376465     │\n",
       "│ Time/FPS                      │ 162.27972412109375     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.020463943481445     │\n",
       "│ Metrics/EpCost                │ 62.939998626708984     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 412.0                  │\n",
       "│ Train/Entropy                 │ -0.2753104567527771    │\n",
       "│ Train/KL                      │ 0.015891732648015022   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.995902419090271      │\n",
       "│ Train/PolicyRatio/Min         │ 0.995902419090271      │\n",
       "│ Train/PolicyRatio/Max         │ 0.995902419090271      │\n",
       "│ Train/PolicyRatio/Std         │ 0.017148030921816826   │\n",
       "│ Train/LR                      │ 5.2200000936863944e-05 │\n",
       "│ Train/PolicyStd               │ 0.1837911754846573     │\n",
       "│ TotalEnvSteps                 │ 845824.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01948707178235054   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002235017716884613  │\n",
       "│ Value/Adv                     │ 0.137472003698349      │\n",
       "│ Loss/Loss_reward_critic       │ 0.025005558505654335   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.014353710226714611   │\n",
       "│ Value/reward                  │ 2.1708953380584717     │\n",
       "│ Time/Total                    │ 5413.52490234375       │\n",
       "│ Time/Rollout                  │ 10.812666893005371     │\n",
       "│ Time/Update                   │ 1.7031378746032715     │\n",
       "│ Time/Epoch                    │ 12.515857696533203     │\n",
       "│ Time/FPS                      │ 163.63243103027344     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.020463943481445     │\n",
       "│ Metrics/EpCost                │ 62.939998626708984     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 412.0                  │\n",
       "│ Train/Entropy                 │ -0.2753104567527771    │\n",
       "│ Train/KL                      │ 0.015891732648015022   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.995902419090271      │\n",
       "│ Train/PolicyRatio/Min         │ 0.995902419090271      │\n",
       "│ Train/PolicyRatio/Max         │ 0.995902419090271      │\n",
       "│ Train/PolicyRatio/Std         │ 0.017148030921816826   │\n",
       "│ Train/LR                      │ 5.2200000936863944e-05 │\n",
       "│ Train/PolicyStd               │ 0.1837911754846573     │\n",
       "│ TotalEnvSteps                 │ 845824.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01948707178235054   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002235017716884613  │\n",
       "│ Value/Adv                     │ 0.137472003698349      │\n",
       "│ Loss/Loss_reward_critic       │ 0.025005558505654335   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.014353710226714611   │\n",
       "│ Value/reward                  │ 2.1708953380584717     │\n",
       "│ Time/Total                    │ 5413.52490234375       │\n",
       "│ Time/Rollout                  │ 10.812666893005371     │\n",
       "│ Time/Update                   │ 1.7031378746032715     │\n",
       "│ Time/Epoch                    │ 12.515857696533203     │\n",
       "│ Time/FPS                      │ 163.63243103027344     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.07602310180664      │\n",
       "│ Metrics/EpCost                │ 62.2599983215332       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 413.0                  │\n",
       "│ Train/Entropy                 │ -0.2766570448875427    │\n",
       "│ Train/KL                      │ 0.01621156558394432    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9914822578430176     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9914822578430176     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9914822578430176     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018936563283205032   │\n",
       "│ Train/LR                      │ 5.160000000614673e-05  │\n",
       "│ Train/PolicyStd               │ 0.18355371057987213    │\n",
       "│ TotalEnvSteps                 │ 847872.0               │\n",
       "│ Loss/Loss_pi                  │ -0.021236995235085487  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0017499234527349472 │\n",
       "│ Value/Adv                     │ -0.09100145101547241   │\n",
       "│ Loss/Loss_reward_critic       │ 0.019250299781560898   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005755258724093437  │\n",
       "│ Value/reward                  │ 2.0656683444976807     │\n",
       "│ Time/Total                    │ 5426.115234375         │\n",
       "│ Time/Rollout                  │ 10.875473022460938     │\n",
       "│ Time/Update                   │ 1.703070878982544      │\n",
       "│ Time/Epoch                    │ 12.578587532043457     │\n",
       "│ Time/FPS                      │ 162.81637573242188     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.07602310180664      │\n",
       "│ Metrics/EpCost                │ 62.2599983215332       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 413.0                  │\n",
       "│ Train/Entropy                 │ -0.2766570448875427    │\n",
       "│ Train/KL                      │ 0.01621156558394432    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9914822578430176     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9914822578430176     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9914822578430176     │\n",
       "│ Train/PolicyRatio/Std         │ 0.018936563283205032   │\n",
       "│ Train/LR                      │ 5.160000000614673e-05  │\n",
       "│ Train/PolicyStd               │ 0.18355371057987213    │\n",
       "│ TotalEnvSteps                 │ 847872.0               │\n",
       "│ Loss/Loss_pi                  │ -0.021236995235085487  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0017499234527349472 │\n",
       "│ Value/Adv                     │ -0.09100145101547241   │\n",
       "│ Loss/Loss_reward_critic       │ 0.019250299781560898   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005755258724093437  │\n",
       "│ Value/reward                  │ 2.0656683444976807     │\n",
       "│ Time/Total                    │ 5426.115234375         │\n",
       "│ Time/Rollout                  │ 10.875473022460938     │\n",
       "│ Time/Update                   │ 1.703070878982544      │\n",
       "│ Time/Epoch                    │ 12.578587532043457     │\n",
       "│ Time/FPS                      │ 162.81637573242188     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.030942916870117     │\n",
       "│ Metrics/EpCost                │ 61.279998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 414.0                  │\n",
       "│ Train/Entropy                 │ -0.27783268690109253   │\n",
       "│ Train/KL                      │ 0.015149593353271484   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9996129870414734     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9996129870414734     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9996129870414734     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016726573929190636   │\n",
       "│ Train/LR                      │ 5.0999999075429514e-05 │\n",
       "│ Train/PolicyStd               │ 0.18334296345710754    │\n",
       "│ TotalEnvSteps                 │ 849920.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01568036712706089   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005556628108024597   │\n",
       "│ Value/Adv                     │ -0.10164681822061539   │\n",
       "│ Loss/Loss_reward_critic       │ 0.017305132001638412   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0019451677799224854 │\n",
       "│ Value/reward                  │ 2.1073226928710938     │\n",
       "│ Time/Total                    │ 5438.6611328125        │\n",
       "│ Time/Rollout                  │ 10.839624404907227     │\n",
       "│ Time/Update                   │ 1.694972276687622      │\n",
       "│ Time/Epoch                    │ 12.534648895263672     │\n",
       "│ Time/FPS                      │ 163.38711547851562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.030942916870117     │\n",
       "│ Metrics/EpCost                │ 61.279998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 414.0                  │\n",
       "│ Train/Entropy                 │ -0.27783268690109253   │\n",
       "│ Train/KL                      │ 0.015149593353271484   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9996129870414734     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9996129870414734     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9996129870414734     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016726573929190636   │\n",
       "│ Train/LR                      │ 5.0999999075429514e-05 │\n",
       "│ Train/PolicyStd               │ 0.18334296345710754    │\n",
       "│ TotalEnvSteps                 │ 849920.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01568036712706089   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005556628108024597   │\n",
       "│ Value/Adv                     │ -0.10164681822061539   │\n",
       "│ Loss/Loss_reward_critic       │ 0.017305132001638412   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0019451677799224854 │\n",
       "│ Value/reward                  │ 2.1073226928710938     │\n",
       "│ Time/Total                    │ 5438.6611328125        │\n",
       "│ Time/Rollout                  │ 10.839624404907227     │\n",
       "│ Time/Update                   │ 1.694972276687622      │\n",
       "│ Time/Epoch                    │ 12.534648895263672     │\n",
       "│ Time/FPS                      │ 163.38711547851562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.998228073120117     │\n",
       "│ Metrics/EpCost                │ 60.0                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 415.0                  │\n",
       "│ Train/Entropy                 │ -0.2783123254776001    │\n",
       "│ Train/KL                      │ 0.00999996718019247    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0002321004867554     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0002321004867554     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0002321004867554     │\n",
       "│ Train/PolicyRatio/Std         │ 0.015880560502409935   │\n",
       "│ Train/LR                      │ 5.0400001782691106e-05 │\n",
       "│ Train/PolicyStd               │ 0.18325389921665192    │\n",
       "│ TotalEnvSteps                 │ 851968.0               │\n",
       "│ Loss/Loss_pi                  │ -0.0184448454529047    │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002764478325843811  │\n",
       "│ Value/Adv                     │ -0.011559780687093735  │\n",
       "│ Loss/Loss_reward_critic       │ 0.016667205840349197   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0006379261612892151 │\n",
       "│ Value/reward                  │ 2.113247871398926      │\n",
       "│ Time/Total                    │ 5451.21826171875       │\n",
       "│ Time/Rollout                  │ 10.8583984375          │\n",
       "│ Time/Update                   │ 1.6872601509094238     │\n",
       "│ Time/Epoch                    │ 12.545705795288086     │\n",
       "│ Time/FPS                      │ 163.24313354492188     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.998228073120117     │\n",
       "│ Metrics/EpCost                │ 60.0                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 415.0                  │\n",
       "│ Train/Entropy                 │ -0.2783123254776001    │\n",
       "│ Train/KL                      │ 0.00999996718019247    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0002321004867554     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0002321004867554     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0002321004867554     │\n",
       "│ Train/PolicyRatio/Std         │ 0.015880560502409935   │\n",
       "│ Train/LR                      │ 5.0400001782691106e-05 │\n",
       "│ Train/PolicyStd               │ 0.18325389921665192    │\n",
       "│ TotalEnvSteps                 │ 851968.0               │\n",
       "│ Loss/Loss_pi                  │ -0.0184448454529047    │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002764478325843811  │\n",
       "│ Value/Adv                     │ -0.011559780687093735  │\n",
       "│ Loss/Loss_reward_critic       │ 0.016667205840349197   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0006379261612892151 │\n",
       "│ Value/reward                  │ 2.113247871398926      │\n",
       "│ Time/Total                    │ 5451.21826171875       │\n",
       "│ Time/Rollout                  │ 10.8583984375          │\n",
       "│ Time/Update                   │ 1.6872601509094238     │\n",
       "│ Time/Epoch                    │ 12.545705795288086     │\n",
       "│ Time/FPS                      │ 163.24313354492188     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.926408767700195     │\n",
       "│ Metrics/EpCost                │ 63.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 416.0                  │\n",
       "│ Train/Entropy                 │ -0.28001514077186584   │\n",
       "│ Train/KL                      │ 0.012561945244669914   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.003137469291687      │\n",
       "│ Train/PolicyRatio/Min         │ 1.003137469291687      │\n",
       "│ Train/PolicyRatio/Max         │ 1.003137469291687      │\n",
       "│ Train/PolicyRatio/Std         │ 0.016741817817091942   │\n",
       "│ Train/LR                      │ 4.980000085197389e-05  │\n",
       "│ Train/PolicyStd               │ 0.18294090032577515    │\n",
       "│ TotalEnvSteps                 │ 854016.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015668638050556183  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0027762074023485184  │\n",
       "│ Value/Adv                     │ -0.1446053683757782    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01592823676764965    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0007389690726995468 │\n",
       "│ Value/reward                  │ 2.0860702991485596     │\n",
       "│ Time/Total                    │ 5463.80419921875       │\n",
       "│ Time/Rollout                  │ 10.8467435836792       │\n",
       "│ Time/Update                   │ 1.7272515296936035     │\n",
       "│ Time/Epoch                    │ 12.574037551879883     │\n",
       "│ Time/FPS                      │ 162.8752899169922      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.926408767700195     │\n",
       "│ Metrics/EpCost                │ 63.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 416.0                  │\n",
       "│ Train/Entropy                 │ -0.28001514077186584   │\n",
       "│ Train/KL                      │ 0.012561945244669914   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.003137469291687      │\n",
       "│ Train/PolicyRatio/Min         │ 1.003137469291687      │\n",
       "│ Train/PolicyRatio/Max         │ 1.003137469291687      │\n",
       "│ Train/PolicyRatio/Std         │ 0.016741817817091942   │\n",
       "│ Train/LR                      │ 4.980000085197389e-05  │\n",
       "│ Train/PolicyStd               │ 0.18294090032577515    │\n",
       "│ TotalEnvSteps                 │ 854016.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015668638050556183  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0027762074023485184  │\n",
       "│ Value/Adv                     │ -0.1446053683757782    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01592823676764965    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0007389690726995468 │\n",
       "│ Value/reward                  │ 2.0860702991485596     │\n",
       "│ Time/Total                    │ 5463.80419921875       │\n",
       "│ Time/Rollout                  │ 10.8467435836792       │\n",
       "│ Time/Update                   │ 1.7272515296936035     │\n",
       "│ Time/Epoch                    │ 12.574037551879883     │\n",
       "│ Time/FPS                      │ 162.8752899169922      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.808364868164062     │\n",
       "│ Metrics/EpCost                │ 62.02000045776367      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 417.0                  │\n",
       "│ Train/Entropy                 │ -0.2819991409778595    │\n",
       "│ Train/KL                      │ 0.00893312506377697    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0070315599441528     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0070315599441528     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0070315599441528     │\n",
       "│ Train/PolicyRatio/Std         │ 0.015051732771098614   │\n",
       "│ Train/LR                      │ 4.9199999921256676e-05 │\n",
       "│ Train/PolicyStd               │ 0.18257483839988708    │\n",
       "│ TotalEnvSteps                 │ 856064.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012523937039077282  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.003144701011478901   │\n",
       "│ Value/Adv                     │ -0.04706381633877754   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01690971478819847    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0009814780205488205  │\n",
       "│ Value/reward                  │ 2.096273422241211      │\n",
       "│ Time/Total                    │ 5476.39697265625       │\n",
       "│ Time/Rollout                  │ 10.86905288696289      │\n",
       "│ Time/Update                   │ 1.7121069431304932     │\n",
       "│ Time/Epoch                    │ 12.581202507019043     │\n",
       "│ Time/FPS                      │ 162.7825469970703      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.808364868164062     │\n",
       "│ Metrics/EpCost                │ 62.02000045776367      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 417.0                  │\n",
       "│ Train/Entropy                 │ -0.2819991409778595    │\n",
       "│ Train/KL                      │ 0.00893312506377697    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0070315599441528     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0070315599441528     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0070315599441528     │\n",
       "│ Train/PolicyRatio/Std         │ 0.015051732771098614   │\n",
       "│ Train/LR                      │ 4.9199999921256676e-05 │\n",
       "│ Train/PolicyStd               │ 0.18257483839988708    │\n",
       "│ TotalEnvSteps                 │ 856064.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012523937039077282  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.003144701011478901   │\n",
       "│ Value/Adv                     │ -0.04706381633877754   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01690971478819847    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0009814780205488205  │\n",
       "│ Value/reward                  │ 2.096273422241211      │\n",
       "│ Time/Total                    │ 5476.39697265625       │\n",
       "│ Time/Rollout                  │ 10.86905288696289      │\n",
       "│ Time/Update                   │ 1.7121069431304932     │\n",
       "│ Time/Epoch                    │ 12.581202507019043     │\n",
       "│ Time/FPS                      │ 162.7825469970703      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.881895065307617    │\n",
       "│ Metrics/EpCost                │ 62.02000045776367     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 418.0                 │\n",
       "│ Train/Entropy                 │ -0.28260451555252075  │\n",
       "│ Train/KL                      │ 0.011554316617548466  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9984521865844727    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9984521865844727    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9984521865844727    │\n",
       "│ Train/PolicyRatio/Std         │ 0.016285253688693047  │\n",
       "│ Train/LR                      │ 4.859999899053946e-05 │\n",
       "│ Train/PolicyStd               │ 0.18246695399284363   │\n",
       "│ TotalEnvSteps                 │ 858112.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01888437382876873  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.006360436789691448 │\n",
       "│ Value/Adv                     │ -0.24591326713562012  │\n",
       "│ Loss/Loss_reward_critic       │ 0.020170703530311584  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0032609887421131134 │\n",
       "│ Value/reward                  │ 2.1886751651763916    │\n",
       "│ Time/Total                    │ 5488.9755859375       │\n",
       "│ Time/Rollout                  │ 10.865533828735352    │\n",
       "│ Time/Update                   │ 1.7001116275787354    │\n",
       "│ Time/Epoch                    │ 12.565689086914062    │\n",
       "│ Time/FPS                      │ 162.9835205078125     │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.881895065307617    │\n",
       "│ Metrics/EpCost                │ 62.02000045776367     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 418.0                 │\n",
       "│ Train/Entropy                 │ -0.28260451555252075  │\n",
       "│ Train/KL                      │ 0.011554316617548466  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9984521865844727    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9984521865844727    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9984521865844727    │\n",
       "│ Train/PolicyRatio/Std         │ 0.016285253688693047  │\n",
       "│ Train/LR                      │ 4.859999899053946e-05 │\n",
       "│ Train/PolicyStd               │ 0.18246695399284363   │\n",
       "│ TotalEnvSteps                 │ 858112.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01888437382876873  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.006360436789691448 │\n",
       "│ Value/Adv                     │ -0.24591326713562012  │\n",
       "│ Loss/Loss_reward_critic       │ 0.020170703530311584  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0032609887421131134 │\n",
       "│ Value/reward                  │ 2.1886751651763916    │\n",
       "│ Time/Total                    │ 5488.9755859375       │\n",
       "│ Time/Rollout                  │ 10.865533828735352    │\n",
       "│ Time/Update                   │ 1.7001116275787354    │\n",
       "│ Time/Epoch                    │ 12.565689086914062    │\n",
       "│ Time/FPS                      │ 162.9835205078125     │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.805871963500977     │\n",
       "│ Metrics/EpCost                │ 63.29999923706055      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 419.0                  │\n",
       "│ Train/Entropy                 │ -0.2801090478897095    │\n",
       "│ Train/KL                      │ 0.012385536916553974   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9957615733146667     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9957615733146667     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9957615733146667     │\n",
       "│ Train/PolicyRatio/Std         │ 0.015680905431509018   │\n",
       "│ Train/LR                      │ 4.8000001697801054e-05 │\n",
       "│ Train/PolicyStd               │ 0.18293136358261108    │\n",
       "│ TotalEnvSteps                 │ 860160.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016368458047509193  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0025159157812595367  │\n",
       "│ Value/Adv                     │ 0.04059571772813797    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02093243971467018    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0007617361843585968  │\n",
       "│ Value/reward                  │ 2.1865053176879883     │\n",
       "│ Time/Total                    │ 5501.6318359375        │\n",
       "│ Time/Rollout                  │ 10.910816192626953     │\n",
       "│ Time/Update                   │ 1.7339727878570557     │\n",
       "│ Time/Epoch                    │ 12.64483642578125      │\n",
       "│ Time/FPS                      │ 161.96334838867188     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.805871963500977     │\n",
       "│ Metrics/EpCost                │ 63.29999923706055      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 419.0                  │\n",
       "│ Train/Entropy                 │ -0.2801090478897095    │\n",
       "│ Train/KL                      │ 0.012385536916553974   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9957615733146667     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9957615733146667     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9957615733146667     │\n",
       "│ Train/PolicyRatio/Std         │ 0.015680905431509018   │\n",
       "│ Train/LR                      │ 4.8000001697801054e-05 │\n",
       "│ Train/PolicyStd               │ 0.18293136358261108    │\n",
       "│ TotalEnvSteps                 │ 860160.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016368458047509193  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0025159157812595367  │\n",
       "│ Value/Adv                     │ 0.04059571772813797    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02093243971467018    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0007617361843585968  │\n",
       "│ Value/reward                  │ 2.1865053176879883     │\n",
       "│ Time/Total                    │ 5501.6318359375        │\n",
       "│ Time/Rollout                  │ 10.910816192626953     │\n",
       "│ Time/Update                   │ 1.7339727878570557     │\n",
       "│ Time/Epoch                    │ 12.64483642578125      │\n",
       "│ Time/FPS                      │ 161.96334838867188     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.844013214111328     │\n",
       "│ Metrics/EpCost                │ 61.81999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 420.0                  │\n",
       "│ Train/Entropy                 │ -0.27989381551742554   │\n",
       "│ Train/KL                      │ 0.011538304388523102   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9920962452888489     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9920962452888489     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9920962452888489     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01623012311756611    │\n",
       "│ Train/LR                      │ 4.740000076708384e-05  │\n",
       "│ Train/PolicyStd               │ 0.1829654425382614     │\n",
       "│ TotalEnvSteps                 │ 862208.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017331432551145554  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0009629745036363602 │\n",
       "│ Value/Adv                     │ -0.050322383642196655  │\n",
       "│ Loss/Loss_reward_critic       │ 0.023038366809487343   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0021059270948171616  │\n",
       "│ Value/reward                  │ 2.1968140602111816     │\n",
       "│ Time/Total                    │ 5514.21826171875       │\n",
       "│ Time/Rollout                  │ 10.865753173828125     │\n",
       "│ Time/Update                   │ 1.7079973220825195     │\n",
       "│ Time/Epoch                    │ 12.573793411254883     │\n",
       "│ Time/FPS                      │ 162.8784637451172      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.844013214111328     │\n",
       "│ Metrics/EpCost                │ 61.81999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 420.0                  │\n",
       "│ Train/Entropy                 │ -0.27989381551742554   │\n",
       "│ Train/KL                      │ 0.011538304388523102   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9920962452888489     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9920962452888489     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9920962452888489     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01623012311756611    │\n",
       "│ Train/LR                      │ 4.740000076708384e-05  │\n",
       "│ Train/PolicyStd               │ 0.1829654425382614     │\n",
       "│ TotalEnvSteps                 │ 862208.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017331432551145554  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0009629745036363602 │\n",
       "│ Value/Adv                     │ -0.050322383642196655  │\n",
       "│ Loss/Loss_reward_critic       │ 0.023038366809487343   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0021059270948171616  │\n",
       "│ Value/reward                  │ 2.1968140602111816     │\n",
       "│ Time/Total                    │ 5514.21826171875       │\n",
       "│ Time/Rollout                  │ 10.865753173828125     │\n",
       "│ Time/Update                   │ 1.7079973220825195     │\n",
       "│ Time/Epoch                    │ 12.573793411254883     │\n",
       "│ Time/FPS                      │ 162.8784637451172      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.670988082885742     │\n",
       "│ Metrics/EpCost                │ 61.7400016784668       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 421.0                  │\n",
       "│ Train/Entropy                 │ -0.2816387712955475    │\n",
       "│ Train/KL                      │ 0.010732063092291355   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.995766282081604      │\n",
       "│ Train/PolicyRatio/Min         │ 0.995766282081604      │\n",
       "│ Train/PolicyRatio/Max         │ 0.995766282081604      │\n",
       "│ Train/PolicyRatio/Std         │ 0.015738394111394882   │\n",
       "│ Train/LR                      │ 4.6799999836366624e-05 │\n",
       "│ Train/PolicyStd               │ 0.1826396882534027     │\n",
       "│ TotalEnvSteps                 │ 864256.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018031124025583267  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0006996914744377136 │\n",
       "│ Value/Adv                     │ 0.017748534679412842   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01789030060172081    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005148066207766533  │\n",
       "│ Value/reward                  │ 2.1762049198150635     │\n",
       "│ Time/Total                    │ 5526.7939453125        │\n",
       "│ Time/Rollout                  │ 10.88056755065918      │\n",
       "│ Time/Update                   │ 1.682915210723877      │\n",
       "│ Time/Epoch                    │ 12.563525199890137     │\n",
       "│ Time/FPS                      │ 163.01158142089844     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.670988082885742     │\n",
       "│ Metrics/EpCost                │ 61.7400016784668       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 421.0                  │\n",
       "│ Train/Entropy                 │ -0.2816387712955475    │\n",
       "│ Train/KL                      │ 0.010732063092291355   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.995766282081604      │\n",
       "│ Train/PolicyRatio/Min         │ 0.995766282081604      │\n",
       "│ Train/PolicyRatio/Max         │ 0.995766282081604      │\n",
       "│ Train/PolicyRatio/Std         │ 0.015738394111394882   │\n",
       "│ Train/LR                      │ 4.6799999836366624e-05 │\n",
       "│ Train/PolicyStd               │ 0.1826396882534027     │\n",
       "│ TotalEnvSteps                 │ 864256.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018031124025583267  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0006996914744377136 │\n",
       "│ Value/Adv                     │ 0.017748534679412842   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01789030060172081    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005148066207766533  │\n",
       "│ Value/reward                  │ 2.1762049198150635     │\n",
       "│ Time/Total                    │ 5526.7939453125        │\n",
       "│ Time/Rollout                  │ 10.88056755065918      │\n",
       "│ Time/Update                   │ 1.682915210723877      │\n",
       "│ Time/Epoch                    │ 12.563525199890137     │\n",
       "│ Time/FPS                      │ 163.01158142089844     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.639320373535156    │\n",
       "│ Metrics/EpCost                │ 60.70000076293945     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 422.0                 │\n",
       "│ Train/Entropy                 │ -0.28387007117271423  │\n",
       "│ Train/KL                      │ 0.011725596152245998  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0049121379852295    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0049121379852295    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0049121379852295    │\n",
       "│ Train/PolicyRatio/Std         │ 0.0172551441937685    │\n",
       "│ Train/LR                      │ 4.619999890564941e-05 │\n",
       "│ Train/PolicyStd               │ 0.18223431706428528   │\n",
       "│ TotalEnvSteps                 │ 866304.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01476221065968275  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0032689133659005165 │\n",
       "│ Value/Adv                     │ -0.06970008462667465  │\n",
       "│ Loss/Loss_reward_critic       │ 0.02632429264485836   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00843399204313755   │\n",
       "│ Value/reward                  │ 2.15632700920105      │\n",
       "│ Time/Total                    │ 5539.3095703125       │\n",
       "│ Time/Rollout                  │ 10.801681518554688    │\n",
       "│ Time/Update                   │ 1.701758861541748     │\n",
       "│ Time/Epoch                    │ 12.503494262695312    │\n",
       "│ Time/FPS                      │ 163.7942352294922     │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.639320373535156    │\n",
       "│ Metrics/EpCost                │ 60.70000076293945     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 422.0                 │\n",
       "│ Train/Entropy                 │ -0.28387007117271423  │\n",
       "│ Train/KL                      │ 0.011725596152245998  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0049121379852295    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0049121379852295    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0049121379852295    │\n",
       "│ Train/PolicyRatio/Std         │ 0.0172551441937685    │\n",
       "│ Train/LR                      │ 4.619999890564941e-05 │\n",
       "│ Train/PolicyStd               │ 0.18223431706428528   │\n",
       "│ TotalEnvSteps                 │ 866304.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01476221065968275  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0032689133659005165 │\n",
       "│ Value/Adv                     │ -0.06970008462667465  │\n",
       "│ Loss/Loss_reward_critic       │ 0.02632429264485836   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00843399204313755   │\n",
       "│ Value/reward                  │ 2.15632700920105      │\n",
       "│ Time/Total                    │ 5539.3095703125       │\n",
       "│ Time/Rollout                  │ 10.801681518554688    │\n",
       "│ Time/Update                   │ 1.701758861541748     │\n",
       "│ Time/Epoch                    │ 12.503494262695312    │\n",
       "│ Time/FPS                      │ 163.7942352294922     │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.439977645874023     │\n",
       "│ Metrics/EpCost                │ 59.31999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 423.0                  │\n",
       "│ Train/Entropy                 │ -0.2860557436943054    │\n",
       "│ Train/KL                      │ 0.013936867006123066   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9961197972297668     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9961197972297668     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9961197972297668     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016162056475877762   │\n",
       "│ Train/LR                      │ 4.5600001612911e-05    │\n",
       "│ Train/PolicyStd               │ 0.18184426426887512    │\n",
       "│ TotalEnvSteps                 │ 868352.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01764853671193123   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002886326052248478  │\n",
       "│ Value/Adv                     │ -0.00511004775762558   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018782785162329674   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0075415074825286865 │\n",
       "│ Value/reward                  │ 2.136037588119507      │\n",
       "│ Time/Total                    │ 5551.8759765625        │\n",
       "│ Time/Rollout                  │ 10.862112045288086     │\n",
       "│ Time/Update                   │ 1.6932339668273926     │\n",
       "│ Time/Epoch                    │ 12.555389404296875     │\n",
       "│ Time/FPS                      │ 163.11721801757812     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.439977645874023     │\n",
       "│ Metrics/EpCost                │ 59.31999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 423.0                  │\n",
       "│ Train/Entropy                 │ -0.2860557436943054    │\n",
       "│ Train/KL                      │ 0.013936867006123066   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9961197972297668     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9961197972297668     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9961197972297668     │\n",
       "│ Train/PolicyRatio/Std         │ 0.016162056475877762   │\n",
       "│ Train/LR                      │ 4.5600001612911e-05    │\n",
       "│ Train/PolicyStd               │ 0.18184426426887512    │\n",
       "│ TotalEnvSteps                 │ 868352.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01764853671193123   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002886326052248478  │\n",
       "│ Value/Adv                     │ -0.00511004775762558   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018782785162329674   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0075415074825286865 │\n",
       "│ Value/reward                  │ 2.136037588119507      │\n",
       "│ Time/Total                    │ 5551.8759765625        │\n",
       "│ Time/Rollout                  │ 10.862112045288086     │\n",
       "│ Time/Update                   │ 1.6932339668273926     │\n",
       "│ Time/Epoch                    │ 12.555389404296875     │\n",
       "│ Time/FPS                      │ 163.11721801757812     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.388154983520508     │\n",
       "│ Metrics/EpCost                │ 58.2599983215332       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 424.0                  │\n",
       "│ Train/Entropy                 │ -0.28926631808280945   │\n",
       "│ Train/KL                      │ 0.01116115041077137    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9982233047485352     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9982233047485352     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9982233047485352     │\n",
       "│ Train/PolicyRatio/Std         │ 0.014909720979630947   │\n",
       "│ Train/LR                      │ 4.5000000682193786e-05 │\n",
       "│ Train/PolicyStd               │ 0.1812697947025299     │\n",
       "│ TotalEnvSteps                 │ 870400.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017282884567975998  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0003656521439552307  │\n",
       "│ Value/Adv                     │ 0.010969532653689384   │\n",
       "│ Loss/Loss_reward_critic       │ 0.016768665984272957   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.002014119178056717  │\n",
       "│ Value/reward                  │ 2.191317319869995      │\n",
       "│ Time/Total                    │ 5564.48388671875       │\n",
       "│ Time/Rollout                  │ 10.85114860534668      │\n",
       "│ Time/Update                   │ 1.7449007034301758     │\n",
       "│ Time/Epoch                    │ 12.596094131469727     │\n",
       "│ Time/FPS                      │ 162.59010314941406     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.388154983520508     │\n",
       "│ Metrics/EpCost                │ 58.2599983215332       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 424.0                  │\n",
       "│ Train/Entropy                 │ -0.28926631808280945   │\n",
       "│ Train/KL                      │ 0.01116115041077137    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9982233047485352     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9982233047485352     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9982233047485352     │\n",
       "│ Train/PolicyRatio/Std         │ 0.014909720979630947   │\n",
       "│ Train/LR                      │ 4.5000000682193786e-05 │\n",
       "│ Train/PolicyStd               │ 0.1812697947025299     │\n",
       "│ TotalEnvSteps                 │ 870400.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017282884567975998  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0003656521439552307  │\n",
       "│ Value/Adv                     │ 0.010969532653689384   │\n",
       "│ Loss/Loss_reward_critic       │ 0.016768665984272957   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.002014119178056717  │\n",
       "│ Value/reward                  │ 2.191317319869995      │\n",
       "│ Time/Total                    │ 5564.48388671875       │\n",
       "│ Time/Rollout                  │ 10.85114860534668      │\n",
       "│ Time/Update                   │ 1.7449007034301758     │\n",
       "│ Time/Epoch                    │ 12.596094131469727     │\n",
       "│ Time/FPS                      │ 162.59010314941406     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.373266220092773     │\n",
       "│ Metrics/EpCost                │ 59.20000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 425.0                  │\n",
       "│ Train/Entropy                 │ -0.29141801595687866   │\n",
       "│ Train/KL                      │ 0.01001036074012518    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0028349161148071     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0028349161148071     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0028349161148071     │\n",
       "│ Train/PolicyRatio/Std         │ 0.015157273039221764   │\n",
       "│ Train/LR                      │ 4.439999975147657e-05  │\n",
       "│ Train/PolicyStd               │ 0.1808784008026123     │\n",
       "│ TotalEnvSteps                 │ 872448.0               │\n",
       "│ Loss/Loss_pi                  │ -0.019516024738550186  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0022331401705741882 │\n",
       "│ Value/Adv                     │ -0.01762630045413971   │\n",
       "│ Loss/Loss_reward_critic       │ 0.017879668623209      │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0011110026389360428  │\n",
       "│ Value/reward                  │ 2.1989355087280273     │\n",
       "│ Time/Total                    │ 5577.0869140625        │\n",
       "│ Time/Rollout                  │ 10.878808975219727     │\n",
       "│ Time/Update                   │ 1.712738037109375      │\n",
       "│ Time/Epoch                    │ 12.59158992767334      │\n",
       "│ Time/FPS                      │ 162.64825439453125     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.373266220092773     │\n",
       "│ Metrics/EpCost                │ 59.20000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 425.0                  │\n",
       "│ Train/Entropy                 │ -0.29141801595687866   │\n",
       "│ Train/KL                      │ 0.01001036074012518    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0028349161148071     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0028349161148071     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0028349161148071     │\n",
       "│ Train/PolicyRatio/Std         │ 0.015157273039221764   │\n",
       "│ Train/LR                      │ 4.439999975147657e-05  │\n",
       "│ Train/PolicyStd               │ 0.1808784008026123     │\n",
       "│ TotalEnvSteps                 │ 872448.0               │\n",
       "│ Loss/Loss_pi                  │ -0.019516024738550186  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0022331401705741882 │\n",
       "│ Value/Adv                     │ -0.01762630045413971   │\n",
       "│ Loss/Loss_reward_critic       │ 0.017879668623209      │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0011110026389360428  │\n",
       "│ Value/reward                  │ 2.1989355087280273     │\n",
       "│ Time/Total                    │ 5577.0869140625        │\n",
       "│ Time/Rollout                  │ 10.878808975219727     │\n",
       "│ Time/Update                   │ 1.712738037109375      │\n",
       "│ Time/Epoch                    │ 12.59158992767334      │\n",
       "│ Time/FPS                      │ 162.64825439453125     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.393136978149414     │\n",
       "│ Metrics/EpCost                │ 59.619998931884766     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 426.0                  │\n",
       "│ Train/Entropy                 │ -0.29218894243240356   │\n",
       "│ Train/KL                      │ 0.009985324926674366   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9981009364128113     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9981009364128113     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9981009364128113     │\n",
       "│ Train/PolicyRatio/Std         │ 0.013528219424188137   │\n",
       "│ Train/LR                      │ 4.3799998820759356e-05 │\n",
       "│ Train/PolicyStd               │ 0.1807306706905365     │\n",
       "│ TotalEnvSteps                 │ 874496.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01469440571963787   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004821619018912315   │\n",
       "│ Value/Adv                     │ 0.0895996242761612     │\n",
       "│ Loss/Loss_reward_critic       │ 0.016881467774510384   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.000998200848698616  │\n",
       "│ Value/reward                  │ 2.211544990539551      │\n",
       "│ Time/Total                    │ 5589.62158203125       │\n",
       "│ Time/Rollout                  │ 10.827255249023438     │\n",
       "│ Time/Update                   │ 1.6957569122314453     │\n",
       "│ Time/Epoch                    │ 12.523056030273438     │\n",
       "│ Time/FPS                      │ 163.53836059570312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.393136978149414     │\n",
       "│ Metrics/EpCost                │ 59.619998931884766     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 426.0                  │\n",
       "│ Train/Entropy                 │ -0.29218894243240356   │\n",
       "│ Train/KL                      │ 0.009985324926674366   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9981009364128113     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9981009364128113     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9981009364128113     │\n",
       "│ Train/PolicyRatio/Std         │ 0.013528219424188137   │\n",
       "│ Train/LR                      │ 4.3799998820759356e-05 │\n",
       "│ Train/PolicyStd               │ 0.1807306706905365     │\n",
       "│ TotalEnvSteps                 │ 874496.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01469440571963787   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004821619018912315   │\n",
       "│ Value/Adv                     │ 0.0895996242761612     │\n",
       "│ Loss/Loss_reward_critic       │ 0.016881467774510384   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.000998200848698616  │\n",
       "│ Value/reward                  │ 2.211544990539551      │\n",
       "│ Time/Total                    │ 5589.62158203125       │\n",
       "│ Time/Rollout                  │ 10.827255249023438     │\n",
       "│ Time/Update                   │ 1.6957569122314453     │\n",
       "│ Time/Epoch                    │ 12.523056030273438     │\n",
       "│ Time/FPS                      │ 163.53836059570312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.355810165405273    │\n",
       "│ Metrics/EpCost                │ 56.29999923706055     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 427.0                 │\n",
       "│ Train/Entropy                 │ -0.29360026121139526  │\n",
       "│ Train/KL                      │ 0.009109236299991608  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9990535974502563    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9990535974502563    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9990535974502563    │\n",
       "│ Train/PolicyRatio/Std         │ 0.015476231463253498  │\n",
       "│ Train/LR                      │ 4.320000152802095e-05 │\n",
       "│ Train/PolicyStd               │ 0.18046751618385315   │\n",
       "│ TotalEnvSteps                 │ 876544.0              │\n",
       "│ Loss/Loss_pi                  │ -0.018221894279122353 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.003527488559484482 │\n",
       "│ Value/Adv                     │ 0.03473135083913803   │\n",
       "│ Loss/Loss_reward_critic       │ 0.025279197841882706  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.008397730067372322  │\n",
       "│ Value/reward                  │ 2.1916770935058594    │\n",
       "│ Time/Total                    │ 5602.19482421875      │\n",
       "│ Time/Rollout                  │ 10.845353126525879    │\n",
       "│ Time/Update                   │ 1.7157542705535889    │\n",
       "│ Time/Epoch                    │ 12.561147689819336    │\n",
       "│ Time/FPS                      │ 163.04241943359375    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.355810165405273    │\n",
       "│ Metrics/EpCost                │ 56.29999923706055     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 427.0                 │\n",
       "│ Train/Entropy                 │ -0.29360026121139526  │\n",
       "│ Train/KL                      │ 0.009109236299991608  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9990535974502563    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9990535974502563    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9990535974502563    │\n",
       "│ Train/PolicyRatio/Std         │ 0.015476231463253498  │\n",
       "│ Train/LR                      │ 4.320000152802095e-05 │\n",
       "│ Train/PolicyStd               │ 0.18046751618385315   │\n",
       "│ TotalEnvSteps                 │ 876544.0              │\n",
       "│ Loss/Loss_pi                  │ -0.018221894279122353 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.003527488559484482 │\n",
       "│ Value/Adv                     │ 0.03473135083913803   │\n",
       "│ Loss/Loss_reward_critic       │ 0.025279197841882706  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.008397730067372322  │\n",
       "│ Value/reward                  │ 2.1916770935058594    │\n",
       "│ Time/Total                    │ 5602.19482421875      │\n",
       "│ Time/Rollout                  │ 10.845353126525879    │\n",
       "│ Time/Update                   │ 1.7157542705535889    │\n",
       "│ Time/Epoch                    │ 12.561147689819336    │\n",
       "│ Time/FPS                      │ 163.04241943359375    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.48802947998047     │\n",
       "│ Metrics/EpCost                │ 56.91999816894531     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 428.0                 │\n",
       "│ Train/Entropy                 │ -0.2949407696723938   │\n",
       "│ Train/KL                      │ 0.008214709348976612  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9995214343070984    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9995214343070984    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9995214343070984    │\n",
       "│ Train/PolicyRatio/Std         │ 0.013890447095036507  │\n",
       "│ Train/LR                      │ 4.260000059730373e-05 │\n",
       "│ Train/PolicyStd               │ 0.18022260069847107   │\n",
       "│ TotalEnvSteps                 │ 878592.0              │\n",
       "│ Loss/Loss_pi                  │ -0.016089636832475662 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0021322574466466904 │\n",
       "│ Value/Adv                     │ 0.01779622957110405   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01383498776704073   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.011444210074841976 │\n",
       "│ Value/reward                  │ 2.180020809173584     │\n",
       "│ Time/Total                    │ 5614.6865234375       │\n",
       "│ Time/Rollout                  │ 10.775921821594238    │\n",
       "│ Time/Update                   │ 1.7038969993591309    │\n",
       "│ Time/Epoch                    │ 12.47986125946045     │\n",
       "│ Time/FPS                      │ 164.10440063476562    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.48802947998047     │\n",
       "│ Metrics/EpCost                │ 56.91999816894531     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 428.0                 │\n",
       "│ Train/Entropy                 │ -0.2949407696723938   │\n",
       "│ Train/KL                      │ 0.008214709348976612  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9995214343070984    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9995214343070984    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9995214343070984    │\n",
       "│ Train/PolicyRatio/Std         │ 0.013890447095036507  │\n",
       "│ Train/LR                      │ 4.260000059730373e-05 │\n",
       "│ Train/PolicyStd               │ 0.18022260069847107   │\n",
       "│ TotalEnvSteps                 │ 878592.0              │\n",
       "│ Loss/Loss_pi                  │ -0.016089636832475662 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0021322574466466904 │\n",
       "│ Value/Adv                     │ 0.01779622957110405   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01383498776704073   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.011444210074841976 │\n",
       "│ Value/reward                  │ 2.180020809173584     │\n",
       "│ Time/Total                    │ 5614.6865234375       │\n",
       "│ Time/Rollout                  │ 10.775921821594238    │\n",
       "│ Time/Update                   │ 1.7038969993591309    │\n",
       "│ Time/Epoch                    │ 12.47986125946045     │\n",
       "│ Time/FPS                      │ 164.10440063476562    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.4508056640625       │\n",
       "│ Metrics/EpCost                │ 59.02000045776367      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 429.0                  │\n",
       "│ Train/Entropy                 │ -0.2942453920841217    │\n",
       "│ Train/KL                      │ 0.01234077662229538    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9975641369819641     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9975641369819641     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9975641369819641     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01568043977022171    │\n",
       "│ Train/LR                      │ 4.199999966658652e-05  │\n",
       "│ Train/PolicyStd               │ 0.18034961819648743    │\n",
       "│ TotalEnvSteps                 │ 880640.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01675272360444069   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0006630867719650269 │\n",
       "│ Value/Adv                     │ 0.16012251377105713    │\n",
       "│ Loss/Loss_reward_critic       │ 0.011381878517568111   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.002453109249472618  │\n",
       "│ Value/reward                  │ 2.1488943099975586     │\n",
       "│ Time/Total                    │ 5627.265625            │\n",
       "│ Time/Rollout                  │ 10.857322692871094     │\n",
       "│ Time/Update                   │ 1.7099740505218506     │\n",
       "│ Time/Epoch                    │ 12.567342758178711     │\n",
       "│ Time/FPS                      │ 162.96206665039062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.4508056640625       │\n",
       "│ Metrics/EpCost                │ 59.02000045776367      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 429.0                  │\n",
       "│ Train/Entropy                 │ -0.2942453920841217    │\n",
       "│ Train/KL                      │ 0.01234077662229538    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9975641369819641     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9975641369819641     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9975641369819641     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01568043977022171    │\n",
       "│ Train/LR                      │ 4.199999966658652e-05  │\n",
       "│ Train/PolicyStd               │ 0.18034961819648743    │\n",
       "│ TotalEnvSteps                 │ 880640.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01675272360444069   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0006630867719650269 │\n",
       "│ Value/Adv                     │ 0.16012251377105713    │\n",
       "│ Loss/Loss_reward_critic       │ 0.011381878517568111   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.002453109249472618  │\n",
       "│ Value/reward                  │ 2.1488943099975586     │\n",
       "│ Time/Total                    │ 5627.265625            │\n",
       "│ Time/Rollout                  │ 10.857322692871094     │\n",
       "│ Time/Update                   │ 1.7099740505218506     │\n",
       "│ Time/Epoch                    │ 12.567342758178711     │\n",
       "│ Time/FPS                      │ 162.96206665039062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.502368927001953    │\n",
       "│ Metrics/EpCost                │ 60.2599983215332      │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 430.0                 │\n",
       "│ Train/Entropy                 │ -0.29407721757888794  │\n",
       "│ Train/KL                      │ 0.009830544702708721  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9978623390197754    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9978623390197754    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9978623390197754    │\n",
       "│ Train/PolicyRatio/Std         │ 0.014147077687084675  │\n",
       "│ Train/LR                      │ 4.13999987358693e-05  │\n",
       "│ Train/PolicyStd               │ 0.1803773194551468    │\n",
       "│ TotalEnvSteps                 │ 882688.0              │\n",
       "│ Loss/Loss_pi                  │ -0.012410280294716358 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004342443309724331  │\n",
       "│ Value/Adv                     │ -0.13707192242145538  │\n",
       "│ Loss/Loss_reward_critic       │ 0.02127164974808693   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.009889771230518818  │\n",
       "│ Value/reward                  │ 2.2268247604370117    │\n",
       "│ Time/Total                    │ 5639.892578125        │\n",
       "│ Time/Rollout                  │ 10.846718788146973    │\n",
       "│ Time/Update                   │ 1.7674968242645264    │\n",
       "│ Time/Epoch                    │ 12.61426067352295     │\n",
       "│ Time/FPS                      │ 162.35594177246094    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.502368927001953    │\n",
       "│ Metrics/EpCost                │ 60.2599983215332      │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 430.0                 │\n",
       "│ Train/Entropy                 │ -0.29407721757888794  │\n",
       "│ Train/KL                      │ 0.009830544702708721  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9978623390197754    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9978623390197754    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9978623390197754    │\n",
       "│ Train/PolicyRatio/Std         │ 0.014147077687084675  │\n",
       "│ Train/LR                      │ 4.13999987358693e-05  │\n",
       "│ Train/PolicyStd               │ 0.1803773194551468    │\n",
       "│ TotalEnvSteps                 │ 882688.0              │\n",
       "│ Loss/Loss_pi                  │ -0.012410280294716358 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004342443309724331  │\n",
       "│ Value/Adv                     │ -0.13707192242145538  │\n",
       "│ Loss/Loss_reward_critic       │ 0.02127164974808693   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.009889771230518818  │\n",
       "│ Value/reward                  │ 2.2268247604370117    │\n",
       "│ Time/Total                    │ 5639.892578125        │\n",
       "│ Time/Rollout                  │ 10.846718788146973    │\n",
       "│ Time/Update                   │ 1.7674968242645264    │\n",
       "│ Time/Epoch                    │ 12.61426067352295     │\n",
       "│ Time/FPS                      │ 162.35594177246094    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.494359970092773     │\n",
       "│ Metrics/EpCost                │ 57.31999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 431.0                  │\n",
       "│ Train/Entropy                 │ -0.294790118932724     │\n",
       "│ Train/KL                      │ 0.01011815294623375    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9981387257575989     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9981387257575989     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9981387257575989     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01595747470855713    │\n",
       "│ Train/LR                      │ 4.0800001443130895e-05 │\n",
       "│ Train/PolicyStd               │ 0.1802431344985962     │\n",
       "│ TotalEnvSteps                 │ 884736.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016331437975168228  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00392115768045187   │\n",
       "│ Value/Adv                     │ -0.19038599729537964   │\n",
       "│ Loss/Loss_reward_critic       │ 0.0208422914147377     │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0004293583333492279 │\n",
       "│ Value/reward                  │ 2.2521812915802        │\n",
       "│ Time/Total                    │ 5652.447265625         │\n",
       "│ Time/Rollout                  │ 10.8349027633667       │\n",
       "│ Time/Update                   │ 1.7078986167907715     │\n",
       "│ Time/Epoch                    │ 12.5428466796875       │\n",
       "│ Time/FPS                      │ 163.28033447265625     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.494359970092773     │\n",
       "│ Metrics/EpCost                │ 57.31999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 431.0                  │\n",
       "│ Train/Entropy                 │ -0.294790118932724     │\n",
       "│ Train/KL                      │ 0.01011815294623375    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9981387257575989     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9981387257575989     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9981387257575989     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01595747470855713    │\n",
       "│ Train/LR                      │ 4.0800001443130895e-05 │\n",
       "│ Train/PolicyStd               │ 0.1802431344985962     │\n",
       "│ TotalEnvSteps                 │ 884736.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016331437975168228  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00392115768045187   │\n",
       "│ Value/Adv                     │ -0.19038599729537964   │\n",
       "│ Loss/Loss_reward_critic       │ 0.0208422914147377     │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0004293583333492279 │\n",
       "│ Value/reward                  │ 2.2521812915802        │\n",
       "│ Time/Total                    │ 5652.447265625         │\n",
       "│ Time/Rollout                  │ 10.8349027633667       │\n",
       "│ Time/Update                   │ 1.7078986167907715     │\n",
       "│ Time/Epoch                    │ 12.5428466796875       │\n",
       "│ Time/FPS                      │ 163.28033447265625     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.744922637939453      │\n",
       "│ Metrics/EpCost                │ 58.47999954223633       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 432.0                   │\n",
       "│ Train/Entropy                 │ -0.29614078998565674    │\n",
       "│ Train/KL                      │ 0.012879334390163422    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0001851320266724      │\n",
       "│ Train/PolicyRatio/Min         │ 1.0001851320266724      │\n",
       "│ Train/PolicyRatio/Max         │ 1.0001851320266724      │\n",
       "│ Train/PolicyRatio/Std         │ 0.017335066571831703    │\n",
       "│ Train/LR                      │ 4.020000051241368e-05   │\n",
       "│ Train/PolicyStd               │ 0.17999909818172455     │\n",
       "│ TotalEnvSteps                 │ 886784.0                │\n",
       "│ Loss/Loss_pi                  │ -0.01829957775771618    │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0019681397825479507  │\n",
       "│ Value/Adv                     │ 0.10376739501953125     │\n",
       "│ Loss/Loss_reward_critic       │ 0.020393380895256996    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00044891051948070526 │\n",
       "│ Value/reward                  │ 2.1854870319366455      │\n",
       "│ Time/Total                    │ 5665.07763671875        │\n",
       "│ Time/Rollout                  │ 10.854704856872559      │\n",
       "│ Time/Update                   │ 1.764035940170288       │\n",
       "│ Time/Epoch                    │ 12.618785858154297      │\n",
       "│ Time/FPS                      │ 162.29771423339844      │\n",
       "└───────────────────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.744922637939453      │\n",
       "│ Metrics/EpCost                │ 58.47999954223633       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 432.0                   │\n",
       "│ Train/Entropy                 │ -0.29614078998565674    │\n",
       "│ Train/KL                      │ 0.012879334390163422    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0001851320266724      │\n",
       "│ Train/PolicyRatio/Min         │ 1.0001851320266724      │\n",
       "│ Train/PolicyRatio/Max         │ 1.0001851320266724      │\n",
       "│ Train/PolicyRatio/Std         │ 0.017335066571831703    │\n",
       "│ Train/LR                      │ 4.020000051241368e-05   │\n",
       "│ Train/PolicyStd               │ 0.17999909818172455     │\n",
       "│ TotalEnvSteps                 │ 886784.0                │\n",
       "│ Loss/Loss_pi                  │ -0.01829957775771618    │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0019681397825479507  │\n",
       "│ Value/Adv                     │ 0.10376739501953125     │\n",
       "│ Loss/Loss_reward_critic       │ 0.020393380895256996    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00044891051948070526 │\n",
       "│ Value/reward                  │ 2.1854870319366455      │\n",
       "│ Time/Total                    │ 5665.07763671875        │\n",
       "│ Time/Rollout                  │ 10.854704856872559      │\n",
       "│ Time/Update                   │ 1.764035940170288       │\n",
       "│ Time/Epoch                    │ 12.618785858154297      │\n",
       "│ Time/FPS                      │ 162.29771423339844      │\n",
       "└───────────────────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.73236656188965      │\n",
       "│ Metrics/EpCost                │ 57.97999954223633      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 433.0                  │\n",
       "│ Train/Entropy                 │ -0.2987380623817444    │\n",
       "│ Train/KL                      │ 0.008782896213233471   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9941474795341492     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9941474795341492     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9941474795341492     │\n",
       "│ Train/PolicyRatio/Std         │ 0.015706215053796768   │\n",
       "│ Train/LR                      │ 3.9599999581696466e-05 │\n",
       "│ Train/PolicyStd               │ 0.179534450173378      │\n",
       "│ TotalEnvSteps                 │ 888832.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01374237984418869   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004557197913527489   │\n",
       "│ Value/Adv                     │ 0.13121847808361053    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017446838319301605   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.002946542575955391  │\n",
       "│ Value/reward                  │ 2.2615747451782227     │\n",
       "│ Time/Total                    │ 5677.63330078125       │\n",
       "│ Time/Rollout                  │ 10.848583221435547     │\n",
       "│ Time/Update                   │ 1.6957037448883057     │\n",
       "│ Time/Epoch                    │ 12.544329643249512     │\n",
       "│ Time/FPS                      │ 163.2610321044922      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.73236656188965      │\n",
       "│ Metrics/EpCost                │ 57.97999954223633      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 433.0                  │\n",
       "│ Train/Entropy                 │ -0.2987380623817444    │\n",
       "│ Train/KL                      │ 0.008782896213233471   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9941474795341492     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9941474795341492     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9941474795341492     │\n",
       "│ Train/PolicyRatio/Std         │ 0.015706215053796768   │\n",
       "│ Train/LR                      │ 3.9599999581696466e-05 │\n",
       "│ Train/PolicyStd               │ 0.179534450173378      │\n",
       "│ TotalEnvSteps                 │ 888832.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01374237984418869   │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004557197913527489   │\n",
       "│ Value/Adv                     │ 0.13121847808361053    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017446838319301605   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.002946542575955391  │\n",
       "│ Value/reward                  │ 2.2615747451782227     │\n",
       "│ Time/Total                    │ 5677.63330078125       │\n",
       "│ Time/Rollout                  │ 10.848583221435547     │\n",
       "│ Time/Update                   │ 1.6957037448883057     │\n",
       "│ Time/Epoch                    │ 12.544329643249512     │\n",
       "│ Time/FPS                      │ 163.2610321044922      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.84286880493164       │\n",
       "│ Metrics/EpCost                │ 56.939998626708984      │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 434.0                   │\n",
       "│ Train/Entropy                 │ -0.3009313642978668     │\n",
       "│ Train/KL                      │ 0.010268164798617363    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9986244440078735      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9986244440078735      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9986244440078735      │\n",
       "│ Train/PolicyRatio/Std         │ 0.015769148245453835    │\n",
       "│ Train/LR                      │ 3.899999865097925e-05   │\n",
       "│ Train/PolicyStd               │ 0.17914000153541565     │\n",
       "│ TotalEnvSteps                 │ 890880.0                │\n",
       "│ Loss/Loss_pi                  │ -0.016796264797449112   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0030538849532604218  │\n",
       "│ Value/Adv                     │ 0.06335721164941788     │\n",
       "│ Loss/Loss_reward_critic       │ 0.017189037054777145    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00025780126452445984 │\n",
       "│ Value/reward                  │ 2.277127265930176       │\n",
       "│ Time/Total                    │ 5690.18701171875        │\n",
       "│ Time/Rollout                  │ 10.850215911865234      │\n",
       "│ Time/Update                   │ 1.6919422149658203      │\n",
       "│ Time/Epoch                    │ 12.542201042175293      │\n",
       "│ Time/FPS                      │ 163.2887420654297       │\n",
       "└───────────────────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.84286880493164       │\n",
       "│ Metrics/EpCost                │ 56.939998626708984      │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 434.0                   │\n",
       "│ Train/Entropy                 │ -0.3009313642978668     │\n",
       "│ Train/KL                      │ 0.010268164798617363    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9986244440078735      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9986244440078735      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9986244440078735      │\n",
       "│ Train/PolicyRatio/Std         │ 0.015769148245453835    │\n",
       "│ Train/LR                      │ 3.899999865097925e-05   │\n",
       "│ Train/PolicyStd               │ 0.17914000153541565     │\n",
       "│ TotalEnvSteps                 │ 890880.0                │\n",
       "│ Loss/Loss_pi                  │ -0.016796264797449112   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0030538849532604218  │\n",
       "│ Value/Adv                     │ 0.06335721164941788     │\n",
       "│ Loss/Loss_reward_critic       │ 0.017189037054777145    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00025780126452445984 │\n",
       "│ Value/reward                  │ 2.277127265930176       │\n",
       "│ Time/Total                    │ 5690.18701171875        │\n",
       "│ Time/Rollout                  │ 10.850215911865234      │\n",
       "│ Time/Update                   │ 1.6919422149658203      │\n",
       "│ Time/Epoch                    │ 12.542201042175293      │\n",
       "│ Time/FPS                      │ 163.2887420654297       │\n",
       "└───────────────────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.112123489379883    │\n",
       "│ Metrics/EpCost                │ 55.52000045776367     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 435.0                 │\n",
       "│ Train/Entropy                 │ -0.30149608850479126  │\n",
       "│ Train/KL                      │ 0.008747701533138752  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0046741962432861    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0046741962432861    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0046741962432861    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01526609342545271   │\n",
       "│ Train/LR                      │ 3.840000135824084e-05 │\n",
       "│ Train/PolicyStd               │ 0.1790381669998169    │\n",
       "│ TotalEnvSteps                 │ 892928.0              │\n",
       "│ Loss/Loss_pi                  │ -0.010324986651539803 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.006471278145909309  │\n",
       "│ Value/Adv                     │ 0.07569670677185059   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02271355874836445   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.005524521693587303  │\n",
       "│ Value/reward                  │ 2.0489914417266846    │\n",
       "│ Time/Total                    │ 5702.74755859375      │\n",
       "│ Time/Rollout                  │ 10.861920356750488    │\n",
       "│ Time/Update                   │ 1.6870427131652832    │\n",
       "│ Time/Epoch                    │ 12.549013137817383    │\n",
       "│ Time/FPS                      │ 163.20010375976562    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.112123489379883    │\n",
       "│ Metrics/EpCost                │ 55.52000045776367     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 435.0                 │\n",
       "│ Train/Entropy                 │ -0.30149608850479126  │\n",
       "│ Train/KL                      │ 0.008747701533138752  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0046741962432861    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0046741962432861    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0046741962432861    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01526609342545271   │\n",
       "│ Train/LR                      │ 3.840000135824084e-05 │\n",
       "│ Train/PolicyStd               │ 0.1790381669998169    │\n",
       "│ TotalEnvSteps                 │ 892928.0              │\n",
       "│ Loss/Loss_pi                  │ -0.010324986651539803 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.006471278145909309  │\n",
       "│ Value/Adv                     │ 0.07569670677185059   │\n",
       "│ Loss/Loss_reward_critic       │ 0.02271355874836445   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.005524521693587303  │\n",
       "│ Value/reward                  │ 2.0489914417266846    │\n",
       "│ Time/Total                    │ 5702.74755859375      │\n",
       "│ Time/Rollout                  │ 10.861920356750488    │\n",
       "│ Time/Update                   │ 1.6870427131652832    │\n",
       "│ Time/Epoch                    │ 12.549013137817383    │\n",
       "│ Time/FPS                      │ 163.20010375976562    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.180479049682617    │\n",
       "│ Metrics/EpCost                │ 55.79999923706055     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 436.0                 │\n",
       "│ Train/Entropy                 │ -0.3028251826763153   │\n",
       "│ Train/KL                      │ 0.00890857819467783   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9951326251029968    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9951326251029968    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9951326251029968    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01579645648598671   │\n",
       "│ Train/LR                      │ 3.780000042752363e-05 │\n",
       "│ Train/PolicyStd               │ 0.17880147695541382   │\n",
       "│ TotalEnvSteps                 │ 894976.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01463491003960371  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004309923388063908 │\n",
       "│ Value/Adv                     │ 0.12748825550079346   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01366956252604723   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.009043996222317219 │\n",
       "│ Value/reward                  │ 2.255154848098755     │\n",
       "│ Time/Total                    │ 5715.3955078125       │\n",
       "│ Time/Rollout                  │ 10.91680908203125     │\n",
       "│ Time/Update                   │ 1.7157971858978271    │\n",
       "│ Time/Epoch                    │ 12.632649421691895    │\n",
       "│ Time/FPS                      │ 162.11961364746094    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.180479049682617    │\n",
       "│ Metrics/EpCost                │ 55.79999923706055     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 436.0                 │\n",
       "│ Train/Entropy                 │ -0.3028251826763153   │\n",
       "│ Train/KL                      │ 0.00890857819467783   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9951326251029968    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9951326251029968    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9951326251029968    │\n",
       "│ Train/PolicyRatio/Std         │ 0.01579645648598671   │\n",
       "│ Train/LR                      │ 3.780000042752363e-05 │\n",
       "│ Train/PolicyStd               │ 0.17880147695541382   │\n",
       "│ TotalEnvSteps                 │ 894976.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01463491003960371  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004309923388063908 │\n",
       "│ Value/Adv                     │ 0.12748825550079346   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01366956252604723   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.009043996222317219 │\n",
       "│ Value/reward                  │ 2.255154848098755     │\n",
       "│ Time/Total                    │ 5715.3955078125       │\n",
       "│ Time/Rollout                  │ 10.91680908203125     │\n",
       "│ Time/Update                   │ 1.7157971858978271    │\n",
       "│ Time/Epoch                    │ 12.632649421691895    │\n",
       "│ Time/FPS                      │ 162.11961364746094    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.103321075439453     │\n",
       "│ Metrics/EpCost                │ 56.13999938964844      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 437.0                  │\n",
       "│ Train/Entropy                 │ -0.3051542639732361    │\n",
       "│ Train/KL                      │ 0.011565887369215488   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9952794909477234     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9952794909477234     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9952794909477234     │\n",
       "│ Train/PolicyRatio/Std         │ 0.014578312635421753   │\n",
       "│ Train/LR                      │ 3.719999949680641e-05  │\n",
       "│ Train/PolicyStd               │ 0.17839032411575317    │\n",
       "│ TotalEnvSteps                 │ 897024.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017861222848296165  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0032263128086924553 │\n",
       "│ Value/Adv                     │ 0.13740000128746033    │\n",
       "│ Loss/Loss_reward_critic       │ 0.015946391969919205   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002276829443871975   │\n",
       "│ Value/reward                  │ 2.2809510231018066     │\n",
       "│ Time/Total                    │ 5727.974609375         │\n",
       "│ Time/Rollout                  │ 10.859811782836914     │\n",
       "│ Time/Update                   │ 1.705951452255249      │\n",
       "│ Time/Epoch                    │ 12.565815925598145     │\n",
       "│ Time/FPS                      │ 162.98187255859375     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.103321075439453     │\n",
       "│ Metrics/EpCost                │ 56.13999938964844      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 437.0                  │\n",
       "│ Train/Entropy                 │ -0.3051542639732361    │\n",
       "│ Train/KL                      │ 0.011565887369215488   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9952794909477234     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9952794909477234     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9952794909477234     │\n",
       "│ Train/PolicyRatio/Std         │ 0.014578312635421753   │\n",
       "│ Train/LR                      │ 3.719999949680641e-05  │\n",
       "│ Train/PolicyStd               │ 0.17839032411575317    │\n",
       "│ TotalEnvSteps                 │ 897024.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017861222848296165  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0032263128086924553 │\n",
       "│ Value/Adv                     │ 0.13740000128746033    │\n",
       "│ Loss/Loss_reward_critic       │ 0.015946391969919205   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002276829443871975   │\n",
       "│ Value/reward                  │ 2.2809510231018066     │\n",
       "│ Time/Total                    │ 5727.974609375         │\n",
       "│ Time/Rollout                  │ 10.859811782836914     │\n",
       "│ Time/Update                   │ 1.705951452255249      │\n",
       "│ Time/Epoch                    │ 12.565815925598145     │\n",
       "│ Time/FPS                      │ 162.98187255859375     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.943632125854492    │\n",
       "│ Metrics/EpCost                │ 54.619998931884766    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 438.0                 │\n",
       "│ Train/Entropy                 │ -0.3067995011806488   │\n",
       "│ Train/KL                      │ 0.009506437927484512  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9993764162063599    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9993764162063599    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9993764162063599    │\n",
       "│ Train/PolicyRatio/Std         │ 0.014663507230579853  │\n",
       "│ Train/LR                      │ 3.65999985660892e-05  │\n",
       "│ Train/PolicyStd               │ 0.17809908092021942   │\n",
       "│ TotalEnvSteps                 │ 899072.0              │\n",
       "│ Loss/Loss_pi                  │ -0.012948749586939812 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004912473261356354  │\n",
       "│ Value/Adv                     │ -0.18048477172851562  │\n",
       "│ Loss/Loss_reward_critic       │ 0.01764681376516819   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0017004217952489853 │\n",
       "│ Value/reward                  │ 2.1330575942993164    │\n",
       "│ Time/Total                    │ 5740.63427734375      │\n",
       "│ Time/Rollout                  │ 10.940715789794922    │\n",
       "│ Time/Update                   │ 1.7075164318084717    │\n",
       "│ Time/Epoch                    │ 12.648276329040527    │\n",
       "│ Time/FPS                      │ 161.91929626464844    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.943632125854492    │\n",
       "│ Metrics/EpCost                │ 54.619998931884766    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 438.0                 │\n",
       "│ Train/Entropy                 │ -0.3067995011806488   │\n",
       "│ Train/KL                      │ 0.009506437927484512  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9993764162063599    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9993764162063599    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9993764162063599    │\n",
       "│ Train/PolicyRatio/Std         │ 0.014663507230579853  │\n",
       "│ Train/LR                      │ 3.65999985660892e-05  │\n",
       "│ Train/PolicyStd               │ 0.17809908092021942   │\n",
       "│ TotalEnvSteps                 │ 899072.0              │\n",
       "│ Loss/Loss_pi                  │ -0.012948749586939812 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004912473261356354  │\n",
       "│ Value/Adv                     │ -0.18048477172851562  │\n",
       "│ Loss/Loss_reward_critic       │ 0.01764681376516819   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0017004217952489853 │\n",
       "│ Value/reward                  │ 2.1330575942993164    │\n",
       "│ Time/Total                    │ 5740.63427734375      │\n",
       "│ Time/Rollout                  │ 10.940715789794922    │\n",
       "│ Time/Update                   │ 1.7075164318084717    │\n",
       "│ Time/Epoch                    │ 12.648276329040527    │\n",
       "│ Time/FPS                      │ 161.91929626464844    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.982858657836914     │\n",
       "│ Metrics/EpCost                │ 56.2400016784668       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 439.0                  │\n",
       "│ Train/Entropy                 │ -0.30789145827293396   │\n",
       "│ Train/KL                      │ 0.009747438132762909   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.998515784740448      │\n",
       "│ Train/PolicyRatio/Min         │ 0.998515784740448      │\n",
       "│ Train/PolicyRatio/Max         │ 0.998515784740448      │\n",
       "│ Train/PolicyRatio/Std         │ 0.013069957494735718   │\n",
       "│ Train/LR                      │ 3.600000127335079e-05  │\n",
       "│ Train/PolicyStd               │ 0.17790400981903076    │\n",
       "│ TotalEnvSteps                 │ 901120.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016616057604551315  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0036673080176115036 │\n",
       "│ Value/Adv                     │ 0.05405258387327194    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01813320815563202    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00048639439046382904 │\n",
       "│ Value/reward                  │ 2.2196810245513916     │\n",
       "│ Time/Total                    │ 5753.169921875         │\n",
       "│ Time/Rollout                  │ 10.81340217590332      │\n",
       "│ Time/Update                   │ 1.7104785442352295     │\n",
       "│ Time/Epoch                    │ 12.523937225341797     │\n",
       "│ Time/FPS                      │ 163.52685546875        │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.982858657836914     │\n",
       "│ Metrics/EpCost                │ 56.2400016784668       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 439.0                  │\n",
       "│ Train/Entropy                 │ -0.30789145827293396   │\n",
       "│ Train/KL                      │ 0.009747438132762909   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.998515784740448      │\n",
       "│ Train/PolicyRatio/Min         │ 0.998515784740448      │\n",
       "│ Train/PolicyRatio/Max         │ 0.998515784740448      │\n",
       "│ Train/PolicyRatio/Std         │ 0.013069957494735718   │\n",
       "│ Train/LR                      │ 3.600000127335079e-05  │\n",
       "│ Train/PolicyStd               │ 0.17790400981903076    │\n",
       "│ TotalEnvSteps                 │ 901120.0               │\n",
       "│ Loss/Loss_pi                  │ -0.016616057604551315  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0036673080176115036 │\n",
       "│ Value/Adv                     │ 0.05405258387327194    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01813320815563202    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00048639439046382904 │\n",
       "│ Value/reward                  │ 2.2196810245513916     │\n",
       "│ Time/Total                    │ 5753.169921875         │\n",
       "│ Time/Rollout                  │ 10.81340217590332      │\n",
       "│ Time/Update                   │ 1.7104785442352295     │\n",
       "│ Time/Epoch                    │ 12.523937225341797     │\n",
       "│ Time/FPS                      │ 163.52685546875        │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.973066329956055     │\n",
       "│ Metrics/EpCost                │ 56.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 440.0                  │\n",
       "│ Train/Entropy                 │ -0.31066349148750305   │\n",
       "│ Train/KL                      │ 0.010415018536150455   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9996101260185242     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9996101260185242     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9996101260185242     │\n",
       "│ Train/PolicyRatio/Std         │ 0.015007554553449154   │\n",
       "│ Train/LR                      │ 3.5400000342633575e-05 │\n",
       "│ Train/PolicyStd               │ 0.17740730941295624    │\n",
       "│ TotalEnvSteps                 │ 903168.0               │\n",
       "│ Loss/Loss_pi                  │ -0.02126207761466503   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004646020010113716  │\n",
       "│ Value/Adv                     │ -0.08655264973640442   │\n",
       "│ Loss/Loss_reward_critic       │ 0.012766796164214611   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005366411991417408  │\n",
       "│ Value/reward                  │ 2.186246156692505      │\n",
       "│ Time/Total                    │ 5765.79638671875       │\n",
       "│ Time/Rollout                  │ 10.892416954040527     │\n",
       "│ Time/Update                   │ 1.7209792137145996     │\n",
       "│ Time/Epoch                    │ 12.61345386505127      │\n",
       "│ Time/FPS                      │ 162.3664093017578      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.973066329956055     │\n",
       "│ Metrics/EpCost                │ 56.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 440.0                  │\n",
       "│ Train/Entropy                 │ -0.31066349148750305   │\n",
       "│ Train/KL                      │ 0.010415018536150455   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9996101260185242     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9996101260185242     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9996101260185242     │\n",
       "│ Train/PolicyRatio/Std         │ 0.015007554553449154   │\n",
       "│ Train/LR                      │ 3.5400000342633575e-05 │\n",
       "│ Train/PolicyStd               │ 0.17740730941295624    │\n",
       "│ TotalEnvSteps                 │ 903168.0               │\n",
       "│ Loss/Loss_pi                  │ -0.02126207761466503   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004646020010113716  │\n",
       "│ Value/Adv                     │ -0.08655264973640442   │\n",
       "│ Loss/Loss_reward_critic       │ 0.012766796164214611   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005366411991417408  │\n",
       "│ Value/reward                  │ 2.186246156692505      │\n",
       "│ Time/Total                    │ 5765.79638671875       │\n",
       "│ Time/Rollout                  │ 10.892416954040527     │\n",
       "│ Time/Update                   │ 1.7209792137145996     │\n",
       "│ Time/Epoch                    │ 12.61345386505127      │\n",
       "│ Time/FPS                      │ 162.3664093017578      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.147724151611328    │\n",
       "│ Metrics/EpCost                │ 52.720001220703125    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 441.0                 │\n",
       "│ Train/Entropy                 │ -0.3130674362182617   │\n",
       "│ Train/KL                      │ 0.008268844336271286  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0014208555221558    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0014208555221558    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0014208555221558    │\n",
       "│ Train/PolicyRatio/Std         │ 0.013773779384791851  │\n",
       "│ Train/LR                      │ 3.479999941191636e-05 │\n",
       "│ Train/PolicyStd               │ 0.17697742581367493   │\n",
       "│ TotalEnvSteps                 │ 905216.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01588703878223896  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005375038832426071  │\n",
       "│ Value/Adv                     │ 0.14209891855716705   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014725337736308575  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0019585415720939636 │\n",
       "│ Value/reward                  │ 2.126361608505249     │\n",
       "│ Time/Total                    │ 5778.3115234375       │\n",
       "│ Time/Rollout                  │ 10.801168441772461    │\n",
       "│ Time/Update                   │ 1.7022252082824707    │\n",
       "│ Time/Epoch                    │ 12.503437042236328    │\n",
       "│ Time/FPS                      │ 163.7949676513672     │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.147724151611328    │\n",
       "│ Metrics/EpCost                │ 52.720001220703125    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 441.0                 │\n",
       "│ Train/Entropy                 │ -0.3130674362182617   │\n",
       "│ Train/KL                      │ 0.008268844336271286  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0014208555221558    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0014208555221558    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0014208555221558    │\n",
       "│ Train/PolicyRatio/Std         │ 0.013773779384791851  │\n",
       "│ Train/LR                      │ 3.479999941191636e-05 │\n",
       "│ Train/PolicyStd               │ 0.17697742581367493   │\n",
       "│ TotalEnvSteps                 │ 905216.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01588703878223896  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.005375038832426071  │\n",
       "│ Value/Adv                     │ 0.14209891855716705   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014725337736308575  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0019585415720939636 │\n",
       "│ Value/reward                  │ 2.126361608505249     │\n",
       "│ Time/Total                    │ 5778.3115234375       │\n",
       "│ Time/Rollout                  │ 10.801168441772461    │\n",
       "│ Time/Update                   │ 1.7022252082824707    │\n",
       "│ Time/Epoch                    │ 12.503437042236328    │\n",
       "│ Time/FPS                      │ 163.7949676513672     │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.241594314575195     │\n",
       "│ Metrics/EpCost                │ 53.619998931884766     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 442.0                  │\n",
       "│ Train/Entropy                 │ -0.3134201765060425    │\n",
       "│ Train/KL                      │ 0.006785034667700529   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0024569034576416     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0024569034576416     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0024569034576416     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01264989748597145    │\n",
       "│ Train/LR                      │ 3.4199998481199145e-05 │\n",
       "│ Train/PolicyStd               │ 0.17691642045974731    │\n",
       "│ TotalEnvSteps                 │ 907264.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012947251088917255  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002939787693321705   │\n",
       "│ Value/Adv                     │ -0.18454734981060028   │\n",
       "│ Loss/Loss_reward_critic       │ 0.016003118827939034   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0012777810916304588  │\n",
       "│ Value/reward                  │ 2.1714258193969727     │\n",
       "│ Time/Total                    │ 5790.90087890625       │\n",
       "│ Time/Rollout                  │ 10.864328384399414     │\n",
       "│ Time/Update                   │ 1.7126290798187256     │\n",
       "│ Time/Epoch                    │ 12.577007293701172     │\n",
       "│ Time/FPS                      │ 162.8368377685547      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.241594314575195     │\n",
       "│ Metrics/EpCost                │ 53.619998931884766     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 442.0                  │\n",
       "│ Train/Entropy                 │ -0.3134201765060425    │\n",
       "│ Train/KL                      │ 0.006785034667700529   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0024569034576416     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0024569034576416     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0024569034576416     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01264989748597145    │\n",
       "│ Train/LR                      │ 3.4199998481199145e-05 │\n",
       "│ Train/PolicyStd               │ 0.17691642045974731    │\n",
       "│ TotalEnvSteps                 │ 907264.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012947251088917255  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002939787693321705   │\n",
       "│ Value/Adv                     │ -0.18454734981060028   │\n",
       "│ Loss/Loss_reward_critic       │ 0.016003118827939034   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0012777810916304588  │\n",
       "│ Value/reward                  │ 2.1714258193969727     │\n",
       "│ Time/Total                    │ 5790.90087890625       │\n",
       "│ Time/Rollout                  │ 10.864328384399414     │\n",
       "│ Time/Update                   │ 1.7126290798187256     │\n",
       "│ Time/Epoch                    │ 12.577007293701172     │\n",
       "│ Time/FPS                      │ 162.8368377685547      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.124006271362305     │\n",
       "│ Metrics/EpCost                │ 51.70000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 443.0                  │\n",
       "│ Train/Entropy                 │ -0.3144950866699219    │\n",
       "│ Train/KL                      │ 0.010794980451464653   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9989059567451477     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9989059567451477     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9989059567451477     │\n",
       "│ Train/PolicyRatio/Std         │ 0.015634572133421898   │\n",
       "│ Train/LR                      │ 3.360000118846074e-05  │\n",
       "│ Train/PolicyStd               │ 0.17672544717788696    │\n",
       "│ TotalEnvSteps                 │ 909312.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015820806846022606  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0028735557571053505 │\n",
       "│ Value/Adv                     │ 0.027404185384511948   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018159914761781693   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002156795933842659   │\n",
       "│ Value/reward                  │ 2.219963312149048      │\n",
       "│ Time/Total                    │ 5803.40966796875       │\n",
       "│ Time/Rollout                  │ 10.793061256408691     │\n",
       "│ Time/Update                   │ 1.704049825668335      │\n",
       "│ Time/Epoch                    │ 12.497154235839844     │\n",
       "│ Time/FPS                      │ 163.8773193359375      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.124006271362305     │\n",
       "│ Metrics/EpCost                │ 51.70000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 443.0                  │\n",
       "│ Train/Entropy                 │ -0.3144950866699219    │\n",
       "│ Train/KL                      │ 0.010794980451464653   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9989059567451477     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9989059567451477     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9989059567451477     │\n",
       "│ Train/PolicyRatio/Std         │ 0.015634572133421898   │\n",
       "│ Train/LR                      │ 3.360000118846074e-05  │\n",
       "│ Train/PolicyStd               │ 0.17672544717788696    │\n",
       "│ TotalEnvSteps                 │ 909312.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015820806846022606  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0028735557571053505 │\n",
       "│ Value/Adv                     │ 0.027404185384511948   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018159914761781693   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.002156795933842659   │\n",
       "│ Value/reward                  │ 2.219963312149048      │\n",
       "│ Time/Total                    │ 5803.40966796875       │\n",
       "│ Time/Rollout                  │ 10.793061256408691     │\n",
       "│ Time/Update                   │ 1.704049825668335      │\n",
       "│ Time/Epoch                    │ 12.497154235839844     │\n",
       "│ Time/FPS                      │ 163.8773193359375      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.154380798339844     │\n",
       "│ Metrics/EpCost                │ 50.20000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 444.0                  │\n",
       "│ Train/Entropy                 │ -0.3162834048271179    │\n",
       "│ Train/KL                      │ 0.009744846262037754   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9998129606246948     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9998129606246948     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9998129606246948     │\n",
       "│ Train/PolicyRatio/Std         │ 0.014803988859057426   │\n",
       "│ Train/LR                      │ 3.300000025774352e-05  │\n",
       "│ Train/PolicyStd               │ 0.17640726268291473    │\n",
       "│ TotalEnvSteps                 │ 911360.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017792169004678726  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0019713621586561203 │\n",
       "│ Value/Adv                     │ 0.12221147865056992    │\n",
       "│ Loss/Loss_reward_critic       │ 0.015885217115283012   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00227469764649868   │\n",
       "│ Value/reward                  │ 2.1314120292663574     │\n",
       "│ Time/Total                    │ 5815.9814453125        │\n",
       "│ Time/Rollout                  │ 10.864338874816895     │\n",
       "│ Time/Update                   │ 1.6957964897155762     │\n",
       "│ Time/Epoch                    │ 12.560179710388184     │\n",
       "│ Time/FPS                      │ 163.0550079345703      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.154380798339844     │\n",
       "│ Metrics/EpCost                │ 50.20000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 444.0                  │\n",
       "│ Train/Entropy                 │ -0.3162834048271179    │\n",
       "│ Train/KL                      │ 0.009744846262037754   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9998129606246948     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9998129606246948     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9998129606246948     │\n",
       "│ Train/PolicyRatio/Std         │ 0.014803988859057426   │\n",
       "│ Train/LR                      │ 3.300000025774352e-05  │\n",
       "│ Train/PolicyStd               │ 0.17640726268291473    │\n",
       "│ TotalEnvSteps                 │ 911360.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017792169004678726  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0019713621586561203 │\n",
       "│ Value/Adv                     │ 0.12221147865056992    │\n",
       "│ Loss/Loss_reward_critic       │ 0.015885217115283012   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00227469764649868   │\n",
       "│ Value/reward                  │ 2.1314120292663574     │\n",
       "│ Time/Total                    │ 5815.9814453125        │\n",
       "│ Time/Rollout                  │ 10.864338874816895     │\n",
       "│ Time/Update                   │ 1.6957964897155762     │\n",
       "│ Time/Epoch                    │ 12.560179710388184     │\n",
       "│ Time/FPS                      │ 163.0550079345703      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.012075424194336     │\n",
       "│ Metrics/EpCost                │ 50.20000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 445.0                  │\n",
       "│ Train/Entropy                 │ -0.31660035252571106   │\n",
       "│ Train/KL                      │ 0.008790154941380024   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.000061273574829      │\n",
       "│ Train/PolicyRatio/Min         │ 1.000061273574829      │\n",
       "│ Train/PolicyRatio/Max         │ 1.000061273574829      │\n",
       "│ Train/PolicyRatio/Std         │ 0.013666821643710136   │\n",
       "│ Train/LR                      │ 3.239999932702631e-05  │\n",
       "│ Train/PolicyStd               │ 0.1763530671596527     │\n",
       "│ TotalEnvSteps                 │ 913408.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01809297502040863   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0003008060157299042 │\n",
       "│ Value/Adv                     │ -0.13541240990161896   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014183595776557922   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00170162133872509   │\n",
       "│ Value/reward                  │ 2.0833330154418945     │\n",
       "│ Time/Total                    │ 5828.5361328125        │\n",
       "│ Time/Rollout                  │ 10.841811180114746     │\n",
       "│ Time/Update                   │ 1.7016088962554932     │\n",
       "│ Time/Epoch                    │ 12.543466567993164     │\n",
       "│ Time/FPS                      │ 163.2722625732422      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.012075424194336     │\n",
       "│ Metrics/EpCost                │ 50.20000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 445.0                  │\n",
       "│ Train/Entropy                 │ -0.31660035252571106   │\n",
       "│ Train/KL                      │ 0.008790154941380024   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.000061273574829      │\n",
       "│ Train/PolicyRatio/Min         │ 1.000061273574829      │\n",
       "│ Train/PolicyRatio/Max         │ 1.000061273574829      │\n",
       "│ Train/PolicyRatio/Std         │ 0.013666821643710136   │\n",
       "│ Train/LR                      │ 3.239999932702631e-05  │\n",
       "│ Train/PolicyStd               │ 0.1763530671596527     │\n",
       "│ TotalEnvSteps                 │ 913408.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01809297502040863   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0003008060157299042 │\n",
       "│ Value/Adv                     │ -0.13541240990161896   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014183595776557922   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.00170162133872509   │\n",
       "│ Value/reward                  │ 2.0833330154418945     │\n",
       "│ Time/Total                    │ 5828.5361328125        │\n",
       "│ Time/Rollout                  │ 10.841811180114746     │\n",
       "│ Time/Update                   │ 1.7016088962554932     │\n",
       "│ Time/Epoch                    │ 12.543466567993164     │\n",
       "│ Time/FPS                      │ 163.2722625732422      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.0421199798584      │\n",
       "│ Metrics/EpCost                │ 51.7599983215332      │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 446.0                 │\n",
       "│ Train/Entropy                 │ -0.31740522384643555  │\n",
       "│ Train/KL                      │ 0.008025165647268295  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0022547245025635    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0022547245025635    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0022547245025635    │\n",
       "│ Train/PolicyRatio/Std         │ 0.014167122542858124  │\n",
       "│ Train/LR                      │ 3.179999839630909e-05 │\n",
       "│ Train/PolicyStd               │ 0.17621088027954102   │\n",
       "│ TotalEnvSteps                 │ 915456.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01658770814538002  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0015052668750286102 │\n",
       "│ Value/Adv                     │ 0.011033168062567711  │\n",
       "│ Loss/Loss_reward_critic       │ 0.018371518701314926  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004187922924757004  │\n",
       "│ Value/reward                  │ 2.237121820449829     │\n",
       "│ Time/Total                    │ 5841.0986328125       │\n",
       "│ Time/Rollout                  │ 10.843003273010254    │\n",
       "│ Time/Update                   │ 1.7082643508911133    │\n",
       "│ Time/Epoch                    │ 12.551314353942871    │\n",
       "│ Time/FPS                      │ 163.170166015625      │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.0421199798584      │\n",
       "│ Metrics/EpCost                │ 51.7599983215332      │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 446.0                 │\n",
       "│ Train/Entropy                 │ -0.31740522384643555  │\n",
       "│ Train/KL                      │ 0.008025165647268295  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0022547245025635    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0022547245025635    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0022547245025635    │\n",
       "│ Train/PolicyRatio/Std         │ 0.014167122542858124  │\n",
       "│ Train/LR                      │ 3.179999839630909e-05 │\n",
       "│ Train/PolicyStd               │ 0.17621088027954102   │\n",
       "│ TotalEnvSteps                 │ 915456.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01658770814538002  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0015052668750286102 │\n",
       "│ Value/Adv                     │ 0.011033168062567711  │\n",
       "│ Loss/Loss_reward_critic       │ 0.018371518701314926  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004187922924757004  │\n",
       "│ Value/reward                  │ 2.237121820449829     │\n",
       "│ Time/Total                    │ 5841.0986328125       │\n",
       "│ Time/Rollout                  │ 10.843003273010254    │\n",
       "│ Time/Update                   │ 1.7082643508911133    │\n",
       "│ Time/Epoch                    │ 12.551314353942871    │\n",
       "│ Time/FPS                      │ 163.170166015625      │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.979324340820312     │\n",
       "│ Metrics/EpCost                │ 52.0                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 447.0                  │\n",
       "│ Train/Entropy                 │ -0.3187551200389862    │\n",
       "│ Train/KL                      │ 0.008904688991606236   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9982007741928101     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9982007741928101     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9982007741928101     │\n",
       "│ Train/PolicyRatio/Std         │ 0.011774846352636814   │\n",
       "│ Train/LR                      │ 3.1200001103570685e-05 │\n",
       "│ Train/PolicyStd               │ 0.17597340047359467    │\n",
       "│ TotalEnvSteps                 │ 917504.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014005405828356743  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0025823023170232773  │\n",
       "│ Value/Adv                     │ 0.13681688904762268    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01801333948969841    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0003581792116165161 │\n",
       "│ Value/reward                  │ 2.131220579147339      │\n",
       "│ Time/Total                    │ 5853.67822265625       │\n",
       "│ Time/Rollout                  │ 10.849068641662598     │\n",
       "│ Time/Update                   │ 1.7189311981201172     │\n",
       "│ Time/Epoch                    │ 12.568044662475586     │\n",
       "│ Time/FPS                      │ 162.95297241210938     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.979324340820312     │\n",
       "│ Metrics/EpCost                │ 52.0                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 447.0                  │\n",
       "│ Train/Entropy                 │ -0.3187551200389862    │\n",
       "│ Train/KL                      │ 0.008904688991606236   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9982007741928101     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9982007741928101     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9982007741928101     │\n",
       "│ Train/PolicyRatio/Std         │ 0.011774846352636814   │\n",
       "│ Train/LR                      │ 3.1200001103570685e-05 │\n",
       "│ Train/PolicyStd               │ 0.17597340047359467    │\n",
       "│ TotalEnvSteps                 │ 917504.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014005405828356743  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0025823023170232773  │\n",
       "│ Value/Adv                     │ 0.13681688904762268    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01801333948969841    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0003581792116165161 │\n",
       "│ Value/reward                  │ 2.131220579147339      │\n",
       "│ Time/Total                    │ 5853.67822265625       │\n",
       "│ Time/Rollout                  │ 10.849068641662598     │\n",
       "│ Time/Update                   │ 1.7189311981201172     │\n",
       "│ Time/Epoch                    │ 12.568044662475586     │\n",
       "│ Time/FPS                      │ 162.95297241210938     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.123340606689453     │\n",
       "│ Metrics/EpCost                │ 54.31999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 448.0                  │\n",
       "│ Train/Entropy                 │ -0.3193807303905487    │\n",
       "│ Train/KL                      │ 0.009981712326407433   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9961292147636414     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9961292147636414     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9961292147636414     │\n",
       "│ Train/PolicyRatio/Std         │ 0.014124146662652493   │\n",
       "│ Train/LR                      │ 3.060000017285347e-05  │\n",
       "│ Train/PolicyStd               │ 0.1758652776479721     │\n",
       "│ TotalEnvSteps                 │ 919552.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015842078253626823  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0018366724252700806 │\n",
       "│ Value/Adv                     │ 0.023609697818756104   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018571704626083374   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.000558365136384964   │\n",
       "│ Value/reward                  │ 2.2076032161712646     │\n",
       "│ Time/Total                    │ 5866.27099609375       │\n",
       "│ Time/Rollout                  │ 10.887296676635742     │\n",
       "│ Time/Update                   │ 1.6939783096313477     │\n",
       "│ Time/Epoch                    │ 12.581317901611328     │\n",
       "│ Time/FPS                      │ 162.7810516357422      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.123340606689453     │\n",
       "│ Metrics/EpCost                │ 54.31999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 448.0                  │\n",
       "│ Train/Entropy                 │ -0.3193807303905487    │\n",
       "│ Train/KL                      │ 0.009981712326407433   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9961292147636414     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9961292147636414     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9961292147636414     │\n",
       "│ Train/PolicyRatio/Std         │ 0.014124146662652493   │\n",
       "│ Train/LR                      │ 3.060000017285347e-05  │\n",
       "│ Train/PolicyStd               │ 0.1758652776479721     │\n",
       "│ TotalEnvSteps                 │ 919552.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015842078253626823  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0018366724252700806 │\n",
       "│ Value/Adv                     │ 0.023609697818756104   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018571704626083374   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.000558365136384964   │\n",
       "│ Value/reward                  │ 2.2076032161712646     │\n",
       "│ Time/Total                    │ 5866.27099609375       │\n",
       "│ Time/Rollout                  │ 10.887296676635742     │\n",
       "│ Time/Update                   │ 1.6939783096313477     │\n",
       "│ Time/Epoch                    │ 12.581317901611328     │\n",
       "│ Time/FPS                      │ 162.7810516357422      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.148801803588867     │\n",
       "│ Metrics/EpCost                │ 55.560001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 449.0                  │\n",
       "│ Train/Entropy                 │ -0.3198821246623993    │\n",
       "│ Train/KL                      │ 0.013005871325731277   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9990482330322266     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9990482330322266     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9990482330322266     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01626717485487461    │\n",
       "│ Train/LR                      │ 2.9999999242136255e-05 │\n",
       "│ Train/PolicyStd               │ 0.17577888071537018    │\n",
       "│ TotalEnvSteps                 │ 921600.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01881386712193489   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0029717888683080673 │\n",
       "│ Value/Adv                     │ -0.07359731197357178   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014194613322615623   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0043770913034677505 │\n",
       "│ Value/reward                  │ 2.2649974822998047     │\n",
       "│ Time/Total                    │ 5878.84521484375       │\n",
       "│ Time/Rollout                  │ 10.844524383544922     │\n",
       "│ Time/Update                   │ 1.7184381484985352     │\n",
       "│ Time/Epoch                    │ 12.563005447387695     │\n",
       "│ Time/FPS                      │ 163.01832580566406     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.148801803588867     │\n",
       "│ Metrics/EpCost                │ 55.560001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 449.0                  │\n",
       "│ Train/Entropy                 │ -0.3198821246623993    │\n",
       "│ Train/KL                      │ 0.013005871325731277   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9990482330322266     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9990482330322266     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9990482330322266     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01626717485487461    │\n",
       "│ Train/LR                      │ 2.9999999242136255e-05 │\n",
       "│ Train/PolicyStd               │ 0.17577888071537018    │\n",
       "│ TotalEnvSteps                 │ 921600.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01881386712193489   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0029717888683080673 │\n",
       "│ Value/Adv                     │ -0.07359731197357178   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014194613322615623   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0043770913034677505 │\n",
       "│ Value/reward                  │ 2.2649974822998047     │\n",
       "│ Time/Total                    │ 5878.84521484375       │\n",
       "│ Time/Rollout                  │ 10.844524383544922     │\n",
       "│ Time/Update                   │ 1.7184381484985352     │\n",
       "│ Time/Epoch                    │ 12.563005447387695     │\n",
       "│ Time/FPS                      │ 163.01832580566406     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.201309204101562     │\n",
       "│ Metrics/EpCost                │ 55.91999816894531      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 450.0                  │\n",
       "│ Train/Entropy                 │ -0.3206873834133148    │\n",
       "│ Train/KL                      │ 0.010317929089069366   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9958797693252563     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9958797693252563     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9958797693252563     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01486007496714592    │\n",
       "│ Train/LR                      │ 2.9400000130408444e-05 │\n",
       "│ Train/PolicyStd               │ 0.17563708126544952    │\n",
       "│ TotalEnvSteps                 │ 923648.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017633918672800064  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0011799484491348267  │\n",
       "│ Value/Adv                     │ -0.07431305944919586   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01883229799568653    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004637684673070908   │\n",
       "│ Value/reward                  │ 2.2578461170196533     │\n",
       "│ Time/Total                    │ 5891.37841796875       │\n",
       "│ Time/Rollout                  │ 10.826152801513672     │\n",
       "│ Time/Update                   │ 1.693392276763916      │\n",
       "│ Time/Epoch                    │ 12.51959228515625      │\n",
       "│ Time/FPS                      │ 163.5836181640625      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.201309204101562     │\n",
       "│ Metrics/EpCost                │ 55.91999816894531      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 450.0                  │\n",
       "│ Train/Entropy                 │ -0.3206873834133148    │\n",
       "│ Train/KL                      │ 0.010317929089069366   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9958797693252563     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9958797693252563     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9958797693252563     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01486007496714592    │\n",
       "│ Train/LR                      │ 2.9400000130408444e-05 │\n",
       "│ Train/PolicyStd               │ 0.17563708126544952    │\n",
       "│ TotalEnvSteps                 │ 923648.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017633918672800064  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0011799484491348267  │\n",
       "│ Value/Adv                     │ -0.07431305944919586   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01883229799568653    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004637684673070908   │\n",
       "│ Value/reward                  │ 2.2578461170196533     │\n",
       "│ Time/Total                    │ 5891.37841796875       │\n",
       "│ Time/Rollout                  │ 10.826152801513672     │\n",
       "│ Time/Update                   │ 1.693392276763916      │\n",
       "│ Time/Epoch                    │ 12.51959228515625      │\n",
       "│ Time/FPS                      │ 163.5836181640625      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.306808471679688    │\n",
       "│ Metrics/EpCost                │ 56.02000045776367     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 451.0                 │\n",
       "│ Train/Entropy                 │ -0.32212692499160767  │\n",
       "│ Train/KL                      │ 0.008125483989715576  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0007479190826416    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0007479190826416    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0007479190826416    │\n",
       "│ Train/PolicyRatio/Std         │ 0.013703862205147743  │\n",
       "│ Train/LR                      │ 2.879999919969123e-05 │\n",
       "│ Train/PolicyStd               │ 0.1753826141357422    │\n",
       "│ TotalEnvSteps                 │ 925696.0              │\n",
       "│ Loss/Loss_pi                  │ -0.012682778760790825 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004951139912009239  │\n",
       "│ Value/Adv                     │ 0.00831659883260727   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015491778030991554  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.003340519964694977 │\n",
       "│ Value/reward                  │ 2.1764516830444336    │\n",
       "│ Time/Total                    │ 5903.9833984375       │\n",
       "│ Time/Rollout                  │ 10.845423698425293    │\n",
       "│ Time/Update                   │ 1.7478930950164795    │\n",
       "│ Time/Epoch                    │ 12.593363761901855    │\n",
       "│ Time/FPS                      │ 162.62535095214844    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.306808471679688    │\n",
       "│ Metrics/EpCost                │ 56.02000045776367     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 451.0                 │\n",
       "│ Train/Entropy                 │ -0.32212692499160767  │\n",
       "│ Train/KL                      │ 0.008125483989715576  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0007479190826416    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0007479190826416    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0007479190826416    │\n",
       "│ Train/PolicyRatio/Std         │ 0.013703862205147743  │\n",
       "│ Train/LR                      │ 2.879999919969123e-05 │\n",
       "│ Train/PolicyStd               │ 0.1753826141357422    │\n",
       "│ TotalEnvSteps                 │ 925696.0              │\n",
       "│ Loss/Loss_pi                  │ -0.012682778760790825 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004951139912009239  │\n",
       "│ Value/Adv                     │ 0.00831659883260727   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015491778030991554  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.003340519964694977 │\n",
       "│ Value/reward                  │ 2.1764516830444336    │\n",
       "│ Time/Total                    │ 5903.9833984375       │\n",
       "│ Time/Rollout                  │ 10.845423698425293    │\n",
       "│ Time/Update                   │ 1.7478930950164795    │\n",
       "│ Time/Epoch                    │ 12.593363761901855    │\n",
       "│ Time/FPS                      │ 162.62535095214844    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.26610565185547      │\n",
       "│ Metrics/EpCost                │ 55.560001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 452.0                  │\n",
       "│ Train/Entropy                 │ -0.32297196984291077   │\n",
       "│ Train/KL                      │ 0.007925397716462612   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9994176626205444     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9994176626205444     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9994176626205444     │\n",
       "│ Train/PolicyRatio/Std         │ 0.014755415730178356   │\n",
       "│ Train/LR                      │ 2.8200000087963417e-05 │\n",
       "│ Train/PolicyStd               │ 0.17523075640201569    │\n",
       "│ TotalEnvSteps                 │ 927744.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014209331944584846  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0015265531837940216 │\n",
       "│ Value/Adv                     │ 0.024173038080334663   │\n",
       "│ Loss/Loss_reward_critic       │ 0.022054333239793777   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006562555208802223   │\n",
       "│ Value/reward                  │ 2.1913161277770996     │\n",
       "│ Time/Total                    │ 5916.51220703125       │\n",
       "│ Time/Rollout                  │ 10.819438934326172     │\n",
       "│ Time/Update                   │ 1.697835922241211      │\n",
       "│ Time/Epoch                    │ 12.517315864562988     │\n",
       "│ Time/FPS                      │ 163.6133575439453      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.26610565185547      │\n",
       "│ Metrics/EpCost                │ 55.560001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 452.0                  │\n",
       "│ Train/Entropy                 │ -0.32297196984291077   │\n",
       "│ Train/KL                      │ 0.007925397716462612   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9994176626205444     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9994176626205444     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9994176626205444     │\n",
       "│ Train/PolicyRatio/Std         │ 0.014755415730178356   │\n",
       "│ Train/LR                      │ 2.8200000087963417e-05 │\n",
       "│ Train/PolicyStd               │ 0.17523075640201569    │\n",
       "│ TotalEnvSteps                 │ 927744.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014209331944584846  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0015265531837940216 │\n",
       "│ Value/Adv                     │ 0.024173038080334663   │\n",
       "│ Loss/Loss_reward_critic       │ 0.022054333239793777   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006562555208802223   │\n",
       "│ Value/reward                  │ 2.1913161277770996     │\n",
       "│ Time/Total                    │ 5916.51220703125       │\n",
       "│ Time/Rollout                  │ 10.819438934326172     │\n",
       "│ Time/Update                   │ 1.697835922241211      │\n",
       "│ Time/Epoch                    │ 12.517315864562988     │\n",
       "│ Time/FPS                      │ 163.6133575439453      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.31045150756836      │\n",
       "│ Metrics/EpCost                │ 54.20000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 453.0                  │\n",
       "│ Train/Entropy                 │ -0.3243926167488098    │\n",
       "│ Train/KL                      │ 0.010227545164525509   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0006773471832275     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0006773471832275     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0006773471832275     │\n",
       "│ Train/PolicyRatio/Std         │ 0.014671551994979382   │\n",
       "│ Train/LR                      │ 2.7599999157246202e-05 │\n",
       "│ Train/PolicyStd               │ 0.1749822199344635     │\n",
       "│ TotalEnvSteps                 │ 929792.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017743539065122604  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.003534207120537758  │\n",
       "│ Value/Adv                     │ -0.140292227268219     │\n",
       "│ Loss/Loss_reward_critic       │ 0.01377558521926403    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.008278748020529747  │\n",
       "│ Value/reward                  │ 2.2323524951934814     │\n",
       "│ Time/Total                    │ 5929.1123046875        │\n",
       "│ Time/Rollout                  │ 10.867810249328613     │\n",
       "│ Time/Update                   │ 1.7212705612182617     │\n",
       "│ Time/Epoch                    │ 12.58912467956543      │\n",
       "│ Time/FPS                      │ 162.6800994873047      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.31045150756836      │\n",
       "│ Metrics/EpCost                │ 54.20000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 453.0                  │\n",
       "│ Train/Entropy                 │ -0.3243926167488098    │\n",
       "│ Train/KL                      │ 0.010227545164525509   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0006773471832275     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0006773471832275     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0006773471832275     │\n",
       "│ Train/PolicyRatio/Std         │ 0.014671551994979382   │\n",
       "│ Train/LR                      │ 2.7599999157246202e-05 │\n",
       "│ Train/PolicyStd               │ 0.1749822199344635     │\n",
       "│ TotalEnvSteps                 │ 929792.0               │\n",
       "│ Loss/Loss_pi                  │ -0.017743539065122604  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.003534207120537758  │\n",
       "│ Value/Adv                     │ -0.140292227268219     │\n",
       "│ Loss/Loss_reward_critic       │ 0.01377558521926403    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.008278748020529747  │\n",
       "│ Value/reward                  │ 2.2323524951934814     │\n",
       "│ Time/Total                    │ 5929.1123046875        │\n",
       "│ Time/Rollout                  │ 10.867810249328613     │\n",
       "│ Time/Update                   │ 1.7212705612182617     │\n",
       "│ Time/Epoch                    │ 12.58912467956543      │\n",
       "│ Time/FPS                      │ 162.6800994873047      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.385515213012695    │\n",
       "│ Metrics/EpCost                │ 51.599998474121094    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 454.0                 │\n",
       "│ Train/Entropy                 │ -0.32533296942710876  │\n",
       "│ Train/KL                      │ 0.011715764179825783  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9949362874031067    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9949362874031067    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9949362874031067    │\n",
       "│ Train/PolicyRatio/Std         │ 0.0158709567040205    │\n",
       "│ Train/LR                      │ 2.700000004551839e-05 │\n",
       "│ Train/PolicyStd               │ 0.1748177409172058    │\n",
       "│ TotalEnvSteps                 │ 931840.0              │\n",
       "│ Loss/Loss_pi                  │ -0.015517997555434704 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0022255415096879005 │\n",
       "│ Value/Adv                     │ -0.1053318902850151   │\n",
       "│ Loss/Loss_reward_critic       │ 0.013150963000953197  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.000624622218310833 │\n",
       "│ Value/reward                  │ 2.2393083572387695    │\n",
       "│ Time/Total                    │ 5941.62255859375      │\n",
       "│ Time/Rollout                  │ 10.803133010864258    │\n",
       "│ Time/Update                   │ 1.6930761337280273    │\n",
       "│ Time/Epoch                    │ 12.496259689331055    │\n",
       "│ Time/FPS                      │ 163.88905334472656    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.385515213012695    │\n",
       "│ Metrics/EpCost                │ 51.599998474121094    │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 454.0                 │\n",
       "│ Train/Entropy                 │ -0.32533296942710876  │\n",
       "│ Train/KL                      │ 0.011715764179825783  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9949362874031067    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9949362874031067    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9949362874031067    │\n",
       "│ Train/PolicyRatio/Std         │ 0.0158709567040205    │\n",
       "│ Train/LR                      │ 2.700000004551839e-05 │\n",
       "│ Train/PolicyStd               │ 0.1748177409172058    │\n",
       "│ TotalEnvSteps                 │ 931840.0              │\n",
       "│ Loss/Loss_pi                  │ -0.015517997555434704 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0022255415096879005 │\n",
       "│ Value/Adv                     │ -0.1053318902850151   │\n",
       "│ Loss/Loss_reward_critic       │ 0.013150963000953197  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.000624622218310833 │\n",
       "│ Value/reward                  │ 2.2393083572387695    │\n",
       "│ Time/Total                    │ 5941.62255859375      │\n",
       "│ Time/Rollout                  │ 10.803133010864258    │\n",
       "│ Time/Update                   │ 1.6930761337280273    │\n",
       "│ Time/Epoch                    │ 12.496259689331055    │\n",
       "│ Time/FPS                      │ 163.88905334472656    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.30854034423828      │\n",
       "│ Metrics/EpCost                │ 51.119998931884766     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 455.0                  │\n",
       "│ Train/Entropy                 │ -0.3251863420009613    │\n",
       "│ Train/KL                      │ 0.011542832478880882   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9953875541687012     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9953875541687012     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9953875541687012     │\n",
       "│ Train/PolicyRatio/Std         │ 0.014591381885111332   │\n",
       "│ Train/LR                      │ 2.6399999114801176e-05 │\n",
       "│ Train/PolicyStd               │ 0.1748393177986145     │\n",
       "│ TotalEnvSteps                 │ 933888.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018702160567045212  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.003184163011610508  │\n",
       "│ Value/Adv                     │ -0.03268910199403763   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015275731682777405   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0021247686818242073  │\n",
       "│ Value/reward                  │ 2.2452566623687744     │\n",
       "│ Time/Total                    │ 5954.14501953125       │\n",
       "│ Time/Rollout                  │ 10.815128326416016     │\n",
       "│ Time/Update                   │ 1.6916921138763428     │\n",
       "│ Time/Epoch                    │ 12.506864547729492     │\n",
       "│ Time/FPS                      │ 163.7500762939453      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.30854034423828      │\n",
       "│ Metrics/EpCost                │ 51.119998931884766     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 455.0                  │\n",
       "│ Train/Entropy                 │ -0.3251863420009613    │\n",
       "│ Train/KL                      │ 0.011542832478880882   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9953875541687012     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9953875541687012     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9953875541687012     │\n",
       "│ Train/PolicyRatio/Std         │ 0.014591381885111332   │\n",
       "│ Train/LR                      │ 2.6399999114801176e-05 │\n",
       "│ Train/PolicyStd               │ 0.1748393177986145     │\n",
       "│ TotalEnvSteps                 │ 933888.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018702160567045212  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.003184163011610508  │\n",
       "│ Value/Adv                     │ -0.03268910199403763   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015275731682777405   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0021247686818242073  │\n",
       "│ Value/reward                  │ 2.2452566623687744     │\n",
       "│ Time/Total                    │ 5954.14501953125       │\n",
       "│ Time/Rollout                  │ 10.815128326416016     │\n",
       "│ Time/Update                   │ 1.6916921138763428     │\n",
       "│ Time/Epoch                    │ 12.506864547729492     │\n",
       "│ Time/FPS                      │ 163.7500762939453      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.28229522705078      │\n",
       "│ Metrics/EpCost                │ 53.2599983215332       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 456.0                  │\n",
       "│ Train/Entropy                 │ -0.3258056342601776    │\n",
       "│ Train/KL                      │ 0.00894780270755291    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0013586282730103     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0013586282730103     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0013586282730103     │\n",
       "│ Train/PolicyRatio/Std         │ 0.014314199797809124   │\n",
       "│ Train/LR                      │ 2.5800000003073364e-05 │\n",
       "│ Train/PolicyStd               │ 0.17472900450229645    │\n",
       "│ TotalEnvSteps                 │ 935936.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015443893149495125  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.003258267417550087   │\n",
       "│ Value/Adv                     │ -0.013453597202897072  │\n",
       "│ Loss/Loss_reward_critic       │ 0.016031017526984215   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00075528584420681    │\n",
       "│ Value/reward                  │ 2.216960906982422      │\n",
       "│ Time/Total                    │ 5966.7421875           │\n",
       "│ Time/Rollout                  │ 10.83834171295166      │\n",
       "│ Time/Update                   │ 1.7441155910491943     │\n",
       "│ Time/Epoch                    │ 12.582500457763672     │\n",
       "│ Time/FPS                      │ 162.7657470703125      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.28229522705078      │\n",
       "│ Metrics/EpCost                │ 53.2599983215332       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 456.0                  │\n",
       "│ Train/Entropy                 │ -0.3258056342601776    │\n",
       "│ Train/KL                      │ 0.00894780270755291    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0013586282730103     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0013586282730103     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0013586282730103     │\n",
       "│ Train/PolicyRatio/Std         │ 0.014314199797809124   │\n",
       "│ Train/LR                      │ 2.5800000003073364e-05 │\n",
       "│ Train/PolicyStd               │ 0.17472900450229645    │\n",
       "│ TotalEnvSteps                 │ 935936.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015443893149495125  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.003258267417550087   │\n",
       "│ Value/Adv                     │ -0.013453597202897072  │\n",
       "│ Loss/Loss_reward_critic       │ 0.016031017526984215   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00075528584420681    │\n",
       "│ Value/reward                  │ 2.216960906982422      │\n",
       "│ Time/Total                    │ 5966.7421875           │\n",
       "│ Time/Rollout                  │ 10.83834171295166      │\n",
       "│ Time/Update                   │ 1.7441155910491943     │\n",
       "│ Time/Epoch                    │ 12.582500457763672     │\n",
       "│ Time/FPS                      │ 162.7657470703125      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.2828311920166        │\n",
       "│ Metrics/EpCost                │ 55.08000183105469       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 457.0                   │\n",
       "│ Train/Entropy                 │ -0.3273889124393463     │\n",
       "│ Train/KL                      │ 0.009417565539479256    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9973269701004028      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9973269701004028      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9973269701004028      │\n",
       "│ Train/PolicyRatio/Std         │ 0.01373195368796587     │\n",
       "│ Train/LR                      │ 2.5200000891345553e-05  │\n",
       "│ Train/PolicyStd               │ 0.1744472086429596      │\n",
       "│ TotalEnvSteps                 │ 937984.0                │\n",
       "│ Loss/Loss_pi                  │ -0.015911562368273735   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00046766921877861023 │\n",
       "│ Value/Adv                     │ 0.16966265439987183     │\n",
       "│ Loss/Loss_reward_critic       │ 0.01067750807851553     │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005353509448468685   │\n",
       "│ Value/reward                  │ 2.182603120803833       │\n",
       "│ Time/Total                    │ 5979.3681640625         │\n",
       "│ Time/Rollout                  │ 10.869539260864258      │\n",
       "│ Time/Update                   │ 1.7443056106567383      │\n",
       "│ Time/Epoch                    │ 12.613889694213867      │\n",
       "│ Time/FPS                      │ 162.3607177734375       │\n",
       "└───────────────────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.2828311920166        │\n",
       "│ Metrics/EpCost                │ 55.08000183105469       │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 457.0                   │\n",
       "│ Train/Entropy                 │ -0.3273889124393463     │\n",
       "│ Train/KL                      │ 0.009417565539479256    │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9973269701004028      │\n",
       "│ Train/PolicyRatio/Min         │ 0.9973269701004028      │\n",
       "│ Train/PolicyRatio/Max         │ 0.9973269701004028      │\n",
       "│ Train/PolicyRatio/Std         │ 0.01373195368796587     │\n",
       "│ Train/LR                      │ 2.5200000891345553e-05  │\n",
       "│ Train/PolicyStd               │ 0.1744472086429596      │\n",
       "│ TotalEnvSteps                 │ 937984.0                │\n",
       "│ Loss/Loss_pi                  │ -0.015911562368273735   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00046766921877861023 │\n",
       "│ Value/Adv                     │ 0.16966265439987183     │\n",
       "│ Loss/Loss_reward_critic       │ 0.01067750807851553     │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005353509448468685   │\n",
       "│ Value/reward                  │ 2.182603120803833       │\n",
       "│ Time/Total                    │ 5979.3681640625         │\n",
       "│ Time/Rollout                  │ 10.869539260864258      │\n",
       "│ Time/Update                   │ 1.7443056106567383      │\n",
       "│ Time/Epoch                    │ 12.613889694213867      │\n",
       "│ Time/FPS                      │ 162.3607177734375       │\n",
       "└───────────────────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.268102645874023     │\n",
       "│ Metrics/EpCost                │ 53.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 458.0                  │\n",
       "│ Train/Entropy                 │ -0.3284444212913513    │\n",
       "│ Train/KL                      │ 0.012030258774757385   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9949265718460083     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9949265718460083     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9949265718460083     │\n",
       "│ Train/PolicyRatio/Std         │ 0.015678897500038147   │\n",
       "│ Train/LR                      │ 2.4599999960628338e-05 │\n",
       "│ Train/PolicyStd               │ 0.1742618829011917     │\n",
       "│ TotalEnvSteps                 │ 940032.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018031155690550804  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002119593322277069  │\n",
       "│ Value/Adv                     │ 0.017725050449371338   │\n",
       "│ Loss/Loss_reward_critic       │ 0.017005369067192078   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006327860988676548   │\n",
       "│ Value/reward                  │ 2.2122206687927246     │\n",
       "│ Time/Total                    │ 5992.02099609375       │\n",
       "│ Time/Rollout                  │ 10.906188011169434     │\n",
       "│ Time/Update                   │ 1.735334873199463      │\n",
       "│ Time/Epoch                    │ 12.641572952270508     │\n",
       "│ Time/FPS                      │ 162.0051727294922      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.268102645874023     │\n",
       "│ Metrics/EpCost                │ 53.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 458.0                  │\n",
       "│ Train/Entropy                 │ -0.3284444212913513    │\n",
       "│ Train/KL                      │ 0.012030258774757385   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9949265718460083     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9949265718460083     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9949265718460083     │\n",
       "│ Train/PolicyRatio/Std         │ 0.015678897500038147   │\n",
       "│ Train/LR                      │ 2.4599999960628338e-05 │\n",
       "│ Train/PolicyStd               │ 0.1742618829011917     │\n",
       "│ TotalEnvSteps                 │ 940032.0               │\n",
       "│ Loss/Loss_pi                  │ -0.018031155690550804  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002119593322277069  │\n",
       "│ Value/Adv                     │ 0.017725050449371338   │\n",
       "│ Loss/Loss_reward_critic       │ 0.017005369067192078   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.006327860988676548   │\n",
       "│ Value/reward                  │ 2.2122206687927246     │\n",
       "│ Time/Total                    │ 5992.02099609375       │\n",
       "│ Time/Rollout                  │ 10.906188011169434     │\n",
       "│ Time/Update                   │ 1.735334873199463      │\n",
       "│ Time/Epoch                    │ 12.641572952270508     │\n",
       "│ Time/FPS                      │ 162.0051727294922      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.32663345336914      │\n",
       "│ Metrics/EpCost                │ 53.63999938964844      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 459.0                  │\n",
       "│ Train/Entropy                 │ -0.3291413187980652    │\n",
       "│ Train/KL                      │ 0.009106279350817204   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9958340525627136     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9958340525627136     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9958340525627136     │\n",
       "│ Train/PolicyRatio/Std         │ 0.014416886493563652   │\n",
       "│ Train/LR                      │ 2.4000000848900527e-05 │\n",
       "│ Train/PolicyStd               │ 0.17413707077503204    │\n",
       "│ TotalEnvSteps                 │ 942080.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015092037618160248  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0029391180723905563  │\n",
       "│ Value/Adv                     │ -0.10146667063236237   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01775043085217476    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0007450617849826813  │\n",
       "│ Value/reward                  │ 2.1748266220092773     │\n",
       "│ Time/Total                    │ 6004.60302734375       │\n",
       "│ Time/Rollout                  │ 10.845690727233887     │\n",
       "│ Time/Update                   │ 1.7221143245697021     │\n",
       "│ Time/Epoch                    │ 12.567850112915039     │\n",
       "│ Time/FPS                      │ 162.9554901123047      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.32663345336914      │\n",
       "│ Metrics/EpCost                │ 53.63999938964844      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 459.0                  │\n",
       "│ Train/Entropy                 │ -0.3291413187980652    │\n",
       "│ Train/KL                      │ 0.009106279350817204   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9958340525627136     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9958340525627136     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9958340525627136     │\n",
       "│ Train/PolicyRatio/Std         │ 0.014416886493563652   │\n",
       "│ Train/LR                      │ 2.4000000848900527e-05 │\n",
       "│ Train/PolicyStd               │ 0.17413707077503204    │\n",
       "│ TotalEnvSteps                 │ 942080.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015092037618160248  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0029391180723905563  │\n",
       "│ Value/Adv                     │ -0.10146667063236237   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01775043085217476    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0007450617849826813  │\n",
       "│ Value/reward                  │ 2.1748266220092773     │\n",
       "│ Time/Total                    │ 6004.60302734375       │\n",
       "│ Time/Rollout                  │ 10.845690727233887     │\n",
       "│ Time/Update                   │ 1.7221143245697021     │\n",
       "│ Time/Epoch                    │ 12.567850112915039     │\n",
       "│ Time/FPS                      │ 162.9554901123047      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 22.131210327148438     │\n",
       "│ Metrics/EpCost                │ 54.18000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 460.0                  │\n",
       "│ Train/Entropy                 │ -0.3297690749168396    │\n",
       "│ Train/KL                      │ 0.007901974022388458   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0018290281295776     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0018290281295776     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0018290281295776     │\n",
       "│ Train/PolicyRatio/Std         │ 0.013773402199149132   │\n",
       "│ Train/LR                      │ 2.3399999918183312e-05 │\n",
       "│ Train/PolicyStd               │ 0.174025297164917      │\n",
       "│ TotalEnvSteps                 │ 944128.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01647513546049595   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.001383097842335701  │\n",
       "│ Value/Adv                     │ 0.2933287024497986     │\n",
       "│ Loss/Loss_reward_critic       │ 0.014971494674682617   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0027789361774921417 │\n",
       "│ Value/reward                  │ 2.1860766410827637     │\n",
       "│ Time/Total                    │ 6017.19091796875       │\n",
       "│ Time/Rollout                  │ 10.869516372680664     │\n",
       "│ Time/Update                   │ 1.705448865890503      │\n",
       "│ Time/Epoch                    │ 12.575010299682617     │\n",
       "│ Time/FPS                      │ 162.86270141601562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 22.131210327148438     │\n",
       "│ Metrics/EpCost                │ 54.18000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 460.0                  │\n",
       "│ Train/Entropy                 │ -0.3297690749168396    │\n",
       "│ Train/KL                      │ 0.007901974022388458   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0018290281295776     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0018290281295776     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0018290281295776     │\n",
       "│ Train/PolicyRatio/Std         │ 0.013773402199149132   │\n",
       "│ Train/LR                      │ 2.3399999918183312e-05 │\n",
       "│ Train/PolicyStd               │ 0.174025297164917      │\n",
       "│ TotalEnvSteps                 │ 944128.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01647513546049595   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.001383097842335701  │\n",
       "│ Value/Adv                     │ 0.2933287024497986     │\n",
       "│ Loss/Loss_reward_critic       │ 0.014971494674682617   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0027789361774921417 │\n",
       "│ Value/reward                  │ 2.1860766410827637     │\n",
       "│ Time/Total                    │ 6017.19091796875       │\n",
       "│ Time/Rollout                  │ 10.869516372680664     │\n",
       "│ Time/Update                   │ 1.705448865890503      │\n",
       "│ Time/Epoch                    │ 12.575010299682617     │\n",
       "│ Time/FPS                      │ 162.86270141601562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 22.097288131713867    │\n",
       "│ Metrics/EpCost                │ 53.2400016784668      │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 461.0                 │\n",
       "│ Train/Entropy                 │ -0.3293948769569397   │\n",
       "│ Train/KL                      │ 0.008902407251298428  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0009076595306396    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0009076595306396    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0009076595306396    │\n",
       "│ Train/PolicyRatio/Std         │ 0.014026382938027382  │\n",
       "│ Train/LR                      │ 2.28000008064555e-05  │\n",
       "│ Train/PolicyStd               │ 0.17409396171569824   │\n",
       "│ TotalEnvSteps                 │ 946176.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01339474506676197  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0030803903937339783 │\n",
       "│ Value/Adv                     │ 0.026064105331897736  │\n",
       "│ Loss/Loss_reward_critic       │ 0.018091987818479538  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0031204931437969208 │\n",
       "│ Value/reward                  │ 2.2058637142181396    │\n",
       "│ Time/Total                    │ 6029.76025390625      │\n",
       "│ Time/Rollout                  │ 10.858443260192871    │\n",
       "│ Time/Update                   │ 1.6968352794647217    │\n",
       "│ Time/Epoch                    │ 12.555320739746094    │\n",
       "│ Time/FPS                      │ 163.11810302734375    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 22.097288131713867    │\n",
       "│ Metrics/EpCost                │ 53.2400016784668      │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 461.0                 │\n",
       "│ Train/Entropy                 │ -0.3293948769569397   │\n",
       "│ Train/KL                      │ 0.008902407251298428  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0009076595306396    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0009076595306396    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0009076595306396    │\n",
       "│ Train/PolicyRatio/Std         │ 0.014026382938027382  │\n",
       "│ Train/LR                      │ 2.28000008064555e-05  │\n",
       "│ Train/PolicyStd               │ 0.17409396171569824   │\n",
       "│ TotalEnvSteps                 │ 946176.0              │\n",
       "│ Loss/Loss_pi                  │ -0.01339474506676197  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0030803903937339783 │\n",
       "│ Value/Adv                     │ 0.026064105331897736  │\n",
       "│ Loss/Loss_reward_critic       │ 0.018091987818479538  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0031204931437969208 │\n",
       "│ Value/reward                  │ 2.2058637142181396    │\n",
       "│ Time/Total                    │ 6029.76025390625      │\n",
       "│ Time/Rollout                  │ 10.858443260192871    │\n",
       "│ Time/Update                   │ 1.6968352794647217    │\n",
       "│ Time/Epoch                    │ 12.555320739746094    │\n",
       "│ Time/FPS                      │ 163.11810302734375    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 22.069421768188477     │\n",
       "│ Metrics/EpCost                │ 53.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 462.0                  │\n",
       "│ Train/Entropy                 │ -0.3293485641479492    │\n",
       "│ Train/KL                      │ 0.008757649920880795   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9982768893241882     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9982768893241882     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9982768893241882     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01350223645567894    │\n",
       "│ Train/LR                      │ 2.2199999875738285e-05 │\n",
       "│ Train/PolicyStd               │ 0.17410291731357574    │\n",
       "│ TotalEnvSteps                 │ 948224.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01784519851207733   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004450453445315361  │\n",
       "│ Value/Adv                     │ 0.005427191033959389   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015216948464512825   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.002875039353966713  │\n",
       "│ Value/reward                  │ 2.190030336380005      │\n",
       "│ Time/Total                    │ 6042.32373046875       │\n",
       "│ Time/Rollout                  │ 10.835030555725098     │\n",
       "│ Time/Update                   │ 1.7167446613311768     │\n",
       "│ Time/Epoch                    │ 12.551819801330566     │\n",
       "│ Time/FPS                      │ 163.16360473632812     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 22.069421768188477     │\n",
       "│ Metrics/EpCost                │ 53.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 462.0                  │\n",
       "│ Train/Entropy                 │ -0.3293485641479492    │\n",
       "│ Train/KL                      │ 0.008757649920880795   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9982768893241882     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9982768893241882     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9982768893241882     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01350223645567894    │\n",
       "│ Train/LR                      │ 2.2199999875738285e-05 │\n",
       "│ Train/PolicyStd               │ 0.17410291731357574    │\n",
       "│ TotalEnvSteps                 │ 948224.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01784519851207733   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.004450453445315361  │\n",
       "│ Value/Adv                     │ 0.005427191033959389   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015216948464512825   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.002875039353966713  │\n",
       "│ Value/reward                  │ 2.190030336380005      │\n",
       "│ Time/Total                    │ 6042.32373046875       │\n",
       "│ Time/Rollout                  │ 10.835030555725098     │\n",
       "│ Time/Update                   │ 1.7167446613311768     │\n",
       "│ Time/Epoch                    │ 12.551819801330566     │\n",
       "│ Time/FPS                      │ 163.16360473632812     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.047189712524414     │\n",
       "│ Metrics/EpCost                │ 52.52000045776367      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 463.0                  │\n",
       "│ Train/Entropy                 │ -0.32930105924606323   │\n",
       "│ Train/KL                      │ 0.007576643954962492   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9984174966812134     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9984174966812134     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9984174966812134     │\n",
       "│ Train/PolicyRatio/Std         │ 0.013445022515952587   │\n",
       "│ Train/LR                      │ 2.1600000764010474e-05 │\n",
       "│ Train/PolicyStd               │ 0.17410865426063538    │\n",
       "│ TotalEnvSteps                 │ 950272.0               │\n",
       "│ Loss/Loss_pi                  │ -0.010022906586527824  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.007822291925549507   │\n",
       "│ Value/Adv                     │ 0.017431102693080902   │\n",
       "│ Loss/Loss_reward_critic       │ 0.019140880554914474   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0039239320904016495  │\n",
       "│ Value/reward                  │ 1.7935248613357544     │\n",
       "│ Time/Total                    │ 6054.81494140625       │\n",
       "│ Time/Rollout                  │ 10.77099609375         │\n",
       "│ Time/Update                   │ 1.7083120346069336     │\n",
       "│ Time/Epoch                    │ 12.479351043701172     │\n",
       "│ Time/FPS                      │ 164.11111450195312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.047189712524414     │\n",
       "│ Metrics/EpCost                │ 52.52000045776367      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 463.0                  │\n",
       "│ Train/Entropy                 │ -0.32930105924606323   │\n",
       "│ Train/KL                      │ 0.007576643954962492   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9984174966812134     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9984174966812134     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9984174966812134     │\n",
       "│ Train/PolicyRatio/Std         │ 0.013445022515952587   │\n",
       "│ Train/LR                      │ 2.1600000764010474e-05 │\n",
       "│ Train/PolicyStd               │ 0.17410865426063538    │\n",
       "│ TotalEnvSteps                 │ 950272.0               │\n",
       "│ Loss/Loss_pi                  │ -0.010022906586527824  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.007822291925549507   │\n",
       "│ Value/Adv                     │ 0.017431102693080902   │\n",
       "│ Loss/Loss_reward_critic       │ 0.019140880554914474   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0039239320904016495  │\n",
       "│ Value/reward                  │ 1.7935248613357544     │\n",
       "│ Time/Total                    │ 6054.81494140625       │\n",
       "│ Time/Rollout                  │ 10.77099609375         │\n",
       "│ Time/Update                   │ 1.7083120346069336     │\n",
       "│ Time/Epoch                    │ 12.479351043701172     │\n",
       "│ Time/FPS                      │ 164.11111450195312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.9444522857666       │\n",
       "│ Metrics/EpCost                │ 52.29999923706055      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 464.0                  │\n",
       "│ Train/Entropy                 │ -0.3292017877101898    │\n",
       "│ Train/KL                      │ 0.006894844584167004   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9995657205581665     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9995657205581665     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9995657205581665     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01258270163089037    │\n",
       "│ Train/LR                      │ 2.099999983329326e-05  │\n",
       "│ Train/PolicyStd               │ 0.1741272360086441     │\n",
       "│ TotalEnvSteps                 │ 952320.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015610319562256336  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.005587412975728512  │\n",
       "│ Value/Adv                     │ 0.00923449918627739    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017666097730398178   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0014747828245162964 │\n",
       "│ Value/reward                  │ 2.1074652671813965     │\n",
       "│ Time/Total                    │ 6067.4365234375        │\n",
       "│ Time/Rollout                  │ 10.884483337402344     │\n",
       "│ Time/Update                   │ 1.7247314453125        │\n",
       "│ Time/Epoch                    │ 12.609259605407715     │\n",
       "│ Time/FPS                      │ 162.4203338623047      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.9444522857666       │\n",
       "│ Metrics/EpCost                │ 52.29999923706055      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 464.0                  │\n",
       "│ Train/Entropy                 │ -0.3292017877101898    │\n",
       "│ Train/KL                      │ 0.006894844584167004   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9995657205581665     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9995657205581665     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9995657205581665     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01258270163089037    │\n",
       "│ Train/LR                      │ 2.099999983329326e-05  │\n",
       "│ Train/PolicyStd               │ 0.1741272360086441     │\n",
       "│ TotalEnvSteps                 │ 952320.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015610319562256336  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.005587412975728512  │\n",
       "│ Value/Adv                     │ 0.00923449918627739    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017666097730398178   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0014747828245162964 │\n",
       "│ Value/reward                  │ 2.1074652671813965     │\n",
       "│ Time/Total                    │ 6067.4365234375        │\n",
       "│ Time/Rollout                  │ 10.884483337402344     │\n",
       "│ Time/Update                   │ 1.7247314453125        │\n",
       "│ Time/Epoch                    │ 12.609259605407715     │\n",
       "│ Time/FPS                      │ 162.4203338623047      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.001327514648438     │\n",
       "│ Metrics/EpCost                │ 52.08000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 465.0                  │\n",
       "│ Train/Entropy                 │ -0.32926419377326965   │\n",
       "│ Train/KL                      │ 0.0074562677182257175  │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0000754594802856     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0000754594802856     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0000754594802856     │\n",
       "│ Train/PolicyRatio/Std         │ 0.011380625888705254   │\n",
       "│ Train/LR                      │ 2.0400000721565448e-05 │\n",
       "│ Train/PolicyStd               │ 0.17412060499191284    │\n",
       "│ TotalEnvSteps                 │ 954368.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013891112990677357  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0017192065715789795  │\n",
       "│ Value/Adv                     │ 0.10152529180049896    │\n",
       "│ Loss/Loss_reward_critic       │ 0.013889551162719727   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0037765465676784515 │\n",
       "│ Value/reward                  │ 2.2061638832092285     │\n",
       "│ Time/Total                    │ 6080.03271484375       │\n",
       "│ Time/Rollout                  │ 10.825974464416504     │\n",
       "│ Time/Update                   │ 1.7569849491119385     │\n",
       "│ Time/Epoch                    │ 12.58301067352295      │\n",
       "│ Time/FPS                      │ 162.7591552734375      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.001327514648438     │\n",
       "│ Metrics/EpCost                │ 52.08000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 465.0                  │\n",
       "│ Train/Entropy                 │ -0.32926419377326965   │\n",
       "│ Train/KL                      │ 0.0074562677182257175  │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0000754594802856     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0000754594802856     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0000754594802856     │\n",
       "│ Train/PolicyRatio/Std         │ 0.011380625888705254   │\n",
       "│ Train/LR                      │ 2.0400000721565448e-05 │\n",
       "│ Train/PolicyStd               │ 0.17412060499191284    │\n",
       "│ TotalEnvSteps                 │ 954368.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013891112990677357  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0017192065715789795  │\n",
       "│ Value/Adv                     │ 0.10152529180049896    │\n",
       "│ Loss/Loss_reward_critic       │ 0.013889551162719727   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0037765465676784515 │\n",
       "│ Value/reward                  │ 2.2061638832092285     │\n",
       "│ Time/Total                    │ 6080.03271484375       │\n",
       "│ Time/Rollout                  │ 10.825974464416504     │\n",
       "│ Time/Update                   │ 1.7569849491119385     │\n",
       "│ Time/Epoch                    │ 12.58301067352295      │\n",
       "│ Time/FPS                      │ 162.7591552734375      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.041519165039062     │\n",
       "│ Metrics/EpCost                │ 51.560001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 466.0                  │\n",
       "│ Train/Entropy                 │ -0.32944363355636597   │\n",
       "│ Train/KL                      │ 0.008647192269563675   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9989340901374817     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9989340901374817     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9989340901374817     │\n",
       "│ Train/PolicyRatio/Std         │ 0.013769927434623241   │\n",
       "│ Train/LR                      │ 1.9799999790848233e-05 │\n",
       "│ Train/PolicyStd               │ 0.1740914285182953     │\n",
       "│ TotalEnvSteps                 │ 956416.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013447755947709084  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00044335704296827316 │\n",
       "│ Value/Adv                     │ -0.0433129146695137    │\n",
       "│ Loss/Loss_reward_critic       │ 0.025102829560637474   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.011213278397917747   │\n",
       "│ Value/reward                  │ 2.231113910675049      │\n",
       "│ Time/Total                    │ 6092.625               │\n",
       "│ Time/Rollout                  │ 10.869426727294922     │\n",
       "│ Time/Update                   │ 1.7107553482055664     │\n",
       "│ Time/Epoch                    │ 12.580224990844727     │\n",
       "│ Time/FPS                      │ 162.79519653320312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.041519165039062     │\n",
       "│ Metrics/EpCost                │ 51.560001373291016     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 466.0                  │\n",
       "│ Train/Entropy                 │ -0.32944363355636597   │\n",
       "│ Train/KL                      │ 0.008647192269563675   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9989340901374817     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9989340901374817     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9989340901374817     │\n",
       "│ Train/PolicyRatio/Std         │ 0.013769927434623241   │\n",
       "│ Train/LR                      │ 1.9799999790848233e-05 │\n",
       "│ Train/PolicyStd               │ 0.1740914285182953     │\n",
       "│ TotalEnvSteps                 │ 956416.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013447755947709084  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00044335704296827316 │\n",
       "│ Value/Adv                     │ -0.0433129146695137    │\n",
       "│ Loss/Loss_reward_critic       │ 0.025102829560637474   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.011213278397917747   │\n",
       "│ Value/reward                  │ 2.231113910675049      │\n",
       "│ Time/Total                    │ 6092.625               │\n",
       "│ Time/Rollout                  │ 10.869426727294922     │\n",
       "│ Time/Update                   │ 1.7107553482055664     │\n",
       "│ Time/Epoch                    │ 12.580224990844727     │\n",
       "│ Time/FPS                      │ 162.79519653320312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.071331024169922    │\n",
       "│ Metrics/EpCost                │ 52.65999984741211     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 467.0                 │\n",
       "│ Train/Entropy                 │ -0.3298555016517639   │\n",
       "│ Train/KL                      │ 0.006366146728396416  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9995034337043762    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9995034337043762    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9995034337043762    │\n",
       "│ Train/PolicyRatio/Std         │ 0.011059710755944252  │\n",
       "│ Train/LR                      │ 1.920000067912042e-05 │\n",
       "│ Train/PolicyStd               │ 0.17402127385139465   │\n",
       "│ TotalEnvSteps                 │ 958464.0              │\n",
       "│ Loss/Loss_pi                  │ -0.010664200410246849 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0027835555374622345 │\n",
       "│ Value/Adv                     │ 0.05929170921444893   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01681322231888771   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.008289607241749763 │\n",
       "│ Value/reward                  │ 2.1686127185821533    │\n",
       "│ Time/Total                    │ 6105.2744140625       │\n",
       "│ Time/Rollout                  │ 10.89646053314209     │\n",
       "│ Time/Update                   │ 1.7414770126342773    │\n",
       "│ Time/Epoch                    │ 12.63798713684082     │\n",
       "│ Time/FPS                      │ 162.05113220214844    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.071331024169922    │\n",
       "│ Metrics/EpCost                │ 52.65999984741211     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 467.0                 │\n",
       "│ Train/Entropy                 │ -0.3298555016517639   │\n",
       "│ Train/KL                      │ 0.006366146728396416  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9995034337043762    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9995034337043762    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9995034337043762    │\n",
       "│ Train/PolicyRatio/Std         │ 0.011059710755944252  │\n",
       "│ Train/LR                      │ 1.920000067912042e-05 │\n",
       "│ Train/PolicyStd               │ 0.17402127385139465   │\n",
       "│ TotalEnvSteps                 │ 958464.0              │\n",
       "│ Loss/Loss_pi                  │ -0.010664200410246849 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0027835555374622345 │\n",
       "│ Value/Adv                     │ 0.05929170921444893   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01681322231888771   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.008289607241749763 │\n",
       "│ Value/reward                  │ 2.1686127185821533    │\n",
       "│ Time/Total                    │ 6105.2744140625       │\n",
       "│ Time/Rollout                  │ 10.89646053314209     │\n",
       "│ Time/Update                   │ 1.7414770126342773    │\n",
       "│ Time/Epoch                    │ 12.63798713684082     │\n",
       "│ Time/FPS                      │ 162.05113220214844    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.151813507080078     │\n",
       "│ Metrics/EpCost                │ 55.20000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 468.0                  │\n",
       "│ Train/Entropy                 │ -0.3302777111530304    │\n",
       "│ Train/KL                      │ 0.007093051448464394   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9998958706855774     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9998958706855774     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9998958706855774     │\n",
       "│ Train/PolicyRatio/Std         │ 0.011346765793859959   │\n",
       "│ Train/LR                      │ 1.8599999748403206e-05 │\n",
       "│ Train/PolicyStd               │ 0.17394718527793884    │\n",
       "│ TotalEnvSteps                 │ 960512.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012079608626663685  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0014154082164168358 │\n",
       "│ Value/Adv                     │ 0.09007716178894043    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02080157957971096    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00398835726082325    │\n",
       "│ Value/reward                  │ 2.1767072677612305     │\n",
       "│ Time/Total                    │ 6117.822265625         │\n",
       "│ Time/Rollout                  │ 10.827658653259277     │\n",
       "│ Time/Update                   │ 1.708521842956543      │\n",
       "│ Time/Epoch                    │ 12.536221504211426     │\n",
       "│ Time/FPS                      │ 163.3666229248047      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.151813507080078     │\n",
       "│ Metrics/EpCost                │ 55.20000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 468.0                  │\n",
       "│ Train/Entropy                 │ -0.3302777111530304    │\n",
       "│ Train/KL                      │ 0.007093051448464394   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9998958706855774     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9998958706855774     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9998958706855774     │\n",
       "│ Train/PolicyRatio/Std         │ 0.011346765793859959   │\n",
       "│ Train/LR                      │ 1.8599999748403206e-05 │\n",
       "│ Train/PolicyStd               │ 0.17394718527793884    │\n",
       "│ TotalEnvSteps                 │ 960512.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012079608626663685  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0014154082164168358 │\n",
       "│ Value/Adv                     │ 0.09007716178894043    │\n",
       "│ Loss/Loss_reward_critic       │ 0.02080157957971096    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00398835726082325    │\n",
       "│ Value/reward                  │ 2.1767072677612305     │\n",
       "│ Time/Total                    │ 6117.822265625         │\n",
       "│ Time/Rollout                  │ 10.827658653259277     │\n",
       "│ Time/Update                   │ 1.708521842956543      │\n",
       "│ Time/Epoch                    │ 12.536221504211426     │\n",
       "│ Time/FPS                      │ 163.3666229248047      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.1008358001709       │\n",
       "│ Metrics/EpCost                │ 57.040000915527344     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 469.0                  │\n",
       "│ Train/Entropy                 │ -0.3314823806285858    │\n",
       "│ Train/KL                      │ 0.006194363813847303   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0023958683013916     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0023958683013916     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0023958683013916     │\n",
       "│ Train/PolicyRatio/Std         │ 0.011589900590479374   │\n",
       "│ Train/LR                      │ 1.8000000636675395e-05 │\n",
       "│ Train/PolicyStd               │ 0.17373746633529663    │\n",
       "│ TotalEnvSteps                 │ 962560.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01244788896292448   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0003682803362607956 │\n",
       "│ Value/Adv                     │ -0.06457178294658661   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015423664823174477   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005377914756536484  │\n",
       "│ Value/reward                  │ 2.109116554260254      │\n",
       "│ Time/Total                    │ 6130.51953125          │\n",
       "│ Time/Rollout                  │ 10.944842338562012     │\n",
       "│ Time/Update                   │ 1.739396572113037      │\n",
       "│ Time/Epoch                    │ 12.684295654296875     │\n",
       "│ Time/FPS                      │ 161.45950317382812     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.1008358001709       │\n",
       "│ Metrics/EpCost                │ 57.040000915527344     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 469.0                  │\n",
       "│ Train/Entropy                 │ -0.3314823806285858    │\n",
       "│ Train/KL                      │ 0.006194363813847303   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0023958683013916     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0023958683013916     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0023958683013916     │\n",
       "│ Train/PolicyRatio/Std         │ 0.011589900590479374   │\n",
       "│ Train/LR                      │ 1.8000000636675395e-05 │\n",
       "│ Train/PolicyStd               │ 0.17373746633529663    │\n",
       "│ TotalEnvSteps                 │ 962560.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01244788896292448   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0003682803362607956 │\n",
       "│ Value/Adv                     │ -0.06457178294658661   │\n",
       "│ Loss/Loss_reward_critic       │ 0.015423664823174477   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.005377914756536484  │\n",
       "│ Value/reward                  │ 2.109116554260254      │\n",
       "│ Time/Total                    │ 6130.51953125          │\n",
       "│ Time/Rollout                  │ 10.944842338562012     │\n",
       "│ Time/Update                   │ 1.739396572113037      │\n",
       "│ Time/Epoch                    │ 12.684295654296875     │\n",
       "│ Time/FPS                      │ 161.45950317382812     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.257070541381836    │\n",
       "│ Metrics/EpCost                │ 59.0                  │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 470.0                 │\n",
       "│ Train/Entropy                 │ -0.3323785662651062   │\n",
       "│ Train/KL                      │ 0.008210617117583752  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9969018697738647    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9969018697738647    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9969018697738647    │\n",
       "│ Train/PolicyRatio/Std         │ 0.013843384571373463  │\n",
       "│ Train/LR                      │ 1.739999970595818e-05 │\n",
       "│ Train/PolicyStd               │ 0.1735820472240448    │\n",
       "│ TotalEnvSteps                 │ 964608.0              │\n",
       "│ Loss/Loss_pi                  │ -0.015011866576969624 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002563977614045143 │\n",
       "│ Value/Adv                     │ -0.14097252488136292  │\n",
       "│ Loss/Loss_reward_critic       │ 0.01946091279387474   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004037247970700264  │\n",
       "│ Value/reward                  │ 2.177333116531372     │\n",
       "│ Time/Total                    │ 6143.0537109375       │\n",
       "│ Time/Rollout                  │ 10.82422924041748     │\n",
       "│ Time/Update                   │ 1.696547031402588     │\n",
       "│ Time/Epoch                    │ 12.520820617675781    │\n",
       "│ Time/FPS                      │ 163.56756591796875    │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.257070541381836    │\n",
       "│ Metrics/EpCost                │ 59.0                  │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 470.0                 │\n",
       "│ Train/Entropy                 │ -0.3323785662651062   │\n",
       "│ Train/KL                      │ 0.008210617117583752  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9969018697738647    │\n",
       "│ Train/PolicyRatio/Min         │ 0.9969018697738647    │\n",
       "│ Train/PolicyRatio/Max         │ 0.9969018697738647    │\n",
       "│ Train/PolicyRatio/Std         │ 0.013843384571373463  │\n",
       "│ Train/LR                      │ 1.739999970595818e-05 │\n",
       "│ Train/PolicyStd               │ 0.1735820472240448    │\n",
       "│ TotalEnvSteps                 │ 964608.0              │\n",
       "│ Loss/Loss_pi                  │ -0.015011866576969624 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.002563977614045143 │\n",
       "│ Value/Adv                     │ -0.14097252488136292  │\n",
       "│ Loss/Loss_reward_critic       │ 0.01946091279387474   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004037247970700264  │\n",
       "│ Value/reward                  │ 2.177333116531372     │\n",
       "│ Time/Total                    │ 6143.0537109375       │\n",
       "│ Time/Rollout                  │ 10.82422924041748     │\n",
       "│ Time/Update                   │ 1.696547031402588     │\n",
       "│ Time/Epoch                    │ 12.520820617675781    │\n",
       "│ Time/FPS                      │ 163.56756591796875    │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.269882202148438     │\n",
       "│ Metrics/EpCost                │ 57.5                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 471.0                  │\n",
       "│ Train/Entropy                 │ -0.3330792486667633    │\n",
       "│ Train/KL                      │ 0.008013302460312843   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0004942417144775     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0004942417144775     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0004942417144775     │\n",
       "│ Train/PolicyRatio/Std         │ 0.012760664336383343   │\n",
       "│ Train/LR                      │ 1.680000059423037e-05  │\n",
       "│ Train/PolicyStd               │ 0.17345967888832092    │\n",
       "│ TotalEnvSteps                 │ 966656.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012964052148163319  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002047814428806305   │\n",
       "│ Value/Adv                     │ 0.11689382046461105    │\n",
       "│ Loss/Loss_reward_critic       │ 0.018059954047203064   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0014009587466716766 │\n",
       "│ Value/reward                  │ 2.216707706451416      │\n",
       "│ Time/Total                    │ 6155.60302734375       │\n",
       "│ Time/Rollout                  │ 10.84037971496582      │\n",
       "│ Time/Update                   │ 1.6955304145812988     │\n",
       "│ Time/Epoch                    │ 12.535951614379883     │\n",
       "│ Time/FPS                      │ 163.37013244628906     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.269882202148438     │\n",
       "│ Metrics/EpCost                │ 57.5                   │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 471.0                  │\n",
       "│ Train/Entropy                 │ -0.3330792486667633    │\n",
       "│ Train/KL                      │ 0.008013302460312843   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0004942417144775     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0004942417144775     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0004942417144775     │\n",
       "│ Train/PolicyRatio/Std         │ 0.012760664336383343   │\n",
       "│ Train/LR                      │ 1.680000059423037e-05  │\n",
       "│ Train/PolicyStd               │ 0.17345967888832092    │\n",
       "│ TotalEnvSteps                 │ 966656.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012964052148163319  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002047814428806305   │\n",
       "│ Value/Adv                     │ 0.11689382046461105    │\n",
       "│ Loss/Loss_reward_critic       │ 0.018059954047203064   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0014009587466716766 │\n",
       "│ Value/reward                  │ 2.216707706451416      │\n",
       "│ Time/Total                    │ 6155.60302734375       │\n",
       "│ Time/Rollout                  │ 10.84037971496582      │\n",
       "│ Time/Update                   │ 1.6955304145812988     │\n",
       "│ Time/Epoch                    │ 12.535951614379883     │\n",
       "│ Time/FPS                      │ 163.37013244628906     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.332521438598633     │\n",
       "│ Metrics/EpCost                │ 59.119998931884766     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 472.0                  │\n",
       "│ Train/Entropy                 │ -0.3338991105556488    │\n",
       "│ Train/KL                      │ 0.006345531437546015   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9995194673538208     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9995194673538208     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9995194673538208     │\n",
       "│ Train/PolicyRatio/Std         │ 0.011666945181787014   │\n",
       "│ Train/LR                      │ 1.6199999663513154e-05 │\n",
       "│ Train/PolicyStd               │ 0.1733180284500122     │\n",
       "│ TotalEnvSteps                 │ 968704.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012347517535090446  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0006165346130728722  │\n",
       "│ Value/Adv                     │ -0.11851577460765839   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01493229903280735    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.003127655014395714  │\n",
       "│ Value/reward                  │ 2.2260355949401855     │\n",
       "│ Time/Total                    │ 6168.177734375         │\n",
       "│ Time/Rollout                  │ 10.80975341796875      │\n",
       "│ Time/Update                   │ 1.7515618801116943     │\n",
       "│ Time/Epoch                    │ 12.561357498168945     │\n",
       "│ Time/FPS                      │ 163.0397186279297      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.332521438598633     │\n",
       "│ Metrics/EpCost                │ 59.119998931884766     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 472.0                  │\n",
       "│ Train/Entropy                 │ -0.3338991105556488    │\n",
       "│ Train/KL                      │ 0.006345531437546015   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9995194673538208     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9995194673538208     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9995194673538208     │\n",
       "│ Train/PolicyRatio/Std         │ 0.011666945181787014   │\n",
       "│ Train/LR                      │ 1.6199999663513154e-05 │\n",
       "│ Train/PolicyStd               │ 0.1733180284500122     │\n",
       "│ TotalEnvSteps                 │ 968704.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012347517535090446  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0006165346130728722  │\n",
       "│ Value/Adv                     │ -0.11851577460765839   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01493229903280735    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.003127655014395714  │\n",
       "│ Value/reward                  │ 2.2260355949401855     │\n",
       "│ Time/Total                    │ 6168.177734375         │\n",
       "│ Time/Rollout                  │ 10.80975341796875      │\n",
       "│ Time/Update                   │ 1.7515618801116943     │\n",
       "│ Time/Epoch                    │ 12.561357498168945     │\n",
       "│ Time/FPS                      │ 163.0397186279297      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.21895980834961      │\n",
       "│ Metrics/EpCost                │ 58.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 473.0                  │\n",
       "│ Train/Entropy                 │ -0.3345991373062134    │\n",
       "│ Train/KL                      │ 0.009870029985904694   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9957200884819031     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9957200884819031     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9957200884819031     │\n",
       "│ Train/PolicyRatio/Std         │ 0.013140331953763962   │\n",
       "│ Train/LR                      │ 1.5600000551785342e-05 │\n",
       "│ Train/PolicyStd               │ 0.17319820821285248    │\n",
       "│ TotalEnvSteps                 │ 970752.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015251574106514454  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0029040565714240074 │\n",
       "│ Value/Adv                     │ 0.21498464047908783    │\n",
       "│ Loss/Loss_reward_critic       │ 0.00983080267906189    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0051014963537454605 │\n",
       "│ Value/reward                  │ 2.0978541374206543     │\n",
       "│ Time/Total                    │ 6180.74169921875       │\n",
       "│ Time/Rollout                  │ 10.838057518005371     │\n",
       "│ Time/Update                   │ 1.7116854190826416     │\n",
       "│ Time/Epoch                    │ 12.549786567687988     │\n",
       "│ Time/FPS                      │ 163.19003295898438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.21895980834961      │\n",
       "│ Metrics/EpCost                │ 58.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 473.0                  │\n",
       "│ Train/Entropy                 │ -0.3345991373062134    │\n",
       "│ Train/KL                      │ 0.009870029985904694   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9957200884819031     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9957200884819031     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9957200884819031     │\n",
       "│ Train/PolicyRatio/Std         │ 0.013140331953763962   │\n",
       "│ Train/LR                      │ 1.5600000551785342e-05 │\n",
       "│ Train/PolicyStd               │ 0.17319820821285248    │\n",
       "│ TotalEnvSteps                 │ 970752.0               │\n",
       "│ Loss/Loss_pi                  │ -0.015251574106514454  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0029040565714240074 │\n",
       "│ Value/Adv                     │ 0.21498464047908783    │\n",
       "│ Loss/Loss_reward_critic       │ 0.00983080267906189    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0051014963537454605 │\n",
       "│ Value/reward                  │ 2.0978541374206543     │\n",
       "│ Time/Total                    │ 6180.74169921875       │\n",
       "│ Time/Rollout                  │ 10.838057518005371     │\n",
       "│ Time/Update                   │ 1.7116854190826416     │\n",
       "│ Time/Epoch                    │ 12.549786567687988     │\n",
       "│ Time/FPS                      │ 163.19003295898438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.18799591064453      │\n",
       "│ Metrics/EpCost                │ 59.099998474121094     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 474.0                  │\n",
       "│ Train/Entropy                 │ -0.33525094389915466   │\n",
       "│ Train/KL                      │ 0.007472050376236439   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9987956285476685     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9987956285476685     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9987956285476685     │\n",
       "│ Train/PolicyRatio/Std         │ 0.012918345630168915   │\n",
       "│ Train/LR                      │ 1.4999999621068127e-05 │\n",
       "│ Train/PolicyStd               │ 0.17308492958545685    │\n",
       "│ TotalEnvSteps                 │ 972800.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013232233934104443  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0020193401724100113  │\n",
       "│ Value/Adv                     │ 0.15367579460144043    │\n",
       "│ Loss/Loss_reward_critic       │ 0.014073586091399193   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004242783412337303   │\n",
       "│ Value/reward                  │ 2.1979424953460693     │\n",
       "│ Time/Total                    │ 6193.408203125         │\n",
       "│ Time/Rollout                  │ 10.913284301757812     │\n",
       "│ Time/Update                   │ 1.741715908050537      │\n",
       "│ Time/Epoch                    │ 12.65504264831543      │\n",
       "│ Time/FPS                      │ 161.83273315429688     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.18799591064453      │\n",
       "│ Metrics/EpCost                │ 59.099998474121094     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 474.0                  │\n",
       "│ Train/Entropy                 │ -0.33525094389915466   │\n",
       "│ Train/KL                      │ 0.007472050376236439   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9987956285476685     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9987956285476685     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9987956285476685     │\n",
       "│ Train/PolicyRatio/Std         │ 0.012918345630168915   │\n",
       "│ Train/LR                      │ 1.4999999621068127e-05 │\n",
       "│ Train/PolicyStd               │ 0.17308492958545685    │\n",
       "│ TotalEnvSteps                 │ 972800.0               │\n",
       "│ Loss/Loss_pi                  │ -0.013232233934104443  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0020193401724100113  │\n",
       "│ Value/Adv                     │ 0.15367579460144043    │\n",
       "│ Loss/Loss_reward_critic       │ 0.014073586091399193   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004242783412337303   │\n",
       "│ Value/reward                  │ 2.1979424953460693     │\n",
       "│ Time/Total                    │ 6193.408203125         │\n",
       "│ Time/Rollout                  │ 10.913284301757812     │\n",
       "│ Time/Update                   │ 1.741715908050537      │\n",
       "│ Time/Epoch                    │ 12.65504264831543      │\n",
       "│ Time/FPS                      │ 161.83273315429688     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.122835159301758     │\n",
       "│ Metrics/EpCost                │ 58.36000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 475.0                  │\n",
       "│ Train/Entropy                 │ -0.3355873227119446    │\n",
       "│ Train/KL                      │ 0.006542968098074198   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.998927116394043      │\n",
       "│ Train/PolicyRatio/Min         │ 0.998927116394043      │\n",
       "│ Train/PolicyRatio/Max         │ 0.998927116394043      │\n",
       "│ Train/PolicyRatio/Std         │ 0.011799989268183708   │\n",
       "│ Train/LR                      │ 1.4399999599845614e-05 │\n",
       "│ Train/PolicyStd               │ 0.17302682995796204    │\n",
       "│ TotalEnvSteps                 │ 974848.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012369414791464806  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.000862819142639637   │\n",
       "│ Value/Adv                     │ -0.16410420835018158   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01827104762196541    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0041974615305662155  │\n",
       "│ Value/reward                  │ 2.1637232303619385     │\n",
       "│ Time/Total                    │ 6206.021484375         │\n",
       "│ Time/Rollout                  │ 10.886655807495117     │\n",
       "│ Time/Update                   │ 1.7151391506195068     │\n",
       "│ Time/Epoch                    │ 12.601836204528809     │\n",
       "│ Time/FPS                      │ 162.51600646972656     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.122835159301758     │\n",
       "│ Metrics/EpCost                │ 58.36000061035156      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 475.0                  │\n",
       "│ Train/Entropy                 │ -0.3355873227119446    │\n",
       "│ Train/KL                      │ 0.006542968098074198   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.998927116394043      │\n",
       "│ Train/PolicyRatio/Min         │ 0.998927116394043      │\n",
       "│ Train/PolicyRatio/Max         │ 0.998927116394043      │\n",
       "│ Train/PolicyRatio/Std         │ 0.011799989268183708   │\n",
       "│ Train/LR                      │ 1.4399999599845614e-05 │\n",
       "│ Train/PolicyStd               │ 0.17302682995796204    │\n",
       "│ TotalEnvSteps                 │ 974848.0               │\n",
       "│ Loss/Loss_pi                  │ -0.012369414791464806  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.000862819142639637   │\n",
       "│ Value/Adv                     │ -0.16410420835018158   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01827104762196541    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0041974615305662155  │\n",
       "│ Value/reward                  │ 2.1637232303619385     │\n",
       "│ Time/Total                    │ 6206.021484375         │\n",
       "│ Time/Rollout                  │ 10.886655807495117     │\n",
       "│ Time/Update                   │ 1.7151391506195068     │\n",
       "│ Time/Epoch                    │ 12.601836204528809     │\n",
       "│ Time/FPS                      │ 162.51600646972656     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.1384334564209       │\n",
       "│ Metrics/EpCost                │ 58.540000915527344     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 476.0                  │\n",
       "│ Train/Entropy                 │ -0.3354463577270508    │\n",
       "│ Train/KL                      │ 0.0071906945668160915  │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0029466152191162     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0029466152191162     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0029466152191162     │\n",
       "│ Train/PolicyRatio/Std         │ 0.011800413951277733   │\n",
       "│ Train/LR                      │ 1.3799999578623101e-05 │\n",
       "│ Train/PolicyStd               │ 0.17305128276348114    │\n",
       "│ TotalEnvSteps                 │ 976896.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01282900758087635   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0004595927894115448 │\n",
       "│ Value/Adv                     │ 0.113062284886837      │\n",
       "│ Loss/Loss_reward_critic       │ 0.017509276047348976   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0007617715746164322 │\n",
       "│ Value/reward                  │ 2.177781343460083      │\n",
       "│ Time/Total                    │ 6218.68212890625       │\n",
       "│ Time/Rollout                  │ 10.903389930725098     │\n",
       "│ Time/Update                   │ 1.743774175643921      │\n",
       "│ Time/Epoch                    │ 12.647214889526367     │\n",
       "│ Time/FPS                      │ 161.93289184570312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.1384334564209       │\n",
       "│ Metrics/EpCost                │ 58.540000915527344     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 476.0                  │\n",
       "│ Train/Entropy                 │ -0.3354463577270508    │\n",
       "│ Train/KL                      │ 0.0071906945668160915  │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0029466152191162     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0029466152191162     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0029466152191162     │\n",
       "│ Train/PolicyRatio/Std         │ 0.011800413951277733   │\n",
       "│ Train/LR                      │ 1.3799999578623101e-05 │\n",
       "│ Train/PolicyStd               │ 0.17305128276348114    │\n",
       "│ TotalEnvSteps                 │ 976896.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01282900758087635   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0004595927894115448 │\n",
       "│ Value/Adv                     │ 0.113062284886837      │\n",
       "│ Loss/Loss_reward_critic       │ 0.017509276047348976   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0007617715746164322 │\n",
       "│ Value/reward                  │ 2.177781343460083      │\n",
       "│ Time/Total                    │ 6218.68212890625       │\n",
       "│ Time/Rollout                  │ 10.903389930725098     │\n",
       "│ Time/Update                   │ 1.743774175643921      │\n",
       "│ Time/Epoch                    │ 12.647214889526367     │\n",
       "│ Time/FPS                      │ 161.93289184570312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.176218032836914     │\n",
       "│ Metrics/EpCost                │ 60.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 477.0                  │\n",
       "│ Train/Entropy                 │ -0.3348695635795593    │\n",
       "│ Train/KL                      │ 0.007653581909835339   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9996222257614136     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9996222257614136     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9996222257614136     │\n",
       "│ Train/PolicyRatio/Std         │ 0.011065518483519554   │\n",
       "│ Train/LR                      │ 1.3199999557400588e-05 │\n",
       "│ Train/PolicyStd               │ 0.17315128445625305    │\n",
       "│ TotalEnvSteps                 │ 978944.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011625395156443119  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0012036124244332314  │\n",
       "│ Value/Adv                     │ 0.09017132222652435    │\n",
       "│ Loss/Loss_reward_critic       │ 0.023875396698713303   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0063661206513643265  │\n",
       "│ Value/reward                  │ 2.1705095767974854     │\n",
       "│ Time/Total                    │ 6231.19677734375       │\n",
       "│ Time/Rollout                  │ 10.802434921264648     │\n",
       "│ Time/Update                   │ 1.700242280960083      │\n",
       "│ Time/Epoch                    │ 12.502721786499023     │\n",
       "│ Time/FPS                      │ 163.80433654785156     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.176218032836914     │\n",
       "│ Metrics/EpCost                │ 60.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 477.0                  │\n",
       "│ Train/Entropy                 │ -0.3348695635795593    │\n",
       "│ Train/KL                      │ 0.007653581909835339   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9996222257614136     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9996222257614136     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9996222257614136     │\n",
       "│ Train/PolicyRatio/Std         │ 0.011065518483519554   │\n",
       "│ Train/LR                      │ 1.3199999557400588e-05 │\n",
       "│ Train/PolicyStd               │ 0.17315128445625305    │\n",
       "│ TotalEnvSteps                 │ 978944.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011625395156443119  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0012036124244332314  │\n",
       "│ Value/Adv                     │ 0.09017132222652435    │\n",
       "│ Loss/Loss_reward_critic       │ 0.023875396698713303   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0063661206513643265  │\n",
       "│ Value/reward                  │ 2.1705095767974854     │\n",
       "│ Time/Total                    │ 6231.19677734375       │\n",
       "│ Time/Rollout                  │ 10.802434921264648     │\n",
       "│ Time/Update                   │ 1.700242280960083      │\n",
       "│ Time/Epoch                    │ 12.502721786499023     │\n",
       "│ Time/FPS                      │ 163.80433654785156     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.234006881713867     │\n",
       "│ Metrics/EpCost                │ 62.02000045776367      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 478.0                  │\n",
       "│ Train/Entropy                 │ -0.33456072211265564   │\n",
       "│ Train/KL                      │ 0.005902639590203762   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9969482421875        │\n",
       "│ Train/PolicyRatio/Min         │ 0.9969482421875        │\n",
       "│ Train/PolicyRatio/Max         │ 0.9969482421875        │\n",
       "│ Train/PolicyRatio/Std         │ 0.011474049650132656   │\n",
       "│ Train/LR                      │ 1.2600000445672777e-05 │\n",
       "│ Train/PolicyStd               │ 0.17320601642131805    │\n",
       "│ TotalEnvSteps                 │ 980992.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011167151853442192  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00045824330300092697 │\n",
       "│ Value/Adv                     │ 0.07205251604318619    │\n",
       "│ Loss/Loss_reward_critic       │ 0.014546090736985207   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.009329305961728096  │\n",
       "│ Value/reward                  │ 2.198091506958008      │\n",
       "│ Time/Total                    │ 6243.77001953125       │\n",
       "│ Time/Rollout                  │ 10.85745620727539      │\n",
       "│ Time/Update                   │ 1.7028567790985107     │\n",
       "│ Time/Epoch                    │ 12.560356140136719     │\n",
       "│ Time/FPS                      │ 163.05271911621094     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.234006881713867     │\n",
       "│ Metrics/EpCost                │ 62.02000045776367      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 478.0                  │\n",
       "│ Train/Entropy                 │ -0.33456072211265564   │\n",
       "│ Train/KL                      │ 0.005902639590203762   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9969482421875        │\n",
       "│ Train/PolicyRatio/Min         │ 0.9969482421875        │\n",
       "│ Train/PolicyRatio/Max         │ 0.9969482421875        │\n",
       "│ Train/PolicyRatio/Std         │ 0.011474049650132656   │\n",
       "│ Train/LR                      │ 1.2600000445672777e-05 │\n",
       "│ Train/PolicyStd               │ 0.17320601642131805    │\n",
       "│ TotalEnvSteps                 │ 980992.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011167151853442192  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00045824330300092697 │\n",
       "│ Value/Adv                     │ 0.07205251604318619    │\n",
       "│ Loss/Loss_reward_critic       │ 0.014546090736985207   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.009329305961728096  │\n",
       "│ Value/reward                  │ 2.198091506958008      │\n",
       "│ Time/Total                    │ 6243.77001953125       │\n",
       "│ Time/Rollout                  │ 10.85745620727539      │\n",
       "│ Time/Update                   │ 1.7028567790985107     │\n",
       "│ Time/Epoch                    │ 12.560356140136719     │\n",
       "│ Time/FPS                      │ 163.05271911621094     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.210718154907227     │\n",
       "│ Metrics/EpCost                │ 61.81999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 479.0                  │\n",
       "│ Train/Entropy                 │ -0.33470726013183594   │\n",
       "│ Train/KL                      │ 0.006483816541731358   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9959079027175903     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9959079027175903     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9959079027175903     │\n",
       "│ Train/PolicyRatio/Std         │ 0.011624841019511223   │\n",
       "│ Train/LR                      │ 1.2000000424450263e-05 │\n",
       "│ Train/PolicyStd               │ 0.1731807142496109     │\n",
       "│ TotalEnvSteps                 │ 983040.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011049161665141582  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00011799018830060959 │\n",
       "│ Value/Adv                     │ -0.05219997838139534   │\n",
       "│ Loss/Loss_reward_critic       │ 0.017917530611157417   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0033714398741722107  │\n",
       "│ Value/reward                  │ 2.2009873390197754     │\n",
       "│ Time/Total                    │ 6256.2841796875        │\n",
       "│ Time/Rollout                  │ 10.799253463745117     │\n",
       "│ Time/Update                   │ 1.7032756805419922     │\n",
       "│ Time/Epoch                    │ 12.502588272094727     │\n",
       "│ Time/FPS                      │ 163.80609130859375     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.210718154907227     │\n",
       "│ Metrics/EpCost                │ 61.81999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 479.0                  │\n",
       "│ Train/Entropy                 │ -0.33470726013183594   │\n",
       "│ Train/KL                      │ 0.006483816541731358   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9959079027175903     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9959079027175903     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9959079027175903     │\n",
       "│ Train/PolicyRatio/Std         │ 0.011624841019511223   │\n",
       "│ Train/LR                      │ 1.2000000424450263e-05 │\n",
       "│ Train/PolicyStd               │ 0.1731807142496109     │\n",
       "│ TotalEnvSteps                 │ 983040.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011049161665141582  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00011799018830060959 │\n",
       "│ Value/Adv                     │ -0.05219997838139534   │\n",
       "│ Loss/Loss_reward_critic       │ 0.017917530611157417   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0033714398741722107  │\n",
       "│ Value/reward                  │ 2.2009873390197754     │\n",
       "│ Time/Total                    │ 6256.2841796875        │\n",
       "│ Time/Rollout                  │ 10.799253463745117     │\n",
       "│ Time/Update                   │ 1.7032756805419922     │\n",
       "│ Time/Epoch                    │ 12.502588272094727     │\n",
       "│ Time/FPS                      │ 163.80609130859375     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.224912643432617     │\n",
       "│ Metrics/EpCost                │ 60.70000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 480.0                  │\n",
       "│ Train/Entropy                 │ -0.334838330745697     │\n",
       "│ Train/KL                      │ 0.007615487091243267   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9979521036148071     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9979521036148071     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9979521036148071     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01180080883204937    │\n",
       "│ Train/LR                      │ 1.140000040322775e-05  │\n",
       "│ Train/PolicyStd               │ 0.17315781116485596    │\n",
       "│ TotalEnvSteps                 │ 985088.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014514630660414696  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0034654689952731133 │\n",
       "│ Value/Adv                     │ 0.03167027235031128    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01054545771330595    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.007372072897851467  │\n",
       "│ Value/reward                  │ 2.1491470336914062     │\n",
       "│ Time/Total                    │ 6268.875               │\n",
       "│ Time/Rollout                  │ 10.857654571533203     │\n",
       "│ Time/Update                   │ 1.7172322273254395     │\n",
       "│ Time/Epoch                    │ 12.574939727783203     │\n",
       "│ Time/FPS                      │ 162.86361694335938     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.224912643432617     │\n",
       "│ Metrics/EpCost                │ 60.70000076293945      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 480.0                  │\n",
       "│ Train/Entropy                 │ -0.334838330745697     │\n",
       "│ Train/KL                      │ 0.007615487091243267   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9979521036148071     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9979521036148071     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9979521036148071     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01180080883204937    │\n",
       "│ Train/LR                      │ 1.140000040322775e-05  │\n",
       "│ Train/PolicyStd               │ 0.17315781116485596    │\n",
       "│ TotalEnvSteps                 │ 985088.0               │\n",
       "│ Loss/Loss_pi                  │ -0.014514630660414696  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0034654689952731133 │\n",
       "│ Value/Adv                     │ 0.03167027235031128    │\n",
       "│ Loss/Loss_reward_critic       │ 0.01054545771330595    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.007372072897851467  │\n",
       "│ Value/reward                  │ 2.1491470336914062     │\n",
       "│ Time/Total                    │ 6268.875               │\n",
       "│ Time/Rollout                  │ 10.857654571533203     │\n",
       "│ Time/Update                   │ 1.7172322273254395     │\n",
       "│ Time/Epoch                    │ 12.574939727783203     │\n",
       "│ Time/FPS                      │ 162.86361694335938     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.319005966186523     │\n",
       "│ Metrics/EpCost                │ 59.63999938964844      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 481.0                  │\n",
       "│ Train/Entropy                 │ -0.3353126645088196    │\n",
       "│ Train/KL                      │ 0.0055254301987588406  │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9998607635498047     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9998607635498047     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9998607635498047     │\n",
       "│ Train/PolicyRatio/Std         │ 0.011154713109135628   │\n",
       "│ Train/LR                      │ 1.0800000382005237e-05 │\n",
       "│ Train/PolicyStd               │ 0.17307497560977936    │\n",
       "│ TotalEnvSteps                 │ 987136.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011517409235239029  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002997221425175667   │\n",
       "│ Value/Adv                     │ 0.21883095800876617    │\n",
       "│ Loss/Loss_reward_critic       │ 0.022482654079794884   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.011937196366488934   │\n",
       "│ Value/reward                  │ 2.1634461879730225     │\n",
       "│ Time/Total                    │ 6281.56005859375       │\n",
       "│ Time/Rollout                  │ 10.906135559082031     │\n",
       "│ Time/Update                   │ 1.767258644104004      │\n",
       "│ Time/Epoch                    │ 12.673439025878906     │\n",
       "│ Time/FPS                      │ 161.5978240966797      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.319005966186523     │\n",
       "│ Metrics/EpCost                │ 59.63999938964844      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 481.0                  │\n",
       "│ Train/Entropy                 │ -0.3353126645088196    │\n",
       "│ Train/KL                      │ 0.0055254301987588406  │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9998607635498047     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9998607635498047     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9998607635498047     │\n",
       "│ Train/PolicyRatio/Std         │ 0.011154713109135628   │\n",
       "│ Train/LR                      │ 1.0800000382005237e-05 │\n",
       "│ Train/PolicyStd               │ 0.17307497560977936    │\n",
       "│ TotalEnvSteps                 │ 987136.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011517409235239029  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.002997221425175667   │\n",
       "│ Value/Adv                     │ 0.21883095800876617    │\n",
       "│ Loss/Loss_reward_critic       │ 0.022482654079794884   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.011937196366488934   │\n",
       "│ Value/reward                  │ 2.1634461879730225     │\n",
       "│ Time/Total                    │ 6281.56005859375       │\n",
       "│ Time/Rollout                  │ 10.906135559082031     │\n",
       "│ Time/Update                   │ 1.767258644104004      │\n",
       "│ Time/Epoch                    │ 12.673439025878906     │\n",
       "│ Time/FPS                      │ 161.5978240966797      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.404394149780273     │\n",
       "│ Metrics/EpCost                │ 56.7400016784668       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 482.0                  │\n",
       "│ Train/Entropy                 │ -0.33567318320274353   │\n",
       "│ Train/KL                      │ 0.006861440371721983   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9995956420898438     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9995956420898438     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9995956420898438     │\n",
       "│ Train/PolicyRatio/Std         │ 0.010543609969317913   │\n",
       "│ Train/LR                      │ 1.0200000360782724e-05 │\n",
       "│ Train/PolicyStd               │ 0.17301300168037415    │\n",
       "│ TotalEnvSteps                 │ 989184.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01315848808735609   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0016410788521170616 │\n",
       "│ Value/Adv                     │ -0.09753107279539108   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018838578835129738   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.003644075244665146  │\n",
       "│ Value/reward                  │ 2.16762638092041       │\n",
       "│ Time/Total                    │ 6294.16064453125       │\n",
       "│ Time/Rollout                  │ 10.860502243041992     │\n",
       "│ Time/Update                   │ 1.7286057472229004     │\n",
       "│ Time/Epoch                    │ 12.589150428771973     │\n",
       "│ Time/FPS                      │ 162.67977905273438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.404394149780273     │\n",
       "│ Metrics/EpCost                │ 56.7400016784668       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 482.0                  │\n",
       "│ Train/Entropy                 │ -0.33567318320274353   │\n",
       "│ Train/KL                      │ 0.006861440371721983   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9995956420898438     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9995956420898438     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9995956420898438     │\n",
       "│ Train/PolicyRatio/Std         │ 0.010543609969317913   │\n",
       "│ Train/LR                      │ 1.0200000360782724e-05 │\n",
       "│ Train/PolicyStd               │ 0.17301300168037415    │\n",
       "│ TotalEnvSteps                 │ 989184.0               │\n",
       "│ Loss/Loss_pi                  │ -0.01315848808735609   │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0016410788521170616 │\n",
       "│ Value/Adv                     │ -0.09753107279539108   │\n",
       "│ Loss/Loss_reward_critic       │ 0.018838578835129738   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.003644075244665146  │\n",
       "│ Value/reward                  │ 2.16762638092041       │\n",
       "│ Time/Total                    │ 6294.16064453125       │\n",
       "│ Time/Rollout                  │ 10.860502243041992     │\n",
       "│ Time/Update                   │ 1.7286057472229004     │\n",
       "│ Time/Epoch                    │ 12.589150428771973     │\n",
       "│ Time/FPS                      │ 162.67977905273438     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.37899398803711     │\n",
       "│ Metrics/EpCost                │ 57.86000061035156     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 483.0                 │\n",
       "│ Train/Entropy                 │ -0.3358037769794464   │\n",
       "│ Train/KL                      │ 0.00653881998732686   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0007154941558838    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0007154941558838    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0007154941558838    │\n",
       "│ Train/PolicyRatio/Std         │ 0.010812526568770409  │\n",
       "│ Train/LR                      │ 9.60000033956021e-06  │\n",
       "│ Train/PolicyStd               │ 0.17298994958400726   │\n",
       "│ TotalEnvSteps                 │ 991232.0              │\n",
       "│ Loss/Loss_pi                  │ -0.012021278962492943 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0011372091248631477 │\n",
       "│ Value/Adv                     │ 0.10243886709213257   │\n",
       "│ Loss/Loss_reward_critic       │ 0.019325781613588333  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0004872027784585953 │\n",
       "│ Value/reward                  │ 2.2133162021636963    │\n",
       "│ Time/Total                    │ 6306.8056640625       │\n",
       "│ Time/Rollout                  │ 10.880472183227539    │\n",
       "│ Time/Update                   │ 1.7528021335601807    │\n",
       "│ Time/Epoch                    │ 12.633322715759277    │\n",
       "│ Time/FPS                      │ 162.1109619140625     │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.37899398803711     │\n",
       "│ Metrics/EpCost                │ 57.86000061035156     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 483.0                 │\n",
       "│ Train/Entropy                 │ -0.3358037769794464   │\n",
       "│ Train/KL                      │ 0.00653881998732686   │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0007154941558838    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0007154941558838    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0007154941558838    │\n",
       "│ Train/PolicyRatio/Std         │ 0.010812526568770409  │\n",
       "│ Train/LR                      │ 9.60000033956021e-06  │\n",
       "│ Train/PolicyStd               │ 0.17298994958400726   │\n",
       "│ TotalEnvSteps                 │ 991232.0              │\n",
       "│ Loss/Loss_pi                  │ -0.012021278962492943 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0011372091248631477 │\n",
       "│ Value/Adv                     │ 0.10243886709213257   │\n",
       "│ Loss/Loss_reward_critic       │ 0.019325781613588333  │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0004872027784585953 │\n",
       "│ Value/reward                  │ 2.2133162021636963    │\n",
       "│ Time/Total                    │ 6306.8056640625       │\n",
       "│ Time/Rollout                  │ 10.880472183227539    │\n",
       "│ Time/Update                   │ 1.7528021335601807    │\n",
       "│ Time/Epoch                    │ 12.633322715759277    │\n",
       "│ Time/FPS                      │ 162.1109619140625     │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.284578323364258     │\n",
       "│ Metrics/EpCost                │ 58.7400016784668       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 484.0                  │\n",
       "│ Train/Entropy                 │ -0.3359642028808594    │\n",
       "│ Train/KL                      │ 0.0058052921667695045  │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0011471509933472     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0011471509933472     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0011471509933472     │\n",
       "│ Train/PolicyRatio/Std         │ 0.010810280218720436   │\n",
       "│ Train/LR                      │ 9.000000318337698e-06  │\n",
       "│ Train/PolicyStd               │ 0.17296145856380463    │\n",
       "│ TotalEnvSteps                 │ 993280.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011369352228939533  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0006519267335534096  │\n",
       "│ Value/Adv                     │ -0.0021071135997772217 │\n",
       "│ Loss/Loss_reward_critic       │ 0.014439391903579235   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.004886389710009098  │\n",
       "│ Value/reward                  │ 2.1418511867523193     │\n",
       "│ Time/Total                    │ 6319.384765625         │\n",
       "│ Time/Rollout                  │ 10.82081127166748      │\n",
       "│ Time/Update                   │ 1.7468252182006836     │\n",
       "│ Time/Epoch                    │ 12.567682266235352     │\n",
       "│ Time/FPS                      │ 162.95767211914062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.284578323364258     │\n",
       "│ Metrics/EpCost                │ 58.7400016784668       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 484.0                  │\n",
       "│ Train/Entropy                 │ -0.3359642028808594    │\n",
       "│ Train/KL                      │ 0.0058052921667695045  │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0011471509933472     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0011471509933472     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0011471509933472     │\n",
       "│ Train/PolicyRatio/Std         │ 0.010810280218720436   │\n",
       "│ Train/LR                      │ 9.000000318337698e-06  │\n",
       "│ Train/PolicyStd               │ 0.17296145856380463    │\n",
       "│ TotalEnvSteps                 │ 993280.0               │\n",
       "│ Loss/Loss_pi                  │ -0.011369352228939533  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0006519267335534096  │\n",
       "│ Value/Adv                     │ -0.0021071135997772217 │\n",
       "│ Loss/Loss_reward_critic       │ 0.014439391903579235   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.004886389710009098  │\n",
       "│ Value/reward                  │ 2.1418511867523193     │\n",
       "│ Time/Total                    │ 6319.384765625         │\n",
       "│ Time/Rollout                  │ 10.82081127166748      │\n",
       "│ Time/Update                   │ 1.7468252182006836     │\n",
       "│ Time/Epoch                    │ 12.567682266235352     │\n",
       "│ Time/FPS                      │ 162.95767211914062     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.1900691986084      │\n",
       "│ Metrics/EpCost                │ 58.15999984741211     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 485.0                 │\n",
       "│ Train/Entropy                 │ -0.3359553813934326   │\n",
       "│ Train/KL                      │ 0.003704283619299531  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0009069442749023    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0009069442749023    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0009069442749023    │\n",
       "│ Train/PolicyRatio/Std         │ 0.00843458529561758   │\n",
       "│ Train/LR                      │ 8.400000297115184e-06 │\n",
       "│ Train/PolicyStd               │ 0.17296381294727325   │\n",
       "│ TotalEnvSteps                 │ 995328.0              │\n",
       "│ Loss/Loss_pi                  │ -0.006979844532907009 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004389507696032524  │\n",
       "│ Value/Adv                     │ 0.08617181330919266   │\n",
       "│ Loss/Loss_reward_critic       │ 0.013411964289844036  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.001027427613735199 │\n",
       "│ Value/reward                  │ 2.140671730041504     │\n",
       "│ Time/Total                    │ 6331.93994140625      │\n",
       "│ Time/Rollout                  │ 10.82231616973877     │\n",
       "│ Time/Update                   │ 1.72119140625         │\n",
       "│ Time/Epoch                    │ 12.543558120727539    │\n",
       "│ Time/FPS                      │ 163.2710723876953     │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.1900691986084      │\n",
       "│ Metrics/EpCost                │ 58.15999984741211     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 485.0                 │\n",
       "│ Train/Entropy                 │ -0.3359553813934326   │\n",
       "│ Train/KL                      │ 0.003704283619299531  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0009069442749023    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0009069442749023    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0009069442749023    │\n",
       "│ Train/PolicyRatio/Std         │ 0.00843458529561758   │\n",
       "│ Train/LR                      │ 8.400000297115184e-06 │\n",
       "│ Train/PolicyStd               │ 0.17296381294727325   │\n",
       "│ TotalEnvSteps                 │ 995328.0              │\n",
       "│ Loss/Loss_pi                  │ -0.006979844532907009 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.004389507696032524  │\n",
       "│ Value/Adv                     │ 0.08617181330919266   │\n",
       "│ Loss/Loss_reward_critic       │ 0.013411964289844036  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.001027427613735199 │\n",
       "│ Value/reward                  │ 2.140671730041504     │\n",
       "│ Time/Total                    │ 6331.93994140625      │\n",
       "│ Time/Rollout                  │ 10.82231616973877     │\n",
       "│ Time/Update                   │ 1.72119140625         │\n",
       "│ Time/Epoch                    │ 12.543558120727539    │\n",
       "│ Time/FPS                      │ 163.2710723876953     │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.929298400878906     │\n",
       "│ Metrics/EpCost                │ 57.619998931884766     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 486.0                  │\n",
       "│ Train/Entropy                 │ -0.3363182544708252    │\n",
       "│ Train/KL                      │ 0.0049021258018910885  │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0039923191070557     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0039923191070557     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0039923191070557     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01043787132948637    │\n",
       "│ Train/LR                      │ 7.800000275892671e-06  │\n",
       "│ Train/PolicyStd               │ 0.17290127277374268    │\n",
       "│ TotalEnvSteps                 │ 997376.0               │\n",
       "│ Loss/Loss_pi                  │ -0.007653283886611462  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0006734393537044525 │\n",
       "│ Value/Adv                     │ -0.17799140512943268   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01084051188081503    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.002571452409029007  │\n",
       "│ Value/reward                  │ 2.056377649307251      │\n",
       "│ Time/Total                    │ 6344.5087890625        │\n",
       "│ Time/Rollout                  │ 10.85151481628418      │\n",
       "│ Time/Update                   │ 1.7047905921936035     │\n",
       "│ Time/Epoch                    │ 12.556350708007812     │\n",
       "│ Time/FPS                      │ 163.10472106933594     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.929298400878906     │\n",
       "│ Metrics/EpCost                │ 57.619998931884766     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 486.0                  │\n",
       "│ Train/Entropy                 │ -0.3363182544708252    │\n",
       "│ Train/KL                      │ 0.0049021258018910885  │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0039923191070557     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0039923191070557     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0039923191070557     │\n",
       "│ Train/PolicyRatio/Std         │ 0.01043787132948637    │\n",
       "│ Train/LR                      │ 7.800000275892671e-06  │\n",
       "│ Train/PolicyStd               │ 0.17290127277374268    │\n",
       "│ TotalEnvSteps                 │ 997376.0               │\n",
       "│ Loss/Loss_pi                  │ -0.007653283886611462  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0006734393537044525 │\n",
       "│ Value/Adv                     │ -0.17799140512943268   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01084051188081503    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.002571452409029007  │\n",
       "│ Value/reward                  │ 2.056377649307251      │\n",
       "│ Time/Total                    │ 6344.5087890625        │\n",
       "│ Time/Rollout                  │ 10.85151481628418      │\n",
       "│ Time/Update                   │ 1.7047905921936035     │\n",
       "│ Time/Epoch                    │ 12.556350708007812     │\n",
       "│ Time/FPS                      │ 163.10472106933594     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.937511444091797     │\n",
       "│ Metrics/EpCost                │ 57.68000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 487.0                  │\n",
       "│ Train/Entropy                 │ -0.33669954538345337   │\n",
       "│ Train/KL                      │ 0.004069531336426735   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.001312017440796      │\n",
       "│ Train/PolicyRatio/Min         │ 1.001312017440796      │\n",
       "│ Train/PolicyRatio/Max         │ 1.001312017440796      │\n",
       "│ Train/PolicyRatio/Std         │ 0.009369934909045696   │\n",
       "│ Train/LR                      │ 7.199999799922807e-06  │\n",
       "│ Train/PolicyStd               │ 0.17283490300178528    │\n",
       "│ TotalEnvSteps                 │ 999424.0               │\n",
       "│ Loss/Loss_pi                  │ -0.008696479722857475  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0010431958362460136 │\n",
       "│ Value/Adv                     │ 0.11049659550189972    │\n",
       "│ Loss/Loss_reward_critic       │ 0.018353702500462532   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.007513190619647503   │\n",
       "│ Value/reward                  │ 2.120832681655884      │\n",
       "│ Time/Total                    │ 6357.16650390625       │\n",
       "│ Time/Rollout                  │ 10.862464904785156     │\n",
       "│ Time/Update                   │ 1.784271001815796      │\n",
       "│ Time/Epoch                    │ 12.646788597106934     │\n",
       "│ Time/FPS                      │ 161.9383544921875      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.937511444091797     │\n",
       "│ Metrics/EpCost                │ 57.68000030517578      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 487.0                  │\n",
       "│ Train/Entropy                 │ -0.33669954538345337   │\n",
       "│ Train/KL                      │ 0.004069531336426735   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.001312017440796      │\n",
       "│ Train/PolicyRatio/Min         │ 1.001312017440796      │\n",
       "│ Train/PolicyRatio/Max         │ 1.001312017440796      │\n",
       "│ Train/PolicyRatio/Std         │ 0.009369934909045696   │\n",
       "│ Train/LR                      │ 7.199999799922807e-06  │\n",
       "│ Train/PolicyStd               │ 0.17283490300178528    │\n",
       "│ TotalEnvSteps                 │ 999424.0               │\n",
       "│ Loss/Loss_pi                  │ -0.008696479722857475  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0010431958362460136 │\n",
       "│ Value/Adv                     │ 0.11049659550189972    │\n",
       "│ Loss/Loss_reward_critic       │ 0.018353702500462532   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.007513190619647503   │\n",
       "│ Value/reward                  │ 2.120832681655884      │\n",
       "│ Time/Total                    │ 6357.16650390625       │\n",
       "│ Time/Rollout                  │ 10.862464904785156     │\n",
       "│ Time/Update                   │ 1.784271001815796      │\n",
       "│ Time/Epoch                    │ 12.646788597106934     │\n",
       "│ Time/FPS                      │ 161.9383544921875      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 22.03609848022461      │\n",
       "│ Metrics/EpCost                │ 59.599998474121094     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 488.0                  │\n",
       "│ Train/Entropy                 │ -0.3367692828178406    │\n",
       "│ Train/KL                      │ 0.00394245283678174    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9994398355484009     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9994398355484009     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9994398355484009     │\n",
       "│ Train/PolicyRatio/Std         │ 0.008555755950510502   │\n",
       "│ Train/LR                      │ 6.599999778700294e-06  │\n",
       "│ Train/PolicyStd               │ 0.17282260954380035    │\n",
       "│ TotalEnvSteps                 │ 1001472.0              │\n",
       "│ Loss/Loss_pi                  │ -0.008429531008005142  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00026694871485233307 │\n",
       "│ Value/Adv                     │ 0.2153860330581665     │\n",
       "│ Loss/Loss_reward_critic       │ 0.02279738523066044    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0044436827301979065  │\n",
       "│ Value/reward                  │ 2.124608039855957      │\n",
       "│ Time/Total                    │ 6369.76708984375       │\n",
       "│ Time/Rollout                  │ 10.87678337097168      │\n",
       "│ Time/Update                   │ 1.7102413177490234     │\n",
       "│ Time/Epoch                    │ 12.587067604064941     │\n",
       "│ Time/FPS                      │ 162.70668029785156     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 22.03609848022461      │\n",
       "│ Metrics/EpCost                │ 59.599998474121094     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 488.0                  │\n",
       "│ Train/Entropy                 │ -0.3367692828178406    │\n",
       "│ Train/KL                      │ 0.00394245283678174    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9994398355484009     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9994398355484009     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9994398355484009     │\n",
       "│ Train/PolicyRatio/Std         │ 0.008555755950510502   │\n",
       "│ Train/LR                      │ 6.599999778700294e-06  │\n",
       "│ Train/PolicyStd               │ 0.17282260954380035    │\n",
       "│ TotalEnvSteps                 │ 1001472.0              │\n",
       "│ Loss/Loss_pi                  │ -0.008429531008005142  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00026694871485233307 │\n",
       "│ Value/Adv                     │ 0.2153860330581665     │\n",
       "│ Loss/Loss_reward_critic       │ 0.02279738523066044    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0044436827301979065  │\n",
       "│ Value/reward                  │ 2.124608039855957      │\n",
       "│ Time/Total                    │ 6369.76708984375       │\n",
       "│ Time/Rollout                  │ 10.87678337097168      │\n",
       "│ Time/Update                   │ 1.7102413177490234     │\n",
       "│ Time/Epoch                    │ 12.587067604064941     │\n",
       "│ Time/FPS                      │ 162.70668029785156     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 22.136070251464844     │\n",
       "│ Metrics/EpCost                │ 59.119998931884766     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 489.0                  │\n",
       "│ Train/Entropy                 │ -0.33673229813575745   │\n",
       "│ Train/KL                      │ 0.004617264959961176   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0008894205093384     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0008894205093384     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0008894205093384     │\n",
       "│ Train/PolicyRatio/Std         │ 0.008205177262425423   │\n",
       "│ Train/LR                      │ 6.000000212225132e-06  │\n",
       "│ Train/PolicyStd               │ 0.17282834649085999    │\n",
       "│ TotalEnvSteps                 │ 1003520.0              │\n",
       "│ Loss/Loss_pi                  │ -0.009863531216979027  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0014340002089738846 │\n",
       "│ Value/Adv                     │ -0.20505674183368683   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01607699692249298    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.006720388308167458  │\n",
       "│ Value/reward                  │ 2.235171318054199      │\n",
       "│ Time/Total                    │ 6382.37451171875       │\n",
       "│ Time/Rollout                  │ 10.879633903503418     │\n",
       "│ Time/Update                   │ 1.715825080871582      │\n",
       "│ Time/Epoch                    │ 12.59552001953125      │\n",
       "│ Time/FPS                      │ 162.59750366210938     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 22.136070251464844     │\n",
       "│ Metrics/EpCost                │ 59.119998931884766     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 489.0                  │\n",
       "│ Train/Entropy                 │ -0.33673229813575745   │\n",
       "│ Train/KL                      │ 0.004617264959961176   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0008894205093384     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0008894205093384     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0008894205093384     │\n",
       "│ Train/PolicyRatio/Std         │ 0.008205177262425423   │\n",
       "│ Train/LR                      │ 6.000000212225132e-06  │\n",
       "│ Train/PolicyStd               │ 0.17282834649085999    │\n",
       "│ TotalEnvSteps                 │ 1003520.0              │\n",
       "│ Loss/Loss_pi                  │ -0.009863531216979027  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0014340002089738846 │\n",
       "│ Value/Adv                     │ -0.20505674183368683   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01607699692249298    │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.006720388308167458  │\n",
       "│ Value/reward                  │ 2.235171318054199      │\n",
       "│ Time/Total                    │ 6382.37451171875       │\n",
       "│ Time/Rollout                  │ 10.879633903503418     │\n",
       "│ Time/Update                   │ 1.715825080871582      │\n",
       "│ Time/Epoch                    │ 12.59552001953125      │\n",
       "│ Time/FPS                      │ 162.59750366210938     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 22.076465606689453     │\n",
       "│ Metrics/EpCost                │ 59.119998931884766     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 490.0                  │\n",
       "│ Train/Entropy                 │ -0.3369489312171936    │\n",
       "│ Train/KL                      │ 0.0049954624846577644  │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0025484561920166     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0025484561920166     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0025484561920166     │\n",
       "│ Train/PolicyRatio/Std         │ 0.009138964116573334   │\n",
       "│ Train/LR                      │ 5.4000001910026185e-06 │\n",
       "│ Train/PolicyStd               │ 0.17279092967510223    │\n",
       "│ TotalEnvSteps                 │ 1005568.0              │\n",
       "│ Loss/Loss_pi                  │ -0.007421121001243591  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0024424102157354355  │\n",
       "│ Value/Adv                     │ -0.03647494688630104   │\n",
       "│ Loss/Loss_reward_critic       │ 0.013578534126281738   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0024984627962112427 │\n",
       "│ Value/reward                  │ 2.184898853302002      │\n",
       "│ Time/Total                    │ 6394.9658203125        │\n",
       "│ Time/Rollout                  │ 10.8285493850708       │\n",
       "│ Time/Update                   │ 1.7486257553100586     │\n",
       "│ Time/Epoch                    │ 12.577219009399414     │\n",
       "│ Time/FPS                      │ 162.83409118652344     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 22.076465606689453     │\n",
       "│ Metrics/EpCost                │ 59.119998931884766     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 490.0                  │\n",
       "│ Train/Entropy                 │ -0.3369489312171936    │\n",
       "│ Train/KL                      │ 0.0049954624846577644  │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0025484561920166     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0025484561920166     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0025484561920166     │\n",
       "│ Train/PolicyRatio/Std         │ 0.009138964116573334   │\n",
       "│ Train/LR                      │ 5.4000001910026185e-06 │\n",
       "│ Train/PolicyStd               │ 0.17279092967510223    │\n",
       "│ TotalEnvSteps                 │ 1005568.0              │\n",
       "│ Loss/Loss_pi                  │ -0.007421121001243591  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0024424102157354355  │\n",
       "│ Value/Adv                     │ -0.03647494688630104   │\n",
       "│ Loss/Loss_reward_critic       │ 0.013578534126281738   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.0024984627962112427 │\n",
       "│ Value/reward                  │ 2.184898853302002      │\n",
       "│ Time/Total                    │ 6394.9658203125        │\n",
       "│ Time/Rollout                  │ 10.8285493850708       │\n",
       "│ Time/Update                   │ 1.7486257553100586     │\n",
       "│ Time/Epoch                    │ 12.577219009399414     │\n",
       "│ Time/FPS                      │ 162.83409118652344     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.434619903564453     │\n",
       "│ Metrics/EpCost                │ 58.7599983215332       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 491.0                  │\n",
       "│ Train/Entropy                 │ -0.33715200424194336   │\n",
       "│ Train/KL                      │ 0.005400057416409254   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0003329515457153     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0003329515457153     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0003329515457153     │\n",
       "│ Train/PolicyRatio/Std         │ 0.011096790432929993   │\n",
       "│ Train/LR                      │ 4.800000169780105e-06  │\n",
       "│ Train/PolicyStd               │ 0.1727568805217743     │\n",
       "│ TotalEnvSteps                 │ 1007616.0              │\n",
       "│ Loss/Loss_pi                  │ -0.008175287395715714  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0007541663944721222 │\n",
       "│ Value/Adv                     │ -0.12506383657455444   │\n",
       "│ Loss/Loss_reward_critic       │ 0.017255563288927078   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00367702916264534    │\n",
       "│ Value/reward                  │ 1.926735758781433      │\n",
       "│ Time/Total                    │ 6407.56689453125       │\n",
       "│ Time/Rollout                  │ 10.870346069335938     │\n",
       "│ Time/Update                   │ 1.7192704677581787     │\n",
       "│ Time/Epoch                    │ 12.58967399597168      │\n",
       "│ Time/FPS                      │ 162.6730194091797      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.434619903564453     │\n",
       "│ Metrics/EpCost                │ 58.7599983215332       │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 491.0                  │\n",
       "│ Train/Entropy                 │ -0.33715200424194336   │\n",
       "│ Train/KL                      │ 0.005400057416409254   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0003329515457153     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0003329515457153     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0003329515457153     │\n",
       "│ Train/PolicyRatio/Std         │ 0.011096790432929993   │\n",
       "│ Train/LR                      │ 4.800000169780105e-06  │\n",
       "│ Train/PolicyStd               │ 0.1727568805217743     │\n",
       "│ TotalEnvSteps                 │ 1007616.0              │\n",
       "│ Loss/Loss_pi                  │ -0.008175287395715714  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.0007541663944721222 │\n",
       "│ Value/Adv                     │ -0.12506383657455444   │\n",
       "│ Loss/Loss_reward_critic       │ 0.017255563288927078   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.00367702916264534    │\n",
       "│ Value/reward                  │ 1.926735758781433      │\n",
       "│ Time/Total                    │ 6407.56689453125       │\n",
       "│ Time/Rollout                  │ 10.870346069335938     │\n",
       "│ Time/Update                   │ 1.7192704677581787     │\n",
       "│ Time/Epoch                    │ 12.58967399597168      │\n",
       "│ Time/FPS                      │ 162.6730194091797      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.390758514404297     │\n",
       "│ Metrics/EpCost                │ 58.08000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 492.0                  │\n",
       "│ Train/Entropy                 │ -0.3371264934539795    │\n",
       "│ Train/KL                      │ 0.00399436941370368    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9994579553604126     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9994579553604126     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9994579553604126     │\n",
       "│ Train/PolicyRatio/Std         │ 0.007413124665617943   │\n",
       "│ Train/LR                      │ 4.200000148557592e-06  │\n",
       "│ Train/PolicyStd               │ 0.1727619767189026     │\n",
       "│ TotalEnvSteps                 │ 1009664.0              │\n",
       "│ Loss/Loss_pi                  │ -0.008042960427701473  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00013232696801424026 │\n",
       "│ Value/Adv                     │ 0.0999256893992424     │\n",
       "│ Loss/Loss_reward_critic       │ 0.017537442967295647   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0002818796783685684  │\n",
       "│ Value/reward                  │ 2.218334436416626      │\n",
       "│ Time/Total                    │ 6420.13818359375       │\n",
       "│ Time/Rollout                  │ 10.84506607055664      │\n",
       "│ Time/Update                   │ 1.7130343914031982     │\n",
       "│ Time/Epoch                    │ 12.558151245117188     │\n",
       "│ Time/FPS                      │ 163.08132934570312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.390758514404297     │\n",
       "│ Metrics/EpCost                │ 58.08000183105469      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 492.0                  │\n",
       "│ Train/Entropy                 │ -0.3371264934539795    │\n",
       "│ Train/KL                      │ 0.00399436941370368    │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 0.9994579553604126     │\n",
       "│ Train/PolicyRatio/Min         │ 0.9994579553604126     │\n",
       "│ Train/PolicyRatio/Max         │ 0.9994579553604126     │\n",
       "│ Train/PolicyRatio/Std         │ 0.007413124665617943   │\n",
       "│ Train/LR                      │ 4.200000148557592e-06  │\n",
       "│ Train/PolicyStd               │ 0.1727619767189026     │\n",
       "│ TotalEnvSteps                 │ 1009664.0              │\n",
       "│ Loss/Loss_pi                  │ -0.008042960427701473  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.00013232696801424026 │\n",
       "│ Value/Adv                     │ 0.0999256893992424     │\n",
       "│ Loss/Loss_reward_critic       │ 0.017537442967295647   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0002818796783685684  │\n",
       "│ Value/reward                  │ 2.218334436416626      │\n",
       "│ Time/Total                    │ 6420.13818359375       │\n",
       "│ Time/Rollout                  │ 10.84506607055664      │\n",
       "│ Time/Update                   │ 1.7130343914031982     │\n",
       "│ Time/Epoch                    │ 12.558151245117188     │\n",
       "│ Time/FPS                      │ 163.08132934570312     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.333364486694336     │\n",
       "│ Metrics/EpCost                │ 57.31999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 493.0                  │\n",
       "│ Train/Entropy                 │ -0.33714836835861206   │\n",
       "│ Train/KL                      │ 0.0037242895923554897  │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0008213520050049     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0008213520050049     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0008213520050049     │\n",
       "│ Train/PolicyRatio/Std         │ 0.00730160204693675    │\n",
       "│ Train/LR                      │ 3.5999998999614036e-06 │\n",
       "│ Train/PolicyStd               │ 0.17275750637054443    │\n",
       "│ TotalEnvSteps                 │ 1011712.0              │\n",
       "│ Loss/Loss_pi                  │ -0.006773649249225855  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0012693111784756184  │\n",
       "│ Value/Adv                     │ -0.1866888850927353    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017449013888835907   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -8.842907845973969e-05 │\n",
       "│ Value/reward                  │ 2.192748785018921      │\n",
       "│ Time/Total                    │ 6432.70458984375       │\n",
       "│ Time/Rollout                  │ 10.814011573791504     │\n",
       "│ Time/Update                   │ 1.7407464981079102     │\n",
       "│ Time/Epoch                    │ 12.5548095703125       │\n",
       "│ Time/FPS                      │ 163.12474060058594     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.333364486694336     │\n",
       "│ Metrics/EpCost                │ 57.31999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 493.0                  │\n",
       "│ Train/Entropy                 │ -0.33714836835861206   │\n",
       "│ Train/KL                      │ 0.0037242895923554897  │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0008213520050049     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0008213520050049     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0008213520050049     │\n",
       "│ Train/PolicyRatio/Std         │ 0.00730160204693675    │\n",
       "│ Train/LR                      │ 3.5999998999614036e-06 │\n",
       "│ Train/PolicyStd               │ 0.17275750637054443    │\n",
       "│ TotalEnvSteps                 │ 1011712.0              │\n",
       "│ Loss/Loss_pi                  │ -0.006773649249225855  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0012693111784756184  │\n",
       "│ Value/Adv                     │ -0.1866888850927353    │\n",
       "│ Loss/Loss_reward_critic       │ 0.017449013888835907   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -8.842907845973969e-05 │\n",
       "│ Value/reward                  │ 2.192748785018921      │\n",
       "│ Time/Total                    │ 6432.70458984375       │\n",
       "│ Time/Rollout                  │ 10.814011573791504     │\n",
       "│ Time/Update                   │ 1.7407464981079102     │\n",
       "│ Time/Epoch                    │ 12.5548095703125       │\n",
       "│ Time/FPS                      │ 163.12474060058594     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.383634567260742    │\n",
       "│ Metrics/EpCost                │ 56.02000045776367     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 494.0                 │\n",
       "│ Train/Entropy                 │ -0.3372654318809509   │\n",
       "│ Train/KL                      │ 0.003459644503891468  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0001144409179688    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0001144409179688    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0001144409179688    │\n",
       "│ Train/PolicyRatio/Std         │ 0.006650225259363651  │\n",
       "│ Train/LR                      │ 3.000000106112566e-06 │\n",
       "│ Train/PolicyStd               │ 0.17273633182048798   │\n",
       "│ TotalEnvSteps                 │ 1013760.0             │\n",
       "│ Loss/Loss_pi                  │ -0.007247647736221552 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.000473998486995697 │\n",
       "│ Value/Adv                     │ 0.01901509426534176   │\n",
       "│ Loss/Loss_reward_critic       │ 0.010012397542595863  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.007436616346240044 │\n",
       "│ Value/reward                  │ 2.1981253623962402    │\n",
       "│ Time/Total                    │ 6445.28173828125      │\n",
       "│ Time/Rollout                  │ 10.861552238464355    │\n",
       "│ Time/Update                   │ 1.7036480903625488    │\n",
       "│ Time/Epoch                    │ 12.565245628356934    │\n",
       "│ Time/FPS                      │ 162.9892578125        │\n",
       "└───────────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.383634567260742    │\n",
       "│ Metrics/EpCost                │ 56.02000045776367     │\n",
       "│ Metrics/EpLen                 │ 1000.0                │\n",
       "│ Train/Epoch                   │ 494.0                 │\n",
       "│ Train/Entropy                 │ -0.3372654318809509   │\n",
       "│ Train/KL                      │ 0.003459644503891468  │\n",
       "│ Train/StopIter                │ 10.0                  │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0001144409179688    │\n",
       "│ Train/PolicyRatio/Min         │ 1.0001144409179688    │\n",
       "│ Train/PolicyRatio/Max         │ 1.0001144409179688    │\n",
       "│ Train/PolicyRatio/Std         │ 0.006650225259363651  │\n",
       "│ Train/LR                      │ 3.000000106112566e-06 │\n",
       "│ Train/PolicyStd               │ 0.17273633182048798   │\n",
       "│ TotalEnvSteps                 │ 1013760.0             │\n",
       "│ Loss/Loss_pi                  │ -0.007247647736221552 │\n",
       "│ Loss/Loss_pi/Delta            │ -0.000473998486995697 │\n",
       "│ Value/Adv                     │ 0.01901509426534176   │\n",
       "│ Loss/Loss_reward_critic       │ 0.010012397542595863  │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.007436616346240044 │\n",
       "│ Value/reward                  │ 2.1981253623962402    │\n",
       "│ Time/Total                    │ 6445.28173828125      │\n",
       "│ Time/Rollout                  │ 10.861552238464355    │\n",
       "│ Time/Update                   │ 1.7036480903625488    │\n",
       "│ Time/Epoch                    │ 12.565245628356934    │\n",
       "│ Time/FPS                      │ 162.9892578125        │\n",
       "└───────────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.3402042388916       │\n",
       "│ Metrics/EpCost                │ 57.31999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 495.0                  │\n",
       "│ Train/Entropy                 │ -0.33730942010879517   │\n",
       "│ Train/KL                      │ 0.003269294975325465   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0022854804992676     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0022854804992676     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0022854804992676     │\n",
       "│ Train/PolicyRatio/Std         │ 0.006497535854578018   │\n",
       "│ Train/LR                      │ 2.4000000848900527e-06 │\n",
       "│ Train/PolicyStd               │ 0.1727285385131836     │\n",
       "│ TotalEnvSteps                 │ 1015808.0              │\n",
       "│ Loss/Loss_pi                  │ -0.0061734942719340324 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0010741534642875195  │\n",
       "│ Value/Adv                     │ -0.06415528059005737   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014493209309875965   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004480811767280102   │\n",
       "│ Value/reward                  │ 2.2015514373779297     │\n",
       "│ Time/Total                    │ 6457.8662109375        │\n",
       "│ Time/Rollout                  │ 10.857185363769531     │\n",
       "│ Time/Update                   │ 1.7157907485961914     │\n",
       "│ Time/Epoch                    │ 12.573018074035645     │\n",
       "│ Time/FPS                      │ 162.8885040283203      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 21.3402042388916       │\n",
       "│ Metrics/EpCost                │ 57.31999969482422      │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 495.0                  │\n",
       "│ Train/Entropy                 │ -0.33730942010879517   │\n",
       "│ Train/KL                      │ 0.003269294975325465   │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0022854804992676     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0022854804992676     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0022854804992676     │\n",
       "│ Train/PolicyRatio/Std         │ 0.006497535854578018   │\n",
       "│ Train/LR                      │ 2.4000000848900527e-06 │\n",
       "│ Train/PolicyStd               │ 0.1727285385131836     │\n",
       "│ TotalEnvSteps                 │ 1015808.0              │\n",
       "│ Loss/Loss_pi                  │ -0.0061734942719340324 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0010741534642875195  │\n",
       "│ Value/Adv                     │ -0.06415528059005737   │\n",
       "│ Loss/Loss_reward_critic       │ 0.014493209309875965   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.004480811767280102   │\n",
       "│ Value/reward                  │ 2.2015514373779297     │\n",
       "│ Time/Total                    │ 6457.8662109375        │\n",
       "│ Time/Rollout                  │ 10.857185363769531     │\n",
       "│ Time/Update                   │ 1.7157907485961914     │\n",
       "│ Time/Epoch                    │ 12.573018074035645     │\n",
       "│ Time/FPS                      │ 162.8885040283203      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.71453857421875      │\n",
       "│ Metrics/EpCost                │ 58.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 496.0                  │\n",
       "│ Train/Entropy                 │ -0.3373030722141266    │\n",
       "│ Train/KL                      │ 0.0026302386540919542  │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.000497817993164      │\n",
       "│ Train/PolicyRatio/Min         │ 1.000497817993164      │\n",
       "│ Train/PolicyRatio/Max         │ 1.000497817993164      │\n",
       "│ Train/PolicyRatio/Std         │ 0.006088963709771633   │\n",
       "│ Train/LR                      │ 1.7999999499807018e-06 │\n",
       "│ Train/PolicyStd               │ 0.1727297604084015     │\n",
       "│ TotalEnvSteps                 │ 1017856.0              │\n",
       "│ Loss/Loss_pi                  │ -0.003014239715412259  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0031592545565217733  │\n",
       "│ Value/Adv                     │ -0.04701643064618111   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01618206687271595    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.001688857562839985   │\n",
       "│ Value/reward                  │ 2.0463263988494873     │\n",
       "│ Time/Total                    │ 6470.458984375         │\n",
       "│ Time/Rollout                  │ 10.825769424438477     │\n",
       "│ Time/Update                   │ 1.7556593418121338     │\n",
       "│ Time/Epoch                    │ 12.581476211547852     │\n",
       "│ Time/FPS                      │ 162.7790069580078      │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.71453857421875      │\n",
       "│ Metrics/EpCost                │ 58.779998779296875     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 496.0                  │\n",
       "│ Train/Entropy                 │ -0.3373030722141266    │\n",
       "│ Train/KL                      │ 0.0026302386540919542  │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.000497817993164      │\n",
       "│ Train/PolicyRatio/Min         │ 1.000497817993164      │\n",
       "│ Train/PolicyRatio/Max         │ 1.000497817993164      │\n",
       "│ Train/PolicyRatio/Std         │ 0.006088963709771633   │\n",
       "│ Train/LR                      │ 1.7999999499807018e-06 │\n",
       "│ Train/PolicyStd               │ 0.1727297604084015     │\n",
       "│ TotalEnvSteps                 │ 1017856.0              │\n",
       "│ Loss/Loss_pi                  │ -0.003014239715412259  │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0031592545565217733  │\n",
       "│ Value/Adv                     │ -0.04701643064618111   │\n",
       "│ Loss/Loss_reward_critic       │ 0.01618206687271595    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.001688857562839985   │\n",
       "│ Value/reward                  │ 2.0463263988494873     │\n",
       "│ Time/Total                    │ 6470.458984375         │\n",
       "│ Time/Rollout                  │ 10.825769424438477     │\n",
       "│ Time/Update                   │ 1.7556593418121338     │\n",
       "│ Time/Epoch                    │ 12.581476211547852     │\n",
       "│ Time/FPS                      │ 162.7790069580078      │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.4188289642334        │\n",
       "│ Metrics/EpCost                │ 57.2400016784668        │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 497.0                   │\n",
       "│ Train/Entropy                 │ -0.33711984753608704    │\n",
       "│ Train/KL                      │ 0.0019809724763035774   │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.001267433166504       │\n",
       "│ Train/PolicyRatio/Min         │ 1.001267433166504       │\n",
       "│ Train/PolicyRatio/Max         │ 1.001267433166504       │\n",
       "│ Train/PolicyRatio/Std         │ 0.005104965530335903    │\n",
       "│ Train/LR                      │ 1.2000000424450263e-06  │\n",
       "│ Train/PolicyStd               │ 0.17276141047477722     │\n",
       "│ TotalEnvSteps                 │ 1019904.0               │\n",
       "│ Loss/Loss_pi                  │ -0.0031950667034834623  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00018082698807120323 │\n",
       "│ Value/Adv                     │ 0.1142880916595459      │\n",
       "│ Loss/Loss_reward_critic       │ 0.018497150391340256    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0023150835186243057   │\n",
       "│ Value/reward                  │ 2.0271575450897217      │\n",
       "│ Time/Total                    │ 6483.0322265625         │\n",
       "│ Time/Rollout                  │ 10.8436279296875        │\n",
       "│ Time/Update                   │ 1.718303918838501       │\n",
       "│ Time/Epoch                    │ 12.56197738647461       │\n",
       "│ Time/FPS                      │ 163.0316619873047       │\n",
       "└───────────────────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.4188289642334        │\n",
       "│ Metrics/EpCost                │ 57.2400016784668        │\n",
       "│ Metrics/EpLen                 │ 1000.0                  │\n",
       "│ Train/Epoch                   │ 497.0                   │\n",
       "│ Train/Entropy                 │ -0.33711984753608704    │\n",
       "│ Train/KL                      │ 0.0019809724763035774   │\n",
       "│ Train/StopIter                │ 10.0                    │\n",
       "│ Train/PolicyRatio/Mean        │ 1.001267433166504       │\n",
       "│ Train/PolicyRatio/Min         │ 1.001267433166504       │\n",
       "│ Train/PolicyRatio/Max         │ 1.001267433166504       │\n",
       "│ Train/PolicyRatio/Std         │ 0.005104965530335903    │\n",
       "│ Train/LR                      │ 1.2000000424450263e-06  │\n",
       "│ Train/PolicyStd               │ 0.17276141047477722     │\n",
       "│ TotalEnvSteps                 │ 1019904.0               │\n",
       "│ Loss/Loss_pi                  │ -0.0031950667034834623  │\n",
       "│ Loss/Loss_pi/Delta            │ -0.00018082698807120323 │\n",
       "│ Value/Adv                     │ 0.1142880916595459      │\n",
       "│ Loss/Loss_reward_critic       │ 0.018497150391340256    │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.0023150835186243057   │\n",
       "│ Value/reward                  │ 2.0271575450897217      │\n",
       "│ Time/Total                    │ 6483.0322265625         │\n",
       "│ Time/Rollout                  │ 10.8436279296875        │\n",
       "│ Time/Update                   │ 1.718303918838501       │\n",
       "│ Time/Epoch                    │ 12.56197738647461       │\n",
       "│ Time/FPS                      │ 163.0316619873047       │\n",
       "└───────────────────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.491483688354492     │\n",
       "│ Metrics/EpCost                │ 54.540000915527344     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 498.0                  │\n",
       "│ Train/Entropy                 │ -0.3370705544948578    │\n",
       "│ Train/KL                      │ 0.0003786672605201602  │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0000019073486328     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0000019073486328     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0000019073486328     │\n",
       "│ Train/PolicyRatio/Std         │ 0.0021999352611601353  │\n",
       "│ Train/LR                      │ 6.000000212225132e-07  │\n",
       "│ Train/PolicyStd               │ 0.17276985943317413    │\n",
       "│ TotalEnvSteps                 │ 1021952.0              │\n",
       "│ Loss/Loss_pi                  │ -0.0021027126349508762 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.001092354068532586   │\n",
       "│ Value/Adv                     │ 0.03177139163017273    │\n",
       "│ Loss/Loss_reward_critic       │ 0.012124128639698029   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.006373021751642227  │\n",
       "│ Value/reward                  │ 2.200991630554199      │\n",
       "│ Time/Total                    │ 6495.62744140625       │\n",
       "│ Time/Rollout                  │ 10.882546424865723     │\n",
       "│ Time/Update                   │ 1.699756383895874      │\n",
       "│ Time/Epoch                    │ 12.582367897033691     │\n",
       "│ Time/FPS                      │ 162.76747131347656     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.491483688354492     │\n",
       "│ Metrics/EpCost                │ 54.540000915527344     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 498.0                  │\n",
       "│ Train/Entropy                 │ -0.3370705544948578    │\n",
       "│ Train/KL                      │ 0.0003786672605201602  │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0000019073486328     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0000019073486328     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0000019073486328     │\n",
       "│ Train/PolicyRatio/Std         │ 0.0021999352611601353  │\n",
       "│ Train/LR                      │ 6.000000212225132e-07  │\n",
       "│ Train/PolicyStd               │ 0.17276985943317413    │\n",
       "│ TotalEnvSteps                 │ 1021952.0              │\n",
       "│ Loss/Loss_pi                  │ -0.0021027126349508762 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.001092354068532586   │\n",
       "│ Value/Adv                     │ 0.03177139163017273    │\n",
       "│ Loss/Loss_reward_critic       │ 0.012124128639698029   │\n",
       "│ Loss/Loss_reward_critic/Delta │ -0.006373021751642227  │\n",
       "│ Value/reward                  │ 2.200991630554199      │\n",
       "│ Time/Total                    │ 6495.62744140625       │\n",
       "│ Time/Rollout                  │ 10.882546424865723     │\n",
       "│ Time/Update                   │ 1.699756383895874      │\n",
       "│ Time/Epoch                    │ 12.582367897033691     │\n",
       "│ Time/FPS                      │ 162.76747131347656     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Warning: trajectory cut off when rollout by epoch at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.0</span><span style=\"color: #008000; text-decoration-color: #008000\"> steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mWarning: trajectory cut off when rollout by epoch at \u001b[0m\u001b[1;36m48.0\u001b[0m\u001b[32m steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Metrics                       </span>┃<span style=\"font-weight: bold\"> Value                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.521821975708008     │\n",
       "│ Metrics/EpCost                │ 53.099998474121094     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 499.0                  │\n",
       "│ Train/Entropy                 │ -0.3371024429798126    │\n",
       "│ Train/KL                      │ 0.00017770612612366676 │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0000972747802734     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0000972747802734     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0000972747802734     │\n",
       "│ Train/PolicyRatio/Std         │ 0.0012749311281368136  │\n",
       "│ Train/LR                      │ 0.0                    │\n",
       "│ Train/PolicyStd               │ 0.17276446521282196    │\n",
       "│ TotalEnvSteps                 │ 1024000.0              │\n",
       "│ Loss/Loss_pi                  │ -0.0010132297175005078 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0010894829174503684  │\n",
       "│ Value/Adv                     │ 0.05211067199707031    │\n",
       "│ Loss/Loss_reward_critic       │ 0.020531201735138893   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.008407073095440865   │\n",
       "│ Value/reward                  │ 2.149447441101074      │\n",
       "│ Time/Total                    │ 6508.22265625          │\n",
       "│ Time/Rollout                  │ 10.829681396484375     │\n",
       "│ Time/Update                   │ 1.7539167404174805     │\n",
       "│ Time/Epoch                    │ 12.583648681640625     │\n",
       "│ Time/FPS                      │ 162.75088500976562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mMetrics                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValue                 \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Metrics/EpRet                 │ 20.521821975708008     │\n",
       "│ Metrics/EpCost                │ 53.099998474121094     │\n",
       "│ Metrics/EpLen                 │ 1000.0                 │\n",
       "│ Train/Epoch                   │ 499.0                  │\n",
       "│ Train/Entropy                 │ -0.3371024429798126    │\n",
       "│ Train/KL                      │ 0.00017770612612366676 │\n",
       "│ Train/StopIter                │ 10.0                   │\n",
       "│ Train/PolicyRatio/Mean        │ 1.0000972747802734     │\n",
       "│ Train/PolicyRatio/Min         │ 1.0000972747802734     │\n",
       "│ Train/PolicyRatio/Max         │ 1.0000972747802734     │\n",
       "│ Train/PolicyRatio/Std         │ 0.0012749311281368136  │\n",
       "│ Train/LR                      │ 0.0                    │\n",
       "│ Train/PolicyStd               │ 0.17276446521282196    │\n",
       "│ TotalEnvSteps                 │ 1024000.0              │\n",
       "│ Loss/Loss_pi                  │ -0.0010132297175005078 │\n",
       "│ Loss/Loss_pi/Delta            │ 0.0010894829174503684  │\n",
       "│ Value/Adv                     │ 0.05211067199707031    │\n",
       "│ Loss/Loss_reward_critic       │ 0.020531201735138893   │\n",
       "│ Loss/Loss_reward_critic/Delta │ 0.008407073095440865   │\n",
       "│ Value/reward                  │ 2.149447441101074      │\n",
       "│ Time/Total                    │ 6508.22265625          │\n",
       "│ Time/Rollout                  │ 10.829681396484375     │\n",
       "│ Time/Update                   │ 1.7539167404174805     │\n",
       "│ Time/Epoch                    │ 12.583648681640625     │\n",
       "│ Time/FPS                      │ 162.75088500976562     │\n",
       "└───────────────────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './results/PPO_SafetyPointGoal1-v0/Rewards.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rewards, costs\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Train PPO and CPO\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m ppo_rewards, ppo_costs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPPO\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_cfgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m cpo_rewards, cpo_costs \u001b[38;5;241m=\u001b[39m train_agent(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCPO\u001b[39m\u001b[38;5;124m'\u001b[39m, env_id, custom_cfgs)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Plotting results\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 39\u001b[0m, in \u001b[0;36mtrain_agent\u001b[0;34m(algo_name, env_id, custom_cfgs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Access logged metrics (assuming logger stores metrics in results/)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m log_dir \u001b[38;5;241m=\u001b[39m custom_cfgs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogger_cfgs\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_dir\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00malgo_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 39\u001b[0m rewards \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlog_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/Rewards.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust based on actual log file\u001b[39;00m\n\u001b[1;32m     40\u001b[0m costs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlog_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/Costs.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)      \u001b[38;5;66;03m# Adjust based on actual log file\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rewards, costs\n",
      "File \u001b[0;32m~/safe_RL/.venv/lib/python3.10/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './results/PPO_SafetyPointGoal1-v0/Rewards.npy'"
     ]
    }
   ],
   "source": [
    "import omnisafe\n",
    "import safety_gymnasium\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Configuration for training\n",
    "custom_cfgs = {\n",
    "    'train_cfgs': {\n",
    "        'total_steps': 1024000,  # Total training steps\n",
    "        'vector_env_nums': 1,    # Number of parallel environments\n",
    "        'parallel': 1,           # Number of parallel processes\n",
    "        'torch_threads': 1,      # Number of PyTorch threads\n",
    "    },\n",
    "    'algo_cfgs': {\n",
    "        'steps_per_epoch': 2048, # Steps per epoch\n",
    "        'update_iters': 10,      # Number of policy updates per epoch\n",
    "    },\n",
    "    'logger_cfgs': {\n",
    "        'use_wandb': False,      # Disable Weights & Biases (use local logging)\n",
    "        'save_model_freq': 10,   # Save model every 10 epochs\n",
    "        'log_dir': './results/', # Directory for logs\n",
    "    },\n",
    "}\n",
    "\n",
    "# Environment setup\n",
    "env_id = 'SafetyPointGoal1-v0'\n",
    "\n",
    "# Function to train an agent and collect metrics\n",
    "def train_agent(algo_name, env_id, custom_cfgs):\n",
    "    # Initialize agent\n",
    "    agent = omnisafe.Agent(algo_name, env_id=env_id, custom_cfgs=custom_cfgs)\n",
    "    \n",
    "    # Train the agent\n",
    "    agent.learn()\n",
    "    \n",
    "    # Access logged metrics (assuming logger stores metrics in results/)\n",
    "    log_dir = custom_cfgs['logger_cfgs']['log_dir'] + f'{algo_name}_{env_id}'\n",
    "    rewards = np.load(f'{log_dir}/Rewards.npy')  # Adjust based on actual log file\n",
    "    costs = np.load(f'{log_dir}/Costs.npy')      # Adjust based on actual log file\n",
    "    return rewards, costs\n",
    "\n",
    "# Train PPO and CPO\n",
    "ppo_rewards, ppo_costs = train_agent('PPO', env_id, custom_cfgs)\n",
    "cpo_rewards, cpo_costs = train_agent('CPO', env_id, custom_cfgs)\n",
    "\n",
    "# Plotting results\n",
    "epochs = np.arange(len(ppo_rewards))  # Assuming rewards/costs are logged per epoch\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot rewards\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, ppo_rewards, label='PPO Reward', color='blue')\n",
    "plt.plot(epochs, cpo_rewards, label='CPO Reward', color='orange')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Episodic Reward')\n",
    "plt.title('Reward Comparison')\n",
    "plt.legend()\n",
    "\n",
    "# Plot costs\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, ppo_costs, label='PPO Cost', color='blue')\n",
    "plt.plot(epochs, cpo_costs, label='CPO Cost', color='orange')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Episodic Cost')\n",
    "plt.title('Cost Comparison')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/ppo_vs_cpo_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transition vers le monde réel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import safety_gymnasium\n",
    "import gymnasium\n",
    "import numpy as np\n",
    "\n",
    "# Wrapper pour simuler un environnement se rapprochant du monde réel\n",
    "\n",
    "class RealWorldWrapper(gymnasium.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.action_delay = 2  # Nombre d'étapes de retard pour les actions\n",
    "        self.action_buffer = []\n",
    "        self.observation_noise_std = 0.05  # Écart-type pour le bruit des observations\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        self.action_buffer = [np.zeros(self.action_space.shape)] * self.action_delay\n",
    "        obs, info = self.env.reset(**kwargs)\n",
    "        \n",
    "        return self._add_noise(obs), info\n",
    "\n",
    "    def step(self, action):\n",
    "        self.action_buffer.append(action)\n",
    "        delayed_action = self.action_buffer.pop(0)  # Utiliser l'action la plus ancienne\n",
    "    \n",
    "        self.env.unwrapped.data.xfrc_applied[0] = np.random.normal(0, 0.1, size=6) # Ajouter une force aléatoire\n",
    "        obs, reward, cost, terminated, truncated, info = self.env.step(delayed_action)\n",
    "        noisy_obs = self._add_noise(obs)\n",
    "\n",
    "        return noisy_obs, reward, cost, terminated, truncated, info\n",
    "\n",
    "    def _add_noise(self, obs):\n",
    "        noise = np.random.normal(0, self.observation_noise_std, size=obs.shape)\n",
    "        return obs + noise\n",
    "\n",
    "# Créer l'environnement\n",
    "env_id = 'SafetyPointGoal1-v0'\n",
    "base_env = safety_gymnasium.make(env_id)\n",
    "real_world_env = RealWorldWrapper(base_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
